Namespace(mode=['alpaca'], base_model='meta-llama/Llama-2-13b-hf', template_name='barebone', total_bsz=64, epoch=3, lr=2e-05, data_path='', task_name='dolly', tuned_dir='./cache')
num gpus:  8
Running 1/1: deepspeed --num_gpus=8 train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True
        --model_name_or_path meta-llama/Llama-2-13b-hf --data_path ../data/stanford_alpaca/dolly_data.json
        --output_dir /fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned
        --num_train_epochs 3
        --per_device_train_batch_size 10
        --per_device_eval_batch_size 4
        --gradient_accumulation_steps 1
        --gradient_checkpointing=True
        --evaluation_strategy=no
        --save_strategy=steps
        --save_steps 500
        --save_total_limit 1
        --learning_rate 2e-6
        --weight_decay 0.
        --report_to tensorboard
        --warmup_ratio 0.03
        --lr_scheduler_type=cosine
        --logging_steps 1
['deepspeed', '--num_gpus=8', 'train.py', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:21,817] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-08 15:45:28,778] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-08-08 15:45:28,778] [INFO] [runner.py:568:main] cmd = /data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True --model_name_or_path meta-llama/Llama-2-13b-hf --data_path ../data/stanford_alpaca/dolly_data.json --output_dir /fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned --num_train_epochs 3 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --gradient_checkpointing=True --evaluation_strategy=no --save_strategy=steps --save_steps 500 --save_total_limit 1 --learning_rate 2e-6 --weight_decay 0. --report_to tensorboard --warmup_ratio 0.03 --lr_scheduler_type=cosine --logging_steps 1
[2024-08-08 15:45:31,584] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-08 15:45:35,502] [INFO] [launch.py:139:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2024-08-08 15:45:35,502] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-08-08 15:45:35,502] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-08 15:45:35,502] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-08 15:45:35,502] [INFO] [launch.py:164:main] dist_world_size=8
[2024-08-08 15:45:35,502] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-08-08 15:45:35,503] [INFO] [launch.py:256:main] process 679468 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=0', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,503] [INFO] [launch.py:256:main] process 679469 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=1', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,504] [INFO] [launch.py:256:main] process 679470 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=2', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,505] [INFO] [launch.py:256:main] process 679471 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=3', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,505] [INFO] [launch.py:256:main] process 679474 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=4', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,506] [INFO] [launch.py:256:main] process 679475 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=5', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,506] [INFO] [launch.py:256:main] process 679476 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=6', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-08-08 15:45:35,507] [INFO] [launch.py:256:main] process 679477 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=7', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-13b-hf', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-13b_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-08-08 15:45:51,492] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-08 15:45:51,759] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,776] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,841] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,858] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,878] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-08 15:45:51,887] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-08 15:45:52,252] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-08 15:45:52,508] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-08 15:45:52,509] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-08 15:45:52,509] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-08 15:45:52,565] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-08 15:45:52,583] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-08 15:45:52,585] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-08 15:45:52,594] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-08 15:45:52,597] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 413.49it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1405.13it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1293.07it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1168.11it/s]
Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1786.84it/s]
Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2071.26it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1413.97it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1435.59it/s]
[2024-08-08 15:46:03,787] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 363, num_elems = 13.02B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:48<01:37, 48.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:00<00:33, 33.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:01<00:33, 33.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 31.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:30<00:00, 30.14s/it]
Loading checkpoint shards:  67%|██████▋   | 2/3 [01:36<00:47, 47.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:12<00:00, 42.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [02:12<00:00, 44.13s/it]
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
[rank4]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank1]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...

Detected CUDA files, patching ldflags
Emitting ninja build file /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[rank7]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank3]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank5]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank6]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank2]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank0]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/adam -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/TH -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_90,code=compute_90 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -std=c++17 -c /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o 
[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/includes -I/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/adam -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/TH -isystem /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /data/home/yunyun/miniconda3/envs/newtorch2/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o 
[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 33.844807147979736 secondsTime to load fused_adam op: 33.7694525718689 secondsTime to load fused_adam op: 33.570003509521484 secondsTime to load fused_adam op: 34.09543323516846 secondsTime to load fused_adam op: 33.515052318573 secondsTime to load fused_adam op: 33.71453809738159 seconds


Time to load fused_adam op: 33.40932321548462 seconds


Time to load fused_adam op: 34.095417737960815 seconds

Parameter Offload: Total persistent parameters: 414720 in 81 params
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/564 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/564 [00:09<1:26:49,  9.25s/it]                                                 {'loss': 1.4362, 'grad_norm': 4.107588700014387, 'learning_rate': 0.0, 'epoch': 0.01}
  0%|          | 1/564 [00:09<1:26:49,  9.25s/it]  0%|          | 2/564 [00:10<44:30,  4.75s/it]                                                 {'loss': 1.5126, 'grad_norm': 3.9020382334661425, 'learning_rate': 4.89301084236452e-07, 'epoch': 0.01}
  0%|          | 2/564 [00:10<44:30,  4.75s/it]  1%|          | 3/564 [00:12<30:37,  3.28s/it]                                               {'loss': 1.4851, 'grad_norm': 5.045577807065397, 'learning_rate': 7.755238700769802e-07, 'epoch': 0.02}
  1%|          | 3/564 [00:12<30:37,  3.28s/it]  1%|          | 4/564 [00:13<24:05,  2.58s/it]                                               {'loss': 1.4573, 'grad_norm': 3.9627988549477835, 'learning_rate': 9.78602168472904e-07, 'epoch': 0.02}
  1%|          | 4/564 [00:13<24:05,  2.58s/it]  1%|          | 5/564 [00:15<20:27,  2.20s/it]                                               {'loss': 1.5547, 'grad_norm': 4.251213620309498, 'learning_rate': 1.1361219343474658e-06, 'epoch': 0.03}
  1%|          | 5/564 [00:15<20:27,  2.20s/it]  1%|          | 6/564 [00:16<18:19,  1.97s/it]                                               {'loss': 1.3287, 'grad_norm': 4.764509653927688, 'learning_rate': 1.264824954313432e-06, 'epoch': 0.03}
  1%|          | 6/564 [00:16<18:19,  1.97s/it]  1%|          | 7/564 [00:18<16:55,  1.82s/it]                                               {'loss': 1.5423, 'grad_norm': 4.775768369598442, 'learning_rate': 1.373641807199326e-06, 'epoch': 0.04}
  1%|          | 7/564 [00:18<16:55,  1.82s/it]  1%|▏         | 8/564 [00:20<16:05,  1.74s/it]                                               {'loss': 1.3942, 'grad_norm': 4.247275500039209, 'learning_rate': 1.4679032527093559e-06, 'epoch': 0.04}
  1%|▏         | 8/564 [00:20<16:05,  1.74s/it]  2%|▏         | 9/564 [00:21<15:30,  1.68s/it]                                               {'loss': 1.4229, 'grad_norm': 3.11488876186163, 'learning_rate': 1.5510477401539603e-06, 'epoch': 0.05}
  2%|▏         | 9/564 [00:21<15:30,  1.68s/it]  2%|▏         | 10/564 [00:23<15:03,  1.63s/it]                                                {'loss': 1.5231, 'grad_norm': 2.5656756421485825, 'learning_rate': 1.625423018583918e-06, 'epoch': 0.05}
  2%|▏         | 10/564 [00:23<15:03,  1.63s/it]  2%|▏         | 11/564 [00:24<14:39,  1.59s/it]                                                {'loss': 1.4815, 'grad_norm': 3.237437202456215, 'learning_rate': 1.6927036418410939e-06, 'epoch': 0.06}
  2%|▏         | 11/564 [00:24<14:39,  1.59s/it]  2%|▏         | 12/564 [00:26<14:25,  1.57s/it]                                                {'loss': 1.3936, 'grad_norm': 2.7820973476321496, 'learning_rate': 1.7541260385498841e-06, 'epoch': 0.06}
  2%|▏         | 12/564 [00:26<14:25,  1.57s/it]  2%|▏         | 13/564 [00:27<14:17,  1.56s/it]                                                {'loss': 1.4649, 'grad_norm': 2.3409029173173757, 'learning_rate': 1.8106291662380673e-06, 'epoch': 0.07}
  2%|▏         | 13/564 [00:27<14:17,  1.56s/it]  2%|▏         | 14/564 [00:29<14:14,  1.55s/it]                                                {'loss': 1.3874, 'grad_norm': 2.10773340433994, 'learning_rate': 1.862942891435778e-06, 'epoch': 0.07}
  2%|▏         | 14/564 [00:29<14:14,  1.55s/it]  3%|▎         | 15/564 [00:30<14:06,  1.54s/it]                                                {'loss': 1.3964, 'grad_norm': 1.7482107442238435, 'learning_rate': 1.911645804424446e-06, 'epoch': 0.08}
  3%|▎         | 15/564 [00:30<14:06,  1.54s/it]  3%|▎         | 16/564 [00:32<14:01,  1.54s/it]                                                {'loss': 1.3116, 'grad_norm': 5.109610862752514, 'learning_rate': 1.957204336945808e-06, 'epoch': 0.09}
  3%|▎         | 16/564 [00:32<14:01,  1.54s/it]  3%|▎         | 17/564 [00:33<13:57,  1.53s/it]                                                {'loss': 1.439, 'grad_norm': 1.9709144272970585, 'learning_rate': 2e-06, 'epoch': 0.09}
  3%|▎         | 17/564 [00:33<13:57,  1.53s/it]  3%|▎         | 18/564 [00:35<14:02,  1.54s/it]                                                {'loss': 1.2869, 'grad_norm': 2.0639586120776294, 'learning_rate': 2e-06, 'epoch': 0.1}
  3%|▎         | 18/564 [00:35<14:02,  1.54s/it]  3%|▎         | 19/564 [00:36<14:01,  1.54s/it]                                                {'loss': 1.2377, 'grad_norm': 2.2705836195144404, 'learning_rate': 1.996343692870201e-06, 'epoch': 0.1}
  3%|▎         | 19/564 [00:36<14:01,  1.54s/it]  4%|▎         | 20/564 [00:38<14:02,  1.55s/it]                                                {'loss': 1.3435, 'grad_norm': 1.788659713702984, 'learning_rate': 1.992687385740402e-06, 'epoch': 0.11}
  4%|▎         | 20/564 [00:38<14:02,  1.55s/it]  4%|▎         | 21/564 [00:39<13:52,  1.53s/it]                                                {'loss': 1.354, 'grad_norm': 1.7766364307083318, 'learning_rate': 1.9890310786106034e-06, 'epoch': 0.11}
  4%|▎         | 21/564 [00:39<13:52,  1.53s/it]  4%|▍         | 22/564 [00:41<13:51,  1.53s/it]                                                {'loss': 1.4052, 'grad_norm': 1.6956568844952493, 'learning_rate': 1.9853747714808044e-06, 'epoch': 0.12}
  4%|▍         | 22/564 [00:41<13:51,  1.53s/it]  4%|▍         | 23/564 [00:42<13:53,  1.54s/it]                                                {'loss': 1.3477, 'grad_norm': 1.83710191298563, 'learning_rate': 1.9817184643510055e-06, 'epoch': 0.12}
  4%|▍         | 23/564 [00:42<13:53,  1.54s/it]  4%|▍         | 24/564 [00:44<13:51,  1.54s/it]                                                {'loss': 1.5269, 'grad_norm': 1.8238496045306727, 'learning_rate': 1.9780621572212065e-06, 'epoch': 0.13}
  4%|▍         | 24/564 [00:44<13:51,  1.54s/it]  4%|▍         | 25/564 [00:46<13:49,  1.54s/it]                                                {'loss': 1.4525, 'grad_norm': 1.6510476560414422, 'learning_rate': 1.9744058500914075e-06, 'epoch': 0.13}
  4%|▍         | 25/564 [00:46<13:49,  1.54s/it]  5%|▍         | 26/564 [00:47<13:44,  1.53s/it]                                                {'loss': 1.3009, 'grad_norm': 1.7820163101952025, 'learning_rate': 1.970749542961609e-06, 'epoch': 0.14}
  5%|▍         | 26/564 [00:47<13:44,  1.53s/it]  5%|▍         | 27/564 [00:49<13:41,  1.53s/it]                                                {'loss': 1.392, 'grad_norm': 1.8903577516838157, 'learning_rate': 1.9670932358318095e-06, 'epoch': 0.14}
  5%|▍         | 27/564 [00:49<13:41,  1.53s/it]  5%|▍         | 28/564 [00:50<13:39,  1.53s/it]                                                {'loss': 1.2998, 'grad_norm': 1.5023698521226028, 'learning_rate': 1.963436928702011e-06, 'epoch': 0.15}
  5%|▍         | 28/564 [00:50<13:39,  1.53s/it]  5%|▌         | 29/564 [00:52<13:35,  1.52s/it]                                                {'loss': 1.4792, 'grad_norm': 2.1410448733778997, 'learning_rate': 1.959780621572212e-06, 'epoch': 0.15}
  5%|▌         | 29/564 [00:52<13:35,  1.52s/it]  5%|▌         | 30/564 [00:53<13:42,  1.54s/it]                                                {'loss': 1.2837, 'grad_norm': 1.8213171050406098, 'learning_rate': 1.956124314442413e-06, 'epoch': 0.16}
  5%|▌         | 30/564 [00:53<13:42,  1.54s/it]  5%|▌         | 31/564 [00:55<13:43,  1.54s/it]                                                {'loss': 1.4293, 'grad_norm': 2.174163892121194, 'learning_rate': 1.952468007312614e-06, 'epoch': 0.16}
  5%|▌         | 31/564 [00:55<13:43,  1.54s/it]  6%|▌         | 32/564 [00:56<13:43,  1.55s/it]                                                {'loss': 1.4119, 'grad_norm': 1.6950807933893453, 'learning_rate': 1.948811700182815e-06, 'epoch': 0.17}
  6%|▌         | 32/564 [00:56<13:43,  1.55s/it]  6%|▌         | 33/564 [00:58<13:32,  1.53s/it]                                                {'loss': 1.428, 'grad_norm': 1.7576695918758367, 'learning_rate': 1.9451553930530165e-06, 'epoch': 0.18}
  6%|▌         | 33/564 [00:58<13:32,  1.53s/it]  6%|▌         | 34/564 [00:59<13:34,  1.54s/it]                                                {'loss': 1.4427, 'grad_norm': 2.0039754928321316, 'learning_rate': 1.9414990859232176e-06, 'epoch': 0.18}
  6%|▌         | 34/564 [00:59<13:34,  1.54s/it]  6%|▌         | 35/564 [01:01<13:34,  1.54s/it]                                                {'loss': 1.3462, 'grad_norm': 1.9124717587116329, 'learning_rate': 1.9378427787934186e-06, 'epoch': 0.19}
  6%|▌         | 35/564 [01:01<13:34,  1.54s/it]  6%|▋         | 36/564 [01:02<13:34,  1.54s/it]                                                {'loss': 1.3039, 'grad_norm': 1.745973631086547, 'learning_rate': 1.9341864716636196e-06, 'epoch': 0.19}
  6%|▋         | 36/564 [01:02<13:34,  1.54s/it]  7%|▋         | 37/564 [01:04<14:30,  1.65s/it]                                                {'loss': 1.4639, 'grad_norm': 1.8747552248565111, 'learning_rate': 1.9305301645338206e-06, 'epoch': 0.2}
  7%|▋         | 37/564 [01:04<14:30,  1.65s/it]  7%|▋         | 38/564 [01:06<14:07,  1.61s/it]                                                {'loss': 1.3975, 'grad_norm': 1.797082273113922, 'learning_rate': 1.9268738574040217e-06, 'epoch': 0.2}
  7%|▋         | 38/564 [01:06<14:07,  1.61s/it]  7%|▋         | 39/564 [01:07<13:49,  1.58s/it]                                                {'loss': 1.2389, 'grad_norm': 1.8491413446606388, 'learning_rate': 1.923217550274223e-06, 'epoch': 0.21}
  7%|▋         | 39/564 [01:07<13:49,  1.58s/it]  7%|▋         | 40/564 [01:09<13:44,  1.57s/it]                                                {'loss': 1.2997, 'grad_norm': 1.8781985577977733, 'learning_rate': 1.919561243144424e-06, 'epoch': 0.21}
  7%|▋         | 40/564 [01:09<13:44,  1.57s/it]  7%|▋         | 41/564 [01:11<13:37,  1.56s/it]                                                {'loss': 1.4972, 'grad_norm': 1.8458994077837725, 'learning_rate': 1.915904936014625e-06, 'epoch': 0.22}
  7%|▋         | 41/564 [01:11<13:37,  1.56s/it]  7%|▋         | 42/564 [01:12<13:25,  1.54s/it]                                                {'loss': 1.4272, 'grad_norm': 1.69624636052329, 'learning_rate': 1.912248628884826e-06, 'epoch': 0.22}
  7%|▋         | 42/564 [01:12<13:25,  1.54s/it]  8%|▊         | 43/564 [01:14<13:32,  1.56s/it]                                                {'loss': 1.3214, 'grad_norm': 2.0579129027261347, 'learning_rate': 1.908592321755027e-06, 'epoch': 0.23}
  8%|▊         | 43/564 [01:14<13:32,  1.56s/it]  8%|▊         | 44/564 [01:15<13:32,  1.56s/it]                                                {'loss': 1.1653, 'grad_norm': 1.9332933854913577, 'learning_rate': 1.9049360146252284e-06, 'epoch': 0.23}
  8%|▊         | 44/564 [01:15<13:32,  1.56s/it]  8%|▊         | 45/564 [01:17<13:28,  1.56s/it]                                                {'loss': 1.5117, 'grad_norm': 1.9046780296531793, 'learning_rate': 1.9012797074954294e-06, 'epoch': 0.24}
  8%|▊         | 45/564 [01:17<13:28,  1.56s/it]  8%|▊         | 46/564 [01:18<13:24,  1.55s/it]                                                {'loss': 1.3468, 'grad_norm': 1.7603960873773994, 'learning_rate': 1.8976234003656307e-06, 'epoch': 0.24}
  8%|▊         | 46/564 [01:18<13:24,  1.55s/it]  8%|▊         | 47/564 [01:20<13:25,  1.56s/it]                                                {'loss': 1.5393, 'grad_norm': 1.6334849309143813, 'learning_rate': 1.8939670932358317e-06, 'epoch': 0.25}
  8%|▊         | 47/564 [01:20<13:25,  1.56s/it]  9%|▊         | 48/564 [01:21<13:21,  1.55s/it]                                                {'loss': 1.3251, 'grad_norm': 2.174620721534732, 'learning_rate': 1.8903107861060327e-06, 'epoch': 0.26}
  9%|▊         | 48/564 [01:21<13:21,  1.55s/it]  9%|▊         | 49/564 [01:23<13:23,  1.56s/it]                                                {'loss': 1.2682, 'grad_norm': 1.6925467758119013, 'learning_rate': 1.886654478976234e-06, 'epoch': 0.26}
  9%|▊         | 49/564 [01:23<13:23,  1.56s/it]  9%|▉         | 50/564 [01:25<13:22,  1.56s/it]                                                {'loss': 1.3423, 'grad_norm': 3.266955110603436, 'learning_rate': 1.882998171846435e-06, 'epoch': 0.27}
  9%|▉         | 50/564 [01:25<13:22,  1.56s/it]  9%|▉         | 51/564 [01:26<13:18,  1.56s/it]                                                {'loss': 1.3188, 'grad_norm': 1.9673188123299352, 'learning_rate': 1.8793418647166362e-06, 'epoch': 0.27}
  9%|▉         | 51/564 [01:26<13:18,  1.56s/it]  9%|▉         | 52/564 [01:28<13:16,  1.56s/it]                                                {'loss': 1.3647, 'grad_norm': 1.8265144520980152, 'learning_rate': 1.875685557586837e-06, 'epoch': 0.28}
  9%|▉         | 52/564 [01:28<13:16,  1.56s/it]  9%|▉         | 53/564 [01:29<13:14,  1.55s/it]                                                {'loss': 1.1561, 'grad_norm': 1.8902574319941683, 'learning_rate': 1.8720292504570383e-06, 'epoch': 0.28}
  9%|▉         | 53/564 [01:29<13:14,  1.55s/it] 10%|▉         | 54/564 [01:31<13:10,  1.55s/it]                                                {'loss': 1.2419, 'grad_norm': 1.6107711125392397, 'learning_rate': 1.8683729433272395e-06, 'epoch': 0.29}
 10%|▉         | 54/564 [01:31<13:10,  1.55s/it] 10%|▉         | 55/564 [01:32<13:08,  1.55s/it]                                                {'loss': 1.2611, 'grad_norm': 1.8193222079580036, 'learning_rate': 1.8647166361974405e-06, 'epoch': 0.29}
 10%|▉         | 55/564 [01:32<13:08,  1.55s/it] 10%|▉         | 56/564 [01:34<13:10,  1.56s/it]                                                {'loss': 1.1128, 'grad_norm': 1.6682525445892304, 'learning_rate': 1.8610603290676416e-06, 'epoch': 0.3}
 10%|▉         | 56/564 [01:34<13:10,  1.56s/it] 10%|█         | 57/564 [01:35<13:07,  1.55s/it]                                                {'loss': 1.3382, 'grad_norm': 1.7660520287794226, 'learning_rate': 1.8574040219378426e-06, 'epoch': 0.3}
 10%|█         | 57/564 [01:35<13:07,  1.55s/it] 10%|█         | 58/564 [01:37<13:03,  1.55s/it]                                                {'loss': 1.4291, 'grad_norm': 1.7483745211665733, 'learning_rate': 1.8537477148080438e-06, 'epoch': 0.31}
 10%|█         | 58/564 [01:37<13:03,  1.55s/it] 10%|█         | 59/564 [01:38<12:57,  1.54s/it]                                                {'loss': 1.3053, 'grad_norm': 1.883009758139494, 'learning_rate': 1.8500914076782448e-06, 'epoch': 0.31}
 10%|█         | 59/564 [01:38<12:57,  1.54s/it] 11%|█         | 60/564 [01:40<12:59,  1.55s/it]                                                {'loss': 1.2487, 'grad_norm': 1.7933298201188201, 'learning_rate': 1.846435100548446e-06, 'epoch': 0.32}
 11%|█         | 60/564 [01:40<12:59,  1.55s/it] 11%|█         | 61/564 [01:42<13:00,  1.55s/it]                                                {'loss': 1.4353, 'grad_norm': 1.7626581379768496, 'learning_rate': 1.842778793418647e-06, 'epoch': 0.32}
 11%|█         | 61/564 [01:42<13:00,  1.55s/it] 11%|█         | 62/564 [01:43<13:01,  1.56s/it]                                                {'loss': 1.3788, 'grad_norm': 1.717840963716302, 'learning_rate': 1.8391224862888481e-06, 'epoch': 0.33}
 11%|█         | 62/564 [01:43<13:01,  1.56s/it] 11%|█         | 63/564 [01:45<12:59,  1.56s/it]                                                {'loss': 1.2351, 'grad_norm': 1.914927420738038, 'learning_rate': 1.8354661791590494e-06, 'epoch': 0.34}
 11%|█         | 63/564 [01:45<12:59,  1.56s/it] 11%|█▏        | 64/564 [01:46<12:54,  1.55s/it]                                                {'loss': 1.23, 'grad_norm': 1.8176700575244318, 'learning_rate': 1.8318098720292504e-06, 'epoch': 0.34}
 11%|█▏        | 64/564 [01:46<12:54,  1.55s/it] 12%|█▏        | 65/564 [01:48<12:51,  1.55s/it]                                                {'loss': 1.5792, 'grad_norm': 1.5813513369893202, 'learning_rate': 1.8281535648994514e-06, 'epoch': 0.35}
 12%|█▏        | 65/564 [01:48<12:51,  1.55s/it] 12%|█▏        | 66/564 [01:49<12:50,  1.55s/it]                                                {'loss': 1.2881, 'grad_norm': 1.4806397093673729, 'learning_rate': 1.8244972577696524e-06, 'epoch': 0.35}
 12%|█▏        | 66/564 [01:49<12:50,  1.55s/it] 12%|█▏        | 67/564 [01:51<12:47,  1.54s/it]                                                {'loss': 1.4177, 'grad_norm': 1.5849938268090928, 'learning_rate': 1.8208409506398537e-06, 'epoch': 0.36}
 12%|█▏        | 67/564 [01:51<12:47,  1.54s/it] 12%|█▏        | 68/564 [01:52<12:46,  1.54s/it]                                                {'loss': 1.2185, 'grad_norm': 1.4856060891644982, 'learning_rate': 1.817184643510055e-06, 'epoch': 0.36}
 12%|█▏        | 68/564 [01:52<12:46,  1.54s/it] 12%|█▏        | 69/564 [01:54<12:45,  1.55s/it]                                                {'loss': 1.3336, 'grad_norm': 1.7276107806862524, 'learning_rate': 1.813528336380256e-06, 'epoch': 0.37}
 12%|█▏        | 69/564 [01:54<12:45,  1.55s/it] 12%|█▏        | 70/564 [01:56<12:48,  1.56s/it]                                                {'loss': 1.3653, 'grad_norm': 1.759538263784706, 'learning_rate': 1.809872029250457e-06, 'epoch': 0.37}
 12%|█▏        | 70/564 [01:56<12:48,  1.56s/it] 13%|█▎        | 71/564 [01:57<12:44,  1.55s/it]                                                {'loss': 1.3802, 'grad_norm': 1.5819617288457977, 'learning_rate': 1.806215722120658e-06, 'epoch': 0.38}
 13%|█▎        | 71/564 [01:57<12:44,  1.55s/it] 13%|█▎        | 72/564 [01:59<12:39,  1.54s/it]                                                {'loss': 1.2289, 'grad_norm': 1.8805092037962041, 'learning_rate': 1.8025594149908592e-06, 'epoch': 0.38}
 13%|█▎        | 72/564 [01:59<12:39,  1.54s/it] 13%|█▎        | 73/564 [02:00<12:44,  1.56s/it]                                                {'loss': 1.363, 'grad_norm': 1.5799777510234898, 'learning_rate': 1.7989031078610602e-06, 'epoch': 0.39}
 13%|█▎        | 73/564 [02:00<12:44,  1.56s/it] 13%|█▎        | 74/564 [02:02<12:38,  1.55s/it]                                                {'loss': 1.2803, 'grad_norm': 1.9113076336213572, 'learning_rate': 1.7952468007312612e-06, 'epoch': 0.39}
 13%|█▎        | 74/564 [02:02<12:38,  1.55s/it] 13%|█▎        | 75/564 [02:03<12:34,  1.54s/it]                                                {'loss': 1.2006, 'grad_norm': 1.712954256658182, 'learning_rate': 1.7915904936014625e-06, 'epoch': 0.4}
 13%|█▎        | 75/564 [02:03<12:34,  1.54s/it] 13%|█▎        | 76/564 [02:05<12:46,  1.57s/it]                                                {'loss': 1.5447, 'grad_norm': 1.6604491863786741, 'learning_rate': 1.7879341864716635e-06, 'epoch': 0.4}
 13%|█▎        | 76/564 [02:05<12:46,  1.57s/it] 14%|█▎        | 77/564 [02:06<12:48,  1.58s/it]                                                {'loss': 1.1364, 'grad_norm': 1.6078254994723444, 'learning_rate': 1.7842778793418647e-06, 'epoch': 0.41}
 14%|█▎        | 77/564 [02:06<12:48,  1.58s/it] 14%|█▍        | 78/564 [02:08<12:42,  1.57s/it]                                                {'loss': 1.4199, 'grad_norm': 1.8698388052568662, 'learning_rate': 1.7806215722120656e-06, 'epoch': 0.41}
 14%|█▍        | 78/564 [02:08<12:42,  1.57s/it] 14%|█▍        | 79/564 [02:10<12:38,  1.56s/it]                                                {'loss': 1.2354, 'grad_norm': 1.7742619591450073, 'learning_rate': 1.7769652650822668e-06, 'epoch': 0.42}
 14%|█▍        | 79/564 [02:10<12:38,  1.56s/it] 14%|█▍        | 80/564 [02:11<12:35,  1.56s/it]                                                {'loss': 1.1886, 'grad_norm': 1.964341028821186, 'learning_rate': 1.7733089579524678e-06, 'epoch': 0.43}
 14%|█▍        | 80/564 [02:11<12:35,  1.56s/it] 14%|█▍        | 81/564 [02:13<12:29,  1.55s/it]                                                {'loss': 1.3539, 'grad_norm': 1.9280077772420672, 'learning_rate': 1.769652650822669e-06, 'epoch': 0.43}
 14%|█▍        | 81/564 [02:13<12:29,  1.55s/it] 15%|█▍        | 82/564 [02:14<12:38,  1.57s/it]                                                {'loss': 1.4388, 'grad_norm': 1.8672304364785717, 'learning_rate': 1.7659963436928703e-06, 'epoch': 0.44}
 15%|█▍        | 82/564 [02:14<12:38,  1.57s/it] 15%|█▍        | 83/564 [02:16<12:27,  1.55s/it]                                                {'loss': 1.441, 'grad_norm': 1.794685146544225, 'learning_rate': 1.762340036563071e-06, 'epoch': 0.44}
 15%|█▍        | 83/564 [02:16<12:27,  1.55s/it] 15%|█▍        | 84/564 [02:17<12:27,  1.56s/it]                                                {'loss': 1.3896, 'grad_norm': 1.7213859891496601, 'learning_rate': 1.7586837294332723e-06, 'epoch': 0.45}
 15%|█▍        | 84/564 [02:17<12:27,  1.56s/it] 15%|█▌        | 85/564 [02:19<12:28,  1.56s/it]                                                {'loss': 1.3476, 'grad_norm': 1.742847547690977, 'learning_rate': 1.7550274223034734e-06, 'epoch': 0.45}
 15%|█▌        | 85/564 [02:19<12:28,  1.56s/it] 15%|█▌        | 86/564 [02:20<12:26,  1.56s/it]                                                {'loss': 1.4855, 'grad_norm': 1.591571533932738, 'learning_rate': 1.7513711151736746e-06, 'epoch': 0.46}
 15%|█▌        | 86/564 [02:20<12:26,  1.56s/it] 15%|█▌        | 87/564 [02:22<12:23,  1.56s/it]                                                {'loss': 1.3007, 'grad_norm': 1.9360227823406868, 'learning_rate': 1.7477148080438754e-06, 'epoch': 0.46}
 15%|█▌        | 87/564 [02:22<12:23,  1.56s/it] 16%|█▌        | 88/564 [02:24<12:16,  1.55s/it]                                                {'loss': 1.3544, 'grad_norm': 1.7217799602928798, 'learning_rate': 1.7440585009140766e-06, 'epoch': 0.47}
 16%|█▌        | 88/564 [02:24<12:16,  1.55s/it] 16%|█▌        | 89/564 [02:25<12:17,  1.55s/it]                                                {'loss': 1.4077, 'grad_norm': 1.7445267331896535, 'learning_rate': 1.7404021937842779e-06, 'epoch': 0.47}
 16%|█▌        | 89/564 [02:25<12:17,  1.55s/it] 16%|█▌        | 90/564 [02:27<12:17,  1.56s/it]                                                {'loss': 1.2117, 'grad_norm': 1.965339516261771, 'learning_rate': 1.736745886654479e-06, 'epoch': 0.48}
 16%|█▌        | 90/564 [02:27<12:17,  1.56s/it] 16%|█▌        | 91/564 [02:28<12:14,  1.55s/it]                                                {'loss': 1.1672, 'grad_norm': 1.5357211972080391, 'learning_rate': 1.7330895795246801e-06, 'epoch': 0.48}
 16%|█▌        | 91/564 [02:28<12:14,  1.55s/it] 16%|█▋        | 92/564 [02:30<12:13,  1.55s/it]                                                {'loss': 1.4821, 'grad_norm': 2.0072233016003556, 'learning_rate': 1.729433272394881e-06, 'epoch': 0.49}
 16%|█▋        | 92/564 [02:30<12:13,  1.55s/it] 16%|█▋        | 93/564 [02:31<12:10,  1.55s/it]                                                {'loss': 1.199, 'grad_norm': 1.9505731941072442, 'learning_rate': 1.7257769652650822e-06, 'epoch': 0.49}
 16%|█▋        | 93/564 [02:31<12:10,  1.55s/it] 17%|█▋        | 94/564 [02:33<12:10,  1.55s/it]                                                {'loss': 1.3277, 'grad_norm': 1.7159307983189231, 'learning_rate': 1.7221206581352832e-06, 'epoch': 0.5}
 17%|█▋        | 94/564 [02:33<12:10,  1.55s/it] 17%|█▋        | 95/564 [02:34<12:11,  1.56s/it]                                                {'loss': 1.1496, 'grad_norm': 1.7959186584926092, 'learning_rate': 1.7184643510054844e-06, 'epoch': 0.51}
 17%|█▋        | 95/564 [02:34<12:11,  1.56s/it] 17%|█▋        | 96/564 [02:36<12:06,  1.55s/it]                                                {'loss': 1.4292, 'grad_norm': 1.6986682563797106, 'learning_rate': 1.7148080438756855e-06, 'epoch': 0.51}
 17%|█▋        | 96/564 [02:36<12:06,  1.55s/it] 17%|█▋        | 97/564 [02:38<12:05,  1.55s/it]                                                {'loss': 1.213, 'grad_norm': 1.7855416387568115, 'learning_rate': 1.7111517367458865e-06, 'epoch': 0.52}
 17%|█▋        | 97/564 [02:38<12:05,  1.55s/it] 17%|█▋        | 98/564 [02:39<12:01,  1.55s/it]                                                {'loss': 1.4909, 'grad_norm': 1.7683334624167735, 'learning_rate': 1.7074954296160877e-06, 'epoch': 0.52}
 17%|█▋        | 98/564 [02:39<12:01,  1.55s/it] 18%|█▊        | 99/564 [02:41<11:58,  1.54s/it]                                                {'loss': 1.4296, 'grad_norm': 1.8186560632028257, 'learning_rate': 1.7038391224862887e-06, 'epoch': 0.53}
 18%|█▊        | 99/564 [02:41<11:58,  1.54s/it] 18%|█▊        | 100/564 [02:42<12:00,  1.55s/it]                                                 {'loss': 1.2508, 'grad_norm': 1.7257763142896247, 'learning_rate': 1.70018281535649e-06, 'epoch': 0.53}
 18%|█▊        | 100/564 [02:42<12:00,  1.55s/it] 18%|█▊        | 101/564 [02:44<12:00,  1.56s/it]                                                 {'loss': 1.2836, 'grad_norm': 1.492889341460344, 'learning_rate': 1.6965265082266908e-06, 'epoch': 0.54}
 18%|█▊        | 101/564 [02:44<12:00,  1.56s/it] 18%|█▊        | 102/564 [02:45<12:01,  1.56s/it]                                                 {'loss': 1.3192, 'grad_norm': 1.5847427020001246, 'learning_rate': 1.692870201096892e-06, 'epoch': 0.54}
 18%|█▊        | 102/564 [02:45<12:01,  1.56s/it] 18%|█▊        | 103/564 [02:47<12:01,  1.57s/it]                                                 {'loss': 1.415, 'grad_norm': 1.6487201386215007, 'learning_rate': 1.6892138939670933e-06, 'epoch': 0.55}
 18%|█▊        | 103/564 [02:47<12:01,  1.57s/it] 18%|█▊        | 104/564 [02:48<11:56,  1.56s/it]                                                 {'loss': 1.4866, 'grad_norm': 1.6216485283351953, 'learning_rate': 1.6855575868372943e-06, 'epoch': 0.55}
 18%|█▊        | 104/564 [02:48<11:56,  1.56s/it] 19%|█▊        | 105/564 [02:50<11:56,  1.56s/it]                                                 {'loss': 1.346, 'grad_norm': 1.9615207628635822, 'learning_rate': 1.6819012797074953e-06, 'epoch': 0.56}
 19%|█▊        | 105/564 [02:50<11:56,  1.56s/it] 19%|█▉        | 106/564 [02:52<11:50,  1.55s/it]                                                 {'loss': 1.3362, 'grad_norm': 1.679878756789361, 'learning_rate': 1.6782449725776963e-06, 'epoch': 0.56}
 19%|█▉        | 106/564 [02:52<11:50,  1.55s/it] 19%|█▉        | 107/564 [02:53<11:49,  1.55s/it]                                                 {'loss': 1.1602, 'grad_norm': 1.6798160758706504, 'learning_rate': 1.6745886654478976e-06, 'epoch': 0.57}
 19%|█▉        | 107/564 [02:53<11:49,  1.55s/it] 19%|█▉        | 108/564 [02:55<11:41,  1.54s/it]                                                 {'loss': 1.3272, 'grad_norm': 2.097118254117184, 'learning_rate': 1.6709323583180986e-06, 'epoch': 0.57}
 19%|█▉        | 108/564 [02:55<11:41,  1.54s/it] 19%|█▉        | 109/564 [02:56<11:39,  1.54s/it]                                                 {'loss': 1.5038, 'grad_norm': 1.682295092158478, 'learning_rate': 1.6672760511882998e-06, 'epoch': 0.58}
 19%|█▉        | 109/564 [02:56<11:39,  1.54s/it] 20%|█▉        | 110/564 [02:58<11:35,  1.53s/it]                                                 {'loss': 1.276, 'grad_norm': 1.5998685669719093, 'learning_rate': 1.6636197440585008e-06, 'epoch': 0.59}
 20%|█▉        | 110/564 [02:58<11:35,  1.53s/it] 20%|█▉        | 111/564 [02:59<11:29,  1.52s/it]                                                 {'loss': 1.3012, 'grad_norm': 1.8386425476552812, 'learning_rate': 1.6599634369287019e-06, 'epoch': 0.59}
 20%|█▉        | 111/564 [02:59<11:29,  1.52s/it] 20%|█▉        | 112/564 [03:01<11:33,  1.54s/it]                                                 {'loss': 1.252, 'grad_norm': 1.7362105498720668, 'learning_rate': 1.6563071297989031e-06, 'epoch': 0.6}
 20%|█▉        | 112/564 [03:01<11:33,  1.54s/it] 20%|██        | 113/564 [03:02<11:31,  1.53s/it]                                                 {'loss': 1.3764, 'grad_norm': 1.685899499634662, 'learning_rate': 1.6526508226691041e-06, 'epoch': 0.6}
 20%|██        | 113/564 [03:02<11:31,  1.53s/it] 20%|██        | 114/564 [03:04<11:32,  1.54s/it]                                                 {'loss': 1.3565, 'grad_norm': 1.9385943675878055, 'learning_rate': 1.6489945155393052e-06, 'epoch': 0.61}
 20%|██        | 114/564 [03:04<11:32,  1.54s/it] 20%|██        | 115/564 [03:05<11:30,  1.54s/it]                                                 {'loss': 1.4473, 'grad_norm': 1.7156138660360158, 'learning_rate': 1.6453382084095064e-06, 'epoch': 0.61}
 20%|██        | 115/564 [03:05<11:30,  1.54s/it] 21%|██        | 116/564 [03:07<11:32,  1.55s/it]                                                 {'loss': 1.3038, 'grad_norm': 1.6054930518163826, 'learning_rate': 1.6416819012797074e-06, 'epoch': 0.62}
 21%|██        | 116/564 [03:07<11:32,  1.55s/it] 21%|██        | 117/564 [03:08<11:33,  1.55s/it]                                                 {'loss': 1.1108, 'grad_norm': 1.7144654136024013, 'learning_rate': 1.6380255941499086e-06, 'epoch': 0.62}
 21%|██        | 117/564 [03:08<11:33,  1.55s/it] 21%|██        | 118/564 [03:10<11:27,  1.54s/it]                                                 {'loss': 1.2928, 'grad_norm': 1.9495393189015222, 'learning_rate': 1.6343692870201097e-06, 'epoch': 0.63}
 21%|██        | 118/564 [03:10<11:27,  1.54s/it] 21%|██        | 119/564 [03:11<11:24,  1.54s/it]                                                 {'loss': 1.2865, 'grad_norm': 1.762286728556403, 'learning_rate': 1.6307129798903107e-06, 'epoch': 0.63}
 21%|██        | 119/564 [03:11<11:24,  1.54s/it] 21%|██▏       | 120/564 [03:13<11:21,  1.53s/it]                                                 {'loss': 1.3761, 'grad_norm': 1.7451130896373719, 'learning_rate': 1.6270566727605117e-06, 'epoch': 0.64}
 21%|██▏       | 120/564 [03:13<11:21,  1.53s/it] 21%|██▏       | 121/564 [03:15<11:33,  1.57s/it]                                                 {'loss': 1.3006, 'grad_norm': 1.7170505146232318, 'learning_rate': 1.623400365630713e-06, 'epoch': 0.64}
 21%|██▏       | 121/564 [03:15<11:33,  1.57s/it] 22%|██▏       | 122/564 [03:16<11:31,  1.56s/it]                                                 {'loss': 1.485, 'grad_norm': 1.4493685385844437, 'learning_rate': 1.6197440585009142e-06, 'epoch': 0.65}
 22%|██▏       | 122/564 [03:16<11:31,  1.56s/it] 22%|██▏       | 123/564 [03:18<12:21,  1.68s/it]                                                 {'loss': 1.3881, 'grad_norm': 1.7804973937067432, 'learning_rate': 1.616087751371115e-06, 'epoch': 0.65}
 22%|██▏       | 123/564 [03:18<12:21,  1.68s/it] 22%|██▏       | 124/564 [03:20<12:03,  1.64s/it]                                                 {'loss': 1.5067, 'grad_norm': 1.724029538251619, 'learning_rate': 1.6124314442413162e-06, 'epoch': 0.66}
 22%|██▏       | 124/564 [03:20<12:03,  1.64s/it] 22%|██▏       | 125/564 [03:21<11:52,  1.62s/it]                                                 {'loss': 1.2668, 'grad_norm': 1.4665608422355654, 'learning_rate': 1.6087751371115173e-06, 'epoch': 0.66}
 22%|██▏       | 125/564 [03:21<11:52,  1.62s/it] 22%|██▏       | 126/564 [03:23<11:39,  1.60s/it]                                                 {'loss': 1.3927, 'grad_norm': 1.784641332319061, 'learning_rate': 1.6051188299817185e-06, 'epoch': 0.67}
 22%|██▏       | 126/564 [03:23<11:39,  1.60s/it] 23%|██▎       | 127/564 [03:24<11:28,  1.57s/it]                                                 {'loss': 1.389, 'grad_norm': 1.9126898192690058, 'learning_rate': 1.6014625228519193e-06, 'epoch': 0.68}
 23%|██▎       | 127/564 [03:24<11:28,  1.57s/it] 23%|██▎       | 128/564 [03:26<11:24,  1.57s/it]                                                 {'loss': 1.372, 'grad_norm': 1.9864716354622731, 'learning_rate': 1.5978062157221205e-06, 'epoch': 0.68}
 23%|██▎       | 128/564 [03:26<11:24,  1.57s/it] 23%|██▎       | 129/564 [03:27<11:20,  1.56s/it]                                                 {'loss': 1.4339, 'grad_norm': 1.8632802531696584, 'learning_rate': 1.5941499085923218e-06, 'epoch': 0.69}
 23%|██▎       | 129/564 [03:27<11:20,  1.56s/it] 23%|██▎       | 130/564 [03:29<11:12,  1.55s/it]                                                 {'loss': 1.235, 'grad_norm': 1.7783732120980107, 'learning_rate': 1.5904936014625228e-06, 'epoch': 0.69}
 23%|██▎       | 130/564 [03:29<11:12,  1.55s/it] 23%|██▎       | 131/564 [03:31<11:15,  1.56s/it]                                                 {'loss': 1.2325, 'grad_norm': 1.698113056502926, 'learning_rate': 1.586837294332724e-06, 'epoch': 0.7}
 23%|██▎       | 131/564 [03:31<11:15,  1.56s/it] 23%|██▎       | 132/564 [03:32<11:16,  1.57s/it]                                                 {'loss': 1.2411, 'grad_norm': 2.120376240553946, 'learning_rate': 1.5831809872029248e-06, 'epoch': 0.7}
 23%|██▎       | 132/564 [03:32<11:16,  1.57s/it] 24%|██▎       | 133/564 [03:34<11:13,  1.56s/it]                                                 {'loss': 1.363, 'grad_norm': 1.7641964382506503, 'learning_rate': 1.579524680073126e-06, 'epoch': 0.71}
 24%|██▎       | 133/564 [03:34<11:13,  1.56s/it] 24%|██▍       | 134/564 [03:35<11:12,  1.56s/it]                                                 {'loss': 1.4795, 'grad_norm': 2.0659303112795064, 'learning_rate': 1.5758683729433271e-06, 'epoch': 0.71}
 24%|██▍       | 134/564 [03:35<11:12,  1.56s/it] 24%|██▍       | 135/564 [03:37<11:07,  1.56s/it]                                                 {'loss': 1.4127, 'grad_norm': 2.0189944347168796, 'learning_rate': 1.5722120658135283e-06, 'epoch': 0.72}
 24%|██▍       | 135/564 [03:37<11:07,  1.56s/it] 24%|██▍       | 136/564 [03:38<11:03,  1.55s/it]                                                 {'loss': 1.2559, 'grad_norm': 1.5913587834710266, 'learning_rate': 1.5685557586837294e-06, 'epoch': 0.72}
 24%|██▍       | 136/564 [03:38<11:03,  1.55s/it] 24%|██▍       | 137/564 [03:40<10:58,  1.54s/it]                                                 {'loss': 1.3472, 'grad_norm': 1.752257924579083, 'learning_rate': 1.5648994515539304e-06, 'epoch': 0.73}
 24%|██▍       | 137/564 [03:40<10:58,  1.54s/it] 24%|██▍       | 138/564 [03:41<10:58,  1.55s/it]                                                 {'loss': 1.4873, 'grad_norm': 1.4856691907795812, 'learning_rate': 1.5612431444241316e-06, 'epoch': 0.73}
 24%|██▍       | 138/564 [03:41<10:58,  1.55s/it] 25%|██▍       | 139/564 [03:43<10:58,  1.55s/it]                                                 {'loss': 1.3585, 'grad_norm': 2.0600031876793654, 'learning_rate': 1.5575868372943326e-06, 'epoch': 0.74}
 25%|██▍       | 139/564 [03:43<10:58,  1.55s/it] 25%|██▍       | 140/564 [03:45<10:59,  1.55s/it]                                                 {'loss': 1.1708, 'grad_norm': 1.9378343744516229, 'learning_rate': 1.5539305301645339e-06, 'epoch': 0.74}
 25%|██▍       | 140/564 [03:45<10:59,  1.55s/it] 25%|██▌       | 141/564 [03:46<10:57,  1.55s/it]                                                 {'loss': 1.5164, 'grad_norm': 1.8788717943878732, 'learning_rate': 1.5502742230347347e-06, 'epoch': 0.75}
 25%|██▌       | 141/564 [03:46<10:57,  1.55s/it] 25%|██▌       | 142/564 [03:48<10:51,  1.54s/it]                                                 {'loss': 1.2874, 'grad_norm': 1.9543325977310522, 'learning_rate': 1.546617915904936e-06, 'epoch': 0.76}
 25%|██▌       | 142/564 [03:48<10:51,  1.54s/it] 25%|██▌       | 143/564 [03:49<10:48,  1.54s/it]                                                 {'loss': 1.3697, 'grad_norm': 1.7612131215388784, 'learning_rate': 1.5429616087751372e-06, 'epoch': 0.76}
 25%|██▌       | 143/564 [03:49<10:48,  1.54s/it] 26%|██▌       | 144/564 [03:51<10:39,  1.52s/it]                                                 {'loss': 1.3814, 'grad_norm': 1.8674586182355453, 'learning_rate': 1.5393053016453382e-06, 'epoch': 0.77}
 26%|██▌       | 144/564 [03:51<10:39,  1.52s/it] 26%|██▌       | 145/564 [03:52<10:38,  1.52s/it]                                                 {'loss': 1.2393, 'grad_norm': 1.6183799950766307, 'learning_rate': 1.5356489945155392e-06, 'epoch': 0.77}
 26%|██▌       | 145/564 [03:52<10:38,  1.52s/it] 26%|██▌       | 146/564 [03:54<10:38,  1.53s/it]                                                 {'loss': 1.4136, 'grad_norm': 1.5482227265258883, 'learning_rate': 1.5319926873857402e-06, 'epoch': 0.78}
 26%|██▌       | 146/564 [03:54<10:38,  1.53s/it] 26%|██▌       | 147/564 [03:55<10:38,  1.53s/it]                                                 {'loss': 1.4571, 'grad_norm': 1.8624503460821167, 'learning_rate': 1.5283363802559415e-06, 'epoch': 0.78}
 26%|██▌       | 147/564 [03:55<10:38,  1.53s/it] 26%|██▌       | 148/564 [03:57<10:37,  1.53s/it]                                                 {'loss': 1.1752, 'grad_norm': 1.7214138153537215, 'learning_rate': 1.5246800731261425e-06, 'epoch': 0.79}
 26%|██▌       | 148/564 [03:57<10:37,  1.53s/it] 26%|██▋       | 149/564 [03:58<10:35,  1.53s/it]                                                 {'loss': 1.2651, 'grad_norm': 1.6466705341180727, 'learning_rate': 1.5210237659963437e-06, 'epoch': 0.79}
 26%|██▋       | 149/564 [03:58<10:35,  1.53s/it] 27%|██▋       | 150/564 [04:00<10:39,  1.54s/it]                                                 {'loss': 1.1751, 'grad_norm': 1.6608298586935277, 'learning_rate': 1.5173674588665448e-06, 'epoch': 0.8}
 27%|██▋       | 150/564 [04:00<10:39,  1.54s/it] 27%|██▋       | 151/564 [04:01<10:33,  1.53s/it]                                                 {'loss': 1.4216, 'grad_norm': 2.013767502444362, 'learning_rate': 1.5137111517367458e-06, 'epoch': 0.8}
 27%|██▋       | 151/564 [04:01<10:33,  1.53s/it] 27%|██▋       | 152/564 [04:03<10:32,  1.54s/it]                                                 {'loss': 1.3802, 'grad_norm': 1.8458117994048941, 'learning_rate': 1.510054844606947e-06, 'epoch': 0.81}
 27%|██▋       | 152/564 [04:03<10:32,  1.54s/it] 27%|██▋       | 153/564 [04:04<10:26,  1.52s/it]                                                 {'loss': 1.3241, 'grad_norm': 4.162516810217349, 'learning_rate': 1.506398537477148e-06, 'epoch': 0.81}
 27%|██▋       | 153/564 [04:04<10:26,  1.52s/it] 27%|██▋       | 154/564 [04:06<10:28,  1.53s/it]                                                 {'loss': 1.3676, 'grad_norm': 1.5387426407519482, 'learning_rate': 1.502742230347349e-06, 'epoch': 0.82}
 27%|██▋       | 154/564 [04:06<10:28,  1.53s/it] 27%|██▋       | 155/564 [04:08<10:29,  1.54s/it]                                                 {'loss': 1.5184, 'grad_norm': 2.0252772028783754, 'learning_rate': 1.49908592321755e-06, 'epoch': 0.82}
 27%|██▋       | 155/564 [04:08<10:29,  1.54s/it] 28%|██▊       | 156/564 [04:09<10:30,  1.55s/it]                                                 {'loss': 1.2094, 'grad_norm': 2.021974879922381, 'learning_rate': 1.4954296160877513e-06, 'epoch': 0.83}
 28%|██▊       | 156/564 [04:09<10:30,  1.55s/it] 28%|██▊       | 157/564 [04:11<10:25,  1.54s/it]                                                 {'loss': 1.1947, 'grad_norm': 1.769712924102048, 'learning_rate': 1.4917733089579526e-06, 'epoch': 0.84}
 28%|██▊       | 157/564 [04:11<10:25,  1.54s/it] 28%|██▊       | 158/564 [04:12<10:21,  1.53s/it]                                                 {'loss': 1.4744, 'grad_norm': 1.6513414806306999, 'learning_rate': 1.4881170018281536e-06, 'epoch': 0.84}
 28%|██▊       | 158/564 [04:12<10:21,  1.53s/it] 28%|██▊       | 159/564 [04:14<10:27,  1.55s/it]                                                 {'loss': 1.2047, 'grad_norm': 2.0446029990702925, 'learning_rate': 1.4844606946983546e-06, 'epoch': 0.85}
 28%|██▊       | 159/564 [04:14<10:27,  1.55s/it] 28%|██▊       | 160/564 [04:15<10:28,  1.55s/it]                                                 {'loss': 1.1241, 'grad_norm': 1.6850750966831045, 'learning_rate': 1.4808043875685556e-06, 'epoch': 0.85}
 28%|██▊       | 160/564 [04:15<10:28,  1.55s/it] 29%|██▊       | 161/564 [04:17<10:21,  1.54s/it]                                                 {'loss': 1.2129, 'grad_norm': 1.8869758180442473, 'learning_rate': 1.4771480804387569e-06, 'epoch': 0.86}
 29%|██▊       | 161/564 [04:17<10:21,  1.54s/it] 29%|██▊       | 162/564 [04:18<10:22,  1.55s/it]                                                 {'loss': 1.4202, 'grad_norm': 1.8256322496559323, 'learning_rate': 1.4734917733089579e-06, 'epoch': 0.86}
 29%|██▊       | 162/564 [04:18<10:22,  1.55s/it] 29%|██▉       | 163/564 [04:20<10:21,  1.55s/it]                                                 {'loss': 1.484, 'grad_norm': 1.6696560030658534, 'learning_rate': 1.469835466179159e-06, 'epoch': 0.87}
 29%|██▉       | 163/564 [04:20<10:21,  1.55s/it] 29%|██▉       | 164/564 [04:21<10:19,  1.55s/it]                                                 {'loss': 1.4014, 'grad_norm': 1.5617947481929435, 'learning_rate': 1.4661791590493601e-06, 'epoch': 0.87}
 29%|██▉       | 164/564 [04:21<10:19,  1.55s/it] 29%|██▉       | 165/564 [04:23<10:16,  1.55s/it]                                                 {'loss': 1.4076, 'grad_norm': 1.741609776448367, 'learning_rate': 1.4625228519195612e-06, 'epoch': 0.88}
 29%|██▉       | 165/564 [04:23<10:16,  1.55s/it] 29%|██▉       | 166/564 [04:25<10:20,  1.56s/it]                                                 {'loss': 1.2288, 'grad_norm': 1.7066669694804715, 'learning_rate': 1.4588665447897624e-06, 'epoch': 0.88}
 29%|██▉       | 166/564 [04:25<10:20,  1.56s/it] 30%|██▉       | 167/564 [04:26<10:21,  1.57s/it]                                                 {'loss': 1.3508, 'grad_norm': 1.7733886010300053, 'learning_rate': 1.4552102376599632e-06, 'epoch': 0.89}
 30%|██▉       | 167/564 [04:26<10:21,  1.57s/it] 30%|██▉       | 168/564 [04:28<10:17,  1.56s/it]                                                 {'loss': 1.1747, 'grad_norm': 1.9106542871630108, 'learning_rate': 1.4515539305301644e-06, 'epoch': 0.89}
 30%|██▉       | 168/564 [04:28<10:17,  1.56s/it] 30%|██▉       | 169/564 [04:29<10:18,  1.57s/it]                                                 {'loss': 1.2279, 'grad_norm': 1.894181207470219, 'learning_rate': 1.4478976234003655e-06, 'epoch': 0.9}
 30%|██▉       | 169/564 [04:29<10:18,  1.57s/it] 30%|███       | 170/564 [04:31<10:13,  1.56s/it]                                                 {'loss': 1.3865, 'grad_norm': 1.9577321196856476, 'learning_rate': 1.4442413162705667e-06, 'epoch': 0.9}
 30%|███       | 170/564 [04:31<10:13,  1.56s/it] 30%|███       | 171/564 [04:32<10:13,  1.56s/it]                                                 {'loss': 1.239, 'grad_norm': 1.661772125586895, 'learning_rate': 1.440585009140768e-06, 'epoch': 0.91}
 30%|███       | 171/564 [04:32<10:13,  1.56s/it] 30%|███       | 172/564 [04:34<10:11,  1.56s/it]                                                 {'loss': 1.4145, 'grad_norm': 1.6645054148261416, 'learning_rate': 1.4369287020109688e-06, 'epoch': 0.91}
 30%|███       | 172/564 [04:34<10:11,  1.56s/it] 31%|███       | 173/564 [04:36<10:08,  1.56s/it]                                                 {'loss': 1.2524, 'grad_norm': 1.6657722807160482, 'learning_rate': 1.43327239488117e-06, 'epoch': 0.92}
 31%|███       | 173/564 [04:36<10:08,  1.56s/it] 31%|███       | 174/564 [04:37<10:05,  1.55s/it]                                                 {'loss': 1.262, 'grad_norm': 1.861520019140644, 'learning_rate': 1.429616087751371e-06, 'epoch': 0.93}
 31%|███       | 174/564 [04:37<10:05,  1.55s/it] 31%|███       | 175/564 [04:39<09:58,  1.54s/it]                                                 {'loss': 1.3133, 'grad_norm': 1.7478400215239418, 'learning_rate': 1.4259597806215722e-06, 'epoch': 0.93}
 31%|███       | 175/564 [04:39<09:58,  1.54s/it] 31%|███       | 176/564 [04:40<09:59,  1.54s/it]                                                 {'loss': 1.4526, 'grad_norm': 1.5282753468806247, 'learning_rate': 1.422303473491773e-06, 'epoch': 0.94}
 31%|███       | 176/564 [04:40<09:59,  1.54s/it] 31%|███▏      | 177/564 [04:42<09:58,  1.55s/it]                                                 {'loss': 1.3658, 'grad_norm': 1.727785872627157, 'learning_rate': 1.4186471663619743e-06, 'epoch': 0.94}
 31%|███▏      | 177/564 [04:42<09:58,  1.55s/it] 32%|███▏      | 178/564 [04:43<09:57,  1.55s/it]                                                 {'loss': 1.2461, 'grad_norm': 1.7929791065711973, 'learning_rate': 1.4149908592321755e-06, 'epoch': 0.95}
 32%|███▏      | 178/564 [04:43<09:57,  1.55s/it] 32%|███▏      | 179/564 [04:45<09:52,  1.54s/it]                                                 {'loss': 1.4063, 'grad_norm': 1.7866738343602455, 'learning_rate': 1.4113345521023766e-06, 'epoch': 0.95}
 32%|███▏      | 179/564 [04:45<09:52,  1.54s/it] 32%|███▏      | 180/564 [04:46<09:49,  1.53s/it]                                                 {'loss': 1.196, 'grad_norm': 1.811537328410375, 'learning_rate': 1.4076782449725778e-06, 'epoch': 0.96}
 32%|███▏      | 180/564 [04:46<09:49,  1.53s/it] 32%|███▏      | 181/564 [04:48<09:46,  1.53s/it]                                                 {'loss': 1.2997, 'grad_norm': 1.8554481349250682, 'learning_rate': 1.4040219378427786e-06, 'epoch': 0.96}
 32%|███▏      | 181/564 [04:48<09:46,  1.53s/it] 32%|███▏      | 182/564 [04:49<09:46,  1.54s/it]                                                 {'loss': 1.1114, 'grad_norm': 1.6147397720493473, 'learning_rate': 1.4003656307129798e-06, 'epoch': 0.97}
 32%|███▏      | 182/564 [04:49<09:46,  1.54s/it] 32%|███▏      | 183/564 [04:51<09:48,  1.54s/it]                                                 {'loss': 1.3549, 'grad_norm': 1.5170384057162283, 'learning_rate': 1.3967093235831809e-06, 'epoch': 0.97}
 32%|███▏      | 183/564 [04:51<09:48,  1.54s/it] 33%|███▎      | 184/564 [04:52<09:48,  1.55s/it]                                                 {'loss': 1.4478, 'grad_norm': 1.6097631603493605, 'learning_rate': 1.393053016453382e-06, 'epoch': 0.98}
 33%|███▎      | 184/564 [04:52<09:48,  1.55s/it] 33%|███▎      | 185/564 [04:54<09:46,  1.55s/it]                                                 {'loss': 1.2972, 'grad_norm': 1.6136508920756507, 'learning_rate': 1.3893967093235831e-06, 'epoch': 0.98}
 33%|███▎      | 185/564 [04:54<09:46,  1.55s/it] 33%|███▎      | 186/564 [04:56<09:39,  1.53s/it]                                                 {'loss': 1.274, 'grad_norm': 1.8155429193722303, 'learning_rate': 1.3857404021937841e-06, 'epoch': 0.99}
 33%|███▎      | 186/564 [04:56<09:39,  1.53s/it] 33%|███▎      | 187/564 [04:57<09:39,  1.54s/it]                                                 {'loss': 1.21, 'grad_norm': 1.5308774423914084, 'learning_rate': 1.3820840950639854e-06, 'epoch': 0.99}
 33%|███▎      | 187/564 [04:57<09:39,  1.54s/it] 33%|███▎      | 188/564 [04:59<09:40,  1.54s/it]                                                 {'loss': 1.1829, 'grad_norm': 2.409592194922985, 'learning_rate': 1.3784277879341864e-06, 'epoch': 1.0}
 33%|███▎      | 188/564 [04:59<09:40,  1.54s/it] 34%|███▎      | 189/564 [05:00<09:41,  1.55s/it]                                                 {'loss': 1.0703, 'grad_norm': 1.4297674931936497, 'learning_rate': 1.3747714808043876e-06, 'epoch': 1.01}
 34%|███▎      | 189/564 [05:00<09:41,  1.55s/it] 34%|███▎      | 190/564 [05:02<09:40,  1.55s/it]                                                 {'loss': 1.0133, 'grad_norm': 1.3922798383866548, 'learning_rate': 1.3711151736745884e-06, 'epoch': 1.01}
 34%|███▎      | 190/564 [05:02<09:40,  1.55s/it] 34%|███▍      | 191/564 [05:03<09:38,  1.55s/it]                                                 {'loss': 1.1727, 'grad_norm': 1.5398986688560685, 'learning_rate': 1.3674588665447897e-06, 'epoch': 1.02}
 34%|███▍      | 191/564 [05:03<09:38,  1.55s/it] 34%|███▍      | 192/564 [05:05<09:36,  1.55s/it]                                                 {'loss': 1.2208, 'grad_norm': 1.5797033401769056, 'learning_rate': 1.363802559414991e-06, 'epoch': 1.02}
 34%|███▍      | 192/564 [05:05<09:36,  1.55s/it] 34%|███▍      | 193/564 [05:06<09:34,  1.55s/it]                                                 {'loss': 1.2332, 'grad_norm': 1.4591492002372477, 'learning_rate': 1.360146252285192e-06, 'epoch': 1.03}
 34%|███▍      | 193/564 [05:06<09:34,  1.55s/it] 34%|███▍      | 194/564 [05:08<09:32,  1.55s/it]                                                 {'loss': 1.3453, 'grad_norm': 1.7698650335727755, 'learning_rate': 1.356489945155393e-06, 'epoch': 1.03}
 34%|███▍      | 194/564 [05:08<09:32,  1.55s/it] 35%|███▍      | 195/564 [05:09<09:29,  1.54s/it]                                                 {'loss': 1.1721, 'grad_norm': 1.5923119560121652, 'learning_rate': 1.352833638025594e-06, 'epoch': 1.04}
 35%|███▍      | 195/564 [05:09<09:29,  1.54s/it] 35%|███▍      | 196/564 [05:11<09:31,  1.55s/it]                                                 {'loss': 1.2093, 'grad_norm': 1.6455680673318345, 'learning_rate': 1.3491773308957952e-06, 'epoch': 1.04}
 35%|███▍      | 196/564 [05:11<09:31,  1.55s/it] 35%|███▍      | 197/564 [05:13<09:30,  1.56s/it]                                                 {'loss': 1.2769, 'grad_norm': 1.6649659188540424, 'learning_rate': 1.3455210237659962e-06, 'epoch': 1.05}
 35%|███▍      | 197/564 [05:13<09:30,  1.56s/it] 35%|███▌      | 198/564 [05:14<09:37,  1.58s/it]                                                 {'loss': 1.1901, 'grad_norm': 1.5884883493063247, 'learning_rate': 1.3418647166361975e-06, 'epoch': 1.05}
 35%|███▌      | 198/564 [05:14<09:37,  1.58s/it] 35%|███▌      | 199/564 [05:16<09:30,  1.56s/it]                                                 {'loss': 1.2408, 'grad_norm': 1.5250514051386892, 'learning_rate': 1.3382084095063985e-06, 'epoch': 1.06}
 35%|███▌      | 199/564 [05:16<09:30,  1.56s/it] 35%|███▌      | 200/564 [05:17<09:26,  1.56s/it]                                                 {'loss': 1.1523, 'grad_norm': 1.7431469646878097, 'learning_rate': 1.3345521023765995e-06, 'epoch': 1.06}
 35%|███▌      | 200/564 [05:17<09:26,  1.56s/it] 36%|███▌      | 201/564 [05:19<09:25,  1.56s/it]                                                 {'loss': 0.9237, 'grad_norm': 1.6130743750466108, 'learning_rate': 1.3308957952468008e-06, 'epoch': 1.07}
 36%|███▌      | 201/564 [05:19<09:25,  1.56s/it] 36%|███▌      | 202/564 [05:20<09:25,  1.56s/it]                                                 {'loss': 1.33, 'grad_norm': 1.5015837414860411, 'learning_rate': 1.3272394881170018e-06, 'epoch': 1.07}
 36%|███▌      | 202/564 [05:20<09:25,  1.56s/it] 36%|███▌      | 203/564 [05:22<09:25,  1.57s/it]                                                 {'loss': 1.328, 'grad_norm': 1.5774027007892286, 'learning_rate': 1.3235831809872028e-06, 'epoch': 1.08}
 36%|███▌      | 203/564 [05:22<09:25,  1.57s/it] 36%|███▌      | 204/564 [05:24<09:22,  1.56s/it]                                                 {'loss': 1.0867, 'grad_norm': 1.9579785210993241, 'learning_rate': 1.3199268738574038e-06, 'epoch': 1.09}
 36%|███▌      | 204/564 [05:24<09:22,  1.56s/it] 36%|███▋      | 205/564 [05:25<09:20,  1.56s/it]                                                 {'loss': 1.2527, 'grad_norm': 1.6384016260374745, 'learning_rate': 1.316270566727605e-06, 'epoch': 1.09}
 36%|███▋      | 205/564 [05:25<09:20,  1.56s/it] 37%|███▋      | 206/564 [05:27<09:21,  1.57s/it]                                                 {'loss': 1.1805, 'grad_norm': 1.6564081483760071, 'learning_rate': 1.3126142595978063e-06, 'epoch': 1.1}
 37%|███▋      | 206/564 [05:27<09:21,  1.57s/it] 37%|███▋      | 207/564 [05:28<09:18,  1.56s/it]                                                 {'loss': 1.4708, 'grad_norm': 1.4736673475554116, 'learning_rate': 1.3089579524680071e-06, 'epoch': 1.1}
 37%|███▋      | 207/564 [05:28<09:18,  1.56s/it] 37%|███▋      | 208/564 [05:30<09:07,  1.54s/it]                                                 {'loss': 1.2335, 'grad_norm': 1.8618070504402415, 'learning_rate': 1.3053016453382084e-06, 'epoch': 1.11}
 37%|███▋      | 208/564 [05:30<09:07,  1.54s/it] 37%|███▋      | 209/564 [05:31<09:10,  1.55s/it]                                                 {'loss': 1.2866, 'grad_norm': 1.6325970875583167, 'learning_rate': 1.3016453382084094e-06, 'epoch': 1.11}
 37%|███▋      | 209/564 [05:31<09:10,  1.55s/it] 37%|███▋      | 210/564 [05:33<09:06,  1.54s/it]                                                 {'loss': 1.2166, 'grad_norm': 1.717063511730867, 'learning_rate': 1.2979890310786106e-06, 'epoch': 1.12}
 37%|███▋      | 210/564 [05:33<09:06,  1.54s/it] 37%|███▋      | 211/564 [05:34<09:04,  1.54s/it]                                                 {'loss': 1.2782, 'grad_norm': 1.7647398590735315, 'learning_rate': 1.2943327239488116e-06, 'epoch': 1.12}
 37%|███▋      | 211/564 [05:34<09:04,  1.54s/it] 38%|███▊      | 212/564 [05:36<09:00,  1.54s/it]                                                 {'loss': 1.3829, 'grad_norm': 1.6839459394620198, 'learning_rate': 1.2906764168190127e-06, 'epoch': 1.13}
 38%|███▊      | 212/564 [05:36<09:00,  1.54s/it] 38%|███▊      | 213/564 [05:37<09:03,  1.55s/it]                                                 {'loss': 1.1379, 'grad_norm': 1.6310248074616467, 'learning_rate': 1.2870201096892139e-06, 'epoch': 1.13}
 38%|███▊      | 213/564 [05:37<09:03,  1.55s/it] 38%|███▊      | 214/564 [05:39<09:00,  1.54s/it]                                                 {'loss': 1.3829, 'grad_norm': 1.8510347824526223, 'learning_rate': 1.283363802559415e-06, 'epoch': 1.14}
 38%|███▊      | 214/564 [05:39<09:00,  1.54s/it] 38%|███▊      | 215/564 [05:41<09:01,  1.55s/it]                                                 {'loss': 1.1799, 'grad_norm': 1.6814278734360164, 'learning_rate': 1.2797074954296162e-06, 'epoch': 1.14}
 38%|███▊      | 215/564 [05:41<09:01,  1.55s/it] 38%|███▊      | 216/564 [05:42<09:00,  1.55s/it]                                                 {'loss': 1.2085, 'grad_norm': 1.7123174556844387, 'learning_rate': 1.276051188299817e-06, 'epoch': 1.15}
 38%|███▊      | 216/564 [05:42<09:00,  1.55s/it] 38%|███▊      | 217/564 [05:44<08:56,  1.55s/it]                                                 {'loss': 1.2072, 'grad_norm': 1.6803962614742394, 'learning_rate': 1.2723948811700182e-06, 'epoch': 1.15}
 38%|███▊      | 217/564 [05:44<08:56,  1.55s/it] 39%|███▊      | 218/564 [05:45<08:59,  1.56s/it]                                                 {'loss': 1.1298, 'grad_norm': 1.6527312166216164, 'learning_rate': 1.2687385740402192e-06, 'epoch': 1.16}
 39%|███▊      | 218/564 [05:45<08:59,  1.56s/it] 39%|███▉      | 219/564 [05:47<08:54,  1.55s/it]                                                 {'loss': 1.3368, 'grad_norm': 1.6486978720808494, 'learning_rate': 1.2650822669104205e-06, 'epoch': 1.16}
 39%|███▉      | 219/564 [05:47<08:54,  1.55s/it] 39%|███▉      | 220/564 [05:48<08:53,  1.55s/it]                                                 {'loss': 1.2446, 'grad_norm': 1.8413107981920758, 'learning_rate': 1.2614259597806217e-06, 'epoch': 1.17}
 39%|███▉      | 220/564 [05:48<08:53,  1.55s/it] 39%|███▉      | 221/564 [05:50<08:54,  1.56s/it]                                                 {'loss': 1.0609, 'grad_norm': 1.8338623242087502, 'learning_rate': 1.2577696526508225e-06, 'epoch': 1.18}
 39%|███▉      | 221/564 [05:50<08:54,  1.56s/it] 39%|███▉      | 222/564 [05:51<08:52,  1.56s/it]                                                 {'loss': 1.3033, 'grad_norm': 1.810832406021385, 'learning_rate': 1.2541133455210237e-06, 'epoch': 1.18}
 39%|███▉      | 222/564 [05:51<08:52,  1.56s/it] 40%|███▉      | 223/564 [05:53<08:51,  1.56s/it]                                                 {'loss': 1.0919, 'grad_norm': 1.8112298157192634, 'learning_rate': 1.2504570383912248e-06, 'epoch': 1.19}
 40%|███▉      | 223/564 [05:53<08:51,  1.56s/it] 40%|███▉      | 224/564 [05:55<08:49,  1.56s/it]                                                 {'loss': 1.4263, 'grad_norm': 1.6025779842248753, 'learning_rate': 1.246800731261426e-06, 'epoch': 1.19}
 40%|███▉      | 224/564 [05:55<08:49,  1.56s/it] 40%|███▉      | 225/564 [05:56<08:43,  1.54s/it]                                                 {'loss': 1.2035, 'grad_norm': 1.7379150311761584, 'learning_rate': 1.2431444241316268e-06, 'epoch': 1.2}
 40%|███▉      | 225/564 [05:56<08:43,  1.54s/it] 40%|████      | 226/564 [05:58<08:37,  1.53s/it]                                                 {'loss': 1.17, 'grad_norm': 1.617463737456956, 'learning_rate': 1.239488117001828e-06, 'epoch': 1.2}
 40%|████      | 226/564 [05:58<08:37,  1.53s/it] 40%|████      | 227/564 [05:59<08:40,  1.55s/it]                                                 {'loss': 1.1909, 'grad_norm': 1.7705427073226827, 'learning_rate': 1.2358318098720293e-06, 'epoch': 1.21}
 40%|████      | 227/564 [05:59<08:40,  1.55s/it] 40%|████      | 228/564 [06:01<08:40,  1.55s/it]                                                 {'loss': 1.0977, 'grad_norm': 1.7963473266266194, 'learning_rate': 1.2321755027422303e-06, 'epoch': 1.21}
 40%|████      | 228/564 [06:01<08:40,  1.55s/it] 41%|████      | 229/564 [06:02<08:41,  1.56s/it]                                                 {'loss': 1.1385, 'grad_norm': 1.6100513624032133, 'learning_rate': 1.2285191956124315e-06, 'epoch': 1.22}
 41%|████      | 229/564 [06:02<08:41,  1.56s/it] 41%|████      | 230/564 [06:04<08:58,  1.61s/it]                                                 {'loss': 1.1474, 'grad_norm': 1.4623713664605573, 'learning_rate': 1.2248628884826324e-06, 'epoch': 1.22}
 41%|████      | 230/564 [06:04<08:58,  1.61s/it] 41%|████      | 231/564 [06:06<08:50,  1.59s/it]                                                 {'loss': 1.2853, 'grad_norm': 1.7783580274295356, 'learning_rate': 1.2212065813528336e-06, 'epoch': 1.23}
 41%|████      | 231/564 [06:06<08:50,  1.59s/it] 41%|████      | 232/564 [06:07<08:43,  1.58s/it]                                                 {'loss': 1.3485, 'grad_norm': 2.5429028796365514, 'learning_rate': 1.2175502742230346e-06, 'epoch': 1.23}
 41%|████      | 232/564 [06:07<08:43,  1.58s/it] 41%|████▏     | 233/564 [06:09<08:37,  1.56s/it]                                                 {'loss': 1.1468, 'grad_norm': 1.8900598037551868, 'learning_rate': 1.2138939670932358e-06, 'epoch': 1.24}
 41%|████▏     | 233/564 [06:09<08:37,  1.56s/it] 41%|████▏     | 234/564 [06:10<08:33,  1.56s/it]                                                 {'loss': 1.1996, 'grad_norm': 1.4117485817171234, 'learning_rate': 1.2102376599634369e-06, 'epoch': 1.24}
 41%|████▏     | 234/564 [06:10<08:33,  1.56s/it] 42%|████▏     | 235/564 [06:12<08:37,  1.57s/it]                                                 {'loss': 1.1959, 'grad_norm': 1.7000200118060464, 'learning_rate': 1.2065813528336379e-06, 'epoch': 1.25}
 42%|████▏     | 235/564 [06:12<08:37,  1.57s/it] 42%|████▏     | 236/564 [06:13<08:35,  1.57s/it]                                                 {'loss': 1.1599, 'grad_norm': 1.814108406079855, 'learning_rate': 1.2029250457038391e-06, 'epoch': 1.26}
 42%|████▏     | 236/564 [06:13<08:35,  1.57s/it] 42%|████▏     | 237/564 [06:15<08:31,  1.57s/it]                                                 {'loss': 1.132, 'grad_norm': 1.8811316524894048, 'learning_rate': 1.1992687385740402e-06, 'epoch': 1.26}
 42%|████▏     | 237/564 [06:15<08:31,  1.57s/it] 42%|████▏     | 238/564 [06:16<08:27,  1.56s/it]                                                 {'loss': 1.1928, 'grad_norm': 1.7488488858918265, 'learning_rate': 1.1956124314442414e-06, 'epoch': 1.27}
 42%|████▏     | 238/564 [06:16<08:27,  1.56s/it] 42%|████▏     | 239/564 [06:18<08:23,  1.55s/it]                                                 {'loss': 1.2572, 'grad_norm': 1.6204329954274752, 'learning_rate': 1.1919561243144422e-06, 'epoch': 1.27}
 42%|████▏     | 239/564 [06:18<08:23,  1.55s/it] 43%|████▎     | 240/564 [06:20<08:21,  1.55s/it]                                                 {'loss': 1.1387, 'grad_norm': 1.4262787143737523, 'learning_rate': 1.1882998171846434e-06, 'epoch': 1.28}
 43%|████▎     | 240/564 [06:20<08:21,  1.55s/it] 43%|████▎     | 241/564 [06:21<08:20,  1.55s/it]                                                 {'loss': 1.254, 'grad_norm': 1.6519939163643433, 'learning_rate': 1.1846435100548447e-06, 'epoch': 1.28}
 43%|████▎     | 241/564 [06:21<08:20,  1.55s/it] 43%|████▎     | 242/564 [06:23<08:20,  1.55s/it]                                                 {'loss': 1.2172, 'grad_norm': 1.7808035248254102, 'learning_rate': 1.1809872029250457e-06, 'epoch': 1.29}
 43%|████▎     | 242/564 [06:23<08:20,  1.55s/it] 43%|████▎     | 243/564 [06:24<08:15,  1.54s/it]                                                 {'loss': 0.9566, 'grad_norm': 1.9400307752288164, 'learning_rate': 1.1773308957952467e-06, 'epoch': 1.29}
 43%|████▎     | 243/564 [06:24<08:15,  1.54s/it] 43%|████▎     | 244/564 [06:26<08:10,  1.53s/it]                                                 {'loss': 1.2535, 'grad_norm': 1.8326496907049807, 'learning_rate': 1.1736745886654477e-06, 'epoch': 1.3}
 43%|████▎     | 244/564 [06:26<08:10,  1.53s/it] 43%|████▎     | 245/564 [06:27<08:09,  1.53s/it]                                                 {'loss': 1.2835, 'grad_norm': 1.792436573538094, 'learning_rate': 1.170018281535649e-06, 'epoch': 1.3}
 43%|████▎     | 245/564 [06:27<08:09,  1.53s/it] 44%|████▎     | 246/564 [06:29<08:10,  1.54s/it]                                                 {'loss': 1.2873, 'grad_norm': 1.7238871014946857, 'learning_rate': 1.16636197440585e-06, 'epoch': 1.31}
 44%|████▎     | 246/564 [06:29<08:10,  1.54s/it] 44%|████▍     | 247/564 [06:30<08:12,  1.55s/it]                                                 {'loss': 1.271, 'grad_norm': 1.6771435025087806, 'learning_rate': 1.1627056672760512e-06, 'epoch': 1.31}
 44%|████▍     | 247/564 [06:30<08:12,  1.55s/it] 44%|████▍     | 248/564 [06:32<08:10,  1.55s/it]                                                 {'loss': 1.0626, 'grad_norm': 1.730010520745991, 'learning_rate': 1.1590493601462523e-06, 'epoch': 1.32}
 44%|████▍     | 248/564 [06:32<08:10,  1.55s/it] 44%|████▍     | 249/564 [06:33<08:08,  1.55s/it]                                                 {'loss': 1.0846, 'grad_norm': 1.5478749537649599, 'learning_rate': 1.1553930530164533e-06, 'epoch': 1.32}
 44%|████▍     | 249/564 [06:33<08:08,  1.55s/it] 44%|████▍     | 250/564 [06:35<08:07,  1.55s/it]                                                 {'loss': 1.2311, 'grad_norm': 1.6201246812180647, 'learning_rate': 1.1517367458866545e-06, 'epoch': 1.33}
 44%|████▍     | 250/564 [06:35<08:07,  1.55s/it] 45%|████▍     | 251/564 [06:37<08:02,  1.54s/it]                                                 {'loss': 1.0364, 'grad_norm': 1.6779980238377015, 'learning_rate': 1.1480804387568555e-06, 'epoch': 1.34}
 45%|████▍     | 251/564 [06:37<08:02,  1.54s/it] 45%|████▍     | 252/564 [06:38<08:03,  1.55s/it]                                                 {'loss': 1.2551, 'grad_norm': 1.6922342251219071, 'learning_rate': 1.1444241316270566e-06, 'epoch': 1.34}
 45%|████▍     | 252/564 [06:38<08:03,  1.55s/it] 45%|████▍     | 253/564 [06:40<08:01,  1.55s/it]                                                 {'loss': 1.2688, 'grad_norm': 1.606728428730723, 'learning_rate': 1.1407678244972576e-06, 'epoch': 1.35}
 45%|████▍     | 253/564 [06:40<08:01,  1.55s/it] 45%|████▌     | 254/564 [06:41<08:00,  1.55s/it]                                                 {'loss': 1.259, 'grad_norm': 1.716694538403854, 'learning_rate': 1.1371115173674588e-06, 'epoch': 1.35}
 45%|████▌     | 254/564 [06:41<08:00,  1.55s/it] 45%|████▌     | 255/564 [06:43<08:01,  1.56s/it]                                                 {'loss': 1.1866, 'grad_norm': 1.609262632243343, 'learning_rate': 1.13345521023766e-06, 'epoch': 1.36}
 45%|████▌     | 255/564 [06:43<08:01,  1.56s/it] 45%|████▌     | 256/564 [06:44<07:59,  1.56s/it]                                                 {'loss': 1.2164, 'grad_norm': 1.6741843066859263, 'learning_rate': 1.1297989031078609e-06, 'epoch': 1.36}
 45%|████▌     | 256/564 [06:44<07:59,  1.56s/it] 46%|████▌     | 257/564 [06:46<07:54,  1.55s/it]                                                 {'loss': 1.0833, 'grad_norm': 1.697226942892335, 'learning_rate': 1.126142595978062e-06, 'epoch': 1.37}
 46%|████▌     | 257/564 [06:46<07:54,  1.55s/it] 46%|████▌     | 258/564 [06:47<07:52,  1.54s/it]                                                 {'loss': 1.3398, 'grad_norm': 1.609283674405401, 'learning_rate': 1.1224862888482631e-06, 'epoch': 1.37}
 46%|████▌     | 258/564 [06:47<07:52,  1.54s/it] 46%|████▌     | 259/564 [06:49<07:51,  1.54s/it]                                                 {'loss': 1.2729, 'grad_norm': 1.8873375286319987, 'learning_rate': 1.1188299817184644e-06, 'epoch': 1.38}
 46%|████▌     | 259/564 [06:49<07:51,  1.54s/it] 46%|████▌     | 260/564 [06:51<07:50,  1.55s/it]                                                 {'loss': 1.2468, 'grad_norm': 1.642224292622682, 'learning_rate': 1.1151736745886654e-06, 'epoch': 1.38}
 46%|████▌     | 260/564 [06:51<07:50,  1.55s/it] 46%|████▋     | 261/564 [06:52<07:46,  1.54s/it]                                                 {'loss': 1.3519, 'grad_norm': 1.7481195796870315, 'learning_rate': 1.1115173674588664e-06, 'epoch': 1.39}
 46%|████▋     | 261/564 [06:52<07:46,  1.54s/it] 46%|████▋     | 262/564 [06:54<07:46,  1.54s/it]                                                 {'loss': 1.3098, 'grad_norm': 1.6856846064667417, 'learning_rate': 1.1078610603290676e-06, 'epoch': 1.39}
 46%|████▋     | 262/564 [06:54<07:46,  1.54s/it] 47%|████▋     | 263/564 [06:55<07:45,  1.55s/it]                                                 {'loss': 1.2046, 'grad_norm': 1.762246063898555, 'learning_rate': 1.1042047531992687e-06, 'epoch': 1.4}
 47%|████▋     | 263/564 [06:55<07:45,  1.55s/it] 47%|████▋     | 264/564 [06:57<07:41,  1.54s/it]                                                 {'loss': 1.2482, 'grad_norm': 1.7278519322816424, 'learning_rate': 1.10054844606947e-06, 'epoch': 1.4}
 47%|████▋     | 264/564 [06:57<07:41,  1.54s/it] 47%|████▋     | 265/564 [06:58<07:40,  1.54s/it]                                                 {'loss': 1.286, 'grad_norm': 1.5493013495879673, 'learning_rate': 1.0968921389396707e-06, 'epoch': 1.41}
 47%|████▋     | 265/564 [06:58<07:40,  1.54s/it] 47%|████▋     | 266/564 [07:00<07:39,  1.54s/it]                                                 {'loss': 1.184, 'grad_norm': 1.5464174702094629, 'learning_rate': 1.093235831809872e-06, 'epoch': 1.41}
 47%|████▋     | 266/564 [07:00<07:39,  1.54s/it] 47%|████▋     | 267/564 [07:01<07:41,  1.55s/it]                                                 {'loss': 0.9721, 'grad_norm': 1.7363171160109854, 'learning_rate': 1.089579524680073e-06, 'epoch': 1.42}
 47%|████▋     | 267/564 [07:01<07:41,  1.55s/it] 48%|████▊     | 268/564 [07:03<07:39,  1.55s/it]                                                 {'loss': 1.066, 'grad_norm': 1.5289050854731328, 'learning_rate': 1.0859232175502742e-06, 'epoch': 1.43}
 48%|████▊     | 268/564 [07:03<07:39,  1.55s/it] 48%|████▊     | 269/564 [07:04<07:34,  1.54s/it]                                                 {'loss': 1.2734, 'grad_norm': 1.9225392233610448, 'learning_rate': 1.0822669104204754e-06, 'epoch': 1.43}
 48%|████▊     | 269/564 [07:04<07:34,  1.54s/it] 48%|████▊     | 270/564 [07:06<07:34,  1.54s/it]                                                 {'loss': 1.2572, 'grad_norm': 1.812058574755414, 'learning_rate': 1.0786106032906763e-06, 'epoch': 1.44}
 48%|████▊     | 270/564 [07:06<07:34,  1.54s/it] 48%|████▊     | 271/564 [07:07<07:30,  1.54s/it]                                                 {'loss': 1.1802, 'grad_norm': 1.9820510625996375, 'learning_rate': 1.0749542961608775e-06, 'epoch': 1.44}
 48%|████▊     | 271/564 [07:07<07:30,  1.54s/it] 48%|████▊     | 272/564 [07:09<07:31,  1.54s/it]                                                 {'loss': 1.1142, 'grad_norm': 1.712565419972385, 'learning_rate': 1.0712979890310785e-06, 'epoch': 1.45}
 48%|████▊     | 272/564 [07:09<07:31,  1.54s/it] 48%|████▊     | 273/564 [07:11<07:32,  1.56s/it]                                                 {'loss': 1.1401, 'grad_norm': 1.8372922290912936, 'learning_rate': 1.0676416819012797e-06, 'epoch': 1.45}
 48%|████▊     | 273/564 [07:11<07:32,  1.56s/it] 49%|████▊     | 274/564 [07:12<07:32,  1.56s/it]                                                 {'loss': 1.2417, 'grad_norm': 1.5873716697576135, 'learning_rate': 1.0639853747714806e-06, 'epoch': 1.46}
 49%|████▊     | 274/564 [07:12<07:32,  1.56s/it] 49%|████▉     | 275/564 [07:14<07:31,  1.56s/it]                                                 {'loss': 1.3032, 'grad_norm': 1.9117342425985377, 'learning_rate': 1.0603290676416818e-06, 'epoch': 1.46}
 49%|████▉     | 275/564 [07:14<07:31,  1.56s/it] 49%|████▉     | 276/564 [07:15<07:29,  1.56s/it]                                                 {'loss': 1.0491, 'grad_norm': 1.683765221829689, 'learning_rate': 1.056672760511883e-06, 'epoch': 1.47}
 49%|████▉     | 276/564 [07:15<07:29,  1.56s/it] 49%|████▉     | 277/564 [07:17<07:28,  1.56s/it]                                                 {'loss': 1.0521, 'grad_norm': 1.7583240070210822, 'learning_rate': 1.053016453382084e-06, 'epoch': 1.47}
 49%|████▉     | 277/564 [07:17<07:28,  1.56s/it] 49%|████▉     | 278/564 [07:18<07:29,  1.57s/it]                                                 {'loss': 1.0584, 'grad_norm': 1.5830637955210713, 'learning_rate': 1.0493601462522853e-06, 'epoch': 1.48}
 49%|████▉     | 278/564 [07:18<07:29,  1.57s/it] 49%|████▉     | 279/564 [07:20<07:26,  1.57s/it]                                                 {'loss': 1.0614, 'grad_norm': 1.7064402760233872, 'learning_rate': 1.045703839122486e-06, 'epoch': 1.48}
 49%|████▉     | 279/564 [07:20<07:26,  1.57s/it] 50%|████▉     | 280/564 [07:22<07:21,  1.55s/it]                                                 {'loss': 1.3017, 'grad_norm': 1.5404531403042667, 'learning_rate': 1.0420475319926873e-06, 'epoch': 1.49}
 50%|████▉     | 280/564 [07:22<07:21,  1.55s/it] 50%|████▉     | 281/564 [07:23<07:18,  1.55s/it]                                                 {'loss': 1.2592, 'grad_norm': 1.7063329180780413, 'learning_rate': 1.0383912248628884e-06, 'epoch': 1.49}
 50%|████▉     | 281/564 [07:23<07:18,  1.55s/it] 50%|█████     | 282/564 [07:25<07:16,  1.55s/it]                                                 {'loss': 1.3301, 'grad_norm': 1.8640502126814151, 'learning_rate': 1.0347349177330896e-06, 'epoch': 1.5}
 50%|█████     | 282/564 [07:25<07:16,  1.55s/it] 50%|█████     | 283/564 [07:26<07:13,  1.54s/it]                                                 {'loss': 1.215, 'grad_norm': 1.6256889567542203, 'learning_rate': 1.0310786106032906e-06, 'epoch': 1.51}
 50%|█████     | 283/564 [07:26<07:13,  1.54s/it] 50%|█████     | 284/564 [07:28<07:12,  1.55s/it]                                                 {'loss': 1.2206, 'grad_norm': 1.6276402476242038, 'learning_rate': 1.0274223034734916e-06, 'epoch': 1.51}
 50%|█████     | 284/564 [07:28<07:12,  1.55s/it] 51%|█████     | 285/564 [07:29<07:14,  1.56s/it]                                                 {'loss': 1.17, 'grad_norm': 1.5868045865209495, 'learning_rate': 1.0237659963436929e-06, 'epoch': 1.52}
 51%|█████     | 285/564 [07:29<07:14,  1.56s/it] 51%|█████     | 286/564 [07:31<07:12,  1.55s/it]                                                 {'loss': 1.2248, 'grad_norm': 1.6017152168547526, 'learning_rate': 1.020109689213894e-06, 'epoch': 1.52}
 51%|█████     | 286/564 [07:31<07:12,  1.55s/it] 51%|█████     | 287/564 [07:32<07:12,  1.56s/it]                                                 {'loss': 1.0082, 'grad_norm': 1.9027456882271323, 'learning_rate': 1.0164533820840951e-06, 'epoch': 1.53}
 51%|█████     | 287/564 [07:32<07:12,  1.56s/it] 51%|█████     | 288/564 [07:34<07:13,  1.57s/it]                                                 {'loss': 1.2941, 'grad_norm': 1.7732122357880569, 'learning_rate': 1.012797074954296e-06, 'epoch': 1.53}
 51%|█████     | 288/564 [07:34<07:13,  1.57s/it] 51%|█████     | 289/564 [07:36<07:08,  1.56s/it]                                                 {'loss': 1.1034, 'grad_norm': 2.0501836883952214, 'learning_rate': 1.0091407678244972e-06, 'epoch': 1.54}
 51%|█████     | 289/564 [07:36<07:08,  1.56s/it] 51%|█████▏    | 290/564 [07:37<07:06,  1.56s/it]                                                 {'loss': 1.3648, 'grad_norm': 1.8227465021290576, 'learning_rate': 1.0054844606946984e-06, 'epoch': 1.54}
 51%|█████▏    | 290/564 [07:37<07:06,  1.56s/it] 52%|█████▏    | 291/564 [07:39<07:01,  1.54s/it]                                                 {'loss': 1.1751, 'grad_norm': 1.7137751016724765, 'learning_rate': 1.0018281535648994e-06, 'epoch': 1.55}
 52%|█████▏    | 291/564 [07:39<07:01,  1.54s/it] 52%|█████▏    | 292/564 [07:40<06:56,  1.53s/it]                                                 {'loss': 1.0622, 'grad_norm': 1.8460133768125169, 'learning_rate': 9.981718464351005e-07, 'epoch': 1.55}
 52%|█████▏    | 292/564 [07:40<06:56,  1.53s/it] 52%|█████▏    | 293/564 [07:42<06:57,  1.54s/it]                                                 {'loss': 1.3303, 'grad_norm': 1.7466504244627488, 'learning_rate': 9.945155393053017e-07, 'epoch': 1.56}
 52%|█████▏    | 293/564 [07:42<06:57,  1.54s/it] 52%|█████▏    | 294/564 [07:43<06:57,  1.54s/it]                                                 {'loss': 1.2812, 'grad_norm': 1.5296601454702097, 'learning_rate': 9.908592321755027e-07, 'epoch': 1.56}
 52%|█████▏    | 294/564 [07:43<06:57,  1.54s/it] 52%|█████▏    | 295/564 [07:45<06:55,  1.54s/it]                                                 {'loss': 1.247, 'grad_norm': 1.71023780640501, 'learning_rate': 9.872029250457037e-07, 'epoch': 1.57}
 52%|█████▏    | 295/564 [07:45<06:55,  1.54s/it] 52%|█████▏    | 296/564 [07:46<06:55,  1.55s/it]                                                 {'loss': 0.9961, 'grad_norm': 1.8510825410757292, 'learning_rate': 9.835466179159048e-07, 'epoch': 1.57}
 52%|█████▏    | 296/564 [07:46<06:55,  1.55s/it] 53%|█████▎    | 297/564 [07:48<06:53,  1.55s/it]                                                 {'loss': 1.2963, 'grad_norm': 1.5904342924717818, 'learning_rate': 9.79890310786106e-07, 'epoch': 1.58}
 53%|█████▎    | 297/564 [07:48<06:53,  1.55s/it] 53%|█████▎    | 298/564 [07:49<06:50,  1.54s/it]                                                 {'loss': 1.377, 'grad_norm': 1.5919087908975507, 'learning_rate': 9.76234003656307e-07, 'epoch': 1.59}
 53%|█████▎    | 298/564 [07:49<06:50,  1.54s/it] 53%|█████▎    | 299/564 [07:51<06:47,  1.54s/it]                                                 {'loss': 1.2561, 'grad_norm': 1.6848001543414826, 'learning_rate': 9.725776965265083e-07, 'epoch': 1.59}
 53%|█████▎    | 299/564 [07:51<06:47,  1.54s/it] 53%|█████▎    | 300/564 [07:52<06:43,  1.53s/it]                                                 {'loss': 1.1864, 'grad_norm': 1.851924180201075, 'learning_rate': 9.689213893967093e-07, 'epoch': 1.6}
 53%|█████▎    | 300/564 [07:52<06:43,  1.53s/it] 53%|█████▎    | 301/564 [07:54<06:43,  1.54s/it]                                                 {'loss': 1.2767, 'grad_norm': 1.7555431986970167, 'learning_rate': 9.652650822669103e-07, 'epoch': 1.6}
 53%|█████▎    | 301/564 [07:54<06:43,  1.54s/it] 54%|█████▎    | 302/564 [07:56<06:41,  1.53s/it]                                                 {'loss': 1.2937, 'grad_norm': 1.602786951038925, 'learning_rate': 9.616087751371115e-07, 'epoch': 1.61}
 54%|█████▎    | 302/564 [07:56<06:41,  1.53s/it] 54%|█████▎    | 303/564 [07:57<06:43,  1.55s/it]                                                 {'loss': 1.4181, 'grad_norm': 2.2792358921334634, 'learning_rate': 9.579524680073126e-07, 'epoch': 1.61}
 54%|█████▎    | 303/564 [07:57<06:43,  1.55s/it] 54%|█████▍    | 304/564 [07:59<06:43,  1.55s/it]                                                 {'loss': 1.3964, 'grad_norm': 1.8048618026687822, 'learning_rate': 9.542961608775136e-07, 'epoch': 1.62}
 54%|█████▍    | 304/564 [07:59<06:43,  1.55s/it] 54%|█████▍    | 305/564 [08:00<06:41,  1.55s/it]                                                 {'loss': 1.3152, 'grad_norm': 1.7274568801718744, 'learning_rate': 9.506398537477147e-07, 'epoch': 1.62}
 54%|█████▍    | 305/564 [08:00<06:41,  1.55s/it] 54%|█████▍    | 306/564 [08:02<06:39,  1.55s/it]                                                 {'loss': 1.2205, 'grad_norm': 1.6561896390877309, 'learning_rate': 9.469835466179159e-07, 'epoch': 1.63}
 54%|█████▍    | 306/564 [08:02<06:39,  1.55s/it] 54%|█████▍    | 307/564 [08:03<06:36,  1.54s/it]                                                 {'loss': 1.1157, 'grad_norm': 1.763940417314856, 'learning_rate': 9.43327239488117e-07, 'epoch': 1.63}
 54%|█████▍    | 307/564 [08:03<06:36,  1.54s/it] 55%|█████▍    | 308/564 [08:05<06:36,  1.55s/it]                                                 {'loss': 1.1871, 'grad_norm': 1.8621867007775874, 'learning_rate': 9.396709323583181e-07, 'epoch': 1.64}
 55%|█████▍    | 308/564 [08:05<06:36,  1.55s/it] 55%|█████▍    | 309/564 [08:06<06:38,  1.56s/it]                                                 {'loss': 1.1716, 'grad_norm': 2.038325732313216, 'learning_rate': 9.360146252285191e-07, 'epoch': 1.64}
 55%|█████▍    | 309/564 [08:06<06:38,  1.56s/it] 55%|█████▍    | 310/564 [08:08<06:37,  1.57s/it]                                                 {'loss': 1.1525, 'grad_norm': 1.7258666157520646, 'learning_rate': 9.323583180987203e-07, 'epoch': 1.65}
 55%|█████▍    | 310/564 [08:08<06:37,  1.57s/it] 55%|█████▌    | 311/564 [08:10<06:34,  1.56s/it]                                                 {'loss': 1.2683, 'grad_norm': 1.71685641526108, 'learning_rate': 9.287020109689213e-07, 'epoch': 1.65}
 55%|█████▌    | 311/564 [08:10<06:34,  1.56s/it] 55%|█████▌    | 312/564 [08:11<06:30,  1.55s/it]                                                 {'loss': 1.299, 'grad_norm': 1.6176977743140044, 'learning_rate': 9.250457038391224e-07, 'epoch': 1.66}
 55%|█████▌    | 312/564 [08:11<06:30,  1.55s/it] 55%|█████▌    | 313/564 [08:13<06:33,  1.57s/it]                                                 {'loss': 1.117, 'grad_norm': 1.5124605316418602, 'learning_rate': 9.213893967093235e-07, 'epoch': 1.66}
 55%|█████▌    | 313/564 [08:13<06:33,  1.57s/it] 56%|█████▌    | 314/564 [08:14<06:35,  1.58s/it]                                                 {'loss': 1.1747, 'grad_norm': 1.6719312938228585, 'learning_rate': 9.177330895795247e-07, 'epoch': 1.67}
 56%|█████▌    | 314/564 [08:14<06:35,  1.58s/it] 56%|█████▌    | 315/564 [08:16<06:33,  1.58s/it]                                                 {'loss': 1.3246, 'grad_norm': 1.6937971526839333, 'learning_rate': 9.140767824497257e-07, 'epoch': 1.68}
 56%|█████▌    | 315/564 [08:16<06:33,  1.58s/it] 56%|█████▌    | 316/564 [08:18<06:52,  1.66s/it]                                                 {'loss': 1.3048, 'grad_norm': 1.9408970716837262, 'learning_rate': 9.104204753199268e-07, 'epoch': 1.68}
 56%|█████▌    | 316/564 [08:18<06:52,  1.66s/it] 56%|█████▌    | 317/564 [08:19<06:44,  1.64s/it]                                                 {'loss': 1.1549, 'grad_norm': 2.098629063887699, 'learning_rate': 9.06764168190128e-07, 'epoch': 1.69}
 56%|█████▌    | 317/564 [08:19<06:44,  1.64s/it] 56%|█████▋    | 318/564 [08:21<06:38,  1.62s/it]                                                 {'loss': 1.241, 'grad_norm': 1.7253834481626844, 'learning_rate': 9.03107861060329e-07, 'epoch': 1.69}
 56%|█████▋    | 318/564 [08:21<06:38,  1.62s/it] 57%|█████▋    | 319/564 [08:22<06:31,  1.60s/it]                                                 {'loss': 1.0888, 'grad_norm': 1.7249170982360669, 'learning_rate': 8.994515539305301e-07, 'epoch': 1.7}
 57%|█████▋    | 319/564 [08:22<06:31,  1.60s/it] 57%|█████▋    | 320/564 [08:24<06:26,  1.59s/it]                                                 {'loss': 1.1893, 'grad_norm': 1.785866130952873, 'learning_rate': 8.957952468007312e-07, 'epoch': 1.7}
 57%|█████▋    | 320/564 [08:24<06:26,  1.59s/it] 57%|█████▋    | 321/564 [08:26<06:23,  1.58s/it]                                                 {'loss': 1.2458, 'grad_norm': 1.8480810119749653, 'learning_rate': 8.921389396709324e-07, 'epoch': 1.71}
 57%|█████▋    | 321/564 [08:26<06:23,  1.58s/it] 57%|█████▋    | 322/564 [08:27<06:18,  1.56s/it]                                                 {'loss': 1.2659, 'grad_norm': 2.080177588739768, 'learning_rate': 8.884826325411334e-07, 'epoch': 1.71}
 57%|█████▋    | 322/564 [08:27<06:18,  1.56s/it] 57%|█████▋    | 323/564 [08:29<06:14,  1.55s/it]                                                 {'loss': 1.2914, 'grad_norm': 2.027513123598377, 'learning_rate': 8.848263254113345e-07, 'epoch': 1.72}
 57%|█████▋    | 323/564 [08:29<06:14,  1.55s/it] 57%|█████▋    | 324/564 [08:30<06:13,  1.56s/it]                                                 {'loss': 1.3131, 'grad_norm': 1.604984406599898, 'learning_rate': 8.811700182815355e-07, 'epoch': 1.72}
 57%|█████▋    | 324/564 [08:30<06:13,  1.56s/it] 58%|█████▊    | 325/564 [08:32<06:11,  1.55s/it]                                                 {'loss': 1.1873, 'grad_norm': 1.682566464006463, 'learning_rate': 8.775137111517367e-07, 'epoch': 1.73}
 58%|█████▊    | 325/564 [08:32<06:11,  1.55s/it] 58%|█████▊    | 326/564 [08:33<06:10,  1.56s/it]                                                 {'loss': 1.1272, 'grad_norm': 1.6401840963661094, 'learning_rate': 8.738574040219377e-07, 'epoch': 1.73}
 58%|█████▊    | 326/564 [08:33<06:10,  1.56s/it] 58%|█████▊    | 327/564 [08:35<06:08,  1.55s/it]                                                 {'loss': 1.1064, 'grad_norm': 1.6880335615704127, 'learning_rate': 8.702010968921389e-07, 'epoch': 1.74}
 58%|█████▊    | 327/564 [08:35<06:08,  1.55s/it] 58%|█████▊    | 328/564 [08:36<06:06,  1.55s/it]                                                 {'loss': 1.1969, 'grad_norm': 1.6041572271704874, 'learning_rate': 8.665447897623401e-07, 'epoch': 1.74}
 58%|█████▊    | 328/564 [08:36<06:06,  1.55s/it] 58%|█████▊    | 329/564 [08:38<06:04,  1.55s/it]                                                 {'loss': 1.0633, 'grad_norm': 1.6844281512413937, 'learning_rate': 8.628884826325411e-07, 'epoch': 1.75}
 58%|█████▊    | 329/564 [08:38<06:04,  1.55s/it] 59%|█████▊    | 330/564 [08:39<06:01,  1.55s/it]                                                 {'loss': 1.1477, 'grad_norm': 1.618268106469923, 'learning_rate': 8.592321755027422e-07, 'epoch': 1.76}
 59%|█████▊    | 330/564 [08:39<06:01,  1.55s/it] 59%|█████▊    | 331/564 [08:41<05:59,  1.54s/it]                                                 {'loss': 1.157, 'grad_norm': 1.720363889510129, 'learning_rate': 8.555758683729432e-07, 'epoch': 1.76}
 59%|█████▊    | 331/564 [08:41<05:59,  1.54s/it] 59%|█████▉    | 332/564 [08:43<05:56,  1.54s/it]                                                 {'loss': 1.0887, 'grad_norm': 1.7209139818829131, 'learning_rate': 8.519195612431444e-07, 'epoch': 1.77}
 59%|█████▉    | 332/564 [08:43<05:56,  1.54s/it] 59%|█████▉    | 333/564 [08:44<05:54,  1.54s/it]                                                 {'loss': 1.2601, 'grad_norm': 1.7667175609380075, 'learning_rate': 8.482632541133454e-07, 'epoch': 1.77}
 59%|█████▉    | 333/564 [08:44<05:54,  1.54s/it] 59%|█████▉    | 334/564 [08:46<05:52,  1.53s/it]                                                 {'loss': 1.2646, 'grad_norm': 1.6859295803648835, 'learning_rate': 8.446069469835466e-07, 'epoch': 1.78}
 59%|█████▉    | 334/564 [08:46<05:52,  1.53s/it] 59%|█████▉    | 335/564 [08:47<05:50,  1.53s/it]                                                 {'loss': 1.1328, 'grad_norm': 1.7853815535386213, 'learning_rate': 8.409506398537477e-07, 'epoch': 1.78}
 59%|█████▉    | 335/564 [08:47<05:50,  1.53s/it] 60%|█████▉    | 336/564 [08:49<05:51,  1.54s/it]                                                 {'loss': 1.0422, 'grad_norm': 1.77034616591466, 'learning_rate': 8.372943327239488e-07, 'epoch': 1.79}
 60%|█████▉    | 336/564 [08:49<05:51,  1.54s/it] 60%|█████▉    | 337/564 [08:50<05:51,  1.55s/it]                                                 {'loss': 1.3273, 'grad_norm': 1.5373175774230523, 'learning_rate': 8.336380255941499e-07, 'epoch': 1.79}
 60%|█████▉    | 337/564 [08:50<05:51,  1.55s/it] 60%|█████▉    | 338/564 [08:52<05:50,  1.55s/it]                                                 {'loss': 1.221, 'grad_norm': 1.778083667430643, 'learning_rate': 8.299817184643509e-07, 'epoch': 1.8}
 60%|█████▉    | 338/564 [08:52<05:50,  1.55s/it] 60%|██████    | 339/564 [08:53<05:47,  1.54s/it]                                                 {'loss': 1.2537, 'grad_norm': 1.6151415046489535, 'learning_rate': 8.263254113345521e-07, 'epoch': 1.8}
 60%|██████    | 339/564 [08:53<05:47,  1.54s/it] 60%|██████    | 340/564 [08:55<05:47,  1.55s/it]                                                 {'loss': 1.2331, 'grad_norm': 1.7411446141405815, 'learning_rate': 8.226691042047532e-07, 'epoch': 1.81}
 60%|██████    | 340/564 [08:55<05:47,  1.55s/it] 60%|██████    | 341/564 [08:56<05:46,  1.55s/it]                                                 {'loss': 1.0589, 'grad_norm': 1.7401232344981459, 'learning_rate': 8.190127970749543e-07, 'epoch': 1.81}
 60%|██████    | 341/564 [08:56<05:46,  1.55s/it] 61%|██████    | 342/564 [08:58<05:43,  1.55s/it]                                                 {'loss': 1.2083, 'grad_norm': 1.9754186995817773, 'learning_rate': 8.153564899451553e-07, 'epoch': 1.82}
 61%|██████    | 342/564 [08:58<05:43,  1.55s/it] 61%|██████    | 343/564 [09:00<05:45,  1.56s/it]                                                 {'loss': 1.3102, 'grad_norm': 1.8254647757984672, 'learning_rate': 8.117001828153565e-07, 'epoch': 1.82}
 61%|██████    | 343/564 [09:00<05:45,  1.56s/it] 61%|██████    | 344/564 [09:01<05:43,  1.56s/it]                                                 {'loss': 1.1583, 'grad_norm': 1.6924759312421005, 'learning_rate': 8.080438756855575e-07, 'epoch': 1.83}
 61%|██████    | 344/564 [09:01<05:43,  1.56s/it] 61%|██████    | 345/564 [09:03<05:42,  1.56s/it]                                                 {'loss': 1.3211, 'grad_norm': 1.6261806188366599, 'learning_rate': 8.043875685557586e-07, 'epoch': 1.84}
 61%|██████    | 345/564 [09:03<05:42,  1.56s/it] 61%|██████▏   | 346/564 [09:04<05:41,  1.57s/it]                                                 {'loss': 1.3899, 'grad_norm': 1.6694783943288987, 'learning_rate': 8.007312614259597e-07, 'epoch': 1.84}
 61%|██████▏   | 346/564 [09:04<05:41,  1.57s/it] 62%|██████▏   | 347/564 [09:06<05:36,  1.55s/it]                                                 {'loss': 1.3292, 'grad_norm': 1.6704808783580596, 'learning_rate': 7.970749542961609e-07, 'epoch': 1.85}
 62%|██████▏   | 347/564 [09:06<05:36,  1.55s/it] 62%|██████▏   | 348/564 [09:07<05:35,  1.55s/it]                                                 {'loss': 1.074, 'grad_norm': 1.7003161501357786, 'learning_rate': 7.93418647166362e-07, 'epoch': 1.85}
 62%|██████▏   | 348/564 [09:07<05:35,  1.55s/it] 62%|██████▏   | 349/564 [09:09<05:32,  1.54s/it]                                                 {'loss': 1.2661, 'grad_norm': 1.675346163852535, 'learning_rate': 7.89762340036563e-07, 'epoch': 1.86}
 62%|██████▏   | 349/564 [09:09<05:32,  1.54s/it] 62%|██████▏   | 350/564 [09:10<05:31,  1.55s/it]                                                 {'loss': 1.1462, 'grad_norm': 2.1735906886183747, 'learning_rate': 7.861060329067642e-07, 'epoch': 1.86}
 62%|██████▏   | 350/564 [09:10<05:31,  1.55s/it] 62%|██████▏   | 351/564 [09:12<05:31,  1.56s/it]                                                 {'loss': 1.2635, 'grad_norm': 1.5878444943328784, 'learning_rate': 7.824497257769652e-07, 'epoch': 1.87}
 62%|██████▏   | 351/564 [09:12<05:31,  1.56s/it] 62%|██████▏   | 352/564 [09:14<05:32,  1.57s/it]                                                 {'loss': 1.3122, 'grad_norm': 1.72463046397493, 'learning_rate': 7.787934186471663e-07, 'epoch': 1.87}
 62%|██████▏   | 352/564 [09:14<05:32,  1.57s/it] 63%|██████▎   | 353/564 [09:15<05:29,  1.56s/it]                                                 {'loss': 1.1414, 'grad_norm': 1.9041511804352875, 'learning_rate': 7.751371115173673e-07, 'epoch': 1.88}
 63%|██████▎   | 353/564 [09:15<05:29,  1.56s/it] 63%|██████▎   | 354/564 [09:17<05:29,  1.57s/it]                                                 {'loss': 1.3231, 'grad_norm': 1.8013938215642133, 'learning_rate': 7.714808043875686e-07, 'epoch': 1.88}
 63%|██████▎   | 354/564 [09:17<05:29,  1.57s/it] 63%|██████▎   | 355/564 [09:18<05:27,  1.57s/it]                                                 {'loss': 1.0925, 'grad_norm': 1.9917555540221192, 'learning_rate': 7.678244972577696e-07, 'epoch': 1.89}
 63%|██████▎   | 355/564 [09:18<05:27,  1.57s/it] 63%|██████▎   | 356/564 [09:20<05:21,  1.55s/it]                                                 {'loss': 1.2831, 'grad_norm': 1.69629971465263, 'learning_rate': 7.641681901279707e-07, 'epoch': 1.89}
 63%|██████▎   | 356/564 [09:20<05:21,  1.55s/it] 63%|██████▎   | 357/564 [09:21<05:20,  1.55s/it]                                                 {'loss': 1.1811, 'grad_norm': 1.5617411269057233, 'learning_rate': 7.605118829981719e-07, 'epoch': 1.9}
 63%|██████▎   | 357/564 [09:21<05:20,  1.55s/it] 63%|██████▎   | 358/564 [09:23<05:17,  1.54s/it]                                                 {'loss': 1.2758, 'grad_norm': 1.6425211902973318, 'learning_rate': 7.568555758683729e-07, 'epoch': 1.9}
 63%|██████▎   | 358/564 [09:23<05:17,  1.54s/it] 64%|██████▎   | 359/564 [09:24<05:14,  1.54s/it]                                                 {'loss': 1.1624, 'grad_norm': 1.673748782366815, 'learning_rate': 7.53199268738574e-07, 'epoch': 1.91}
 64%|██████▎   | 359/564 [09:24<05:14,  1.54s/it] 64%|██████▍   | 360/564 [09:26<05:14,  1.54s/it]                                                 {'loss': 1.1495, 'grad_norm': 1.6201269425376261, 'learning_rate': 7.49542961608775e-07, 'epoch': 1.91}
 64%|██████▍   | 360/564 [09:26<05:14,  1.54s/it] 64%|██████▍   | 361/564 [09:28<05:13,  1.55s/it]                                                 {'loss': 1.1318, 'grad_norm': 1.5499816095360874, 'learning_rate': 7.458866544789763e-07, 'epoch': 1.92}
 64%|██████▍   | 361/564 [09:28<05:13,  1.55s/it] 64%|██████▍   | 362/564 [09:29<05:13,  1.55s/it]                                                 {'loss': 1.2653, 'grad_norm': 1.6546803053278716, 'learning_rate': 7.422303473491773e-07, 'epoch': 1.93}
 64%|██████▍   | 362/564 [09:29<05:13,  1.55s/it] 64%|██████▍   | 363/564 [09:31<05:10,  1.55s/it]                                                 {'loss': 1.214, 'grad_norm': 1.8006685403356342, 'learning_rate': 7.385740402193784e-07, 'epoch': 1.93}
 64%|██████▍   | 363/564 [09:31<05:10,  1.55s/it] 65%|██████▍   | 364/564 [09:32<05:06,  1.53s/it]                                                 {'loss': 1.1765, 'grad_norm': 1.9164211533173907, 'learning_rate': 7.349177330895795e-07, 'epoch': 1.94}
 65%|██████▍   | 364/564 [09:32<05:06,  1.53s/it] 65%|██████▍   | 365/564 [09:34<05:05,  1.53s/it]                                                 {'loss': 1.4151, 'grad_norm': 1.721668089742088, 'learning_rate': 7.312614259597806e-07, 'epoch': 1.94}
 65%|██████▍   | 365/564 [09:34<05:05,  1.53s/it] 65%|██████▍   | 366/564 [09:35<05:03,  1.53s/it]                                                 {'loss': 1.2552, 'grad_norm': 1.751005683989299, 'learning_rate': 7.276051188299816e-07, 'epoch': 1.95}
 65%|██████▍   | 366/564 [09:35<05:03,  1.53s/it] 65%|██████▌   | 367/564 [09:37<05:05,  1.55s/it]                                                 {'loss': 1.1781, 'grad_norm': 1.8987697059882274, 'learning_rate': 7.239488117001827e-07, 'epoch': 1.95}
 65%|██████▌   | 367/564 [09:37<05:05,  1.55s/it] 65%|██████▌   | 368/564 [09:38<05:01,  1.54s/it]                                                 {'loss': 1.199, 'grad_norm': 1.914513261657668, 'learning_rate': 7.20292504570384e-07, 'epoch': 1.96}
 65%|██████▌   | 368/564 [09:38<05:01,  1.54s/it] 65%|██████▌   | 369/564 [09:40<05:02,  1.55s/it]                                                 {'loss': 1.3511, 'grad_norm': 1.759690043967038, 'learning_rate': 7.16636197440585e-07, 'epoch': 1.96}
 65%|██████▌   | 369/564 [09:40<05:02,  1.55s/it] 66%|██████▌   | 370/564 [09:41<05:02,  1.56s/it]                                                 {'loss': 1.0579, 'grad_norm': 1.8428647326934524, 'learning_rate': 7.129798903107861e-07, 'epoch': 1.97}
 66%|██████▌   | 370/564 [09:41<05:02,  1.56s/it] 66%|██████▌   | 371/564 [09:43<04:59,  1.55s/it]                                                 {'loss': 1.3362, 'grad_norm': 1.7914681759622575, 'learning_rate': 7.093235831809871e-07, 'epoch': 1.97}
 66%|██████▌   | 371/564 [09:43<04:59,  1.55s/it] 66%|██████▌   | 372/564 [09:45<04:58,  1.55s/it]                                                 {'loss': 1.0972, 'grad_norm': 1.8664692467819581, 'learning_rate': 7.056672760511883e-07, 'epoch': 1.98}
 66%|██████▌   | 372/564 [09:45<04:58,  1.55s/it] 66%|██████▌   | 373/564 [09:46<04:55,  1.54s/it]                                                 {'loss': 1.1845, 'grad_norm': 1.7489803394370182, 'learning_rate': 7.020109689213893e-07, 'epoch': 1.98}
 66%|██████▌   | 373/564 [09:46<04:55,  1.54s/it] 66%|██████▋   | 374/564 [09:48<04:55,  1.56s/it]                                                 {'loss': 1.1932, 'grad_norm': 1.7208702474639417, 'learning_rate': 6.983546617915904e-07, 'epoch': 1.99}
 66%|██████▋   | 374/564 [09:48<04:55,  1.56s/it] 66%|██████▋   | 375/564 [09:49<04:54,  1.56s/it]                                                 {'loss': 1.2204, 'grad_norm': 1.72900134103347, 'learning_rate': 6.946983546617916e-07, 'epoch': 1.99}
 66%|██████▋   | 375/564 [09:49<04:54,  1.56s/it] 67%|██████▋   | 376/564 [09:51<04:54,  1.57s/it]                                                 {'loss': 1.1722, 'grad_norm': 1.5917051845473862, 'learning_rate': 6.910420475319927e-07, 'epoch': 2.0}
 67%|██████▋   | 376/564 [09:51<04:54,  1.57s/it] 67%|██████▋   | 377/564 [09:52<04:52,  1.57s/it]                                                 {'loss': 1.3004, 'grad_norm': 1.6933683047225092, 'learning_rate': 6.873857404021938e-07, 'epoch': 2.01}
 67%|██████▋   | 377/564 [09:52<04:52,  1.57s/it] 67%|██████▋   | 378/564 [09:54<04:50,  1.56s/it]                                                 {'loss': 1.1507, 'grad_norm': 1.7929241170854449, 'learning_rate': 6.837294332723948e-07, 'epoch': 2.01}
 67%|██████▋   | 378/564 [09:54<04:50,  1.56s/it] 67%|██████▋   | 379/564 [09:55<04:48,  1.56s/it]                                                 {'loss': 1.0891, 'grad_norm': 1.6677224853840924, 'learning_rate': 6.80073126142596e-07, 'epoch': 2.02}
 67%|██████▋   | 379/564 [09:55<04:48,  1.56s/it] 67%|██████▋   | 380/564 [09:57<04:44,  1.55s/it]                                                 {'loss': 1.1254, 'grad_norm': 2.1183034218721137, 'learning_rate': 6.76416819012797e-07, 'epoch': 2.02}
 67%|██████▋   | 380/564 [09:57<04:44,  1.55s/it] 68%|██████▊   | 381/564 [09:59<04:43,  1.55s/it]                                                 {'loss': 1.125, 'grad_norm': 2.11049824358455, 'learning_rate': 6.727605118829981e-07, 'epoch': 2.03}
 68%|██████▊   | 381/564 [09:59<04:43,  1.55s/it] 68%|██████▊   | 382/564 [10:00<04:41,  1.55s/it]                                                 {'loss': 1.0939, 'grad_norm': 1.9276916089427036, 'learning_rate': 6.691042047531993e-07, 'epoch': 2.03}
 68%|██████▊   | 382/564 [10:00<04:41,  1.55s/it] 68%|██████▊   | 383/564 [10:02<04:39,  1.55s/it]                                                 {'loss': 0.9379, 'grad_norm': 1.574427638279321, 'learning_rate': 6.654478976234004e-07, 'epoch': 2.04}
 68%|██████▊   | 383/564 [10:02<04:39,  1.55s/it] 68%|██████▊   | 384/564 [10:03<04:37,  1.54s/it]                                                 {'loss': 1.2326, 'grad_norm': 1.7045838673093394, 'learning_rate': 6.617915904936014e-07, 'epoch': 2.04}
 68%|██████▊   | 384/564 [10:03<04:37,  1.54s/it] 68%|██████▊   | 385/564 [10:05<04:36,  1.55s/it]                                                 {'loss': 1.1829, 'grad_norm': 1.502536409788553, 'learning_rate': 6.581352833638025e-07, 'epoch': 2.05}
 68%|██████▊   | 385/564 [10:05<04:36,  1.55s/it] 68%|██████▊   | 386/564 [10:06<04:33,  1.54s/it]                                                 {'loss': 1.1245, 'grad_norm': 1.8386508727944706, 'learning_rate': 6.544789762340036e-07, 'epoch': 2.05}
 68%|██████▊   | 386/564 [10:06<04:33,  1.54s/it] 69%|██████▊   | 387/564 [10:08<04:32,  1.54s/it]                                                 {'loss': 1.1779, 'grad_norm': 1.7302432572593491, 'learning_rate': 6.508226691042047e-07, 'epoch': 2.06}
 69%|██████▊   | 387/564 [10:08<04:32,  1.54s/it] 69%|██████▉   | 388/564 [10:09<04:31,  1.54s/it]                                                 {'loss': 0.9098, 'grad_norm': 1.6440961964564933, 'learning_rate': 6.471663619744058e-07, 'epoch': 2.06}
 69%|██████▉   | 388/564 [10:09<04:31,  1.54s/it] 69%|██████▉   | 389/564 [10:11<04:28,  1.54s/it]                                                 {'loss': 1.0429, 'grad_norm': 1.9148923218117522, 'learning_rate': 6.435100548446069e-07, 'epoch': 2.07}
 69%|██████▉   | 389/564 [10:11<04:28,  1.54s/it] 69%|██████▉   | 390/564 [10:12<04:27,  1.54s/it]                                                 {'loss': 0.9908, 'grad_norm': 1.89871208267063, 'learning_rate': 6.398537477148081e-07, 'epoch': 2.07}
 69%|██████▉   | 390/564 [10:12<04:27,  1.54s/it] 69%|██████▉   | 391/564 [10:14<04:25,  1.54s/it]                                                 {'loss': 1.0647, 'grad_norm': 1.696418961072394, 'learning_rate': 6.361974405850091e-07, 'epoch': 2.08}
 69%|██████▉   | 391/564 [10:14<04:25,  1.54s/it] 70%|██████▉   | 392/564 [10:15<04:25,  1.54s/it]                                                 {'loss': 1.2132, 'grad_norm': 1.9000892369145157, 'learning_rate': 6.325411334552102e-07, 'epoch': 2.09}
 70%|██████▉   | 392/564 [10:15<04:25,  1.54s/it] 70%|██████▉   | 393/564 [10:17<04:23,  1.54s/it]                                                 {'loss': 1.181, 'grad_norm': 2.0395552372594965, 'learning_rate': 6.288848263254113e-07, 'epoch': 2.09}
 70%|██████▉   | 393/564 [10:17<04:23,  1.54s/it] 70%|██████▉   | 394/564 [10:19<04:23,  1.55s/it]                                                 {'loss': 1.2626, 'grad_norm': 2.0503883251457315, 'learning_rate': 6.252285191956124e-07, 'epoch': 2.1}
 70%|██████▉   | 394/564 [10:19<04:23,  1.55s/it] 70%|███████   | 395/564 [10:20<04:21,  1.55s/it]                                                 {'loss': 1.0781, 'grad_norm': 1.932335616970612, 'learning_rate': 6.215722120658134e-07, 'epoch': 2.1}
 70%|███████   | 395/564 [10:20<04:21,  1.55s/it] 70%|███████   | 396/564 [10:22<04:18,  1.54s/it]                                                 {'loss': 1.0185, 'grad_norm': 1.9799221294353404, 'learning_rate': 6.179159049360146e-07, 'epoch': 2.11}
 70%|███████   | 396/564 [10:22<04:18,  1.54s/it] 70%|███████   | 397/564 [10:23<04:17,  1.54s/it]                                                 {'loss': 1.056, 'grad_norm': 1.7299671737226745, 'learning_rate': 6.142595978062158e-07, 'epoch': 2.11}
 70%|███████   | 397/564 [10:23<04:17,  1.54s/it] 71%|███████   | 398/564 [10:25<04:16,  1.54s/it]                                                 {'loss': 1.1415, 'grad_norm': 1.9090072220351253, 'learning_rate': 6.106032906764168e-07, 'epoch': 2.12}
 71%|███████   | 398/564 [10:25<04:16,  1.54s/it] 71%|███████   | 399/564 [10:26<04:14,  1.54s/it]                                                 {'loss': 1.2074, 'grad_norm': 1.8949996180811914, 'learning_rate': 6.069469835466179e-07, 'epoch': 2.12}
 71%|███████   | 399/564 [10:26<04:14,  1.54s/it] 71%|███████   | 400/564 [10:28<04:13,  1.55s/it]                                                 {'loss': 0.9518, 'grad_norm': 1.772840793126322, 'learning_rate': 6.032906764168189e-07, 'epoch': 2.13}
 71%|███████   | 400/564 [10:28<04:13,  1.55s/it] 71%|███████   | 401/564 [10:29<04:11,  1.55s/it]                                                 {'loss': 1.1548, 'grad_norm': 1.7916818988252907, 'learning_rate': 5.996343692870201e-07, 'epoch': 2.13}
 71%|███████   | 401/564 [10:29<04:11,  1.55s/it] 71%|███████▏  | 402/564 [10:31<04:10,  1.54s/it]                                                 {'loss': 1.2072, 'grad_norm': 1.7054569114747837, 'learning_rate': 5.959780621572211e-07, 'epoch': 2.14}
 71%|███████▏  | 402/564 [10:31<04:10,  1.54s/it] 71%|███████▏  | 403/564 [10:32<04:06,  1.53s/it]                                                 {'loss': 1.2666, 'grad_norm': 1.787124386480763, 'learning_rate': 5.923217550274223e-07, 'epoch': 2.14}
 71%|███████▏  | 403/564 [10:32<04:06,  1.53s/it] 72%|███████▏  | 404/564 [10:34<04:06,  1.54s/it]                                                 {'loss': 1.1588, 'grad_norm': 1.9335173870881386, 'learning_rate': 5.886654478976234e-07, 'epoch': 2.15}
 72%|███████▏  | 404/564 [10:34<04:06,  1.54s/it] 72%|███████▏  | 405/564 [10:36<04:04,  1.53s/it]                                                 {'loss': 1.1375, 'grad_norm': 1.8080422711676787, 'learning_rate': 5.850091407678245e-07, 'epoch': 2.15}
 72%|███████▏  | 405/564 [10:36<04:04,  1.53s/it] 72%|███████▏  | 406/564 [10:37<04:02,  1.54s/it]                                                 {'loss': 1.0912, 'grad_norm': 2.013720724483132, 'learning_rate': 5.813528336380256e-07, 'epoch': 2.16}
 72%|███████▏  | 406/564 [10:37<04:02,  1.54s/it] 72%|███████▏  | 407/564 [10:39<04:00,  1.53s/it]                                                 {'loss': 1.1668, 'grad_norm': 1.674689715347153, 'learning_rate': 5.776965265082266e-07, 'epoch': 2.16}
 72%|███████▏  | 407/564 [10:39<04:00,  1.53s/it] 72%|███████▏  | 408/564 [10:40<04:00,  1.54s/it]                                                 {'loss': 1.3505, 'grad_norm': 1.8542355368932502, 'learning_rate': 5.740402193784278e-07, 'epoch': 2.17}
 72%|███████▏  | 408/564 [10:40<04:00,  1.54s/it] 73%|███████▎  | 409/564 [10:42<03:58,  1.54s/it]                                                 {'loss': 1.2378, 'grad_norm': 1.971564864236399, 'learning_rate': 5.703839122486288e-07, 'epoch': 2.18}
 73%|███████▎  | 409/564 [10:42<03:58,  1.54s/it] 73%|███████▎  | 410/564 [10:43<03:57,  1.54s/it]                                                 {'loss': 1.2365, 'grad_norm': 1.748049496148743, 'learning_rate': 5.6672760511883e-07, 'epoch': 2.18}
 73%|███████▎  | 410/564 [10:43<03:57,  1.54s/it] 73%|███████▎  | 411/564 [10:45<03:54,  1.54s/it]                                                 {'loss': 0.9817, 'grad_norm': 1.783348826614015, 'learning_rate': 5.63071297989031e-07, 'epoch': 2.19}
 73%|███████▎  | 411/564 [10:45<03:54,  1.54s/it] 73%|███████▎  | 412/564 [10:46<03:54,  1.54s/it]                                                 {'loss': 1.0641, 'grad_norm': 1.7417866031069518, 'learning_rate': 5.594149908592322e-07, 'epoch': 2.19}
 73%|███████▎  | 412/564 [10:46<03:54,  1.54s/it] 73%|███████▎  | 413/564 [10:48<03:52,  1.54s/it]                                                 {'loss': 1.2164, 'grad_norm': 1.6205302655501996, 'learning_rate': 5.557586837294332e-07, 'epoch': 2.2}
 73%|███████▎  | 413/564 [10:48<03:52,  1.54s/it] 73%|███████▎  | 414/564 [10:49<03:50,  1.53s/it]                                                 {'loss': 1.0916, 'grad_norm': 1.6176795131704655, 'learning_rate': 5.521023765996343e-07, 'epoch': 2.2}
 73%|███████▎  | 414/564 [10:49<03:50,  1.53s/it] 74%|███████▎  | 415/564 [10:51<03:49,  1.54s/it]                                                 {'loss': 1.2496, 'grad_norm': 2.0578749054121714, 'learning_rate': 5.484460694698354e-07, 'epoch': 2.21}
 74%|███████▎  | 415/564 [10:51<03:49,  1.54s/it] 74%|███████▍  | 416/564 [10:52<03:47,  1.54s/it]                                                 {'loss': 1.2441, 'grad_norm': 1.8095316747479369, 'learning_rate': 5.447897623400365e-07, 'epoch': 2.21}
 74%|███████▍  | 416/564 [10:52<03:47,  1.54s/it] 74%|███████▍  | 417/564 [10:54<03:46,  1.54s/it]                                                 {'loss': 1.1796, 'grad_norm': 1.839322063899956, 'learning_rate': 5.411334552102377e-07, 'epoch': 2.22}
 74%|███████▍  | 417/564 [10:54<03:46,  1.54s/it] 74%|███████▍  | 418/564 [10:56<03:44,  1.54s/it]                                                 {'loss': 1.1456, 'grad_norm': 1.835480512587957, 'learning_rate': 5.374771480804387e-07, 'epoch': 2.22}
 74%|███████▍  | 418/564 [10:56<03:44,  1.54s/it] 74%|███████▍  | 419/564 [10:57<03:42,  1.54s/it]                                                 {'loss': 1.0169, 'grad_norm': 1.763646208300387, 'learning_rate': 5.338208409506399e-07, 'epoch': 2.23}
 74%|███████▍  | 419/564 [10:57<03:42,  1.54s/it] 74%|███████▍  | 420/564 [10:59<03:42,  1.54s/it]                                                 {'loss': 1.1577, 'grad_norm': 1.7553548539586696, 'learning_rate': 5.301645338208409e-07, 'epoch': 2.23}
 74%|███████▍  | 420/564 [10:59<03:42,  1.54s/it] 75%|███████▍  | 421/564 [11:00<03:40,  1.54s/it]                                                 {'loss': 0.9649, 'grad_norm': 1.9159616898468632, 'learning_rate': 5.26508226691042e-07, 'epoch': 2.24}
 75%|███████▍  | 421/564 [11:00<03:40,  1.54s/it] 75%|███████▍  | 422/564 [11:02<03:40,  1.55s/it]                                                 {'loss': 1.1149, 'grad_norm': 2.0346802885874617, 'learning_rate': 5.22851919561243e-07, 'epoch': 2.24}
 75%|███████▍  | 422/564 [11:02<03:40,  1.55s/it] 75%|███████▌  | 423/564 [11:04<03:54,  1.66s/it]                                                 {'loss': 1.1735, 'grad_norm': 1.704536971477094, 'learning_rate': 5.191956124314442e-07, 'epoch': 2.25}
 75%|███████▌  | 423/564 [11:04<03:54,  1.66s/it] 75%|███████▌  | 424/564 [11:05<03:48,  1.63s/it]                                                 {'loss': 1.1748, 'grad_norm': 2.0754367641825544, 'learning_rate': 5.155393053016453e-07, 'epoch': 2.26}
 75%|███████▌  | 424/564 [11:05<03:48,  1.63s/it] 75%|███████▌  | 425/564 [11:07<03:44,  1.62s/it]                                                 {'loss': 1.1368, 'grad_norm': 1.7868997075414943, 'learning_rate': 5.118829981718464e-07, 'epoch': 2.26}
 75%|███████▌  | 425/564 [11:07<03:44,  1.62s/it] 76%|███████▌  | 426/564 [11:08<03:40,  1.60s/it]                                                 {'loss': 1.0327, 'grad_norm': 1.638816280323872, 'learning_rate': 5.082266910420476e-07, 'epoch': 2.27}
 76%|███████▌  | 426/564 [11:08<03:40,  1.60s/it] 76%|███████▌  | 427/564 [11:10<03:37,  1.59s/it]                                                 {'loss': 0.9729, 'grad_norm': 1.6365464284480293, 'learning_rate': 5.045703839122486e-07, 'epoch': 2.27}
 76%|███████▌  | 427/564 [11:10<03:37,  1.59s/it] 76%|███████▌  | 428/564 [11:11<03:35,  1.58s/it]                                                 {'loss': 1.134, 'grad_norm': 1.9281964083259062, 'learning_rate': 5.009140767824497e-07, 'epoch': 2.28}
 76%|███████▌  | 428/564 [11:11<03:35,  1.58s/it] 76%|███████▌  | 429/564 [11:13<03:33,  1.58s/it]                                                 {'loss': 1.1573, 'grad_norm': 1.6306092052023535, 'learning_rate': 4.972577696526509e-07, 'epoch': 2.28}
 76%|███████▌  | 429/564 [11:13<03:33,  1.58s/it] 76%|███████▌  | 430/564 [11:15<03:29,  1.57s/it]                                                 {'loss': 1.1486, 'grad_norm': 1.9138673897794027, 'learning_rate': 4.936014625228519e-07, 'epoch': 2.29}
 76%|███████▌  | 430/564 [11:15<03:29,  1.57s/it] 76%|███████▋  | 431/564 [11:16<03:27,  1.56s/it]                                                 {'loss': 1.1598, 'grad_norm': 1.6519054713181598, 'learning_rate': 4.89945155393053e-07, 'epoch': 2.29}
 76%|███████▋  | 431/564 [11:16<03:27,  1.56s/it] 77%|███████▋  | 432/564 [11:18<03:24,  1.55s/it]                                                 {'loss': 1.0318, 'grad_norm': 1.970081660495772, 'learning_rate': 4.862888482632541e-07, 'epoch': 2.3}
 77%|███████▋  | 432/564 [11:18<03:24,  1.55s/it] 77%|███████▋  | 433/564 [11:19<03:23,  1.55s/it]                                                 {'loss': 1.044, 'grad_norm': 1.8360540119588749, 'learning_rate': 4.826325411334552e-07, 'epoch': 2.3}
 77%|███████▋  | 433/564 [11:19<03:23,  1.55s/it] 77%|███████▋  | 434/564 [11:21<03:21,  1.55s/it]                                                 {'loss': 1.1555, 'grad_norm': 1.848733570941063, 'learning_rate': 4.789762340036563e-07, 'epoch': 2.31}
 77%|███████▋  | 434/564 [11:21<03:21,  1.55s/it] 77%|███████▋  | 435/564 [11:22<03:19,  1.55s/it]                                                 {'loss': 1.1076, 'grad_norm': 1.9534641004847395, 'learning_rate': 4.7531992687385736e-07, 'epoch': 2.31}
 77%|███████▋  | 435/564 [11:22<03:19,  1.55s/it] 77%|███████▋  | 436/564 [11:24<03:17,  1.54s/it]                                                 {'loss': 1.1873, 'grad_norm': 1.904696399243453, 'learning_rate': 4.716636197440585e-07, 'epoch': 2.32}
 77%|███████▋  | 436/564 [11:24<03:17,  1.54s/it] 77%|███████▋  | 437/564 [11:25<03:17,  1.56s/it]                                                 {'loss': 1.064, 'grad_norm': 1.8648689813592805, 'learning_rate': 4.6800731261425957e-07, 'epoch': 2.32}
 77%|███████▋  | 437/564 [11:25<03:17,  1.56s/it] 78%|███████▊  | 438/564 [11:27<03:15,  1.55s/it]                                                 {'loss': 1.1153, 'grad_norm': 1.8612095504987498, 'learning_rate': 4.6435100548446064e-07, 'epoch': 2.33}
 78%|███████▊  | 438/564 [11:27<03:15,  1.55s/it] 78%|███████▊  | 439/564 [11:29<03:15,  1.56s/it]                                                 {'loss': 1.2158, 'grad_norm': 1.8709916797575783, 'learning_rate': 4.606946983546618e-07, 'epoch': 2.34}
 78%|███████▊  | 439/564 [11:29<03:15,  1.56s/it] 78%|███████▊  | 440/564 [11:30<03:13,  1.56s/it]                                                 {'loss': 1.2165, 'grad_norm': 2.0098823394048173, 'learning_rate': 4.5703839122486285e-07, 'epoch': 2.34}
 78%|███████▊  | 440/564 [11:30<03:13,  1.56s/it] 78%|███████▊  | 441/564 [11:32<03:10,  1.55s/it]                                                 {'loss': 1.1069, 'grad_norm': 1.6891820058442992, 'learning_rate': 4.53382084095064e-07, 'epoch': 2.35}
 78%|███████▊  | 441/564 [11:32<03:10,  1.55s/it] 78%|███████▊  | 442/564 [11:33<03:08,  1.54s/it]                                                 {'loss': 1.2375, 'grad_norm': 1.8180105745519628, 'learning_rate': 4.4972577696526506e-07, 'epoch': 2.35}
 78%|███████▊  | 442/564 [11:33<03:08,  1.54s/it] 79%|███████▊  | 443/564 [11:35<03:06,  1.54s/it]                                                 {'loss': 1.0362, 'grad_norm': 1.9485404574416545, 'learning_rate': 4.460694698354662e-07, 'epoch': 2.36}
 79%|███████▊  | 443/564 [11:35<03:06,  1.54s/it] 79%|███████▊  | 444/564 [11:36<03:05,  1.54s/it]                                                 {'loss': 1.3535, 'grad_norm': 1.607579388835495, 'learning_rate': 4.4241316270566726e-07, 'epoch': 2.36}
 79%|███████▊  | 444/564 [11:36<03:05,  1.54s/it] 79%|███████▉  | 445/564 [11:38<03:04,  1.55s/it]                                                 {'loss': 1.1849, 'grad_norm': 2.0740140356231724, 'learning_rate': 4.3875685557586834e-07, 'epoch': 2.37}
 79%|███████▉  | 445/564 [11:38<03:04,  1.55s/it] 79%|███████▉  | 446/564 [11:39<03:01,  1.54s/it]                                                 {'loss': 1.0037, 'grad_norm': 2.0663239727125386, 'learning_rate': 4.3510054844606947e-07, 'epoch': 2.37}
 79%|███████▉  | 446/564 [11:39<03:01,  1.54s/it] 79%|███████▉  | 447/564 [11:41<03:00,  1.54s/it]                                                 {'loss': 1.2922, 'grad_norm': 1.720069071616164, 'learning_rate': 4.3144424131627054e-07, 'epoch': 2.38}
 79%|███████▉  | 447/564 [11:41<03:00,  1.54s/it] 79%|███████▉  | 448/564 [11:42<02:58,  1.54s/it]                                                 {'loss': 1.2754, 'grad_norm': 1.9851153511612885, 'learning_rate': 4.277879341864716e-07, 'epoch': 2.38}
 79%|███████▉  | 448/564 [11:42<02:58,  1.54s/it] 80%|███████▉  | 449/564 [11:44<02:57,  1.54s/it]                                                 {'loss': 1.1936, 'grad_norm': 1.716111526727771, 'learning_rate': 4.241316270566727e-07, 'epoch': 2.39}
 80%|███████▉  | 449/564 [11:44<02:57,  1.54s/it] 80%|███████▉  | 450/564 [11:45<02:54,  1.53s/it]                                                 {'loss': 1.0982, 'grad_norm': 1.7796385316436558, 'learning_rate': 4.2047531992687383e-07, 'epoch': 2.39}
 80%|███████▉  | 450/564 [11:45<02:54,  1.53s/it] 80%|███████▉  | 451/564 [11:47<02:53,  1.53s/it]                                                 {'loss': 1.2679, 'grad_norm': 1.6564170526704591, 'learning_rate': 4.1681901279707496e-07, 'epoch': 2.4}
 80%|███████▉  | 451/564 [11:47<02:53,  1.53s/it] 80%|████████  | 452/564 [11:49<02:51,  1.53s/it]                                                 {'loss': 1.1857, 'grad_norm': 1.7793749150651654, 'learning_rate': 4.1316270566727603e-07, 'epoch': 2.4}
 80%|████████  | 452/564 [11:49<02:51,  1.53s/it] 80%|████████  | 453/564 [11:50<02:50,  1.54s/it]                                                 {'loss': 1.3096, 'grad_norm': 1.687513372006032, 'learning_rate': 4.0950639853747716e-07, 'epoch': 2.41}
 80%|████████  | 453/564 [11:50<02:50,  1.54s/it] 80%|████████  | 454/564 [11:52<02:49,  1.54s/it]                                                 {'loss': 1.0758, 'grad_norm': 1.9969765193595088, 'learning_rate': 4.0585009140767824e-07, 'epoch': 2.41}
 80%|████████  | 454/564 [11:52<02:49,  1.54s/it] 81%|████████  | 455/564 [11:53<02:48,  1.54s/it]                                                 {'loss': 1.0673, 'grad_norm': 1.9325762502801938, 'learning_rate': 4.021937842778793e-07, 'epoch': 2.42}
 81%|████████  | 455/564 [11:53<02:48,  1.54s/it] 81%|████████  | 456/564 [11:55<02:47,  1.55s/it]                                                 {'loss': 1.1856, 'grad_norm': 1.7579954146415158, 'learning_rate': 3.9853747714808044e-07, 'epoch': 2.43}
 81%|████████  | 456/564 [11:55<02:47,  1.55s/it] 81%|████████  | 457/564 [11:56<02:46,  1.56s/it]                                                 {'loss': 1.4022, 'grad_norm': 1.7730068424428744, 'learning_rate': 3.948811700182815e-07, 'epoch': 2.43}
 81%|████████  | 457/564 [11:56<02:46,  1.56s/it] 81%|████████  | 458/564 [11:58<02:43,  1.55s/it]                                                 {'loss': 1.1055, 'grad_norm': 1.7683408404954237, 'learning_rate': 3.912248628884826e-07, 'epoch': 2.44}
 81%|████████  | 458/564 [11:58<02:43,  1.55s/it] 81%|████████▏ | 459/564 [11:59<02:42,  1.55s/it]                                                 {'loss': 1.1446, 'grad_norm': 1.7625417889179016, 'learning_rate': 3.875685557586837e-07, 'epoch': 2.44}
 81%|████████▏ | 459/564 [11:59<02:42,  1.55s/it] 82%|████████▏ | 460/564 [12:01<02:41,  1.55s/it]                                                 {'loss': 1.0532, 'grad_norm': 1.654412207176552, 'learning_rate': 3.839122486288848e-07, 'epoch': 2.45}
 82%|████████▏ | 460/564 [12:01<02:41,  1.55s/it] 82%|████████▏ | 461/564 [12:02<02:39,  1.55s/it]                                                 {'loss': 1.2536, 'grad_norm': 1.5476531264998927, 'learning_rate': 3.8025594149908593e-07, 'epoch': 2.45}
 82%|████████▏ | 461/564 [12:02<02:39,  1.55s/it] 82%|████████▏ | 462/564 [12:04<02:38,  1.55s/it]                                                 {'loss': 1.0743, 'grad_norm': 1.6080454649779716, 'learning_rate': 3.76599634369287e-07, 'epoch': 2.46}
 82%|████████▏ | 462/564 [12:04<02:38,  1.55s/it] 82%|████████▏ | 463/564 [12:06<02:36,  1.55s/it]                                                 {'loss': 1.4019, 'grad_norm': 1.9544437562580546, 'learning_rate': 3.7294332723948814e-07, 'epoch': 2.46}
 82%|████████▏ | 463/564 [12:06<02:36,  1.55s/it] 82%|████████▏ | 464/564 [12:07<02:35,  1.55s/it]                                                 {'loss': 1.0739, 'grad_norm': 1.7992198983601435, 'learning_rate': 3.692870201096892e-07, 'epoch': 2.47}
 82%|████████▏ | 464/564 [12:07<02:35,  1.55s/it] 82%|████████▏ | 465/564 [12:09<02:33,  1.55s/it]                                                 {'loss': 1.1522, 'grad_norm': 1.7316793034880595, 'learning_rate': 3.656307129798903e-07, 'epoch': 2.47}
 82%|████████▏ | 465/564 [12:09<02:33,  1.55s/it] 83%|████████▎ | 466/564 [12:10<02:31,  1.54s/it]                                                 {'loss': 0.9549, 'grad_norm': 2.1464775178579605, 'learning_rate': 3.6197440585009137e-07, 'epoch': 2.48}
 83%|████████▎ | 466/564 [12:10<02:31,  1.54s/it] 83%|████████▎ | 467/564 [12:12<02:31,  1.56s/it]                                                 {'loss': 1.2044, 'grad_norm': 1.6192520776683335, 'learning_rate': 3.583180987202925e-07, 'epoch': 2.48}
 83%|████████▎ | 467/564 [12:12<02:31,  1.56s/it] 83%|████████▎ | 468/564 [12:13<02:29,  1.56s/it]                                                 {'loss': 1.1235, 'grad_norm': 1.8472850982141271, 'learning_rate': 3.5466179159049357e-07, 'epoch': 2.49}
 83%|████████▎ | 468/564 [12:13<02:29,  1.56s/it] 83%|████████▎ | 469/564 [12:15<02:27,  1.56s/it]                                                 {'loss': 1.2002, 'grad_norm': 1.695012901041442, 'learning_rate': 3.5100548446069465e-07, 'epoch': 2.49}
 83%|████████▎ | 469/564 [12:15<02:27,  1.56s/it] 83%|████████▎ | 470/564 [12:16<02:26,  1.56s/it]                                                 {'loss': 0.9575, 'grad_norm': 1.8446834312213645, 'learning_rate': 3.473491773308958e-07, 'epoch': 2.5}
 83%|████████▎ | 470/564 [12:16<02:26,  1.56s/it] 84%|████████▎ | 471/564 [12:18<02:24,  1.55s/it]                                                 {'loss': 1.076, 'grad_norm': 2.0291810469211806, 'learning_rate': 3.436928702010969e-07, 'epoch': 2.51}
 84%|████████▎ | 471/564 [12:18<02:24,  1.55s/it] 84%|████████▎ | 472/564 [12:20<02:23,  1.56s/it]                                                 {'loss': 1.0859, 'grad_norm': 1.9773406881839721, 'learning_rate': 3.40036563071298e-07, 'epoch': 2.51}
 84%|████████▎ | 472/564 [12:20<02:23,  1.56s/it] 84%|████████▍ | 473/564 [12:21<02:22,  1.56s/it]                                                 {'loss': 1.2964, 'grad_norm': 1.869430070416397, 'learning_rate': 3.3638025594149906e-07, 'epoch': 2.52}
 84%|████████▍ | 473/564 [12:21<02:22,  1.56s/it] 84%|████████▍ | 474/564 [12:23<02:20,  1.57s/it]                                                 {'loss': 1.1367, 'grad_norm': 1.9725217478788832, 'learning_rate': 3.327239488117002e-07, 'epoch': 2.52}
 84%|████████▍ | 474/564 [12:23<02:20,  1.57s/it] 84%|████████▍ | 475/564 [12:24<02:19,  1.56s/it]                                                 {'loss': 1.1637, 'grad_norm': 1.744600784899191, 'learning_rate': 3.2906764168190127e-07, 'epoch': 2.53}
 84%|████████▍ | 475/564 [12:24<02:19,  1.56s/it] 84%|████████▍ | 476/564 [12:26<02:15,  1.54s/it]                                                 {'loss': 1.1588, 'grad_norm': 2.0512633307640145, 'learning_rate': 3.2541133455210234e-07, 'epoch': 2.53}
 84%|████████▍ | 476/564 [12:26<02:15,  1.54s/it] 85%|████████▍ | 477/564 [12:27<02:14,  1.55s/it]                                                 {'loss': 1.3298, 'grad_norm': 1.9232037380002653, 'learning_rate': 3.2175502742230347e-07, 'epoch': 2.54}
 85%|████████▍ | 477/564 [12:27<02:14,  1.55s/it] 85%|████████▍ | 478/564 [12:29<02:12,  1.54s/it]                                                 {'loss': 1.0513, 'grad_norm': 1.8147091062076248, 'learning_rate': 3.1809872029250455e-07, 'epoch': 2.54}
 85%|████████▍ | 478/564 [12:29<02:12,  1.54s/it] 85%|████████▍ | 479/564 [12:30<02:11,  1.54s/it]                                                 {'loss': 0.9523, 'grad_norm': 1.86461116275123, 'learning_rate': 3.144424131627056e-07, 'epoch': 2.55}
 85%|████████▍ | 479/564 [12:30<02:11,  1.54s/it] 85%|████████▌ | 480/564 [12:32<02:09,  1.55s/it]                                                 {'loss': 1.1181, 'grad_norm': 1.8084370139136012, 'learning_rate': 3.107861060329067e-07, 'epoch': 2.55}
 85%|████████▌ | 480/564 [12:32<02:09,  1.55s/it] 85%|████████▌ | 481/564 [12:34<02:08,  1.55s/it]                                                 {'loss': 1.072, 'grad_norm': 1.8434906547630845, 'learning_rate': 3.071297989031079e-07, 'epoch': 2.56}
 85%|████████▌ | 481/564 [12:34<02:08,  1.55s/it] 85%|████████▌ | 482/564 [12:35<02:08,  1.56s/it]                                                 {'loss': 1.2828, 'grad_norm': 1.7362606550303088, 'learning_rate': 3.0347349177330896e-07, 'epoch': 2.56}
 85%|████████▌ | 482/564 [12:35<02:08,  1.56s/it] 86%|████████▌ | 483/564 [12:37<02:07,  1.57s/it]                                                 {'loss': 1.1783, 'grad_norm': 1.5675504309828103, 'learning_rate': 2.9981718464351004e-07, 'epoch': 2.57}
 86%|████████▌ | 483/564 [12:37<02:07,  1.57s/it] 86%|████████▌ | 484/564 [12:38<02:05,  1.57s/it]                                                 {'loss': 1.0028, 'grad_norm': 1.7177563411538026, 'learning_rate': 2.9616087751371117e-07, 'epoch': 2.57}
 86%|████████▌ | 484/564 [12:38<02:05,  1.57s/it] 86%|████████▌ | 485/564 [12:40<02:03,  1.56s/it]                                                 {'loss': 1.2037, 'grad_norm': 1.817191743580232, 'learning_rate': 2.9250457038391224e-07, 'epoch': 2.58}
 86%|████████▌ | 485/564 [12:40<02:03,  1.56s/it] 86%|████████▌ | 486/564 [12:41<02:01,  1.56s/it]                                                 {'loss': 1.1377, 'grad_norm': 1.9677013208628298, 'learning_rate': 2.888482632541133e-07, 'epoch': 2.59}
 86%|████████▌ | 486/564 [12:41<02:01,  1.56s/it] 86%|████████▋ | 487/564 [12:43<01:59,  1.55s/it]                                                 {'loss': 0.9743, 'grad_norm': 1.8438436211694318, 'learning_rate': 2.851919561243144e-07, 'epoch': 2.59}
 86%|████████▋ | 487/564 [12:43<01:59,  1.55s/it] 87%|████████▋ | 488/564 [12:45<01:58,  1.56s/it]                                                 {'loss': 0.9461, 'grad_norm': 1.6219820158507627, 'learning_rate': 2.815356489945155e-07, 'epoch': 2.6}
 87%|████████▋ | 488/564 [12:45<01:58,  1.56s/it] 87%|████████▋ | 489/564 [12:46<01:57,  1.56s/it]                                                 {'loss': 1.0932, 'grad_norm': 2.0432549551130212, 'learning_rate': 2.778793418647166e-07, 'epoch': 2.6}
 87%|████████▋ | 489/564 [12:46<01:57,  1.56s/it] 87%|████████▋ | 490/564 [12:48<01:54,  1.55s/it]                                                 {'loss': 1.0659, 'grad_norm': 1.9242775198580286, 'learning_rate': 2.742230347349177e-07, 'epoch': 2.61}
 87%|████████▋ | 490/564 [12:48<01:54,  1.55s/it] 87%|████████▋ | 491/564 [12:49<01:53,  1.55s/it]                                                 {'loss': 1.0524, 'grad_norm': 1.8390683394140326, 'learning_rate': 2.7056672760511886e-07, 'epoch': 2.61}
 87%|████████▋ | 491/564 [12:49<01:53,  1.55s/it] 87%|████████▋ | 492/564 [12:51<01:51,  1.55s/it]                                                 {'loss': 1.1569, 'grad_norm': 2.018046630339663, 'learning_rate': 2.6691042047531994e-07, 'epoch': 2.62}
 87%|████████▋ | 492/564 [12:51<01:51,  1.55s/it] 87%|████████▋ | 493/564 [12:52<01:50,  1.56s/it]                                                 {'loss': 1.2558, 'grad_norm': 1.8445137462249863, 'learning_rate': 2.63254113345521e-07, 'epoch': 2.62}
 87%|████████▋ | 493/564 [12:52<01:50,  1.56s/it] 88%|████████▊ | 494/564 [12:54<01:48,  1.55s/it]                                                 {'loss': 1.2504, 'grad_norm': 1.9316003321424338, 'learning_rate': 2.595978062157221e-07, 'epoch': 2.63}
 88%|████████▊ | 494/564 [12:54<01:48,  1.55s/it] 88%|████████▊ | 495/564 [12:55<01:47,  1.55s/it]                                                 {'loss': 1.1279, 'grad_norm': 1.942597760165166, 'learning_rate': 2.559414990859232e-07, 'epoch': 2.63}
 88%|████████▊ | 495/564 [12:55<01:47,  1.55s/it] 88%|████████▊ | 496/564 [12:57<01:45,  1.54s/it]                                                 {'loss': 1.0051, 'grad_norm': 1.8942177620345264, 'learning_rate': 2.522851919561243e-07, 'epoch': 2.64}
 88%|████████▊ | 496/564 [12:57<01:45,  1.54s/it] 88%|████████▊ | 497/564 [12:58<01:44,  1.55s/it]                                                 {'loss': 1.1604, 'grad_norm': 2.08231802576706, 'learning_rate': 2.486288848263254e-07, 'epoch': 2.64}
 88%|████████▊ | 497/564 [12:58<01:44,  1.55s/it] 88%|████████▊ | 498/564 [13:00<01:42,  1.55s/it]                                                 {'loss': 1.1949, 'grad_norm': 1.982961734226277, 'learning_rate': 2.449725776965265e-07, 'epoch': 2.65}
 88%|████████▊ | 498/564 [13:00<01:42,  1.55s/it] 88%|████████▊ | 499/564 [13:02<01:40,  1.55s/it]                                                 {'loss': 1.1091, 'grad_norm': 1.6829802829863565, 'learning_rate': 2.413162705667276e-07, 'epoch': 2.65}
 88%|████████▊ | 499/564 [13:02<01:40,  1.55s/it] 89%|████████▊ | 500/564 [13:03<01:39,  1.55s/it]                                                 {'loss': 1.0598, 'grad_norm': 1.6396559257673446, 'learning_rate': 2.3765996343692868e-07, 'epoch': 2.66}
 89%|████████▊ | 500/564 [13:03<01:39,  1.55s/it]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 89%|████████▉ | 501/564 [14:57<36:55, 35.17s/it]                                                 {'loss': 1.1102, 'grad_norm': 2.131455719278707, 'learning_rate': 2.3400365630712978e-07, 'epoch': 2.66}
 89%|████████▉ | 501/564 [14:57<36:55, 35.17s/it] 89%|████████▉ | 502/564 [14:58<25:54, 25.08s/it]                                                 {'loss': 1.1321, 'grad_norm': 2.4156959282246464, 'learning_rate': 2.303473491773309e-07, 'epoch': 2.67}
 89%|████████▉ | 502/564 [14:58<25:54, 25.08s/it] 89%|████████▉ | 503/564 [15:00<18:19, 18.02s/it]                                                 {'loss': 1.1066, 'grad_norm': 1.7808827576731154, 'learning_rate': 2.26691042047532e-07, 'epoch': 2.68}
 89%|████████▉ | 503/564 [15:00<18:19, 18.02s/it] 89%|████████▉ | 504/564 [15:01<13:04, 13.08s/it]                                                 {'loss': 1.1642, 'grad_norm': 1.9830049753086312, 'learning_rate': 2.230347349177331e-07, 'epoch': 2.68}
 89%|████████▉ | 504/564 [15:01<13:04, 13.08s/it] 90%|████████▉ | 505/564 [15:03<09:27,  9.62s/it]                                                 {'loss': 1.1408, 'grad_norm': 1.93779464662948, 'learning_rate': 2.1937842778793417e-07, 'epoch': 2.69}
 90%|████████▉ | 505/564 [15:03<09:27,  9.62s/it] 90%|████████▉ | 506/564 [15:04<06:58,  7.21s/it]                                                 {'loss': 1.1552, 'grad_norm': 1.737164370244022, 'learning_rate': 2.1572212065813527e-07, 'epoch': 2.69}
 90%|████████▉ | 506/564 [15:04<06:58,  7.21s/it] 90%|████████▉ | 507/564 [15:06<05:13,  5.51s/it]                                                 {'loss': 1.1935, 'grad_norm': 1.9112212676653895, 'learning_rate': 2.1206581352833635e-07, 'epoch': 2.7}
 90%|████████▉ | 507/564 [15:06<05:13,  5.51s/it] 90%|█████████ | 508/564 [15:08<04:01,  4.31s/it]                                                 {'loss': 0.9944, 'grad_norm': 2.0188475058987567, 'learning_rate': 2.0840950639853748e-07, 'epoch': 2.7}
 90%|█████████ | 508/564 [15:08<04:01,  4.31s/it] 90%|█████████ | 509/564 [15:09<03:11,  3.47s/it]                                                 {'loss': 1.2151, 'grad_norm': 1.6288734427050136, 'learning_rate': 2.0475319926873858e-07, 'epoch': 2.71}
 90%|█████████ | 509/564 [15:09<03:11,  3.47s/it] 90%|█████████ | 510/564 [15:11<02:36,  2.89s/it]                                                 {'loss': 1.2454, 'grad_norm': 1.9615508146231209, 'learning_rate': 2.0109689213893966e-07, 'epoch': 2.71}
 90%|█████████ | 510/564 [15:11<02:36,  2.89s/it] 91%|█████████ | 511/564 [15:12<02:11,  2.47s/it]                                                 {'loss': 1.1691, 'grad_norm': 1.832828757093182, 'learning_rate': 1.9744058500914076e-07, 'epoch': 2.72}
 91%|█████████ | 511/564 [15:12<02:11,  2.47s/it] 91%|█████████ | 512/564 [15:14<01:54,  2.19s/it]                                                 {'loss': 1.201, 'grad_norm': 1.9957478072573267, 'learning_rate': 1.9378427787934184e-07, 'epoch': 2.72}
 91%|█████████ | 512/564 [15:14<01:54,  2.19s/it] 91%|█████████ | 513/564 [15:15<01:41,  1.99s/it]                                                 {'loss': 1.1798, 'grad_norm': 1.7320290762211854, 'learning_rate': 1.9012797074954297e-07, 'epoch': 2.73}
 91%|█████████ | 513/564 [15:15<01:41,  1.99s/it] 91%|█████████ | 514/564 [15:17<01:32,  1.86s/it]                                                 {'loss': 1.0926, 'grad_norm': 1.8639389429809854, 'learning_rate': 1.8647166361974407e-07, 'epoch': 2.73}
 91%|█████████ | 514/564 [15:17<01:32,  1.86s/it] 91%|█████████▏| 515/564 [15:18<01:26,  1.77s/it]                                                 {'loss': 1.0196, 'grad_norm': 2.0780061118139286, 'learning_rate': 1.8281535648994515e-07, 'epoch': 2.74}
 91%|█████████▏| 515/564 [15:18<01:26,  1.77s/it] 91%|█████████▏| 516/564 [15:20<01:21,  1.70s/it]                                                 {'loss': 1.0024, 'grad_norm': 1.6623966154873429, 'learning_rate': 1.7915904936014625e-07, 'epoch': 2.74}
 91%|█████████▏| 516/564 [15:20<01:21,  1.70s/it] 92%|█████████▏| 517/564 [15:21<01:17,  1.65s/it]                                                 {'loss': 1.0659, 'grad_norm': 1.7465887724641436, 'learning_rate': 1.7550274223034732e-07, 'epoch': 2.75}
 92%|█████████▏| 517/564 [15:21<01:17,  1.65s/it] 92%|█████████▏| 518/564 [15:23<01:14,  1.62s/it]                                                 {'loss': 1.246, 'grad_norm': 1.7895700369988434, 'learning_rate': 1.7184643510054845e-07, 'epoch': 2.76}
 92%|█████████▏| 518/564 [15:23<01:14,  1.62s/it] 92%|█████████▏| 519/564 [15:24<01:11,  1.60s/it]                                                 {'loss': 1.0049, 'grad_norm': 1.8249001960578601, 'learning_rate': 1.6819012797074953e-07, 'epoch': 2.76}
 92%|█████████▏| 519/564 [15:24<01:11,  1.60s/it] 92%|█████████▏| 520/564 [15:26<01:09,  1.58s/it]                                                 {'loss': 1.1865, 'grad_norm': 1.946866344876299, 'learning_rate': 1.6453382084095063e-07, 'epoch': 2.77}
 92%|█████████▏| 520/564 [15:26<01:09,  1.58s/it] 92%|█████████▏| 521/564 [15:28<01:07,  1.57s/it]                                                 {'loss': 1.1856, 'grad_norm': 2.0626581931238457, 'learning_rate': 1.6087751371115174e-07, 'epoch': 2.77}
 92%|█████████▏| 521/564 [15:28<01:07,  1.57s/it] 93%|█████████▎| 522/564 [15:29<01:05,  1.56s/it]                                                 {'loss': 1.1482, 'grad_norm': 2.1511982649181416, 'learning_rate': 1.572212065813528e-07, 'epoch': 2.78}
 93%|█████████▎| 522/564 [15:29<01:05,  1.56s/it] 93%|█████████▎| 523/564 [15:31<01:03,  1.54s/it]                                                 {'loss': 0.8265, 'grad_norm': 1.9342022132393821, 'learning_rate': 1.5356489945155394e-07, 'epoch': 2.78}
 93%|█████████▎| 523/564 [15:31<01:03,  1.54s/it] 93%|█████████▎| 524/564 [15:32<01:01,  1.54s/it]                                                 {'loss': 1.1008, 'grad_norm': 1.9525946368840632, 'learning_rate': 1.4990859232175502e-07, 'epoch': 2.79}
 93%|█████████▎| 524/564 [15:32<01:01,  1.54s/it] 93%|█████████▎| 525/564 [15:34<01:00,  1.55s/it]                                                 {'loss': 1.0971, 'grad_norm': 1.827241733917503, 'learning_rate': 1.4625228519195612e-07, 'epoch': 2.79}
 93%|█████████▎| 525/564 [15:34<01:00,  1.55s/it] 93%|█████████▎| 526/564 [15:35<00:58,  1.55s/it]                                                 {'loss': 0.8185, 'grad_norm': 1.9266939197450894, 'learning_rate': 1.425959780621572e-07, 'epoch': 2.8}
 93%|█████████▎| 526/564 [15:35<00:58,  1.55s/it] 93%|█████████▎| 527/564 [15:37<00:57,  1.56s/it]                                                 {'loss': 0.8865, 'grad_norm': 1.7365000413468896, 'learning_rate': 1.389396709323583e-07, 'epoch': 2.8}
 93%|█████████▎| 527/564 [15:37<00:57,  1.56s/it] 94%|█████████▎| 528/564 [15:38<00:56,  1.56s/it]                                                 {'loss': 1.1949, 'grad_norm': 1.8919841727077331, 'learning_rate': 1.3528336380255943e-07, 'epoch': 2.81}
 94%|█████████▎| 528/564 [15:38<00:56,  1.56s/it] 94%|█████████▍| 529/564 [15:40<00:54,  1.56s/it]                                                 {'loss': 1.0729, 'grad_norm': 1.857372728479183, 'learning_rate': 1.316270566727605e-07, 'epoch': 2.81}
 94%|█████████▍| 529/564 [15:40<00:54,  1.56s/it] 94%|█████████▍| 530/564 [15:41<00:53,  1.57s/it]                                                 {'loss': 1.1462, 'grad_norm': 1.7656306365460641, 'learning_rate': 1.279707495429616e-07, 'epoch': 2.82}
 94%|█████████▍| 530/564 [15:41<00:53,  1.57s/it] 94%|█████████▍| 531/564 [15:43<00:51,  1.56s/it]                                                 {'loss': 1.0242, 'grad_norm': 2.298048139833861, 'learning_rate': 1.243144424131627e-07, 'epoch': 2.82}
 94%|█████████▍| 531/564 [15:43<00:51,  1.56s/it] 94%|█████████▍| 532/564 [15:45<00:49,  1.55s/it]                                                 {'loss': 1.3245, 'grad_norm': 1.987876964415739, 'learning_rate': 1.206581352833638e-07, 'epoch': 2.83}
 94%|█████████▍| 532/564 [15:45<00:49,  1.55s/it] 95%|█████████▍| 533/564 [15:46<00:47,  1.55s/it]                                                 {'loss': 0.9651, 'grad_norm': 1.8115391577452464, 'learning_rate': 1.1700182815356489e-07, 'epoch': 2.84}
 95%|█████████▍| 533/564 [15:46<00:47,  1.55s/it] 95%|█████████▍| 534/564 [15:48<00:46,  1.55s/it]                                                 {'loss': 1.0788, 'grad_norm': 1.9924328872602677, 'learning_rate': 1.13345521023766e-07, 'epoch': 2.84}
 95%|█████████▍| 534/564 [15:48<00:46,  1.55s/it] 95%|█████████▍| 535/564 [15:49<00:44,  1.55s/it]                                                 {'loss': 1.3014, 'grad_norm': 2.0685338927859305, 'learning_rate': 1.0968921389396708e-07, 'epoch': 2.85}
 95%|█████████▍| 535/564 [15:49<00:44,  1.55s/it] 95%|█████████▌| 536/564 [15:51<00:43,  1.55s/it]                                                 {'loss': 0.9858, 'grad_norm': 1.8312529093104477, 'learning_rate': 1.0603290676416817e-07, 'epoch': 2.85}
 95%|█████████▌| 536/564 [15:51<00:43,  1.55s/it] 95%|█████████▌| 537/564 [15:52<00:41,  1.55s/it]                                                 {'loss': 1.1781, 'grad_norm': 1.946560026877154, 'learning_rate': 1.0237659963436929e-07, 'epoch': 2.86}
 95%|█████████▌| 537/564 [15:52<00:41,  1.55s/it] 95%|█████████▌| 538/564 [15:54<00:40,  1.56s/it]                                                 {'loss': 1.0137, 'grad_norm': 1.9810493967439085, 'learning_rate': 9.872029250457038e-08, 'epoch': 2.86}
 95%|█████████▌| 538/564 [15:54<00:40,  1.56s/it] 96%|█████████▌| 539/564 [15:55<00:38,  1.55s/it]                                                 {'loss': 1.0055, 'grad_norm': 1.9241286215561908, 'learning_rate': 9.506398537477148e-08, 'epoch': 2.87}
 96%|█████████▌| 539/564 [15:55<00:38,  1.55s/it] 96%|█████████▌| 540/564 [15:57<00:37,  1.56s/it]                                                 {'loss': 1.0748, 'grad_norm': 1.7707240531764397, 'learning_rate': 9.140767824497257e-08, 'epoch': 2.87}
 96%|█████████▌| 540/564 [15:57<00:37,  1.56s/it] 96%|█████████▌| 541/564 [15:59<00:35,  1.56s/it]                                                 {'loss': 1.1122, 'grad_norm': 1.9629101026486826, 'learning_rate': 8.775137111517366e-08, 'epoch': 2.88}
 96%|█████████▌| 541/564 [15:59<00:35,  1.56s/it] 96%|█████████▌| 542/564 [16:00<00:34,  1.56s/it]                                                 {'loss': 1.2539, 'grad_norm': 1.8349020872873927, 'learning_rate': 8.409506398537477e-08, 'epoch': 2.88}
 96%|█████████▌| 542/564 [16:00<00:34,  1.56s/it] 96%|█████████▋| 543/564 [16:02<00:32,  1.56s/it]                                                 {'loss': 1.0653, 'grad_norm': 1.681093269227946, 'learning_rate': 8.043875685557587e-08, 'epoch': 2.89}
 96%|█████████▋| 543/564 [16:02<00:32,  1.56s/it] 96%|█████████▋| 544/564 [16:04<00:32,  1.64s/it]                                                 {'loss': 1.1051, 'grad_norm': 1.6153404968397307, 'learning_rate': 7.678244972577697e-08, 'epoch': 2.89}
 96%|█████████▋| 544/564 [16:04<00:32,  1.64s/it] 97%|█████████▋| 545/564 [16:05<00:31,  1.66s/it]                                                 {'loss': 1.1838, 'grad_norm': 1.5598085509846145, 'learning_rate': 7.312614259597806e-08, 'epoch': 2.9}
 97%|█████████▋| 545/564 [16:05<00:31,  1.66s/it] 97%|█████████▋| 546/564 [16:07<00:29,  1.64s/it]                                                 {'loss': 1.089, 'grad_norm': 1.8546543880443356, 'learning_rate': 6.946983546617915e-08, 'epoch': 2.9}
 97%|█████████▋| 546/564 [16:07<00:29,  1.64s/it] 97%|█████████▋| 547/564 [16:08<00:27,  1.61s/it]                                                 {'loss': 1.3014, 'grad_norm': 1.9705692908061538, 'learning_rate': 6.581352833638025e-08, 'epoch': 2.91}
 97%|█████████▋| 547/564 [16:08<00:27,  1.61s/it] 97%|█████████▋| 548/564 [16:10<00:25,  1.59s/it]                                                 {'loss': 1.1338, 'grad_norm': 2.055680225017053, 'learning_rate': 6.215722120658136e-08, 'epoch': 2.91}
 97%|█████████▋| 548/564 [16:10<00:25,  1.59s/it] 97%|█████████▋| 549/564 [16:11<00:23,  1.56s/it]                                                 {'loss': 1.186, 'grad_norm': 1.637656099085004, 'learning_rate': 5.8500914076782446e-08, 'epoch': 2.92}
 97%|█████████▋| 549/564 [16:11<00:23,  1.56s/it] 98%|█████████▊| 550/564 [16:13<00:21,  1.56s/it]                                                 {'loss': 1.3241, 'grad_norm': 1.809677536797325, 'learning_rate': 5.484460694698354e-08, 'epoch': 2.93}
 98%|█████████▊| 550/564 [16:13<00:21,  1.56s/it] 98%|█████████▊| 551/564 [16:14<00:19,  1.54s/it]                                                 {'loss': 1.0243, 'grad_norm': 2.021889695810409, 'learning_rate': 5.1188299817184645e-08, 'epoch': 2.93}
 98%|█████████▊| 551/564 [16:14<00:19,  1.54s/it] 98%|█████████▊| 552/564 [16:16<00:18,  1.53s/it]                                                 {'loss': 1.0771, 'grad_norm': 2.004798707081724, 'learning_rate': 4.753199268738574e-08, 'epoch': 2.94}
 98%|█████████▊| 552/564 [16:16<00:18,  1.53s/it] 98%|█████████▊| 553/564 [16:18<00:17,  1.55s/it]                                                 {'loss': 1.3248, 'grad_norm': 1.8369840710399077, 'learning_rate': 4.387568555758683e-08, 'epoch': 2.94}
 98%|█████████▊| 553/564 [16:18<00:17,  1.55s/it] 98%|█████████▊| 554/564 [16:19<00:15,  1.55s/it]                                                 {'loss': 1.1619, 'grad_norm': 1.7211910938871429, 'learning_rate': 4.0219378427787934e-08, 'epoch': 2.95}
 98%|█████████▊| 554/564 [16:19<00:15,  1.55s/it] 98%|█████████▊| 555/564 [16:21<00:13,  1.55s/it]                                                 {'loss': 1.1552, 'grad_norm': 1.9346162085287526, 'learning_rate': 3.656307129798903e-08, 'epoch': 2.95}
 98%|█████████▊| 555/564 [16:21<00:13,  1.55s/it] 99%|█████████▊| 556/564 [16:22<00:12,  1.55s/it]                                                 {'loss': 0.9154, 'grad_norm': 1.9362921866956277, 'learning_rate': 3.290676416819013e-08, 'epoch': 2.96}
 99%|█████████▊| 556/564 [16:22<00:12,  1.55s/it] 99%|█████████▉| 557/564 [16:24<00:10,  1.55s/it]                                                 {'loss': 1.0425, 'grad_norm': 1.8242700917086032, 'learning_rate': 2.9250457038391223e-08, 'epoch': 2.96}
 99%|█████████▉| 557/564 [16:24<00:10,  1.55s/it] 99%|█████████▉| 558/564 [16:25<00:09,  1.55s/it]                                                 {'loss': 1.1303, 'grad_norm': 1.7625491235393445, 'learning_rate': 2.5594149908592323e-08, 'epoch': 2.97}
 99%|█████████▉| 558/564 [16:25<00:09,  1.55s/it] 99%|█████████▉| 559/564 [16:27<00:07,  1.55s/it]                                                 {'loss': 0.9434, 'grad_norm': 2.080164252556217, 'learning_rate': 2.1937842778793416e-08, 'epoch': 2.97}
 99%|█████████▉| 559/564 [16:27<00:07,  1.55s/it] 99%|█████████▉| 560/564 [16:28<00:06,  1.54s/it]                                                 {'loss': 0.9979, 'grad_norm': 1.8161998219034576, 'learning_rate': 1.8281535648994515e-08, 'epoch': 2.98}
 99%|█████████▉| 560/564 [16:28<00:06,  1.54s/it] 99%|█████████▉| 561/564 [16:30<00:04,  1.54s/it]                                                 {'loss': 1.0263, 'grad_norm': 1.7427255660548853, 'learning_rate': 1.4625228519195612e-08, 'epoch': 2.98}
 99%|█████████▉| 561/564 [16:30<00:04,  1.54s/it]100%|█████████▉| 562/564 [16:31<00:03,  1.55s/it]                                                 {'loss': 0.9686, 'grad_norm': 1.7873796499096108, 'learning_rate': 1.0968921389396708e-08, 'epoch': 2.99}
100%|█████████▉| 562/564 [16:31<00:03,  1.55s/it]100%|█████████▉| 563/564 [16:33<00:01,  1.56s/it]                                                 {'loss': 1.2157, 'grad_norm': 2.4015692458156552, 'learning_rate': 7.312614259597806e-09, 'epoch': 2.99}
100%|█████████▉| 563/564 [16:33<00:01,  1.56s/it]100%|██████████| 564/564 [16:35<00:00,  1.56s/it]                                                 {'loss': 1.1574, 'grad_norm': 1.7606216630530884, 'learning_rate': 3.656307129798903e-09, 'epoch': 3.0}
100%|██████████| 564/564 [16:35<00:00,  1.56s/it]                                                 {'train_runtime': 995.1034, 'train_samples_per_second': 45.255, 'train_steps_per_second': 0.567, 'train_loss': 1.2273550821957013, 'epoch': 3.0}
100%|██████████| 564/564 [16:35<00:00,  1.56s/it]100%|██████████| 564/564 [16:35<00:00,  1.76s/it]
[2024-08-08 16:06:21,656] [INFO] [launch.py:351:main] Process 679476 exits successfully.
[2024-08-08 16:06:22,657] [INFO] [launch.py:351:main] Process 679475 exits successfully.
[2024-08-08 16:06:22,657] [INFO] [launch.py:351:main] Process 679477 exits successfully.
[2024-08-08 16:06:22,657] [INFO] [launch.py:351:main] Process 679471 exits successfully.
[2024-08-08 16:06:22,658] [INFO] [launch.py:351:main] Process 679474 exits successfully.
[2024-08-08 16:06:23,658] [INFO] [launch.py:351:main] Process 679470 exits successfully.
[2024-08-08 16:06:23,658] [INFO] [launch.py:351:main] Process 679469 exits successfully.
[2024-08-08 16:07:09,664] [INFO] [launch.py:351:main] Process 679468 exits successfully.

Namespace(mode=['alpaca'], base_model='/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', template_name='barebone', total_bsz=64, epoch=3, lr=2e-05, data_path='', task_name='dolly', tuned_dir='./cache', use_peft=False, lora_r=16, lora_alpha=32)
num gpus:  8
Running 1/1: deepspeed --num_gpus=8 train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True
        --model_name_or_path /fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned --data_path ../data/stanford_alpaca/dolly_data.json
        --output_dir /fsx-project/yunyun/models/_fsx-project_dolly_tuned
        --num_train_epochs 3
        --per_device_train_batch_size 10
        --per_device_eval_batch_size 4
        --gradient_accumulation_steps 1
        --gradient_checkpointing=True
        --evaluation_strategy=no
        --save_strategy=steps
        --save_steps 500
        --save_total_limit 1
        --learning_rate 2e-6
        --weight_decay 0.
        --report_to tensorboard
        --warmup_ratio 0.03
        --lr_scheduler_type=cosine
        --logging_steps 1
        --use_peft False 
        --lora_r 16 --lora_alpha 32
['deepspeed', '--num_gpus=8', 'train.py', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:10,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-26 18:11:17,751] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-08-26 18:11:17,752] [INFO] [runner.py:568:main] cmd = /data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True --model_name_or_path /fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned --data_path ../data/stanford_alpaca/dolly_data.json --output_dir /fsx-project/yunyun/models/_fsx-project_dolly_tuned --num_train_epochs 3 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --gradient_checkpointing=True --evaluation_strategy=no --save_strategy=steps --save_steps 500 --save_total_limit 1 --learning_rate 2e-6 --weight_decay 0. --report_to tensorboard --warmup_ratio 0.03 --lr_scheduler_type=cosine --logging_steps 1 --use_peft False --lora_r 16 --lora_alpha 32
[2024-08-26 18:11:20,450] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-26 18:11:23,962] [INFO] [launch.py:139:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2024-08-26 18:11:23,962] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-08-26 18:11:23,963] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-26 18:11:23,963] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-26 18:11:23,963] [INFO] [launch.py:164:main] dist_world_size=8
[2024-08-26 18:11:23,963] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-08-26 18:11:23,963] [INFO] [launch.py:256:main] process 1034822 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=0', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,964] [INFO] [launch.py:256:main] process 1034823 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=1', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,965] [INFO] [launch.py:256:main] process 1034824 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=2', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,965] [INFO] [launch.py:256:main] process 1034825 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=3', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,966] [INFO] [launch.py:256:main] process 1034826 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=4', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,966] [INFO] [launch.py:256:main] process 1034827 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=5', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,967] [INFO] [launch.py:256:main] process 1034828 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=6', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-26 18:11:23,967] [INFO] [launch.py:256:main] process 1034829 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=7', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', '/fsx-project/yunyun/models/llama2-7b_second_stage_ni_tuned', '--data_path', '../data/stanford_alpaca/dolly_data.json', '--output_dir', '/fsx-project/yunyun/models/_fsx-project_dolly_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-08-26 18:11:38,005] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-08-26 18:11:38,174] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[2024-08-26 18:11:38,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-26 18:11:38,273] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 18:11:38,274] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 18:11:38,291] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 18:11:38,293] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 18:11:38,294] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible

[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-26 18:11:38,777] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 18:11:38,777] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-08-26 18:11:38,925] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:38,987] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:39,014] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 18:11:39,017] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:39,026] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:39,030] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:39,062] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[2024-08-26 18:11:49,578] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.38it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.39it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.39it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.39it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.38it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.38it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.37it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:06<00:13,  6.89s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.30s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.30s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.30s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.31s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.31s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.31s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:04,  4.32s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.01s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.40s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.41s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]
Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:06,  6.85s/it]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:18<00:00,  6.05s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:18<00:00,  6.27s/it]
[2024-08-26 18:12:08,549] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 582, num_elems = 13.48B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.76s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.76s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.77s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.77s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.77s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.78s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:03,  1.78s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:02<00:05,  2.91s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.43s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.07s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.10s/it]
Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.89s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.63s/it]
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
[rank6]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank5]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank2]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...

[rank4]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank0]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank7]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank1]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[rank3]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 2.695241689682007 secondsTime to load fused_adam op: 2.845446825027466 secondsTime to load fused_adam op: 2.916778326034546 secondsTime to load fused_adam op: 2.887732982635498 secondsTime to load fused_adam op: 2.9478836059570312 seconds
Time to load fused_adam op: 2.915299892425537 secondsTime to load fused_adam op: 2.752699851989746 secondsTime to load fused_adam op: 2.947737455368042 seconds






Parameter Offload: Total persistent parameters: 266240 in 65 params
  0%|          | 0/564 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/564 [00:08<1:16:36,  8.16s/it]                                                 {'loss': 1.555, 'grad_norm': 10.663691523359528, 'learning_rate': 0.0, 'epoch': 0.01}
  0%|          | 1/564 [00:08<1:16:36,  8.16s/it]  0%|          | 2/564 [00:09<37:34,  4.01s/it]                                                 {'loss': 1.5882, 'grad_norm': 9.175155087819132, 'learning_rate': 4.89301084236452e-07, 'epoch': 0.01}
  0%|          | 2/564 [00:09<37:34,  4.01s/it]  1%|          | 3/564 [00:10<24:00,  2.57s/it]                                               {'loss': 1.5964, 'grad_norm': 13.47416857155505, 'learning_rate': 7.755238700769802e-07, 'epoch': 0.02}
  1%|          | 3/564 [00:10<24:00,  2.57s/it]  1%|          | 4/564 [00:10<17:36,  1.89s/it]                                               {'loss': 1.5377, 'grad_norm': 10.270348269950334, 'learning_rate': 9.78602168472904e-07, 'epoch': 0.02}
  1%|          | 4/564 [00:10<17:36,  1.89s/it]  1%|          | 5/564 [00:11<14:02,  1.51s/it]                                               {'loss': 1.6202, 'grad_norm': 10.135231572824445, 'learning_rate': 1.1361219343474658e-06, 'epoch': 0.03}
  1%|          | 5/564 [00:11<14:02,  1.51s/it]  1%|          | 6/564 [00:12<11:57,  1.28s/it]                                               {'loss': 1.3935, 'grad_norm': 8.337532920583527, 'learning_rate': 1.264824954313432e-06, 'epoch': 0.03}
  1%|          | 6/564 [00:12<11:57,  1.28s/it]  1%|          | 7/564 [00:13<10:32,  1.14s/it]                                               {'loss': 1.6077, 'grad_norm': 7.6805185879838165, 'learning_rate': 1.373641807199326e-06, 'epoch': 0.04}
  1%|          | 7/564 [00:13<10:32,  1.14s/it]  1%|â–         | 8/564 [00:14<09:39,  1.04s/it]                                               {'loss': 1.4386, 'grad_norm': 6.381301673565768, 'learning_rate': 1.4679032527093559e-06, 'epoch': 0.04}
  1%|â–         | 8/564 [00:14<09:39,  1.04s/it]  2%|â–         | 9/564 [00:15<09:02,  1.02it/s]                                               {'loss': 1.5106, 'grad_norm': 4.028187674681637, 'learning_rate': 1.5510477401539603e-06, 'epoch': 0.05}
  2%|â–         | 9/564 [00:15<09:02,  1.02it/s]  2%|â–         | 10/564 [00:15<08:38,  1.07it/s]                                                {'loss': 1.6018, 'grad_norm': 2.987548916285931, 'learning_rate': 1.625423018583918e-06, 'epoch': 0.05}
  2%|â–         | 10/564 [00:16<08:38,  1.07it/s]  2%|â–         | 11/564 [00:16<08:21,  1.10it/s]                                                {'loss': 1.5522, 'grad_norm': 4.006510440638167, 'learning_rate': 1.6927036418410939e-06, 'epoch': 0.06}
  2%|â–         | 11/564 [00:16<08:21,  1.10it/s]  2%|â–         | 12/564 [00:17<08:07,  1.13it/s]                                                {'loss': 1.4731, 'grad_norm': 3.206858772646212, 'learning_rate': 1.7541260385498841e-06, 'epoch': 0.06}
  2%|â–         | 12/564 [00:17<08:07,  1.13it/s]  2%|â–         | 13/564 [00:18<08:00,  1.15it/s]                                                {'loss': 1.5436, 'grad_norm': 3.383392254324067, 'learning_rate': 1.8106291662380673e-06, 'epoch': 0.07}
  2%|â–         | 13/564 [00:18<08:00,  1.15it/s]  2%|â–         | 14/564 [00:19<07:54,  1.16it/s]                                                {'loss': 1.4666, 'grad_norm': 3.2534733656229147, 'learning_rate': 1.862942891435778e-06, 'epoch': 0.07}
  2%|â–         | 14/564 [00:19<07:54,  1.16it/s]  3%|â–         | 15/564 [00:20<07:49,  1.17it/s]                                                {'loss': 1.4603, 'grad_norm': 2.6839983309928397, 'learning_rate': 1.911645804424446e-06, 'epoch': 0.08}
  3%|â–         | 15/564 [00:20<07:49,  1.17it/s]  3%|â–         | 16/564 [00:21<07:46,  1.18it/s]                                                {'loss': 1.3747, 'grad_norm': 3.6261080210447987, 'learning_rate': 1.957204336945808e-06, 'epoch': 0.09}
  3%|â–         | 16/564 [00:21<07:46,  1.18it/s]  3%|â–         | 17/564 [00:21<07:43,  1.18it/s]                                                {'loss': 1.489, 'grad_norm': 2.7623768942071214, 'learning_rate': 2e-06, 'epoch': 0.09}
  3%|â–         | 17/564 [00:21<07:43,  1.18it/s]  3%|â–         | 18/564 [00:22<07:40,  1.18it/s]                                                {'loss': 1.3857, 'grad_norm': 2.9380340427847074, 'learning_rate': 2e-06, 'epoch': 0.1}
  3%|â–         | 18/564 [00:22<07:40,  1.18it/s]  3%|â–         | 19/564 [00:23<07:38,  1.19it/s]                                                {'loss': 1.341, 'grad_norm': 3.2595953936585746, 'learning_rate': 1.996343692870201e-06, 'epoch': 0.1}
  3%|â–         | 19/564 [00:23<07:38,  1.19it/s]  4%|â–         | 20/564 [00:24<07:36,  1.19it/s]                                                {'loss': 1.4081, 'grad_norm': 2.5043323655783203, 'learning_rate': 1.992687385740402e-06, 'epoch': 0.11}
  4%|â–         | 20/564 [00:24<07:36,  1.19it/s]  4%|â–         | 21/564 [00:25<07:34,  1.20it/s]                                                {'loss': 1.4225, 'grad_norm': 2.523019283588873, 'learning_rate': 1.9890310786106034e-06, 'epoch': 0.11}
  4%|â–         | 21/564 [00:25<07:34,  1.20it/s]  4%|â–         | 22/564 [00:26<07:34,  1.19it/s]                                                {'loss': 1.4713, 'grad_norm': 2.3013494051099017, 'learning_rate': 1.9853747714808044e-06, 'epoch': 0.12}
  4%|â–         | 22/564 [00:26<07:34,  1.19it/s]  4%|â–         | 23/564 [00:26<07:33,  1.19it/s]                                                {'loss': 1.415, 'grad_norm': 2.4735501485416886, 'learning_rate': 1.9817184643510055e-06, 'epoch': 0.12}
  4%|â–         | 23/564 [00:26<07:33,  1.19it/s]  4%|â–         | 24/564 [00:27<07:31,  1.20it/s]                                                {'loss': 1.5851, 'grad_norm': 2.60455787860372, 'learning_rate': 1.9780621572212065e-06, 'epoch': 0.13}
  4%|â–         | 24/564 [00:27<07:31,  1.20it/s]  4%|â–         | 25/564 [00:28<07:31,  1.19it/s]                                                {'loss': 1.5065, 'grad_norm': 2.223349680573299, 'learning_rate': 1.9744058500914075e-06, 'epoch': 0.13}
  4%|â–         | 25/564 [00:28<07:31,  1.19it/s]  5%|â–         | 26/564 [00:29<07:32,  1.19it/s]                                                {'loss': 1.3574, 'grad_norm': 2.3965302198510594, 'learning_rate': 1.970749542961609e-06, 'epoch': 0.14}
  5%|â–         | 26/564 [00:29<07:32,  1.19it/s]  5%|â–         | 27/564 [00:30<07:29,  1.19it/s]                                                {'loss': 1.4869, 'grad_norm': 2.4871067867532766, 'learning_rate': 1.9670932358318095e-06, 'epoch': 0.14}
  5%|â–         | 27/564 [00:30<07:29,  1.19it/s]  5%|â–         | 28/564 [00:31<07:28,  1.20it/s]                                                {'loss': 1.362, 'grad_norm': 2.091718331952042, 'learning_rate': 1.963436928702011e-06, 'epoch': 0.15}
  5%|â–         | 28/564 [00:31<07:28,  1.20it/s]  5%|â–Œ         | 29/564 [00:31<07:26,  1.20it/s]                                                {'loss': 1.5461, 'grad_norm': 3.024809312184139, 'learning_rate': 1.959780621572212e-06, 'epoch': 0.15}
  5%|â–Œ         | 29/564 [00:31<07:26,  1.20it/s]  5%|â–Œ         | 30/564 [00:32<07:26,  1.20it/s]                                                {'loss': 1.3501, 'grad_norm': 2.5069933429721543, 'learning_rate': 1.956124314442413e-06, 'epoch': 0.16}
  5%|â–Œ         | 30/564 [00:32<07:26,  1.20it/s]  5%|â–Œ         | 31/564 [00:33<07:25,  1.20it/s]                                                {'loss': 1.4846, 'grad_norm': 2.8543570056563086, 'learning_rate': 1.952468007312614e-06, 'epoch': 0.16}
  5%|â–Œ         | 31/564 [00:33<07:25,  1.20it/s]  6%|â–Œ         | 32/564 [00:34<07:25,  1.19it/s]                                                {'loss': 1.4846, 'grad_norm': 2.455011168894306, 'learning_rate': 1.948811700182815e-06, 'epoch': 0.17}
  6%|â–Œ         | 32/564 [00:34<07:25,  1.19it/s]  6%|â–Œ         | 33/564 [00:35<07:23,  1.20it/s]                                                {'loss': 1.493, 'grad_norm': 2.442287351385922, 'learning_rate': 1.9451553930530165e-06, 'epoch': 0.18}
  6%|â–Œ         | 33/564 [00:35<07:23,  1.20it/s]  6%|â–Œ         | 34/564 [00:36<07:23,  1.19it/s]                                                {'loss': 1.5394, 'grad_norm': 2.4608621781585707, 'learning_rate': 1.9414990859232176e-06, 'epoch': 0.18}
  6%|â–Œ         | 34/564 [00:36<07:23,  1.19it/s]  6%|â–Œ         | 35/564 [00:36<07:23,  1.19it/s]                                                {'loss': 1.411, 'grad_norm': 2.6084956236712804, 'learning_rate': 1.9378427787934186e-06, 'epoch': 0.19}
  6%|â–Œ         | 35/564 [00:36<07:23,  1.19it/s]  6%|â–‹         | 36/564 [00:37<07:22,  1.19it/s]                                                {'loss': 1.3876, 'grad_norm': 2.5644842720320153, 'learning_rate': 1.9341864716636196e-06, 'epoch': 0.19}
  6%|â–‹         | 36/564 [00:37<07:22,  1.19it/s]  7%|â–‹         | 37/564 [00:38<07:19,  1.20it/s]                                                {'loss': 1.5192, 'grad_norm': 2.58550716236004, 'learning_rate': 1.9305301645338206e-06, 'epoch': 0.2}
  7%|â–‹         | 37/564 [00:38<07:19,  1.20it/s]  7%|â–‹         | 38/564 [00:39<07:18,  1.20it/s]                                                {'loss': 1.4615, 'grad_norm': 2.3384129216507605, 'learning_rate': 1.9268738574040217e-06, 'epoch': 0.2}
  7%|â–‹         | 38/564 [00:39<07:18,  1.20it/s]  7%|â–‹         | 39/564 [00:40<07:18,  1.20it/s]                                                {'loss': 1.306, 'grad_norm': 2.7989712630875165, 'learning_rate': 1.923217550274223e-06, 'epoch': 0.21}
  7%|â–‹         | 39/564 [00:40<07:18,  1.20it/s]  7%|â–‹         | 40/564 [00:41<07:18,  1.19it/s]                                                {'loss': 1.3536, 'grad_norm': 2.3167613444751027, 'learning_rate': 1.919561243144424e-06, 'epoch': 0.21}
  7%|â–‹         | 40/564 [00:41<07:18,  1.19it/s]  7%|â–‹         | 41/564 [00:41<07:17,  1.19it/s]                                                {'loss': 1.5642, 'grad_norm': 2.326293425086621, 'learning_rate': 1.915904936014625e-06, 'epoch': 0.22}
  7%|â–‹         | 41/564 [00:41<07:17,  1.19it/s]  7%|â–‹         | 42/564 [00:42<07:16,  1.20it/s]                                                {'loss': 1.4897, 'grad_norm': 2.4323205368773135, 'learning_rate': 1.912248628884826e-06, 'epoch': 0.22}
  7%|â–‹         | 42/564 [00:42<07:16,  1.20it/s]  8%|â–Š         | 43/564 [00:43<07:15,  1.20it/s]                                                {'loss': 1.3662, 'grad_norm': 2.660518998071257, 'learning_rate': 1.908592321755027e-06, 'epoch': 0.23}
  8%|â–Š         | 43/564 [00:43<07:15,  1.20it/s]  8%|â–Š         | 44/564 [00:44<07:14,  1.20it/s]                                                {'loss': 1.221, 'grad_norm': 2.4870171908448984, 'learning_rate': 1.9049360146252284e-06, 'epoch': 0.23}
  8%|â–Š         | 44/564 [00:44<07:14,  1.20it/s]  8%|â–Š         | 45/564 [00:45<07:14,  1.20it/s]                                                {'loss': 1.5477, 'grad_norm': 2.320708901342419, 'learning_rate': 1.9012797074954294e-06, 'epoch': 0.24}
  8%|â–Š         | 45/564 [00:45<07:14,  1.20it/s]  8%|â–Š         | 46/564 [00:46<07:13,  1.19it/s]                                                {'loss': 1.4039, 'grad_norm': 2.407717929835197, 'learning_rate': 1.8976234003656307e-06, 'epoch': 0.24}
  8%|â–Š         | 46/564 [00:46<07:13,  1.19it/s]  8%|â–Š         | 47/564 [00:46<07:12,  1.20it/s]                                                {'loss': 1.6157, 'grad_norm': 2.1549755591039514, 'learning_rate': 1.8939670932358317e-06, 'epoch': 0.25}
  8%|â–Š         | 47/564 [00:46<07:12,  1.20it/s]  9%|â–Š         | 48/564 [00:47<07:13,  1.19it/s]                                                {'loss': 1.3967, 'grad_norm': 2.4747022522634743, 'learning_rate': 1.8903107861060327e-06, 'epoch': 0.26}
  9%|â–Š         | 48/564 [00:47<07:13,  1.19it/s]  9%|â–Š         | 49/564 [00:48<07:12,  1.19it/s]                                                {'loss': 1.3455, 'grad_norm': 2.3040119460327224, 'learning_rate': 1.886654478976234e-06, 'epoch': 0.26}
  9%|â–Š         | 49/564 [00:48<07:12,  1.19it/s]  9%|â–‰         | 50/564 [00:49<07:11,  1.19it/s]                                                {'loss': 1.4024, 'grad_norm': 2.474075124279629, 'learning_rate': 1.882998171846435e-06, 'epoch': 0.27}
  9%|â–‰         | 50/564 [00:49<07:11,  1.19it/s]  9%|â–‰         | 51/564 [00:50<07:10,  1.19it/s]                                                {'loss': 1.4175, 'grad_norm': 2.4329706648755027, 'learning_rate': 1.8793418647166362e-06, 'epoch': 0.27}
  9%|â–‰         | 51/564 [00:50<07:10,  1.19it/s]  9%|â–‰         | 52/564 [00:51<07:08,  1.19it/s]                                                {'loss': 1.4234, 'grad_norm': 2.397950005363391, 'learning_rate': 1.875685557586837e-06, 'epoch': 0.28}
  9%|â–‰         | 52/564 [00:51<07:08,  1.19it/s]  9%|â–‰         | 53/564 [00:51<07:07,  1.19it/s]                                                {'loss': 1.2389, 'grad_norm': 2.3736716898384254, 'learning_rate': 1.8720292504570383e-06, 'epoch': 0.28}
  9%|â–‰         | 53/564 [00:51<07:07,  1.19it/s] 10%|â–‰         | 54/564 [00:52<07:07,  1.19it/s]                                                {'loss': 1.2942, 'grad_norm': 2.076828789631075, 'learning_rate': 1.8683729433272395e-06, 'epoch': 0.29}
 10%|â–‰         | 54/564 [00:52<07:07,  1.19it/s] 10%|â–‰         | 55/564 [00:53<07:07,  1.19it/s]                                                {'loss': 1.3155, 'grad_norm': 3.4083598392162138, 'learning_rate': 1.8647166361974405e-06, 'epoch': 0.29}
 10%|â–‰         | 55/564 [00:53<07:07,  1.19it/s] 10%|â–‰         | 56/564 [00:54<07:06,  1.19it/s]                                                {'loss': 1.1682, 'grad_norm': 2.150490932634396, 'learning_rate': 1.8610603290676416e-06, 'epoch': 0.3}
 10%|â–‰         | 56/564 [00:54<07:06,  1.19it/s] 10%|â–ˆ         | 57/564 [00:55<07:06,  1.19it/s]                                                {'loss': 1.3947, 'grad_norm': 2.333915701098166, 'learning_rate': 1.8574040219378426e-06, 'epoch': 0.3}
 10%|â–ˆ         | 57/564 [00:55<07:06,  1.19it/s] 10%|â–ˆ         | 58/564 [00:56<07:06,  1.19it/s]                                                {'loss': 1.4922, 'grad_norm': 2.253449749752094, 'learning_rate': 1.8537477148080438e-06, 'epoch': 0.31}
 10%|â–ˆ         | 58/564 [00:56<07:06,  1.19it/s] 10%|â–ˆ         | 59/564 [00:57<07:04,  1.19it/s]                                                {'loss': 1.3563, 'grad_norm': 2.479783410260637, 'learning_rate': 1.8500914076782448e-06, 'epoch': 0.31}
 10%|â–ˆ         | 59/564 [00:57<07:04,  1.19it/s] 11%|â–ˆ         | 60/564 [00:57<07:03,  1.19it/s]                                                {'loss': 1.3001, 'grad_norm': 2.230293207757033, 'learning_rate': 1.846435100548446e-06, 'epoch': 0.32}
 11%|â–ˆ         | 60/564 [00:57<07:03,  1.19it/s] 11%|â–ˆ         | 61/564 [00:58<07:03,  1.19it/s]                                                {'loss': 1.4925, 'grad_norm': 2.333364327440938, 'learning_rate': 1.842778793418647e-06, 'epoch': 0.32}
 11%|â–ˆ         | 61/564 [00:58<07:03,  1.19it/s] 11%|â–ˆ         | 62/564 [00:59<07:03,  1.19it/s]                                                {'loss': 1.4427, 'grad_norm': 2.171031979819362, 'learning_rate': 1.8391224862888481e-06, 'epoch': 0.33}
 11%|â–ˆ         | 62/564 [00:59<07:03,  1.19it/s] 11%|â–ˆ         | 63/564 [01:00<07:03,  1.18it/s]                                                {'loss': 1.2928, 'grad_norm': 2.468942459352969, 'learning_rate': 1.8354661791590494e-06, 'epoch': 0.34}
 11%|â–ˆ         | 63/564 [01:00<07:03,  1.18it/s] 11%|â–ˆâ–        | 64/564 [01:01<07:01,  1.19it/s]                                                {'loss': 1.3103, 'grad_norm': 2.5197974135172014, 'learning_rate': 1.8318098720292504e-06, 'epoch': 0.34}
 11%|â–ˆâ–        | 64/564 [01:01<07:01,  1.19it/s] 12%|â–ˆâ–        | 65/564 [01:02<07:00,  1.19it/s]                                                {'loss': 1.6308, 'grad_norm': 2.0562989688960096, 'learning_rate': 1.8281535648994514e-06, 'epoch': 0.35}
 12%|â–ˆâ–        | 65/564 [01:02<07:00,  1.19it/s] 12%|â–ˆâ–        | 66/564 [01:02<06:59,  1.19it/s]                                                {'loss': 1.3655, 'grad_norm': 2.1256549674194862, 'learning_rate': 1.8244972577696524e-06, 'epoch': 0.35}
 12%|â–ˆâ–        | 66/564 [01:02<06:59,  1.19it/s] 12%|â–ˆâ–        | 67/564 [01:03<06:58,  1.19it/s]                                                {'loss': 1.4817, 'grad_norm': 2.1630932657644997, 'learning_rate': 1.8208409506398537e-06, 'epoch': 0.36}
 12%|â–ˆâ–        | 67/564 [01:03<06:58,  1.19it/s] 12%|â–ˆâ–        | 68/564 [01:04<06:57,  1.19it/s]                                                {'loss': 1.2901, 'grad_norm': 1.980564131475155, 'learning_rate': 1.817184643510055e-06, 'epoch': 0.36}
 12%|â–ˆâ–        | 68/564 [01:04<06:57,  1.19it/s] 12%|â–ˆâ–        | 69/564 [01:05<06:57,  1.19it/s]                                                {'loss': 1.3927, 'grad_norm': 2.282064030493257, 'learning_rate': 1.813528336380256e-06, 'epoch': 0.37}
 12%|â–ˆâ–        | 69/564 [01:05<06:57,  1.19it/s] 12%|â–ˆâ–        | 70/564 [01:06<06:57,  1.18it/s]                                                {'loss': 1.4394, 'grad_norm': 2.248900766367441, 'learning_rate': 1.809872029250457e-06, 'epoch': 0.37}
 12%|â–ˆâ–        | 70/564 [01:06<06:57,  1.18it/s] 13%|â–ˆâ–        | 71/564 [01:07<06:56,  1.18it/s]                                                {'loss': 1.4402, 'grad_norm': 2.1268332946823745, 'learning_rate': 1.806215722120658e-06, 'epoch': 0.38}
 13%|â–ˆâ–        | 71/564 [01:07<06:56,  1.18it/s] 13%|â–ˆâ–        | 72/564 [01:08<06:54,  1.19it/s]                                                {'loss': 1.2811, 'grad_norm': 2.4539090647539656, 'learning_rate': 1.8025594149908592e-06, 'epoch': 0.38}
 13%|â–ˆâ–        | 72/564 [01:08<06:54,  1.19it/s] 13%|â–ˆâ–        | 73/564 [01:08<06:55,  1.18it/s]                                                {'loss': 1.4255, 'grad_norm': 2.1527005588604653, 'learning_rate': 1.7989031078610602e-06, 'epoch': 0.39}
 13%|â–ˆâ–        | 73/564 [01:08<06:55,  1.18it/s] 13%|â–ˆâ–        | 74/564 [01:09<06:54,  1.18it/s]                                                {'loss': 1.3388, 'grad_norm': 2.5218533107339978, 'learning_rate': 1.7952468007312612e-06, 'epoch': 0.39}
 13%|â–ˆâ–        | 74/564 [01:09<06:54,  1.18it/s] 13%|â–ˆâ–        | 75/564 [01:10<06:53,  1.18it/s]                                                {'loss': 1.2554, 'grad_norm': 2.3357542103895126, 'learning_rate': 1.7915904936014625e-06, 'epoch': 0.4}
 13%|â–ˆâ–        | 75/564 [01:10<06:53,  1.18it/s] 13%|â–ˆâ–        | 76/564 [01:11<06:52,  1.18it/s]                                                {'loss': 1.6078, 'grad_norm': 2.3333127613019173, 'learning_rate': 1.7879341864716635e-06, 'epoch': 0.4}
 13%|â–ˆâ–        | 76/564 [01:11<06:52,  1.18it/s] 14%|â–ˆâ–        | 77/564 [01:12<06:52,  1.18it/s]                                                {'loss': 1.1991, 'grad_norm': 2.345700669249804, 'learning_rate': 1.7842778793418647e-06, 'epoch': 0.41}
 14%|â–ˆâ–        | 77/564 [01:12<06:52,  1.18it/s] 14%|â–ˆâ–        | 78/564 [01:13<06:52,  1.18it/s]                                                {'loss': 1.4848, 'grad_norm': 2.477350006012737, 'learning_rate': 1.7806215722120656e-06, 'epoch': 0.41}
 14%|â–ˆâ–        | 78/564 [01:13<06:52,  1.18it/s] 14%|â–ˆâ–        | 79/564 [01:13<06:51,  1.18it/s]                                                {'loss': 1.3018, 'grad_norm': 2.334997093760921, 'learning_rate': 1.7769652650822668e-06, 'epoch': 0.42}
 14%|â–ˆâ–        | 79/564 [01:13<06:51,  1.18it/s] 14%|â–ˆâ–        | 80/564 [01:14<06:50,  1.18it/s]                                                {'loss': 1.2395, 'grad_norm': 2.6934419116015964, 'learning_rate': 1.7733089579524678e-06, 'epoch': 0.43}
 14%|â–ˆâ–        | 80/564 [01:14<06:50,  1.18it/s] 14%|â–ˆâ–        | 81/564 [01:15<06:47,  1.19it/s]                                                {'loss': 1.4061, 'grad_norm': 2.3452207395700384, 'learning_rate': 1.769652650822669e-06, 'epoch': 0.43}
 14%|â–ˆâ–        | 81/564 [01:15<06:47,  1.19it/s] 15%|â–ˆâ–        | 82/564 [01:16<06:46,  1.19it/s]                                                {'loss': 1.5057, 'grad_norm': 2.5548247030989883, 'learning_rate': 1.7659963436928703e-06, 'epoch': 0.44}
 15%|â–ˆâ–        | 82/564 [01:16<06:46,  1.19it/s] 15%|â–ˆâ–        | 83/564 [01:17<06:44,  1.19it/s]                                                {'loss': 1.4972, 'grad_norm': 2.2114690750871464, 'learning_rate': 1.762340036563071e-06, 'epoch': 0.44}
 15%|â–ˆâ–        | 83/564 [01:17<06:44,  1.19it/s] 15%|â–ˆâ–        | 84/564 [01:18<06:43,  1.19it/s]                                                {'loss': 1.4683, 'grad_norm': 2.3747654756821803, 'learning_rate': 1.7586837294332723e-06, 'epoch': 0.45}
 15%|â–ˆâ–        | 84/564 [01:18<06:43,  1.19it/s] 15%|â–ˆâ–Œ        | 85/564 [01:18<06:43,  1.19it/s]                                                {'loss': 1.4087, 'grad_norm': 2.216792279422098, 'learning_rate': 1.7550274223034734e-06, 'epoch': 0.45}
 15%|â–ˆâ–Œ        | 85/564 [01:18<06:43,  1.19it/s] 15%|â–ˆâ–Œ        | 86/564 [01:19<06:43,  1.18it/s]                                                {'loss': 1.5472, 'grad_norm': 2.0873834248961582, 'learning_rate': 1.7513711151736746e-06, 'epoch': 0.46}
 15%|â–ˆâ–Œ        | 86/564 [01:19<06:43,  1.18it/s] 15%|â–ˆâ–Œ        | 87/564 [01:20<06:42,  1.19it/s]                                                {'loss': 1.4024, 'grad_norm': 2.5857906908175603, 'learning_rate': 1.7477148080438754e-06, 'epoch': 0.46}
 15%|â–ˆâ–Œ        | 87/564 [01:20<06:42,  1.19it/s] 16%|â–ˆâ–Œ        | 88/564 [01:21<06:40,  1.19it/s]                                                {'loss': 1.4132, 'grad_norm': 2.2605815118278585, 'learning_rate': 1.7440585009140766e-06, 'epoch': 0.47}
 16%|â–ˆâ–Œ        | 88/564 [01:21<06:40,  1.19it/s] 16%|â–ˆâ–Œ        | 89/564 [01:22<06:40,  1.19it/s]                                                {'loss': 1.465, 'grad_norm': 2.382328779508058, 'learning_rate': 1.7404021937842779e-06, 'epoch': 0.47}
 16%|â–ˆâ–Œ        | 89/564 [01:22<06:40,  1.19it/s] 16%|â–ˆâ–Œ        | 90/564 [01:23<06:39,  1.19it/s]                                                {'loss': 1.28, 'grad_norm': 2.4055201991196333, 'learning_rate': 1.736745886654479e-06, 'epoch': 0.48}
 16%|â–ˆâ–Œ        | 90/564 [01:23<06:39,  1.19it/s] 16%|â–ˆâ–Œ        | 91/564 [01:24<06:39,  1.18it/s]                                                {'loss': 1.218, 'grad_norm': 2.0192731263402997, 'learning_rate': 1.7330895795246801e-06, 'epoch': 0.48}
 16%|â–ˆâ–Œ        | 91/564 [01:24<06:39,  1.18it/s] 16%|â–ˆâ–‹        | 92/564 [01:24<06:38,  1.18it/s]                                                {'loss': 1.5584, 'grad_norm': 2.596673576084108, 'learning_rate': 1.729433272394881e-06, 'epoch': 0.49}
 16%|â–ˆâ–‹        | 92/564 [01:24<06:38,  1.18it/s] 16%|â–ˆâ–‹        | 93/564 [01:25<06:36,  1.19it/s]                                                {'loss': 1.2579, 'grad_norm': 2.5672076548788576, 'learning_rate': 1.7257769652650822e-06, 'epoch': 0.49}
 16%|â–ˆâ–‹        | 93/564 [01:25<06:36,  1.19it/s] 17%|â–ˆâ–‹        | 94/564 [01:26<06:35,  1.19it/s]                                                {'loss': 1.3844, 'grad_norm': 2.244636313001305, 'learning_rate': 1.7221206581352832e-06, 'epoch': 0.5}
 17%|â–ˆâ–‹        | 94/564 [01:26<06:35,  1.19it/s] 17%|â–ˆâ–‹        | 95/564 [01:27<06:36,  1.18it/s]                                                {'loss': 1.2595, 'grad_norm': 2.55428689816653, 'learning_rate': 1.7184643510054844e-06, 'epoch': 0.51}
 17%|â–ˆâ–‹        | 95/564 [01:27<06:36,  1.18it/s] 17%|â–ˆâ–‹        | 96/564 [01:28<06:36,  1.18it/s]                                                {'loss': 1.4777, 'grad_norm': 2.4128313782246416, 'learning_rate': 1.7148080438756855e-06, 'epoch': 0.51}
 17%|â–ˆâ–‹        | 96/564 [01:28<06:36,  1.18it/s] 17%|â–ˆâ–‹        | 97/564 [01:29<06:34,  1.18it/s]                                                {'loss': 1.2681, 'grad_norm': 2.41024412372602, 'learning_rate': 1.7111517367458865e-06, 'epoch': 0.52}
 17%|â–ˆâ–‹        | 97/564 [01:29<06:34,  1.18it/s] 17%|â–ˆâ–‹        | 98/564 [01:29<06:33,  1.19it/s]                                                {'loss': 1.5665, 'grad_norm': 2.638963893630925, 'learning_rate': 1.7074954296160877e-06, 'epoch': 0.52}
 17%|â–ˆâ–‹        | 98/564 [01:29<06:33,  1.19it/s] 18%|â–ˆâ–Š        | 99/564 [01:30<06:31,  1.19it/s]                                                {'loss': 1.5028, 'grad_norm': 2.155107196656307, 'learning_rate': 1.7038391224862887e-06, 'epoch': 0.53}
 18%|â–ˆâ–Š        | 99/564 [01:30<06:31,  1.19it/s] 18%|â–ˆâ–Š        | 100/564 [01:31<06:32,  1.18it/s]                                                 {'loss': 1.3008, 'grad_norm': 2.4565462704540444, 'learning_rate': 1.70018281535649e-06, 'epoch': 0.53}
 18%|â–ˆâ–Š        | 100/564 [01:31<06:32,  1.18it/s] 18%|â–ˆâ–Š        | 101/564 [01:32<06:31,  1.18it/s]                                                 {'loss': 1.3232, 'grad_norm': 1.973908699966435, 'learning_rate': 1.6965265082266908e-06, 'epoch': 0.54}
 18%|â–ˆâ–Š        | 101/564 [01:32<06:31,  1.18it/s] 18%|â–ˆâ–Š        | 102/564 [01:33<06:30,  1.18it/s]                                                 {'loss': 1.3717, 'grad_norm': 2.1410410797607184, 'learning_rate': 1.692870201096892e-06, 'epoch': 0.54}
 18%|â–ˆâ–Š        | 102/564 [01:33<06:30,  1.18it/s] 18%|â–ˆâ–Š        | 103/564 [01:34<06:30,  1.18it/s]                                                 {'loss': 1.4811, 'grad_norm': 2.2004653965184295, 'learning_rate': 1.6892138939670933e-06, 'epoch': 0.55}
 18%|â–ˆâ–Š        | 103/564 [01:34<06:30,  1.18it/s] 18%|â–ˆâ–Š        | 104/564 [01:35<06:29,  1.18it/s]                                                 {'loss': 1.5488, 'grad_norm': 2.176882119303329, 'learning_rate': 1.6855575868372943e-06, 'epoch': 0.55}
 18%|â–ˆâ–Š        | 104/564 [01:35<06:29,  1.18it/s] 19%|â–ˆâ–Š        | 105/564 [01:35<06:28,  1.18it/s]                                                 {'loss': 1.3962, 'grad_norm': 2.155011065537622, 'learning_rate': 1.6819012797074953e-06, 'epoch': 0.56}
 19%|â–ˆâ–Š        | 105/564 [01:35<06:28,  1.18it/s] 19%|â–ˆâ–‰        | 106/564 [01:36<06:27,  1.18it/s]                                                 {'loss': 1.3856, 'grad_norm': 2.1040559325148074, 'learning_rate': 1.6782449725776963e-06, 'epoch': 0.56}
 19%|â–ˆâ–‰        | 106/564 [01:36<06:27,  1.18it/s] 19%|â–ˆâ–‰        | 107/564 [01:37<06:26,  1.18it/s]                                                 {'loss': 1.2145, 'grad_norm': 2.1527445562197567, 'learning_rate': 1.6745886654478976e-06, 'epoch': 0.57}
 19%|â–ˆâ–‰        | 107/564 [01:37<06:26,  1.18it/s] 19%|â–ˆâ–‰        | 108/564 [01:38<06:23,  1.19it/s]                                                 {'loss': 1.3836, 'grad_norm': 2.6623165996354565, 'learning_rate': 1.6709323583180986e-06, 'epoch': 0.57}
 19%|â–ˆâ–‰        | 108/564 [01:38<06:23,  1.19it/s] 19%|â–ˆâ–‰        | 109/564 [01:39<06:22,  1.19it/s]                                                 {'loss': 1.5475, 'grad_norm': 2.1039618131942475, 'learning_rate': 1.6672760511882998e-06, 'epoch': 0.58}
 19%|â–ˆâ–‰        | 109/564 [01:39<06:22,  1.19it/s] 20%|â–ˆâ–‰        | 110/564 [01:40<06:22,  1.19it/s]                                                 {'loss': 1.3344, 'grad_norm': 2.1243676116383683, 'learning_rate': 1.6636197440585008e-06, 'epoch': 0.59}
 20%|â–ˆâ–‰        | 110/564 [01:40<06:22,  1.19it/s] 20%|â–ˆâ–‰        | 111/564 [01:40<06:20,  1.19it/s]                                                 {'loss': 1.3656, 'grad_norm': 2.507679673785741, 'learning_rate': 1.6599634369287019e-06, 'epoch': 0.59}
 20%|â–ˆâ–‰        | 111/564 [01:40<06:20,  1.19it/s] 20%|â–ˆâ–‰        | 112/564 [01:41<06:20,  1.19it/s]                                                 {'loss': 1.292, 'grad_norm': 2.2529389681406755, 'learning_rate': 1.6563071297989031e-06, 'epoch': 0.6}
 20%|â–ˆâ–‰        | 112/564 [01:41<06:20,  1.19it/s] 20%|â–ˆâ–ˆ        | 113/564 [01:42<06:19,  1.19it/s]                                                 {'loss': 1.4382, 'grad_norm': 2.1966172353495845, 'learning_rate': 1.6526508226691041e-06, 'epoch': 0.6}
 20%|â–ˆâ–ˆ        | 113/564 [01:42<06:19,  1.19it/s] 20%|â–ˆâ–ˆ        | 114/564 [01:43<06:18,  1.19it/s]                                                 {'loss': 1.4136, 'grad_norm': 2.546147274776454, 'learning_rate': 1.6489945155393052e-06, 'epoch': 0.61}
 20%|â–ˆâ–ˆ        | 114/564 [01:43<06:18,  1.19it/s] 20%|â–ˆâ–ˆ        | 115/564 [01:44<06:17,  1.19it/s]                                                 {'loss': 1.4898, 'grad_norm': 2.3442691942773677, 'learning_rate': 1.6453382084095064e-06, 'epoch': 0.61}
 20%|â–ˆâ–ˆ        | 115/564 [01:44<06:17,  1.19it/s] 21%|â–ˆâ–ˆ        | 116/564 [01:45<06:18,  1.18it/s]                                                 {'loss': 1.37, 'grad_norm': 2.081846597727176, 'learning_rate': 1.6416819012797074e-06, 'epoch': 0.62}
 21%|â–ˆâ–ˆ        | 116/564 [01:45<06:18,  1.18it/s] 21%|â–ˆâ–ˆ        | 117/564 [01:46<06:18,  1.18it/s]                                                 {'loss': 1.1913, 'grad_norm': 2.2301184686899678, 'learning_rate': 1.6380255941499086e-06, 'epoch': 0.62}
 21%|â–ˆâ–ˆ        | 117/564 [01:46<06:18,  1.18it/s] 21%|â–ˆâ–ˆ        | 118/564 [01:46<06:15,  1.19it/s]                                                 {'loss': 1.3919, 'grad_norm': 2.2827576494183295, 'learning_rate': 1.6343692870201097e-06, 'epoch': 0.63}
 21%|â–ˆâ–ˆ        | 118/564 [01:46<06:15,  1.19it/s] 21%|â–ˆâ–ˆ        | 119/564 [01:47<06:14,  1.19it/s]                                                 {'loss': 1.3571, 'grad_norm': 2.2695735231655343, 'learning_rate': 1.6307129798903107e-06, 'epoch': 0.63}
 21%|â–ˆâ–ˆ        | 119/564 [01:47<06:14,  1.19it/s] 21%|â–ˆâ–ˆâ–       | 120/564 [01:48<06:13,  1.19it/s]                                                 {'loss': 1.4357, 'grad_norm': 2.239972693473169, 'learning_rate': 1.6270566727605117e-06, 'epoch': 0.64}
 21%|â–ˆâ–ˆâ–       | 120/564 [01:48<06:13,  1.19it/s] 21%|â–ˆâ–ˆâ–       | 121/564 [01:49<06:12,  1.19it/s]                                                 {'loss': 1.3514, 'grad_norm': 2.453075077013736, 'learning_rate': 1.623400365630713e-06, 'epoch': 0.64}
 21%|â–ˆâ–ˆâ–       | 121/564 [01:49<06:12,  1.19it/s] 22%|â–ˆâ–ˆâ–       | 122/564 [01:50<06:13,  1.18it/s]                                                 {'loss': 1.5362, 'grad_norm': 1.9373663213433394, 'learning_rate': 1.6197440585009142e-06, 'epoch': 0.65}
 22%|â–ˆâ–ˆâ–       | 122/564 [01:50<06:13,  1.18it/s] 22%|â–ˆâ–ˆâ–       | 123/564 [01:51<06:12,  1.18it/s]                                                 {'loss': 1.4389, 'grad_norm': 2.2377027809621763, 'learning_rate': 1.616087751371115e-06, 'epoch': 0.65}
 22%|â–ˆâ–ˆâ–       | 123/564 [01:51<06:12,  1.18it/s] 22%|â–ˆâ–ˆâ–       | 124/564 [01:51<06:11,  1.19it/s]                                                 {'loss': 1.5897, 'grad_norm': 2.2594228014481397, 'learning_rate': 1.6124314442413162e-06, 'epoch': 0.66}
 22%|â–ˆâ–ˆâ–       | 124/564 [01:51<06:11,  1.19it/s] 22%|â–ˆâ–ˆâ–       | 125/564 [01:52<06:10,  1.19it/s]                                                 {'loss': 1.315, 'grad_norm': 1.9118678442035881, 'learning_rate': 1.6087751371115173e-06, 'epoch': 0.66}
 22%|â–ˆâ–ˆâ–       | 125/564 [01:52<06:10,  1.19it/s] 22%|â–ˆâ–ˆâ–       | 126/564 [01:53<06:07,  1.19it/s]                                                 {'loss': 1.4363, 'grad_norm': 2.3992031517490138, 'learning_rate': 1.6051188299817185e-06, 'epoch': 0.67}
 22%|â–ˆâ–ˆâ–       | 126/564 [01:53<06:07,  1.19it/s] 23%|â–ˆâ–ˆâ–       | 127/564 [01:54<06:07,  1.19it/s]                                                 {'loss': 1.4511, 'grad_norm': 2.503915480246353, 'learning_rate': 1.6014625228519193e-06, 'epoch': 0.68}
 23%|â–ˆâ–ˆâ–       | 127/564 [01:54<06:07,  1.19it/s] 23%|â–ˆâ–ˆâ–       | 128/564 [01:55<06:06,  1.19it/s]                                                 {'loss': 1.4219, 'grad_norm': 2.5577960367164123, 'learning_rate': 1.5978062157221205e-06, 'epoch': 0.68}
 23%|â–ˆâ–ˆâ–       | 128/564 [01:55<06:06,  1.19it/s] 23%|â–ˆâ–ˆâ–       | 129/564 [01:56<06:05,  1.19it/s]                                                 {'loss': 1.5253, 'grad_norm': 2.4904246458720505, 'learning_rate': 1.5941499085923218e-06, 'epoch': 0.69}
 23%|â–ˆâ–ˆâ–       | 129/564 [01:56<06:05,  1.19it/s] 23%|â–ˆâ–ˆâ–       | 130/564 [01:56<06:05,  1.19it/s]                                                 {'loss': 1.299, 'grad_norm': 2.4783941542389036, 'learning_rate': 1.5904936014625228e-06, 'epoch': 0.69}
 23%|â–ˆâ–ˆâ–       | 130/564 [01:56<06:05,  1.19it/s] 23%|â–ˆâ–ˆâ–       | 131/564 [01:57<06:05,  1.18it/s]                                                 {'loss': 1.2773, 'grad_norm': 2.0901449156504555, 'learning_rate': 1.586837294332724e-06, 'epoch': 0.7}
 23%|â–ˆâ–ˆâ–       | 131/564 [01:57<06:05,  1.18it/s] 23%|â–ˆâ–ˆâ–       | 132/564 [01:58<06:04,  1.19it/s]                                                 {'loss': 1.3005, 'grad_norm': 2.2405315734756517, 'learning_rate': 1.5831809872029248e-06, 'epoch': 0.7}
 23%|â–ˆâ–ˆâ–       | 132/564 [01:58<06:04,  1.19it/s] 24%|â–ˆâ–ˆâ–       | 133/564 [01:59<06:04,  1.18it/s]                                                 {'loss': 1.4301, 'grad_norm': 2.2677680520685963, 'learning_rate': 1.579524680073126e-06, 'epoch': 0.71}
 24%|â–ˆâ–ˆâ–       | 133/564 [01:59<06:04,  1.18it/s] 24%|â–ˆâ–ˆâ–       | 134/564 [02:00<06:03,  1.18it/s]                                                 {'loss': 1.5208, 'grad_norm': 2.5711186404731707, 'learning_rate': 1.5758683729433271e-06, 'epoch': 0.71}
 24%|â–ˆâ–ˆâ–       | 134/564 [02:00<06:03,  1.18it/s] 24%|â–ˆâ–ˆâ–       | 135/564 [02:01<06:03,  1.18it/s]                                                 {'loss': 1.4923, 'grad_norm': 2.2705043396683116, 'learning_rate': 1.5722120658135283e-06, 'epoch': 0.72}
 24%|â–ˆâ–ˆâ–       | 135/564 [02:01<06:03,  1.18it/s] 24%|â–ˆâ–ˆâ–       | 136/564 [02:02<06:01,  1.18it/s]                                                 {'loss': 1.3162, 'grad_norm': 2.153590149272133, 'learning_rate': 1.5685557586837294e-06, 'epoch': 0.72}
 24%|â–ˆâ–ˆâ–       | 136/564 [02:02<06:01,  1.18it/s] 24%|â–ˆâ–ˆâ–       | 137/564 [02:02<06:01,  1.18it/s]                                                 {'loss': 1.4278, 'grad_norm': 2.330907127969509, 'learning_rate': 1.5648994515539304e-06, 'epoch': 0.73}
 24%|â–ˆâ–ˆâ–       | 137/564 [02:02<06:01,  1.18it/s] 24%|â–ˆâ–ˆâ–       | 138/564 [02:03<06:00,  1.18it/s]                                                 {'loss': 1.5461, 'grad_norm': 2.0775905171474207, 'learning_rate': 1.5612431444241316e-06, 'epoch': 0.73}
 24%|â–ˆâ–ˆâ–       | 138/564 [02:03<06:00,  1.18it/s] 25%|â–ˆâ–ˆâ–       | 139/564 [02:04<05:58,  1.19it/s]                                                 {'loss': 1.4458, 'grad_norm': 2.637008946820969, 'learning_rate': 1.5575868372943326e-06, 'epoch': 0.74}
 25%|â–ˆâ–ˆâ–       | 139/564 [02:04<05:58,  1.19it/s] 25%|â–ˆâ–ˆâ–       | 140/564 [02:05<05:57,  1.19it/s]                                                 {'loss': 1.2377, 'grad_norm': 2.4296565425394263, 'learning_rate': 1.5539305301645339e-06, 'epoch': 0.74}
 25%|â–ˆâ–ˆâ–       | 140/564 [02:05<05:57,  1.19it/s] 25%|â–ˆâ–ˆâ–Œ       | 141/564 [02:06<05:56,  1.19it/s]                                                 {'loss': 1.5986, 'grad_norm': 2.618013505965442, 'learning_rate': 1.5502742230347347e-06, 'epoch': 0.75}
 25%|â–ˆâ–ˆâ–Œ       | 141/564 [02:06<05:56,  1.19it/s] 25%|â–ˆâ–ˆâ–Œ       | 142/564 [02:07<05:54,  1.19it/s]                                                 {'loss': 1.3222, 'grad_norm': 2.398916898819689, 'learning_rate': 1.546617915904936e-06, 'epoch': 0.76}
 25%|â–ˆâ–ˆâ–Œ       | 142/564 [02:07<05:54,  1.19it/s] 25%|â–ˆâ–ˆâ–Œ       | 143/564 [02:07<05:53,  1.19it/s]                                                 {'loss': 1.429, 'grad_norm': 2.1532685355757573, 'learning_rate': 1.5429616087751372e-06, 'epoch': 0.76}
 25%|â–ˆâ–ˆâ–Œ       | 143/564 [02:07<05:53,  1.19it/s] 26%|â–ˆâ–ˆâ–Œ       | 144/564 [02:08<05:51,  1.20it/s]                                                 {'loss': 1.4401, 'grad_norm': 2.270085706212737, 'learning_rate': 1.5393053016453382e-06, 'epoch': 0.77}
 26%|â–ˆâ–ˆâ–Œ       | 144/564 [02:08<05:51,  1.20it/s] 26%|â–ˆâ–ˆâ–Œ       | 145/564 [02:09<05:50,  1.20it/s]                                                 {'loss': 1.2897, 'grad_norm': 2.160812563470009, 'learning_rate': 1.5356489945155392e-06, 'epoch': 0.77}
 26%|â–ˆâ–ˆâ–Œ       | 145/564 [02:09<05:50,  1.20it/s] 26%|â–ˆâ–ˆâ–Œ       | 146/564 [02:10<05:50,  1.19it/s]                                                 {'loss': 1.482, 'grad_norm': 2.1113823561990746, 'learning_rate': 1.5319926873857402e-06, 'epoch': 0.78}
 26%|â–ˆâ–ˆâ–Œ       | 146/564 [02:10<05:50,  1.19it/s] 26%|â–ˆâ–ˆâ–Œ       | 147/564 [02:11<05:48,  1.20it/s]                                                 {'loss': 1.5177, 'grad_norm': 2.2766815483200666, 'learning_rate': 1.5283363802559415e-06, 'epoch': 0.78}
 26%|â–ˆâ–ˆâ–Œ       | 147/564 [02:11<05:48,  1.20it/s] 26%|â–ˆâ–ˆâ–Œ       | 148/564 [02:12<05:49,  1.19it/s]                                                 {'loss': 1.229, 'grad_norm': 2.175254070818365, 'learning_rate': 1.5246800731261425e-06, 'epoch': 0.79}
 26%|â–ˆâ–ˆâ–Œ       | 148/564 [02:12<05:49,  1.19it/s] 26%|â–ˆâ–ˆâ–‹       | 149/564 [02:12<05:49,  1.19it/s]                                                 {'loss': 1.3304, 'grad_norm': 2.2726314707820605, 'learning_rate': 1.5210237659963437e-06, 'epoch': 0.79}
 26%|â–ˆâ–ˆâ–‹       | 149/564 [02:12<05:49,  1.19it/s] 27%|â–ˆâ–ˆâ–‹       | 150/564 [02:13<05:49,  1.18it/s]                                                 {'loss': 1.2388, 'grad_norm': 2.0113282936409558, 'learning_rate': 1.5173674588665448e-06, 'epoch': 0.8}
 27%|â–ˆâ–ˆâ–‹       | 150/564 [02:13<05:49,  1.18it/s] 27%|â–ˆâ–ˆâ–‹       | 151/564 [02:14<05:47,  1.19it/s]                                                 {'loss': 1.4851, 'grad_norm': 2.422904690394547, 'learning_rate': 1.5137111517367458e-06, 'epoch': 0.8}
 27%|â–ˆâ–ˆâ–‹       | 151/564 [02:14<05:47,  1.19it/s] 27%|â–ˆâ–ˆâ–‹       | 152/564 [02:15<05:45,  1.19it/s]                                                 {'loss': 1.4526, 'grad_norm': 2.496234388631833, 'learning_rate': 1.510054844606947e-06, 'epoch': 0.81}
 27%|â–ˆâ–ˆâ–‹       | 152/564 [02:15<05:45,  1.19it/s] 27%|â–ˆâ–ˆâ–‹       | 153/564 [02:16<05:43,  1.20it/s]                                                 {'loss': 1.3924, 'grad_norm': 3.0693777930902, 'learning_rate': 1.506398537477148e-06, 'epoch': 0.81}
 27%|â–ˆâ–ˆâ–‹       | 153/564 [02:16<05:43,  1.20it/s] 27%|â–ˆâ–ˆâ–‹       | 154/564 [02:17<05:44,  1.19it/s]                                                 {'loss': 1.4346, 'grad_norm': 2.031866977732342, 'learning_rate': 1.502742230347349e-06, 'epoch': 0.82}
 27%|â–ˆâ–ˆâ–‹       | 154/564 [02:17<05:44,  1.19it/s] 27%|â–ˆâ–ˆâ–‹       | 155/564 [02:17<05:44,  1.19it/s]                                                 {'loss': 1.5968, 'grad_norm': 2.4821305722197686, 'learning_rate': 1.49908592321755e-06, 'epoch': 0.82}
 27%|â–ˆâ–ˆâ–‹       | 155/564 [02:17<05:44,  1.19it/s] 28%|â–ˆâ–ˆâ–Š       | 156/564 [02:18<05:43,  1.19it/s]                                                 {'loss': 1.2537, 'grad_norm': 2.5632423216436666, 'learning_rate': 1.4954296160877513e-06, 'epoch': 0.83}
 28%|â–ˆâ–ˆâ–Š       | 156/564 [02:18<05:43,  1.19it/s] 28%|â–ˆâ–ˆâ–Š       | 157/564 [02:19<05:42,  1.19it/s]                                                 {'loss': 1.2752, 'grad_norm': 2.2484936473730155, 'learning_rate': 1.4917733089579526e-06, 'epoch': 0.84}
 28%|â–ˆâ–ˆâ–Š       | 157/564 [02:19<05:42,  1.19it/s] 28%|â–ˆâ–ˆâ–Š       | 158/564 [02:20<05:42,  1.19it/s]                                                 {'loss': 1.5333, 'grad_norm': 2.181457993765456, 'learning_rate': 1.4881170018281536e-06, 'epoch': 0.84}
 28%|â–ˆâ–ˆâ–Š       | 158/564 [02:20<05:42,  1.19it/s] 28%|â–ˆâ–ˆâ–Š       | 159/564 [02:21<05:40,  1.19it/s]                                                 {'loss': 1.2967, 'grad_norm': 2.6776945932597513, 'learning_rate': 1.4844606946983546e-06, 'epoch': 0.85}
 28%|â–ˆâ–ˆâ–Š       | 159/564 [02:21<05:40,  1.19it/s] 28%|â–ˆâ–ˆâ–Š       | 160/564 [02:22<05:40,  1.19it/s]                                                 {'loss': 1.1763, 'grad_norm': 2.12963889116133, 'learning_rate': 1.4808043875685556e-06, 'epoch': 0.85}
 28%|â–ˆâ–ˆâ–Š       | 160/564 [02:22<05:40,  1.19it/s] 29%|â–ˆâ–ˆâ–Š       | 161/564 [02:23<05:40,  1.19it/s]                                                 {'loss': 1.2961, 'grad_norm': 2.5753788812908827, 'learning_rate': 1.4771480804387569e-06, 'epoch': 0.86}
 29%|â–ˆâ–ˆâ–Š       | 161/564 [02:23<05:40,  1.19it/s] 29%|â–ˆâ–ˆâ–Š       | 162/564 [02:23<05:38,  1.19it/s]                                                 {'loss': 1.4912, 'grad_norm': 2.3320326342843325, 'learning_rate': 1.4734917733089579e-06, 'epoch': 0.86}
 29%|â–ˆâ–ˆâ–Š       | 162/564 [02:23<05:38,  1.19it/s] 29%|â–ˆâ–ˆâ–‰       | 163/564 [02:24<05:38,  1.19it/s]                                                 {'loss': 1.536, 'grad_norm': 2.3029058456511926, 'learning_rate': 1.469835466179159e-06, 'epoch': 0.87}
 29%|â–ˆâ–ˆâ–‰       | 163/564 [02:24<05:38,  1.19it/s] 29%|â–ˆâ–ˆâ–‰       | 164/564 [02:25<05:37,  1.18it/s]                                                 {'loss': 1.4742, 'grad_norm': 1.9423153243641984, 'learning_rate': 1.4661791590493601e-06, 'epoch': 0.87}
 29%|â–ˆâ–ˆâ–‰       | 164/564 [02:25<05:37,  1.18it/s] 29%|â–ˆâ–ˆâ–‰       | 165/564 [02:26<05:36,  1.19it/s]                                                 {'loss': 1.4506, 'grad_norm': 2.2553061821123537, 'learning_rate': 1.4625228519195612e-06, 'epoch': 0.88}
 29%|â–ˆâ–ˆâ–‰       | 165/564 [02:26<05:36,  1.19it/s] 29%|â–ˆâ–ˆâ–‰       | 166/564 [02:27<05:35,  1.19it/s]                                                 {'loss': 1.2929, 'grad_norm': 2.323310924203964, 'learning_rate': 1.4588665447897624e-06, 'epoch': 0.88}
 29%|â–ˆâ–ˆâ–‰       | 166/564 [02:27<05:35,  1.19it/s] 30%|â–ˆâ–ˆâ–‰       | 167/564 [02:28<05:34,  1.19it/s]                                                 {'loss': 1.4078, 'grad_norm': 2.387301994734193, 'learning_rate': 1.4552102376599632e-06, 'epoch': 0.89}
 30%|â–ˆâ–ˆâ–‰       | 167/564 [02:28<05:34,  1.19it/s] 30%|â–ˆâ–ˆâ–‰       | 168/564 [02:28<05:33,  1.19it/s]                                                 {'loss': 1.2247, 'grad_norm': 2.388098341493817, 'learning_rate': 1.4515539305301644e-06, 'epoch': 0.89}
 30%|â–ˆâ–ˆâ–‰       | 168/564 [02:28<05:33,  1.19it/s] 30%|â–ˆâ–ˆâ–‰       | 169/564 [02:29<05:33,  1.19it/s]                                                 {'loss': 1.3019, 'grad_norm': 2.437435025744204, 'learning_rate': 1.4478976234003655e-06, 'epoch': 0.9}
 30%|â–ˆâ–ˆâ–‰       | 169/564 [02:29<05:33,  1.19it/s] 30%|â–ˆâ–ˆâ–ˆ       | 170/564 [02:30<05:32,  1.19it/s]                                                 {'loss': 1.4433, 'grad_norm': 2.7215864140392356, 'learning_rate': 1.4442413162705667e-06, 'epoch': 0.9}
 30%|â–ˆâ–ˆâ–ˆ       | 170/564 [02:30<05:32,  1.19it/s] 30%|â–ˆâ–ˆâ–ˆ       | 171/564 [02:31<05:31,  1.19it/s]                                                 {'loss': 1.2838, 'grad_norm': 2.2025099456909194, 'learning_rate': 1.440585009140768e-06, 'epoch': 0.91}
 30%|â–ˆâ–ˆâ–ˆ       | 171/564 [02:31<05:31,  1.19it/s] 30%|â–ˆâ–ˆâ–ˆ       | 172/564 [02:32<05:31,  1.18it/s]                                                 {'loss': 1.4702, 'grad_norm': 2.1802717785684904, 'learning_rate': 1.4369287020109688e-06, 'epoch': 0.91}
 30%|â–ˆâ–ˆâ–ˆ       | 172/564 [02:32<05:31,  1.18it/s] 31%|â–ˆâ–ˆâ–ˆ       | 173/564 [02:33<05:29,  1.19it/s]                                                 {'loss': 1.3019, 'grad_norm': 2.0918725489317183, 'learning_rate': 1.43327239488117e-06, 'epoch': 0.92}
 31%|â–ˆâ–ˆâ–ˆ       | 173/564 [02:33<05:29,  1.19it/s] 31%|â–ˆâ–ˆâ–ˆ       | 174/564 [02:34<05:29,  1.18it/s]                                                 {'loss': 1.3232, 'grad_norm': 2.403062725360873, 'learning_rate': 1.429616087751371e-06, 'epoch': 0.93}
 31%|â–ˆâ–ˆâ–ˆ       | 174/564 [02:34<05:29,  1.18it/s] 31%|â–ˆâ–ˆâ–ˆ       | 175/564 [02:34<05:27,  1.19it/s]                                                 {'loss': 1.3686, 'grad_norm': 2.2606247382174423, 'learning_rate': 1.4259597806215722e-06, 'epoch': 0.93}
 31%|â–ˆâ–ˆâ–ˆ       | 175/564 [02:34<05:27,  1.19it/s] 31%|â–ˆâ–ˆâ–ˆ       | 176/564 [02:35<05:26,  1.19it/s]                                                 {'loss': 1.5088, 'grad_norm': 1.9231287991798371, 'learning_rate': 1.422303473491773e-06, 'epoch': 0.94}
 31%|â–ˆâ–ˆâ–ˆ       | 176/564 [02:35<05:26,  1.19it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 177/564 [02:36<05:25,  1.19it/s]                                                 {'loss': 1.4157, 'grad_norm': 2.167250752438051, 'learning_rate': 1.4186471663619743e-06, 'epoch': 0.94}
 31%|â–ˆâ–ˆâ–ˆâ–      | 177/564 [02:36<05:25,  1.19it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 178/564 [02:37<05:24,  1.19it/s]                                                 {'loss': 1.298, 'grad_norm': 2.4273849511228787, 'learning_rate': 1.4149908592321755e-06, 'epoch': 0.95}
 32%|â–ˆâ–ˆâ–ˆâ–      | 178/564 [02:37<05:24,  1.19it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 179/564 [02:38<05:24,  1.19it/s]                                                 {'loss': 1.4602, 'grad_norm': 2.3332975232778796, 'learning_rate': 1.4113345521023766e-06, 'epoch': 0.95}
 32%|â–ˆâ–ˆâ–ˆâ–      | 179/564 [02:38<05:24,  1.19it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 180/564 [02:39<05:25,  1.18it/s]                                                 {'loss': 1.2589, 'grad_norm': 2.0899839362555257, 'learning_rate': 1.4076782449725778e-06, 'epoch': 0.96}
 32%|â–ˆâ–ˆâ–ˆâ–      | 180/564 [02:39<05:25,  1.18it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 181/564 [02:39<05:23,  1.18it/s]                                                 {'loss': 1.3541, 'grad_norm': 2.333538733006526, 'learning_rate': 1.4040219378427786e-06, 'epoch': 0.96}
 32%|â–ˆâ–ˆâ–ˆâ–      | 181/564 [02:39<05:23,  1.18it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 182/564 [02:40<05:21,  1.19it/s]                                                 {'loss': 1.1535, 'grad_norm': 2.1274569549219167, 'learning_rate': 1.4003656307129798e-06, 'epoch': 0.97}
 32%|â–ˆâ–ˆâ–ˆâ–      | 182/564 [02:40<05:21,  1.19it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 183/564 [02:41<05:20,  1.19it/s]                                                 {'loss': 1.4146, 'grad_norm': 2.063416442495887, 'learning_rate': 1.3967093235831809e-06, 'epoch': 0.97}
 32%|â–ˆâ–ˆâ–ˆâ–      | 183/564 [02:41<05:20,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 184/564 [02:42<05:20,  1.19it/s]                                                 {'loss': 1.5021, 'grad_norm': 2.099633363196493, 'learning_rate': 1.393053016453382e-06, 'epoch': 0.98}
 33%|â–ˆâ–ˆâ–ˆâ–      | 184/564 [02:42<05:20,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 185/564 [02:43<05:19,  1.19it/s]                                                 {'loss': 1.3501, 'grad_norm': 2.1406530298828508, 'learning_rate': 1.3893967093235831e-06, 'epoch': 0.98}
 33%|â–ˆâ–ˆâ–ˆâ–      | 185/564 [02:43<05:19,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 186/564 [02:44<05:17,  1.19it/s]                                                 {'loss': 1.3333, 'grad_norm': 2.440481941855946, 'learning_rate': 1.3857404021937841e-06, 'epoch': 0.99}
 33%|â–ˆâ–ˆâ–ˆâ–      | 186/564 [02:44<05:17,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 187/564 [02:44<05:16,  1.19it/s]                                                 {'loss': 1.268, 'grad_norm': 2.0223166453864847, 'learning_rate': 1.3820840950639854e-06, 'epoch': 0.99}
 33%|â–ˆâ–ˆâ–ˆâ–      | 187/564 [02:44<05:16,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 188/564 [02:45<05:16,  1.19it/s]                                                 {'loss': 1.2801, 'grad_norm': 2.7698738958376534, 'learning_rate': 1.3784277879341864e-06, 'epoch': 1.0}
 33%|â–ˆâ–ˆâ–ˆâ–      | 188/564 [02:45<05:16,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 189/564 [02:46<05:15,  1.19it/s]                                                 {'loss': 1.128, 'grad_norm': 1.8820358083162538, 'learning_rate': 1.3747714808043876e-06, 'epoch': 1.01}
 34%|â–ˆâ–ˆâ–ˆâ–      | 189/564 [02:46<05:15,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 190/564 [02:47<05:14,  1.19it/s]                                                 {'loss': 1.0615, 'grad_norm': 1.9043377054961557, 'learning_rate': 1.3711151736745884e-06, 'epoch': 1.01}
 34%|â–ˆâ–ˆâ–ˆâ–      | 190/564 [02:47<05:14,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 191/564 [02:48<05:13,  1.19it/s]                                                 {'loss': 1.2304, 'grad_norm': 2.026126499103252, 'learning_rate': 1.3674588665447897e-06, 'epoch': 1.02}
 34%|â–ˆâ–ˆâ–ˆâ–      | 191/564 [02:48<05:13,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 192/564 [02:49<05:13,  1.19it/s]                                                 {'loss': 1.2908, 'grad_norm': 1.9884147571497712, 'learning_rate': 1.363802559414991e-06, 'epoch': 1.02}
 34%|â–ˆâ–ˆâ–ˆâ–      | 192/564 [02:49<05:13,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 193/564 [02:49<05:11,  1.19it/s]                                                 {'loss': 1.3316, 'grad_norm': 2.096865869752487, 'learning_rate': 1.360146252285192e-06, 'epoch': 1.03}
 34%|â–ˆâ–ˆâ–ˆâ–      | 193/564 [02:49<05:11,  1.19it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 194/564 [02:50<05:11,  1.19it/s]                                                 {'loss': 1.4087, 'grad_norm': 2.3466879129320732, 'learning_rate': 1.356489945155393e-06, 'epoch': 1.03}
 34%|â–ˆâ–ˆâ–ˆâ–      | 194/564 [02:50<05:11,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 195/564 [02:51<05:09,  1.19it/s]                                                 {'loss': 1.2384, 'grad_norm': 2.09015002003376, 'learning_rate': 1.352833638025594e-06, 'epoch': 1.04}
 35%|â–ˆâ–ˆâ–ˆâ–      | 195/564 [02:51<05:09,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 196/564 [02:52<05:08,  1.19it/s]                                                 {'loss': 1.2655, 'grad_norm': 2.1540527504149254, 'learning_rate': 1.3491773308957952e-06, 'epoch': 1.04}
 35%|â–ˆâ–ˆâ–ˆâ–      | 196/564 [02:52<05:08,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 197/564 [02:53<05:07,  1.19it/s]                                                 {'loss': 1.3338, 'grad_norm': 2.1498464822477388, 'learning_rate': 1.3455210237659962e-06, 'epoch': 1.05}
 35%|â–ˆâ–ˆâ–ˆâ–      | 197/564 [02:53<05:07,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 198/564 [02:54<05:07,  1.19it/s]                                                 {'loss': 1.2684, 'grad_norm': 2.1346894409506985, 'learning_rate': 1.3418647166361975e-06, 'epoch': 1.05}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 198/564 [02:54<05:07,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 199/564 [02:55<05:07,  1.19it/s]                                                 {'loss': 1.2899, 'grad_norm': 2.060887090017351, 'learning_rate': 1.3382084095063985e-06, 'epoch': 1.06}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 199/564 [02:55<05:07,  1.19it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/564 [02:55<05:06,  1.19it/s]                                                 {'loss': 1.2385, 'grad_norm': 2.448815360835858, 'learning_rate': 1.3345521023765995e-06, 'epoch': 1.06}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 200/564 [02:55<05:06,  1.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 201/564 [02:56<05:05,  1.19it/s]                                                 {'loss': 0.9698, 'grad_norm': 2.1342267297472097, 'learning_rate': 1.3308957952468008e-06, 'epoch': 1.07}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 201/564 [02:56<05:05,  1.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 202/564 [02:57<05:05,  1.19it/s]                                                 {'loss': 1.4198, 'grad_norm': 1.9965434314299635, 'learning_rate': 1.3272394881170018e-06, 'epoch': 1.07}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 202/564 [02:57<05:05,  1.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 203/564 [02:58<05:04,  1.19it/s]                                                 {'loss': 1.3759, 'grad_norm': 2.124487547878297, 'learning_rate': 1.3235831809872028e-06, 'epoch': 1.08}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 203/564 [02:58<05:04,  1.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 204/564 [02:59<05:03,  1.19it/s]                                                 {'loss': 1.1902, 'grad_norm': 2.326182388229199, 'learning_rate': 1.3199268738574038e-06, 'epoch': 1.09}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 204/564 [02:59<05:03,  1.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 205/564 [03:00<05:01,  1.19it/s]                                                 {'loss': 1.31, 'grad_norm': 2.137147267583745, 'learning_rate': 1.316270566727605e-06, 'epoch': 1.09}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 205/564 [03:00<05:01,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 206/564 [03:00<05:01,  1.19it/s]                                                 {'loss': 1.2407, 'grad_norm': 2.088865426691627, 'learning_rate': 1.3126142595978063e-06, 'epoch': 1.1}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 206/564 [03:00<05:01,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 207/564 [03:01<05:00,  1.19it/s]                                                 {'loss': 1.537, 'grad_norm': 1.8911381985936768, 'learning_rate': 1.3089579524680071e-06, 'epoch': 1.1}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 207/564 [03:01<05:00,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 208/564 [03:02<04:58,  1.19it/s]                                                 {'loss': 1.2964, 'grad_norm': 2.36964976138677, 'learning_rate': 1.3053016453382084e-06, 'epoch': 1.11}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 208/564 [03:02<04:58,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 209/564 [03:03<04:58,  1.19it/s]                                                 {'loss': 1.3698, 'grad_norm': 2.118052243780444, 'learning_rate': 1.3016453382084094e-06, 'epoch': 1.11}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 209/564 [03:03<04:58,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 210/564 [03:04<04:57,  1.19it/s]                                                 {'loss': 1.2776, 'grad_norm': 2.0620308842815693, 'learning_rate': 1.2979890310786106e-06, 'epoch': 1.12}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 210/564 [03:04<04:57,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 211/564 [03:05<04:57,  1.19it/s]                                                 {'loss': 1.3459, 'grad_norm': 2.1056481702666234, 'learning_rate': 1.2943327239488116e-06, 'epoch': 1.12}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 211/564 [03:05<04:57,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 212/564 [03:05<04:56,  1.19it/s]                                                 {'loss': 1.4502, 'grad_norm': 2.2092954059973673, 'learning_rate': 1.2906764168190127e-06, 'epoch': 1.13}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 212/564 [03:05<04:56,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 213/564 [03:06<04:55,  1.19it/s]                                                 {'loss': 1.2239, 'grad_norm': 2.2440209071604094, 'learning_rate': 1.2870201096892139e-06, 'epoch': 1.13}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 213/564 [03:06<04:55,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 214/564 [03:07<04:54,  1.19it/s]                                                 {'loss': 1.4375, 'grad_norm': 2.413934359417382, 'learning_rate': 1.283363802559415e-06, 'epoch': 1.14}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 214/564 [03:07<04:54,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 215/564 [03:08<04:53,  1.19it/s]                                                 {'loss': 1.2435, 'grad_norm': 2.201466470372694, 'learning_rate': 1.2797074954296162e-06, 'epoch': 1.14}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 215/564 [03:08<04:53,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 216/564 [03:09<04:52,  1.19it/s]                                                 {'loss': 1.2863, 'grad_norm': 2.1676402275777713, 'learning_rate': 1.276051188299817e-06, 'epoch': 1.15}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 216/564 [03:09<04:52,  1.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 217/564 [03:10<04:51,  1.19it/s]                                                 {'loss': 1.27, 'grad_norm': 2.210657297772846, 'learning_rate': 1.2723948811700182e-06, 'epoch': 1.15}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 217/564 [03:10<04:51,  1.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 218/564 [03:11<04:50,  1.19it/s]                                                 {'loss': 1.2346, 'grad_norm': 2.087639986267377, 'learning_rate': 1.2687385740402192e-06, 'epoch': 1.16}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 218/564 [03:11<04:50,  1.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 219/564 [03:11<04:49,  1.19it/s]                                                 {'loss': 1.4441, 'grad_norm': 2.145233777840229, 'learning_rate': 1.2650822669104205e-06, 'epoch': 1.16}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 219/564 [03:11<04:49,  1.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 220/564 [03:12<04:48,  1.19it/s]                                                 {'loss': 1.3148, 'grad_norm': 2.4539346250728182, 'learning_rate': 1.2614259597806217e-06, 'epoch': 1.17}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 220/564 [03:12<04:48,  1.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 221/564 [03:13<04:50,  1.18it/s]                                                 {'loss': 1.1397, 'grad_norm': 2.4611291534439603, 'learning_rate': 1.2577696526508225e-06, 'epoch': 1.18}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 221/564 [03:13<04:50,  1.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 222/564 [03:14<04:49,  1.18it/s]                                                 {'loss': 1.3722, 'grad_norm': 2.3134900597453814, 'learning_rate': 1.2541133455210237e-06, 'epoch': 1.18}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 222/564 [03:14<04:49,  1.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 223/564 [03:15<04:48,  1.18it/s]                                                 {'loss': 1.1628, 'grad_norm': 2.264555447454756, 'learning_rate': 1.2504570383912248e-06, 'epoch': 1.19}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 223/564 [03:15<04:48,  1.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 224/564 [03:16<04:46,  1.19it/s]                                                 {'loss': 1.4924, 'grad_norm': 1.978610146866519, 'learning_rate': 1.246800731261426e-06, 'epoch': 1.19}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 224/564 [03:16<04:46,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 225/564 [03:16<04:45,  1.19it/s]                                                 {'loss': 1.2436, 'grad_norm': 2.2367239214071835, 'learning_rate': 1.2431444241316268e-06, 'epoch': 1.2}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 225/564 [03:16<04:45,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 226/564 [03:17<04:43,  1.19it/s]                                                 {'loss': 1.2509, 'grad_norm': 2.2017767234852705, 'learning_rate': 1.239488117001828e-06, 'epoch': 1.2}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 226/564 [03:17<04:43,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 227/564 [03:18<04:43,  1.19it/s]                                                 {'loss': 1.2384, 'grad_norm': 2.240048703005244, 'learning_rate': 1.2358318098720293e-06, 'epoch': 1.21}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 227/564 [03:18<04:43,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 228/564 [03:19<04:43,  1.19it/s]                                                 {'loss': 1.1615, 'grad_norm': 2.1480842486947838, 'learning_rate': 1.2321755027422303e-06, 'epoch': 1.21}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 228/564 [03:19<04:43,  1.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 229/564 [03:20<04:42,  1.18it/s]                                                 {'loss': 1.1877, 'grad_norm': 2.0767525039642356, 'learning_rate': 1.2285191956124315e-06, 'epoch': 1.22}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 229/564 [03:20<04:42,  1.18it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 230/564 [03:21<04:42,  1.18it/s]                                                 {'loss': 1.1979, 'grad_norm': 1.9948830838705303, 'learning_rate': 1.2248628884826324e-06, 'epoch': 1.22}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 230/564 [03:21<04:42,  1.18it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 231/564 [03:21<04:40,  1.19it/s]                                                 {'loss': 1.3452, 'grad_norm': 2.258154231541526, 'learning_rate': 1.2212065813528336e-06, 'epoch': 1.23}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 231/564 [03:21<04:40,  1.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 232/564 [03:22<04:39,  1.19it/s]                                                 {'loss': 1.4034, 'grad_norm': 2.0171806852047793, 'learning_rate': 1.2175502742230346e-06, 'epoch': 1.23}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 232/564 [03:22<04:39,  1.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 233/564 [03:23<04:39,  1.19it/s]                                                 {'loss': 1.2129, 'grad_norm': 2.3972972118608578, 'learning_rate': 1.2138939670932358e-06, 'epoch': 1.24}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 233/564 [03:23<04:39,  1.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 234/564 [03:24<04:38,  1.19it/s]                                                 {'loss': 1.2653, 'grad_norm': 1.8666531889152147, 'learning_rate': 1.2102376599634369e-06, 'epoch': 1.24}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 234/564 [03:24<04:38,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 235/564 [03:25<04:36,  1.19it/s]                                                 {'loss': 1.2503, 'grad_norm': 2.1475304674504776, 'learning_rate': 1.2065813528336379e-06, 'epoch': 1.25}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 235/564 [03:25<04:36,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 236/564 [03:26<04:35,  1.19it/s]                                                 {'loss': 1.2135, 'grad_norm': 2.1369964463446522, 'learning_rate': 1.2029250457038391e-06, 'epoch': 1.26}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 236/564 [03:26<04:35,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 237/564 [03:27<04:35,  1.19it/s]                                                 {'loss': 1.2028, 'grad_norm': 2.343770879330434, 'learning_rate': 1.1992687385740402e-06, 'epoch': 1.26}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 237/564 [03:27<04:35,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 238/564 [03:27<04:34,  1.19it/s]                                                 {'loss': 1.2592, 'grad_norm': 2.1824826623179447, 'learning_rate': 1.1956124314442414e-06, 'epoch': 1.27}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 238/564 [03:27<04:34,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 239/564 [03:28<04:33,  1.19it/s]                                                 {'loss': 1.3247, 'grad_norm': 2.043651889945643, 'learning_rate': 1.1919561243144422e-06, 'epoch': 1.27}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 239/564 [03:28<04:33,  1.19it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 240/564 [03:29<04:33,  1.19it/s]                                                 {'loss': 1.2061, 'grad_norm': 1.8547255547758539, 'learning_rate': 1.1882998171846434e-06, 'epoch': 1.28}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 240/564 [03:29<04:33,  1.19it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 241/564 [03:30<04:33,  1.18it/s]                                                 {'loss': 1.3269, 'grad_norm': 2.0885582307368566, 'learning_rate': 1.1846435100548447e-06, 'epoch': 1.28}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 241/564 [03:30<04:33,  1.18it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 242/564 [03:31<04:32,  1.18it/s]                                                 {'loss': 1.2946, 'grad_norm': 2.092627995542161, 'learning_rate': 1.1809872029250457e-06, 'epoch': 1.29}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 242/564 [03:31<04:32,  1.18it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 243/564 [03:32<04:30,  1.19it/s]                                                 {'loss': 1.0121, 'grad_norm': 2.431315467535582, 'learning_rate': 1.1773308957952467e-06, 'epoch': 1.29}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 243/564 [03:32<04:30,  1.19it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 244/564 [03:32<04:28,  1.19it/s]                                                 {'loss': 1.3072, 'grad_norm': 2.335682420784803, 'learning_rate': 1.1736745886654477e-06, 'epoch': 1.3}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 244/564 [03:32<04:28,  1.19it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 245/564 [03:33<04:26,  1.20it/s]                                                 {'loss': 1.3456, 'grad_norm': 3.3750819462528554, 'learning_rate': 1.170018281535649e-06, 'epoch': 1.3}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 245/564 [03:33<04:26,  1.20it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 246/564 [03:34<04:26,  1.19it/s]                                                 {'loss': 1.3546, 'grad_norm': 2.229247122586244, 'learning_rate': 1.16636197440585e-06, 'epoch': 1.31}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 246/564 [03:34<04:26,  1.19it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 247/564 [03:35<04:25,  1.19it/s]                                                 {'loss': 1.347, 'grad_norm': 2.0171938272550025, 'learning_rate': 1.1627056672760512e-06, 'epoch': 1.31}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 247/564 [03:35<04:25,  1.19it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 248/564 [03:36<04:25,  1.19it/s]                                                 {'loss': 1.1308, 'grad_norm': 2.165082246422628, 'learning_rate': 1.1590493601462523e-06, 'epoch': 1.32}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 248/564 [03:36<04:25,  1.19it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 249/564 [03:37<04:24,  1.19it/s]                                                 {'loss': 1.1612, 'grad_norm': 1.9746244684460714, 'learning_rate': 1.1553930530164533e-06, 'epoch': 1.32}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 249/564 [03:37<04:24,  1.19it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/564 [03:37<04:24,  1.19it/s]                                                 {'loss': 1.3007, 'grad_norm': 2.090627087733397, 'learning_rate': 1.1517367458866545e-06, 'epoch': 1.33}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 250/564 [03:37<04:24,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 251/564 [03:38<04:22,  1.19it/s]                                                 {'loss': 1.0837, 'grad_norm': 2.1581208533675, 'learning_rate': 1.1480804387568555e-06, 'epoch': 1.34}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 251/564 [03:38<04:22,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 252/564 [03:39<04:21,  1.19it/s]                                                 {'loss': 1.3182, 'grad_norm': 2.2237655187017236, 'learning_rate': 1.1444241316270566e-06, 'epoch': 1.34}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 252/564 [03:39<04:21,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 253/564 [03:40<04:21,  1.19it/s]                                                 {'loss': 1.3399, 'grad_norm': 1.9432663174555482, 'learning_rate': 1.1407678244972576e-06, 'epoch': 1.35}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 253/564 [03:40<04:21,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 254/564 [03:41<04:20,  1.19it/s]                                                 {'loss': 1.3111, 'grad_norm': 2.1461683434046317, 'learning_rate': 1.1371115173674588e-06, 'epoch': 1.35}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 254/564 [03:41<04:20,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 255/564 [03:42<04:20,  1.19it/s]                                                 {'loss': 1.2642, 'grad_norm': 2.016619491276808, 'learning_rate': 1.13345521023766e-06, 'epoch': 1.36}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 255/564 [03:42<04:20,  1.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 256/564 [03:43<04:19,  1.19it/s]                                                 {'loss': 1.3288, 'grad_norm': 2.211926818319254, 'learning_rate': 1.1297989031078609e-06, 'epoch': 1.36}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 256/564 [03:43<04:19,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 257/564 [03:43<04:18,  1.19it/s]                                                 {'loss': 1.139, 'grad_norm': 2.108238887351972, 'learning_rate': 1.126142595978062e-06, 'epoch': 1.37}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 257/564 [03:43<04:18,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 258/564 [03:44<04:17,  1.19it/s]                                                 {'loss': 1.4512, 'grad_norm': 2.0591258549014313, 'learning_rate': 1.1224862888482631e-06, 'epoch': 1.37}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 258/564 [03:44<04:17,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 259/564 [03:45<04:16,  1.19it/s]                                                 {'loss': 1.3483, 'grad_norm': 2.4261280974810133, 'learning_rate': 1.1188299817184644e-06, 'epoch': 1.38}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 259/564 [03:45<04:16,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 260/564 [03:46<04:15,  1.19it/s]                                                 {'loss': 1.3023, 'grad_norm': 2.1214722481248685, 'learning_rate': 1.1151736745886654e-06, 'epoch': 1.38}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 260/564 [03:46<04:15,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 261/564 [03:47<04:14,  1.19it/s]                                                 {'loss': 1.3987, 'grad_norm': 2.288380834808656, 'learning_rate': 1.1115173674588664e-06, 'epoch': 1.39}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 261/564 [03:47<04:14,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 262/564 [03:48<04:13,  1.19it/s]                                                 {'loss': 1.3807, 'grad_norm': 2.137475256932165, 'learning_rate': 1.1078610603290676e-06, 'epoch': 1.39}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 262/564 [03:48<04:13,  1.19it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 263/564 [03:48<04:13,  1.19it/s]                                                 {'loss': 1.3049, 'grad_norm': 2.189316257784898, 'learning_rate': 1.1042047531992687e-06, 'epoch': 1.4}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 263/564 [03:48<04:13,  1.19it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 264/564 [03:49<04:11,  1.19it/s]                                                 {'loss': 1.3119, 'grad_norm': 2.2323360810958635, 'learning_rate': 1.10054844606947e-06, 'epoch': 1.4}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 264/564 [03:49<04:11,  1.19it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 265/564 [03:50<04:11,  1.19it/s]                                                 {'loss': 1.3513, 'grad_norm': 2.015966006972391, 'learning_rate': 1.0968921389396707e-06, 'epoch': 1.41}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 265/564 [03:50<04:11,  1.19it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 266/564 [03:51<04:10,  1.19it/s]                                                 {'loss': 1.267, 'grad_norm': 1.9974357554535342, 'learning_rate': 1.093235831809872e-06, 'epoch': 1.41}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 266/564 [03:51<04:10,  1.19it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 267/564 [03:52<04:10,  1.19it/s]                                                 {'loss': 1.0434, 'grad_norm': 2.218953067106402, 'learning_rate': 1.089579524680073e-06, 'epoch': 1.42}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 267/564 [03:52<04:10,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 268/564 [03:53<04:09,  1.19it/s]                                                 {'loss': 1.1333, 'grad_norm': 1.9168298990067854, 'learning_rate': 1.0859232175502742e-06, 'epoch': 1.43}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 268/564 [03:53<04:09,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 269/564 [03:53<04:08,  1.19it/s]                                                 {'loss': 1.3695, 'grad_norm': 2.424295531211787, 'learning_rate': 1.0822669104204754e-06, 'epoch': 1.43}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 269/564 [03:53<04:08,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 270/564 [03:54<04:07,  1.19it/s]                                                 {'loss': 1.3104, 'grad_norm': 2.2381317868167057, 'learning_rate': 1.0786106032906763e-06, 'epoch': 1.44}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 270/564 [03:54<04:07,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 271/564 [03:55<04:07,  1.19it/s]                                                 {'loss': 1.2461, 'grad_norm': 2.541984616370064, 'learning_rate': 1.0749542961608775e-06, 'epoch': 1.44}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 271/564 [03:55<04:07,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 272/564 [03:56<04:05,  1.19it/s]                                                 {'loss': 1.1863, 'grad_norm': 2.269662225333497, 'learning_rate': 1.0712979890310785e-06, 'epoch': 1.45}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 272/564 [03:56<04:05,  1.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 273/564 [03:57<04:05,  1.19it/s]                                                 {'loss': 1.2144, 'grad_norm': 2.22540815585813, 'learning_rate': 1.0676416819012797e-06, 'epoch': 1.45}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 273/564 [03:57<04:05,  1.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 274/564 [03:58<04:04,  1.18it/s]                                                 {'loss': 1.3073, 'grad_norm': 1.8589223309127467, 'learning_rate': 1.0639853747714806e-06, 'epoch': 1.46}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 274/564 [03:58<04:04,  1.18it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 275/564 [03:59<04:03,  1.19it/s]                                                 {'loss': 1.368, 'grad_norm': 2.4111231854366286, 'learning_rate': 1.0603290676416818e-06, 'epoch': 1.46}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 275/564 [03:59<04:03,  1.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 276/564 [03:59<04:02,  1.19it/s]                                                 {'loss': 1.1174, 'grad_norm': 2.1245443532359394, 'learning_rate': 1.056672760511883e-06, 'epoch': 1.47}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 276/564 [03:59<04:02,  1.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 277/564 [04:00<04:02,  1.19it/s]                                                 {'loss': 1.1258, 'grad_norm': 2.2135485222992783, 'learning_rate': 1.053016453382084e-06, 'epoch': 1.47}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 277/564 [04:00<04:02,  1.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 278/564 [04:01<04:01,  1.18it/s]                                                 {'loss': 1.1358, 'grad_norm': 2.0448516865772777, 'learning_rate': 1.0493601462522853e-06, 'epoch': 1.48}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 278/564 [04:01<04:01,  1.18it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 279/564 [04:02<03:59,  1.19it/s]                                                 {'loss': 1.1175, 'grad_norm': 2.229542985113656, 'learning_rate': 1.045703839122486e-06, 'epoch': 1.48}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 279/564 [04:02<03:59,  1.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 280/564 [04:03<03:59,  1.19it/s]                                                 {'loss': 1.3673, 'grad_norm': 1.9087255420895148, 'learning_rate': 1.0420475319926873e-06, 'epoch': 1.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 280/564 [04:03<03:59,  1.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 281/564 [04:04<03:58,  1.19it/s]                                                 {'loss': 1.3266, 'grad_norm': 2.2201166768834724, 'learning_rate': 1.0383912248628884e-06, 'epoch': 1.49}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 281/564 [04:04<03:58,  1.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 282/564 [04:04<03:57,  1.19it/s]                                                 {'loss': 1.3902, 'grad_norm': 2.429829435175157, 'learning_rate': 1.0347349177330896e-06, 'epoch': 1.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 282/564 [04:04<03:57,  1.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 283/564 [04:05<03:56,  1.19it/s]                                                 {'loss': 1.2765, 'grad_norm': 2.153753521155381, 'learning_rate': 1.0310786106032906e-06, 'epoch': 1.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 283/564 [04:05<03:56,  1.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 284/564 [04:06<03:55,  1.19it/s]                                                 {'loss': 1.2907, 'grad_norm': 2.088017711907982, 'learning_rate': 1.0274223034734916e-06, 'epoch': 1.51}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 284/564 [04:06<03:55,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 285/564 [04:07<03:55,  1.19it/s]                                                 {'loss': 1.2728, 'grad_norm': 2.1762526292905773, 'learning_rate': 1.0237659963436929e-06, 'epoch': 1.52}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 285/564 [04:07<03:55,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 286/564 [04:08<03:54,  1.19it/s]                                                 {'loss': 1.3134, 'grad_norm': 2.2944748406882463, 'learning_rate': 1.020109689213894e-06, 'epoch': 1.52}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 286/564 [04:08<03:54,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 287/564 [04:09<03:53,  1.19it/s]                                                 {'loss': 1.1351, 'grad_norm': 2.532735569368558, 'learning_rate': 1.0164533820840951e-06, 'epoch': 1.53}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 287/564 [04:09<03:53,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 288/564 [04:09<03:52,  1.19it/s]                                                 {'loss': 1.3689, 'grad_norm': 2.2019048647596233, 'learning_rate': 1.012797074954296e-06, 'epoch': 1.53}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 288/564 [04:09<03:52,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 289/564 [04:10<03:51,  1.19it/s]                                                 {'loss': 1.1812, 'grad_norm': 2.538397697935493, 'learning_rate': 1.0091407678244972e-06, 'epoch': 1.54}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 289/564 [04:10<03:51,  1.19it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 290/564 [04:11<03:50,  1.19it/s]                                                 {'loss': 1.4444, 'grad_norm': 2.2139708031184995, 'learning_rate': 1.0054844606946984e-06, 'epoch': 1.54}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 290/564 [04:11<03:50,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 291/564 [04:12<03:49,  1.19it/s]                                                 {'loss': 1.2518, 'grad_norm': 2.2209177261036026, 'learning_rate': 1.0018281535648994e-06, 'epoch': 1.55}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 291/564 [04:12<03:49,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 292/564 [04:13<03:48,  1.19it/s]                                                 {'loss': 1.1469, 'grad_norm': 2.3551981014432597, 'learning_rate': 9.981718464351005e-07, 'epoch': 1.55}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 292/564 [04:13<03:48,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 293/564 [04:14<03:48,  1.19it/s]                                                 {'loss': 1.4045, 'grad_norm': 2.2527351171473224, 'learning_rate': 9.945155393053017e-07, 'epoch': 1.56}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 293/564 [04:14<03:48,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 294/564 [04:15<03:47,  1.19it/s]                                                 {'loss': 1.3566, 'grad_norm': 1.9991624904154748, 'learning_rate': 9.908592321755027e-07, 'epoch': 1.56}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 294/564 [04:15<03:47,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 295/564 [04:15<03:46,  1.19it/s]                                                 {'loss': 1.3503, 'grad_norm': 2.1557861766351096, 'learning_rate': 9.872029250457037e-07, 'epoch': 1.57}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 295/564 [04:15<03:46,  1.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 296/564 [04:16<03:46,  1.19it/s]                                                 {'loss': 1.0598, 'grad_norm': 2.293613223366235, 'learning_rate': 9.835466179159048e-07, 'epoch': 1.57}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 296/564 [04:16<03:46,  1.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 297/564 [04:17<03:45,  1.18it/s]                                                 {'loss': 1.3819, 'grad_norm': 2.058250979882098, 'learning_rate': 9.79890310786106e-07, 'epoch': 1.58}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 297/564 [04:17<03:45,  1.18it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 298/564 [04:18<03:44,  1.19it/s]                                                 {'loss': 1.4483, 'grad_norm': 2.026926380653221, 'learning_rate': 9.76234003656307e-07, 'epoch': 1.59}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 298/564 [04:18<03:44,  1.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 299/564 [04:19<03:43,  1.19it/s]                                                 {'loss': 1.3187, 'grad_norm': 2.2450083358239037, 'learning_rate': 9.725776965265083e-07, 'epoch': 1.59}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 299/564 [04:19<03:43,  1.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 300/564 [04:20<03:42,  1.19it/s]                                                 {'loss': 1.2534, 'grad_norm': 2.304466252196144, 'learning_rate': 9.689213893967093e-07, 'epoch': 1.6}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 300/564 [04:20<03:42,  1.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 301/564 [04:20<03:41,  1.19it/s]                                                 {'loss': 1.3782, 'grad_norm': 2.2604880386710753, 'learning_rate': 9.652650822669103e-07, 'epoch': 1.6}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 301/564 [04:20<03:41,  1.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 302/564 [04:21<03:40,  1.19it/s]                                                 {'loss': 1.3616, 'grad_norm': 2.0527933979377972, 'learning_rate': 9.616087751371115e-07, 'epoch': 1.61}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 302/564 [04:21<03:40,  1.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 303/564 [04:22<03:40,  1.18it/s]                                                 {'loss': 1.4955, 'grad_norm': 2.1944489262246565, 'learning_rate': 9.579524680073126e-07, 'epoch': 1.61}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 303/564 [04:22<03:40,  1.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 304/564 [04:23<03:40,  1.18it/s]                                                 {'loss': 1.4643, 'grad_norm': 2.0762458559605306, 'learning_rate': 9.542961608775136e-07, 'epoch': 1.62}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 304/564 [04:23<03:40,  1.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 305/564 [04:24<03:39,  1.18it/s]                                                 {'loss': 1.3641, 'grad_norm': 2.2675334647181806, 'learning_rate': 9.506398537477147e-07, 'epoch': 1.62}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 305/564 [04:24<03:39,  1.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 306/564 [04:25<03:38,  1.18it/s]                                                 {'loss': 1.2683, 'grad_norm': 2.1890762151743783, 'learning_rate': 9.469835466179159e-07, 'epoch': 1.63}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 306/564 [04:25<03:38,  1.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/564 [04:25<03:36,  1.19it/s]                                                 {'loss': 1.1999, 'grad_norm': 2.2810946341577036, 'learning_rate': 9.43327239488117e-07, 'epoch': 1.63}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 307/564 [04:25<03:36,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 308/564 [04:26<03:35,  1.19it/s]                                                 {'loss': 1.2683, 'grad_norm': 2.37725512218198, 'learning_rate': 9.396709323583181e-07, 'epoch': 1.64}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 308/564 [04:26<03:35,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/564 [04:27<03:34,  1.19it/s]                                                 {'loss': 1.2351, 'grad_norm': 2.4987492971107534, 'learning_rate': 9.360146252285191e-07, 'epoch': 1.64}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 309/564 [04:27<03:34,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/564 [04:28<03:34,  1.19it/s]                                                 {'loss': 1.2214, 'grad_norm': 2.220994335898373, 'learning_rate': 9.323583180987203e-07, 'epoch': 1.65}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/564 [04:28<03:34,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 311/564 [04:29<03:32,  1.19it/s]                                                 {'loss': 1.3254, 'grad_norm': 2.1439364756141033, 'learning_rate': 9.287020109689213e-07, 'epoch': 1.65}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 311/564 [04:29<03:32,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 312/564 [04:30<03:31,  1.19it/s]                                                 {'loss': 1.3561, 'grad_norm': 2.2055453113607943, 'learning_rate': 9.250457038391224e-07, 'epoch': 1.66}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 312/564 [04:30<03:31,  1.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 313/564 [04:31<03:30,  1.19it/s]                                                 {'loss': 1.1855, 'grad_norm': 1.9198974448086756, 'learning_rate': 9.213893967093235e-07, 'epoch': 1.66}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 313/564 [04:31<03:30,  1.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 314/564 [04:31<03:30,  1.19it/s]                                                 {'loss': 1.2409, 'grad_norm': 2.09795595693846, 'learning_rate': 9.177330895795247e-07, 'epoch': 1.67}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 314/564 [04:31<03:30,  1.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 315/564 [04:32<03:29,  1.19it/s]                                                 {'loss': 1.4106, 'grad_norm': 2.120897405737084, 'learning_rate': 9.140767824497257e-07, 'epoch': 1.68}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 315/564 [04:32<03:29,  1.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 316/564 [04:33<03:28,  1.19it/s]                                                 {'loss': 1.3763, 'grad_norm': 2.1577469122390944, 'learning_rate': 9.104204753199268e-07, 'epoch': 1.68}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 316/564 [04:33<03:28,  1.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 317/564 [04:34<03:27,  1.19it/s]                                                 {'loss': 1.2231, 'grad_norm': 2.716154723147437, 'learning_rate': 9.06764168190128e-07, 'epoch': 1.69}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 317/564 [04:34<03:27,  1.19it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 318/564 [04:35<03:26,  1.19it/s]                                                 {'loss': 1.3125, 'grad_norm': 2.2113857836181183, 'learning_rate': 9.03107861060329e-07, 'epoch': 1.69}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 318/564 [04:35<03:26,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 319/564 [04:36<03:26,  1.19it/s]                                                 {'loss': 1.1793, 'grad_norm': 2.1861944174218686, 'learning_rate': 8.994515539305301e-07, 'epoch': 1.7}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 319/564 [04:36<03:26,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 320/564 [04:36<03:25,  1.19it/s]                                                 {'loss': 1.28, 'grad_norm': 2.1735886544312497, 'learning_rate': 8.957952468007312e-07, 'epoch': 1.7}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 320/564 [04:36<03:25,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 321/564 [04:37<03:24,  1.19it/s]                                                 {'loss': 1.3043, 'grad_norm': 2.3204715465179793, 'learning_rate': 8.921389396709324e-07, 'epoch': 1.71}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 321/564 [04:37<03:24,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 322/564 [04:38<03:23,  1.19it/s]                                                 {'loss': 1.3108, 'grad_norm': 2.572245988853389, 'learning_rate': 8.884826325411334e-07, 'epoch': 1.71}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 322/564 [04:38<03:23,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 323/564 [04:39<03:22,  1.19it/s]                                                 {'loss': 1.3421, 'grad_norm': 2.5142541366544124, 'learning_rate': 8.848263254113345e-07, 'epoch': 1.72}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 323/564 [04:39<03:22,  1.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 324/564 [04:40<03:22,  1.19it/s]                                                 {'loss': 1.3733, 'grad_norm': 2.17028878582354, 'learning_rate': 8.811700182815355e-07, 'epoch': 1.72}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 324/564 [04:40<03:22,  1.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 325/564 [04:41<03:20,  1.19it/s]                                                 {'loss': 1.2568, 'grad_norm': 2.1093637021581766, 'learning_rate': 8.775137111517367e-07, 'epoch': 1.73}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 325/564 [04:41<03:20,  1.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 326/564 [04:41<03:19,  1.19it/s]                                                 {'loss': 1.2364, 'grad_norm': 2.127755746232103, 'learning_rate': 8.738574040219377e-07, 'epoch': 1.73}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 326/564 [04:41<03:19,  1.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 327/564 [04:42<03:18,  1.19it/s]                                                 {'loss': 1.1802, 'grad_norm': 2.166174948687006, 'learning_rate': 8.702010968921389e-07, 'epoch': 1.74}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 327/564 [04:42<03:18,  1.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 328/564 [04:43<03:18,  1.19it/s]                                                 {'loss': 1.2476, 'grad_norm': 2.0545173521730407, 'learning_rate': 8.665447897623401e-07, 'epoch': 1.74}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 328/564 [04:43<03:18,  1.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 329/564 [04:44<03:17,  1.19it/s]                                                 {'loss': 1.132, 'grad_norm': 2.1968498271750474, 'learning_rate': 8.628884826325411e-07, 'epoch': 1.75}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 329/564 [04:44<03:17,  1.19it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 330/564 [04:45<03:16,  1.19it/s]                                                 {'loss': 1.1888, 'grad_norm': 2.0050860833922552, 'learning_rate': 8.592321755027422e-07, 'epoch': 1.76}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 330/564 [04:45<03:16,  1.19it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 331/564 [04:46<03:15,  1.19it/s]                                                 {'loss': 1.2274, 'grad_norm': 2.354433750900921, 'learning_rate': 8.555758683729432e-07, 'epoch': 1.76}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 331/564 [04:46<03:15,  1.19it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 332/564 [04:46<03:14,  1.19it/s]                                                 {'loss': 1.1523, 'grad_norm': 2.2007282899641876, 'learning_rate': 8.519195612431444e-07, 'epoch': 1.77}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 332/564 [04:46<03:14,  1.19it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 333/564 [04:47<03:13,  1.19it/s]                                                 {'loss': 1.3407, 'grad_norm': 2.1844510878310386, 'learning_rate': 8.482632541133454e-07, 'epoch': 1.77}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 333/564 [04:47<03:13,  1.19it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 334/564 [04:48<03:12,  1.20it/s]                                                 {'loss': 1.3194, 'grad_norm': 2.0695369767757783, 'learning_rate': 8.446069469835466e-07, 'epoch': 1.78}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 334/564 [04:48<03:12,  1.20it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 335/564 [04:49<03:11,  1.20it/s]                                                 {'loss': 1.1872, 'grad_norm': 2.2160854848086884, 'learning_rate': 8.409506398537477e-07, 'epoch': 1.78}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 335/564 [04:49<03:11,  1.20it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 336/564 [04:50<03:10,  1.20it/s]                                                 {'loss': 1.1648, 'grad_norm': 2.057355301014656, 'learning_rate': 8.372943327239488e-07, 'epoch': 1.79}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 336/564 [04:50<03:10,  1.20it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 337/564 [04:51<03:10,  1.19it/s]                                                 {'loss': 1.3894, 'grad_norm': 2.015649345478491, 'learning_rate': 8.336380255941499e-07, 'epoch': 1.79}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 337/564 [04:51<03:10,  1.19it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 338/564 [04:51<03:09,  1.19it/s]                                                 {'loss': 1.2843, 'grad_norm': 2.3786021672825197, 'learning_rate': 8.299817184643509e-07, 'epoch': 1.8}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 338/564 [04:51<03:09,  1.19it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 339/564 [04:52<03:09,  1.19it/s]                                                 {'loss': 1.3081, 'grad_norm': 1.9554298913761896, 'learning_rate': 8.263254113345521e-07, 'epoch': 1.8}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 339/564 [04:52<03:09,  1.19it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 340/564 [04:53<03:08,  1.19it/s]                                                 {'loss': 1.3188, 'grad_norm': 2.188624645993013, 'learning_rate': 8.226691042047532e-07, 'epoch': 1.81}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 340/564 [04:53<03:08,  1.19it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 341/564 [04:54<03:07,  1.19it/s]                                                 {'loss': 1.1213, 'grad_norm': 2.2114324677365067, 'learning_rate': 8.190127970749543e-07, 'epoch': 1.81}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 341/564 [04:54<03:07,  1.19it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 342/564 [04:55<03:06,  1.19it/s]                                                 {'loss': 1.2777, 'grad_norm': 2.5061643363039368, 'learning_rate': 8.153564899451553e-07, 'epoch': 1.82}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 342/564 [04:55<03:06,  1.19it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 343/564 [04:56<03:05,  1.19it/s]                                                 {'loss': 1.3791, 'grad_norm': 2.2826487169466216, 'learning_rate': 8.117001828153565e-07, 'epoch': 1.82}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 343/564 [04:56<03:05,  1.19it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 344/564 [04:57<03:05,  1.19it/s]                                                 {'loss': 1.2184, 'grad_norm': 2.073154994521086, 'learning_rate': 8.080438756855575e-07, 'epoch': 1.83}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 344/564 [04:57<03:05,  1.19it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 345/564 [04:57<03:04,  1.19it/s]                                                 {'loss': 1.3748, 'grad_norm': 2.0283261899901017, 'learning_rate': 8.043875685557586e-07, 'epoch': 1.84}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 345/564 [04:57<03:04,  1.19it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 346/564 [04:58<03:04,  1.18it/s]                                                 {'loss': 1.4486, 'grad_norm': 2.254942587924672, 'learning_rate': 8.007312614259597e-07, 'epoch': 1.84}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 346/564 [04:58<03:04,  1.18it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 347/564 [04:59<03:03,  1.18it/s]                                                 {'loss': 1.4011, 'grad_norm': 2.030160558791226, 'learning_rate': 7.970749542961609e-07, 'epoch': 1.85}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 347/564 [04:59<03:03,  1.18it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 348/564 [05:00<03:01,  1.19it/s]                                                 {'loss': 1.1651, 'grad_norm': 2.3450539796039607, 'learning_rate': 7.93418647166362e-07, 'epoch': 1.85}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 348/564 [05:00<03:01,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 349/564 [05:01<03:00,  1.19it/s]                                                 {'loss': 1.336, 'grad_norm': 2.0817839970579497, 'learning_rate': 7.89762340036563e-07, 'epoch': 1.86}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 349/564 [05:01<03:00,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/564 [05:02<02:59,  1.19it/s]                                                 {'loss': 1.2266, 'grad_norm': 2.598062821718463, 'learning_rate': 7.861060329067642e-07, 'epoch': 1.86}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/564 [05:02<02:59,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 351/564 [05:02<02:59,  1.19it/s]                                                 {'loss': 1.3416, 'grad_norm': 2.0882000891823087, 'learning_rate': 7.824497257769652e-07, 'epoch': 1.87}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 351/564 [05:02<02:59,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 352/564 [05:03<02:58,  1.19it/s]                                                 {'loss': 1.3723, 'grad_norm': 2.210636472405461, 'learning_rate': 7.787934186471663e-07, 'epoch': 1.87}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 352/564 [05:03<02:58,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 353/564 [05:04<02:57,  1.19it/s]                                                 {'loss': 1.2148, 'grad_norm': 2.452222389815141, 'learning_rate': 7.751371115173673e-07, 'epoch': 1.88}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 353/564 [05:04<02:57,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 354/564 [05:05<02:56,  1.19it/s]                                                 {'loss': 1.3803, 'grad_norm': 2.1607716149915914, 'learning_rate': 7.714808043875686e-07, 'epoch': 1.88}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 354/564 [05:05<02:56,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 355/564 [05:06<02:56,  1.19it/s]                                                 {'loss': 1.1878, 'grad_norm': 2.3967622564145903, 'learning_rate': 7.678244972577696e-07, 'epoch': 1.89}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 355/564 [05:06<02:56,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 356/564 [05:07<02:54,  1.19it/s]                                                 {'loss': 1.331, 'grad_norm': 2.244820042609409, 'learning_rate': 7.641681901279707e-07, 'epoch': 1.89}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 356/564 [05:07<02:54,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 357/564 [05:07<02:53,  1.19it/s]                                                 {'loss': 1.2393, 'grad_norm': 2.0262561313647187, 'learning_rate': 7.605118829981719e-07, 'epoch': 1.9}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 357/564 [05:07<02:53,  1.19it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 358/564 [05:08<02:52,  1.19it/s]                                                 {'loss': 1.3561, 'grad_norm': 2.061103900227258, 'learning_rate': 7.568555758683729e-07, 'epoch': 1.9}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 358/564 [05:08<02:52,  1.19it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 359/564 [05:09<02:52,  1.19it/s]                                                 {'loss': 1.2259, 'grad_norm': 2.1047669618634615, 'learning_rate': 7.53199268738574e-07, 'epoch': 1.91}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 359/564 [05:09<02:52,  1.19it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 360/564 [05:10<02:52,  1.18it/s]                                                 {'loss': 1.2279, 'grad_norm': 2.1340969314006046, 'learning_rate': 7.49542961608775e-07, 'epoch': 1.91}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 360/564 [05:10<02:52,  1.18it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 361/564 [05:11<02:51,  1.19it/s]                                                 {'loss': 1.184, 'grad_norm': 1.9970483523681262, 'learning_rate': 7.458866544789763e-07, 'epoch': 1.92}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 361/564 [05:11<02:51,  1.19it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 362/564 [05:12<02:50,  1.19it/s]                                                 {'loss': 1.3397, 'grad_norm': 2.1417237017934196, 'learning_rate': 7.422303473491773e-07, 'epoch': 1.93}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 362/564 [05:12<02:50,  1.19it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 363/564 [05:13<02:49,  1.18it/s]                                                 {'loss': 1.2687, 'grad_norm': 2.246884602057865, 'learning_rate': 7.385740402193784e-07, 'epoch': 1.93}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 363/564 [05:13<02:49,  1.18it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/564 [05:13<02:48,  1.19it/s]                                                 {'loss': 1.272, 'grad_norm': 2.503961439920495, 'learning_rate': 7.349177330895795e-07, 'epoch': 1.94}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 364/564 [05:13<02:48,  1.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 365/564 [05:14<02:47,  1.19it/s]                                                 {'loss': 1.483, 'grad_norm': 2.1998554199615366, 'learning_rate': 7.312614259597806e-07, 'epoch': 1.94}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 365/564 [05:14<02:47,  1.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/564 [05:15<02:46,  1.19it/s]                                                 {'loss': 1.3325, 'grad_norm': 2.09601377408593, 'learning_rate': 7.276051188299816e-07, 'epoch': 1.95}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 366/564 [05:15<02:46,  1.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 367/564 [05:16<02:46,  1.19it/s]                                                 {'loss': 1.3048, 'grad_norm': 2.3840456826817085, 'learning_rate': 7.239488117001827e-07, 'epoch': 1.95}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 367/564 [05:16<02:46,  1.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 368/564 [05:17<02:45,  1.19it/s]                                                 {'loss': 1.2672, 'grad_norm': 2.4398034518880487, 'learning_rate': 7.20292504570384e-07, 'epoch': 1.96}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 368/564 [05:17<02:45,  1.19it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 369/564 [05:18<02:44,  1.19it/s]                                                 {'loss': 1.4077, 'grad_norm': 2.2481409270696187, 'learning_rate': 7.16636197440585e-07, 'epoch': 1.96}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 369/564 [05:18<02:44,  1.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 370/564 [05:18<02:43,  1.18it/s]                                                 {'loss': 1.1455, 'grad_norm': 2.317690610098849, 'learning_rate': 7.129798903107861e-07, 'epoch': 1.97}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 370/564 [05:18<02:43,  1.18it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 371/564 [05:19<02:42,  1.19it/s]                                                 {'loss': 1.3939, 'grad_norm': 2.2420970890366676, 'learning_rate': 7.093235831809871e-07, 'epoch': 1.97}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 371/564 [05:19<02:42,  1.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 372/564 [05:20<02:41,  1.19it/s]                                                 {'loss': 1.1984, 'grad_norm': 2.542971792447342, 'learning_rate': 7.056672760511883e-07, 'epoch': 1.98}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 372/564 [05:20<02:41,  1.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 373/564 [05:21<02:40,  1.19it/s]                                                 {'loss': 1.2539, 'grad_norm': 2.2882460798617066, 'learning_rate': 7.020109689213893e-07, 'epoch': 1.98}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 373/564 [05:21<02:40,  1.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 374/564 [05:22<02:39,  1.19it/s]                                                 {'loss': 1.2754, 'grad_norm': 2.164146713303656, 'learning_rate': 6.983546617915904e-07, 'epoch': 1.99}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 374/564 [05:22<02:39,  1.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 375/564 [05:23<02:39,  1.19it/s]                                                 {'loss': 1.2919, 'grad_norm': 2.1522699474818996, 'learning_rate': 6.946983546617916e-07, 'epoch': 1.99}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 375/564 [05:23<02:39,  1.19it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 376/564 [05:24<02:39,  1.18it/s]                                                 {'loss': 1.2357, 'grad_norm': 2.089028859317029, 'learning_rate': 6.910420475319927e-07, 'epoch': 2.0}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 376/564 [05:24<02:39,  1.18it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 377/564 [05:24<02:37,  1.18it/s]                                                 {'loss': 1.3822, 'grad_norm': 2.008712661498983, 'learning_rate': 6.873857404021938e-07, 'epoch': 2.01}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 377/564 [05:24<02:37,  1.18it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 378/564 [05:25<02:36,  1.19it/s]                                                 {'loss': 1.2259, 'grad_norm': 2.245665334884697, 'learning_rate': 6.837294332723948e-07, 'epoch': 2.01}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 378/564 [05:25<02:36,  1.19it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 379/564 [05:26<02:36,  1.18it/s]                                                 {'loss': 1.217, 'grad_norm': 2.5268936948547402, 'learning_rate': 6.80073126142596e-07, 'epoch': 2.02}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 379/564 [05:26<02:36,  1.18it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 380/564 [05:27<02:35,  1.18it/s]                                                 {'loss': 1.2192, 'grad_norm': 2.0378282731199766, 'learning_rate': 6.76416819012797e-07, 'epoch': 2.02}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 380/564 [05:27<02:35,  1.18it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 381/564 [05:28<02:34,  1.19it/s]                                                 {'loss': 1.2082, 'grad_norm': 2.3107678143801165, 'learning_rate': 6.727605118829981e-07, 'epoch': 2.03}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 381/564 [05:28<02:34,  1.19it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 382/564 [05:29<02:33,  1.19it/s]                                                 {'loss': 1.1375, 'grad_norm': 2.3993575986628115, 'learning_rate': 6.691042047531993e-07, 'epoch': 2.03}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 382/564 [05:29<02:33,  1.19it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 383/564 [05:29<02:32,  1.19it/s]                                                 {'loss': 1.0209, 'grad_norm': 1.9255405478629721, 'learning_rate': 6.654478976234004e-07, 'epoch': 2.04}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 383/564 [05:29<02:32,  1.19it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 384/564 [05:30<02:31,  1.19it/s]                                                 {'loss': 1.3185, 'grad_norm': 2.104491547217847, 'learning_rate': 6.617915904936014e-07, 'epoch': 2.04}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 384/564 [05:30<02:31,  1.19it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 385/564 [05:31<02:30,  1.19it/s]                                                 {'loss': 1.27, 'grad_norm': 1.8724780908768657, 'learning_rate': 6.581352833638025e-07, 'epoch': 2.05}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 385/564 [05:31<02:30,  1.19it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 386/564 [05:32<02:29,  1.19it/s]                                                 {'loss': 1.1866, 'grad_norm': 2.5094222309227026, 'learning_rate': 6.544789762340036e-07, 'epoch': 2.05}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 386/564 [05:32<02:29,  1.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 387/564 [05:33<02:28,  1.19it/s]                                                 {'loss': 1.2511, 'grad_norm': 2.143112074777944, 'learning_rate': 6.508226691042047e-07, 'epoch': 2.06}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 387/564 [05:33<02:28,  1.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 388/564 [05:34<02:27,  1.19it/s]                                                 {'loss': 1.0009, 'grad_norm': 2.1110493505423245, 'learning_rate': 6.471663619744058e-07, 'epoch': 2.06}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 388/564 [05:34<02:27,  1.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 389/564 [05:34<02:27,  1.19it/s]                                                 {'loss': 1.1089, 'grad_norm': 2.2063013193011964, 'learning_rate': 6.435100548446069e-07, 'epoch': 2.07}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 389/564 [05:34<02:27,  1.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 390/564 [05:35<02:26,  1.19it/s]                                                 {'loss': 1.0649, 'grad_norm': 2.253657686352366, 'learning_rate': 6.398537477148081e-07, 'epoch': 2.07}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 390/564 [05:35<02:26,  1.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 391/564 [05:36<02:25,  1.19it/s]                                                 {'loss': 1.1634, 'grad_norm': 1.9173429120098806, 'learning_rate': 6.361974405850091e-07, 'epoch': 2.08}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 391/564 [05:36<02:25,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 392/564 [05:37<02:24,  1.19it/s]                                                 {'loss': 1.2983, 'grad_norm': 2.296654200151893, 'learning_rate': 6.325411334552102e-07, 'epoch': 2.09}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 392/564 [05:37<02:24,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 393/564 [05:38<02:23,  1.19it/s]                                                 {'loss': 1.2489, 'grad_norm': 2.311874204049344, 'learning_rate': 6.288848263254113e-07, 'epoch': 2.09}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 393/564 [05:38<02:23,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 394/564 [05:39<02:22,  1.19it/s]                                                 {'loss': 1.3306, 'grad_norm': 2.302298346372843, 'learning_rate': 6.252285191956124e-07, 'epoch': 2.1}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 394/564 [05:39<02:22,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 395/564 [05:39<02:22,  1.19it/s]                                                 {'loss': 1.1516, 'grad_norm': 2.224905691380814, 'learning_rate': 6.215722120658134e-07, 'epoch': 2.1}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 395/564 [05:39<02:22,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 396/564 [05:40<02:21,  1.19it/s]                                                 {'loss': 1.1044, 'grad_norm': 2.279955782987474, 'learning_rate': 6.179159049360146e-07, 'epoch': 2.11}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 396/564 [05:40<02:21,  1.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 397/564 [05:41<02:20,  1.19it/s]                                                 {'loss': 1.1429, 'grad_norm': 2.013669617798856, 'learning_rate': 6.142595978062158e-07, 'epoch': 2.11}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 397/564 [05:41<02:20,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 398/564 [05:42<02:19,  1.19it/s]                                                 {'loss': 1.2163, 'grad_norm': 2.341794713953626, 'learning_rate': 6.106032906764168e-07, 'epoch': 2.12}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 398/564 [05:42<02:19,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 399/564 [05:43<02:18,  1.19it/s]                                                 {'loss': 1.2938, 'grad_norm': 2.3540719896807367, 'learning_rate': 6.069469835466179e-07, 'epoch': 2.12}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 399/564 [05:43<02:18,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/564 [05:44<02:17,  1.19it/s]                                                 {'loss': 1.0488, 'grad_norm': 2.1901087004963635, 'learning_rate': 6.032906764168189e-07, 'epoch': 2.13}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 400/564 [05:44<02:17,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 401/564 [05:45<02:16,  1.19it/s]                                                 {'loss': 1.2473, 'grad_norm': 2.1269576003694053, 'learning_rate': 5.996343692870201e-07, 'epoch': 2.13}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 401/564 [05:45<02:16,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 402/564 [05:45<02:15,  1.19it/s]                                                 {'loss': 1.2877, 'grad_norm': 2.0558083509826637, 'learning_rate': 5.959780621572211e-07, 'epoch': 2.14}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 402/564 [05:45<02:15,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 403/564 [05:46<02:15,  1.19it/s]                                                 {'loss': 1.3443, 'grad_norm': 2.067171487704854, 'learning_rate': 5.923217550274223e-07, 'epoch': 2.14}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 403/564 [05:46<02:15,  1.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 404/564 [05:47<02:14,  1.19it/s]                                                 {'loss': 1.2201, 'grad_norm': 2.3875981926645298, 'learning_rate': 5.886654478976234e-07, 'epoch': 2.15}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 404/564 [05:47<02:14,  1.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 405/564 [05:48<02:13,  1.19it/s]                                                 {'loss': 1.215, 'grad_norm': 2.284553416402818, 'learning_rate': 5.850091407678245e-07, 'epoch': 2.15}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 405/564 [05:48<02:13,  1.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 406/564 [05:49<02:12,  1.19it/s]                                                 {'loss': 1.1963, 'grad_norm': 2.4457858984128262, 'learning_rate': 5.813528336380256e-07, 'epoch': 2.16}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 406/564 [05:49<02:12,  1.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 407/564 [05:50<02:11,  1.19it/s]                                                 {'loss': 1.2463, 'grad_norm': 2.063613640341321, 'learning_rate': 5.776965265082266e-07, 'epoch': 2.16}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 407/564 [05:50<02:11,  1.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 408/564 [05:50<02:10,  1.19it/s]                                                 {'loss': 1.4181, 'grad_norm': 2.3451624838019676, 'learning_rate': 5.740402193784278e-07, 'epoch': 2.17}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 408/564 [05:50<02:10,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 409/564 [05:51<02:10,  1.19it/s]                                                 {'loss': 1.3229, 'grad_norm': 2.257004746104525, 'learning_rate': 5.703839122486288e-07, 'epoch': 2.18}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 409/564 [05:51<02:10,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 410/564 [05:52<02:09,  1.19it/s]                                                 {'loss': 1.3218, 'grad_norm': 2.221161591985262, 'learning_rate': 5.6672760511883e-07, 'epoch': 2.18}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 410/564 [05:52<02:09,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 411/564 [05:53<02:08,  1.19it/s]                                                 {'loss': 1.057, 'grad_norm': 2.158695226586914, 'learning_rate': 5.63071297989031e-07, 'epoch': 2.19}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 411/564 [05:53<02:08,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 412/564 [05:54<02:07,  1.19it/s]                                                 {'loss': 1.1393, 'grad_norm': 2.1510365695158997, 'learning_rate': 5.594149908592322e-07, 'epoch': 2.19}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 412/564 [05:54<02:07,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 413/564 [05:55<02:06,  1.19it/s]                                                 {'loss': 1.2634, 'grad_norm': 2.0980743187320563, 'learning_rate': 5.557586837294332e-07, 'epoch': 2.2}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 413/564 [05:55<02:06,  1.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 414/564 [05:55<02:06,  1.19it/s]                                                 {'loss': 1.1717, 'grad_norm': 2.0396788760029816, 'learning_rate': 5.521023765996343e-07, 'epoch': 2.2}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 414/564 [05:55<02:06,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 415/564 [05:56<02:05,  1.19it/s]                                                 {'loss': 1.3292, 'grad_norm': 2.452292049171257, 'learning_rate': 5.484460694698354e-07, 'epoch': 2.21}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 415/564 [05:56<02:05,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 416/564 [05:57<02:04,  1.19it/s]                                                 {'loss': 1.3237, 'grad_norm': 2.2717560401726407, 'learning_rate': 5.447897623400365e-07, 'epoch': 2.21}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 416/564 [05:57<02:04,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 417/564 [05:58<02:03,  1.19it/s]                                                 {'loss': 1.2534, 'grad_norm': 2.3408169449155607, 'learning_rate': 5.411334552102377e-07, 'epoch': 2.22}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 417/564 [05:58<02:03,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 418/564 [05:59<02:02,  1.19it/s]                                                 {'loss': 1.2357, 'grad_norm': 2.2548401836004492, 'learning_rate': 5.374771480804387e-07, 'epoch': 2.22}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 418/564 [05:59<02:02,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 419/564 [06:00<02:01,  1.19it/s]                                                 {'loss': 1.1015, 'grad_norm': 2.251214001205503, 'learning_rate': 5.338208409506399e-07, 'epoch': 2.23}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 419/564 [06:00<02:01,  1.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 420/564 [06:00<02:00,  1.19it/s]                                                 {'loss': 1.2777, 'grad_norm': 2.250954815138883, 'learning_rate': 5.301645338208409e-07, 'epoch': 2.23}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 420/564 [06:00<02:00,  1.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 421/564 [06:01<02:00,  1.19it/s]                                                 {'loss': 1.0349, 'grad_norm': 2.3609859666259347, 'learning_rate': 5.26508226691042e-07, 'epoch': 2.24}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 421/564 [06:01<02:00,  1.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/564 [06:02<01:59,  1.19it/s]                                                 {'loss': 1.254, 'grad_norm': 2.6896466330466655, 'learning_rate': 5.22851919561243e-07, 'epoch': 2.24}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 422/564 [06:02<01:59,  1.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 423/564 [06:03<01:58,  1.19it/s]                                                 {'loss': 1.2503, 'grad_norm': 2.100941496918975, 'learning_rate': 5.191956124314442e-07, 'epoch': 2.25}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 423/564 [06:03<01:58,  1.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 424/564 [06:04<01:57,  1.19it/s]                                                 {'loss': 1.2718, 'grad_norm': 2.314841719875395, 'learning_rate': 5.155393053016453e-07, 'epoch': 2.26}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 424/564 [06:04<01:57,  1.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 425/564 [06:05<01:56,  1.19it/s]                                                 {'loss': 1.244, 'grad_norm': 2.21594714182065, 'learning_rate': 5.118829981718464e-07, 'epoch': 2.26}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 425/564 [06:05<01:56,  1.19it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 426/564 [06:06<01:56,  1.19it/s]                                                 {'loss': 1.0866, 'grad_norm': 2.1639881733650443, 'learning_rate': 5.082266910420476e-07, 'epoch': 2.27}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 426/564 [06:06<01:56,  1.19it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 427/564 [06:06<01:55,  1.18it/s]                                                 {'loss': 1.0499, 'grad_norm': 2.1070974432318628, 'learning_rate': 5.045703839122486e-07, 'epoch': 2.27}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 427/564 [06:06<01:55,  1.18it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 428/564 [06:07<01:54,  1.18it/s]                                                 {'loss': 1.2872, 'grad_norm': 2.62315440363613, 'learning_rate': 5.009140767824497e-07, 'epoch': 2.28}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 428/564 [06:07<01:54,  1.18it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 429/564 [06:08<01:54,  1.18it/s]                                                 {'loss': 1.2527, 'grad_norm': 2.002278360058138, 'learning_rate': 4.972577696526509e-07, 'epoch': 2.28}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 429/564 [06:08<01:54,  1.18it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 430/564 [06:09<01:52,  1.19it/s]                                                 {'loss': 1.2335, 'grad_norm': 2.180726211892315, 'learning_rate': 4.936014625228519e-07, 'epoch': 2.29}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 430/564 [06:09<01:52,  1.19it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 431/564 [06:10<01:52,  1.18it/s]                                                 {'loss': 1.2127, 'grad_norm': 1.976862770872233, 'learning_rate': 4.89945155393053e-07, 'epoch': 2.29}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 431/564 [06:10<01:52,  1.18it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 432/564 [06:11<01:50,  1.19it/s]                                                 {'loss': 1.0927, 'grad_norm': 2.457637057868615, 'learning_rate': 4.862888482632541e-07, 'epoch': 2.3}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 432/564 [06:11<01:50,  1.19it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 433/564 [06:11<01:50,  1.19it/s]                                                 {'loss': 1.123, 'grad_norm': 2.219253160620271, 'learning_rate': 4.826325411334552e-07, 'epoch': 2.3}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 433/564 [06:11<01:50,  1.19it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 434/564 [06:12<01:49,  1.19it/s]                                                 {'loss': 1.2369, 'grad_norm': 2.4791074510457882, 'learning_rate': 4.789762340036563e-07, 'epoch': 2.31}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 434/564 [06:12<01:49,  1.19it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 435/564 [06:13<01:48,  1.19it/s]                                                 {'loss': 1.2042, 'grad_norm': 2.452349092847103, 'learning_rate': 4.7531992687385736e-07, 'epoch': 2.31}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 435/564 [06:13<01:48,  1.19it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 436/564 [06:14<01:47,  1.19it/s]                                                 {'loss': 1.2557, 'grad_norm': 2.237582671564738, 'learning_rate': 4.716636197440585e-07, 'epoch': 2.32}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 436/564 [06:14<01:47,  1.19it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 437/564 [06:15<01:47,  1.19it/s]                                                 {'loss': 1.1331, 'grad_norm': 2.413960581363571, 'learning_rate': 4.6800731261425957e-07, 'epoch': 2.32}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 437/564 [06:15<01:47,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 438/564 [06:16<01:46,  1.19it/s]                                                 {'loss': 1.1722, 'grad_norm': 2.277278376388431, 'learning_rate': 4.6435100548446064e-07, 'epoch': 2.33}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 438/564 [06:16<01:46,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 439/564 [06:16<01:44,  1.19it/s]                                                 {'loss': 1.283, 'grad_norm': 2.30710683389258, 'learning_rate': 4.606946983546618e-07, 'epoch': 2.34}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 439/564 [06:16<01:44,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 440/564 [06:17<01:44,  1.19it/s]                                                 {'loss': 1.3055, 'grad_norm': 2.5226861511267438, 'learning_rate': 4.5703839122486285e-07, 'epoch': 2.34}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 440/564 [06:17<01:44,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 441/564 [06:18<01:43,  1.19it/s]                                                 {'loss': 1.1945, 'grad_norm': 2.0708279279585997, 'learning_rate': 4.53382084095064e-07, 'epoch': 2.35}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 441/564 [06:18<01:43,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 442/564 [06:19<01:42,  1.19it/s]                                                 {'loss': 1.3189, 'grad_norm': 2.152937833582971, 'learning_rate': 4.4972577696526506e-07, 'epoch': 2.35}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 442/564 [06:19<01:42,  1.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 443/564 [06:20<01:42,  1.19it/s]                                                 {'loss': 1.1437, 'grad_norm': 2.196710124362601, 'learning_rate': 4.460694698354662e-07, 'epoch': 2.36}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 443/564 [06:20<01:42,  1.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 444/564 [06:21<01:41,  1.18it/s]                                                 {'loss': 1.4287, 'grad_norm': 4.205763553515175, 'learning_rate': 4.4241316270566726e-07, 'epoch': 2.36}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 444/564 [06:21<01:41,  1.18it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 445/564 [06:22<01:40,  1.18it/s]                                                 {'loss': 1.2715, 'grad_norm': 2.4686648915433893, 'learning_rate': 4.3875685557586834e-07, 'epoch': 2.37}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 445/564 [06:22<01:40,  1.18it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 446/564 [06:22<01:39,  1.18it/s]                                                 {'loss': 1.1048, 'grad_norm': 2.619826303973632, 'learning_rate': 4.3510054844606947e-07, 'epoch': 2.37}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 446/564 [06:22<01:39,  1.18it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 447/564 [06:23<01:38,  1.18it/s]                                                 {'loss': 1.3628, 'grad_norm': 1.9938245539940418, 'learning_rate': 4.3144424131627054e-07, 'epoch': 2.38}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 447/564 [06:23<01:38,  1.18it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 448/564 [06:24<01:37,  1.19it/s]                                                 {'loss': 1.3402, 'grad_norm': 2.099258033175267, 'learning_rate': 4.277879341864716e-07, 'epoch': 2.38}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 448/564 [06:24<01:37,  1.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 449/564 [06:25<01:37,  1.19it/s]                                                 {'loss': 1.2619, 'grad_norm': 2.369371551554132, 'learning_rate': 4.241316270566727e-07, 'epoch': 2.39}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 449/564 [06:25<01:37,  1.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/564 [06:26<01:36,  1.18it/s]                                                 {'loss': 1.1969, 'grad_norm': 2.256441032292102, 'learning_rate': 4.2047531992687383e-07, 'epoch': 2.39}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 450/564 [06:26<01:36,  1.18it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 451/564 [06:27<01:35,  1.19it/s]                                                 {'loss': 1.3356, 'grad_norm': 2.0482707222942707, 'learning_rate': 4.1681901279707496e-07, 'epoch': 2.4}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 451/564 [06:27<01:35,  1.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 452/564 [06:27<01:34,  1.19it/s]                                                 {'loss': 1.2982, 'grad_norm': 2.2071971622535127, 'learning_rate': 4.1316270566727603e-07, 'epoch': 2.4}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 452/564 [06:27<01:34,  1.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 453/564 [06:28<01:33,  1.19it/s]                                                 {'loss': 1.392, 'grad_norm': 2.124981054717815, 'learning_rate': 4.0950639853747716e-07, 'epoch': 2.41}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 453/564 [06:28<01:33,  1.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 454/564 [06:29<01:32,  1.19it/s]                                                 {'loss': 1.1752, 'grad_norm': 2.4684166575886737, 'learning_rate': 4.0585009140767824e-07, 'epoch': 2.41}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 454/564 [06:29<01:32,  1.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 455/564 [06:30<01:31,  1.19it/s]                                                 {'loss': 1.1335, 'grad_norm': 2.509331665107499, 'learning_rate': 4.021937842778793e-07, 'epoch': 2.42}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 455/564 [06:30<01:31,  1.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 456/564 [06:31<01:30,  1.19it/s]                                                 {'loss': 1.2637, 'grad_norm': 2.179464454881183, 'learning_rate': 3.9853747714808044e-07, 'epoch': 2.43}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 456/564 [06:31<01:30,  1.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 457/564 [06:32<01:30,  1.18it/s]                                                 {'loss': 1.4863, 'grad_norm': 2.1994745472271027, 'learning_rate': 3.948811700182815e-07, 'epoch': 2.43}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 457/564 [06:32<01:30,  1.18it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 458/564 [06:33<01:29,  1.19it/s]                                                 {'loss': 1.2393, 'grad_norm': 2.174218835645187, 'learning_rate': 3.912248628884826e-07, 'epoch': 2.44}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 458/564 [06:33<01:29,  1.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 459/564 [06:33<01:28,  1.19it/s]                                                 {'loss': 1.2357, 'grad_norm': 2.2128439562789275, 'learning_rate': 3.875685557586837e-07, 'epoch': 2.44}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 459/564 [06:33<01:28,  1.19it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 460/564 [06:34<01:27,  1.19it/s]                                                 {'loss': 1.155, 'grad_norm': 1.9679627558986545, 'learning_rate': 3.839122486288848e-07, 'epoch': 2.45}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 460/564 [06:34<01:27,  1.19it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 461/564 [06:35<01:26,  1.18it/s]                                                 {'loss': 1.3367, 'grad_norm': 1.902631667133483, 'learning_rate': 3.8025594149908593e-07, 'epoch': 2.45}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 461/564 [06:35<01:26,  1.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 462/564 [06:36<01:26,  1.18it/s]                                                 {'loss': 1.1577, 'grad_norm': 1.991575690051867, 'learning_rate': 3.76599634369287e-07, 'epoch': 2.46}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 462/564 [06:36<01:26,  1.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 463/564 [06:37<01:25,  1.18it/s]                                                 {'loss': 1.4705, 'grad_norm': 2.3607648159834396, 'learning_rate': 3.7294332723948814e-07, 'epoch': 2.46}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 463/564 [06:37<01:25,  1.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 464/564 [06:38<01:24,  1.18it/s]                                                 {'loss': 1.1569, 'grad_norm': 2.2403435987710214, 'learning_rate': 3.692870201096892e-07, 'epoch': 2.47}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 464/564 [06:38<01:24,  1.18it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 465/564 [06:38<01:23,  1.18it/s]                                                 {'loss': 1.2269, 'grad_norm': 2.1726289313160376, 'learning_rate': 3.656307129798903e-07, 'epoch': 2.47}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 465/564 [06:38<01:23,  1.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 466/564 [06:39<01:22,  1.18it/s]                                                 {'loss': 1.0565, 'grad_norm': 2.662291925230584, 'learning_rate': 3.6197440585009137e-07, 'epoch': 2.48}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 466/564 [06:39<01:22,  1.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 467/564 [06:40<01:22,  1.18it/s]                                                 {'loss': 1.2766, 'grad_norm': 2.0213823422217065, 'learning_rate': 3.583180987202925e-07, 'epoch': 2.48}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 467/564 [06:40<01:22,  1.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 468/564 [06:41<01:20,  1.19it/s]                                                 {'loss': 1.221, 'grad_norm': 2.287514527766796, 'learning_rate': 3.5466179159049357e-07, 'epoch': 2.49}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 468/564 [06:41<01:20,  1.19it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 469/564 [06:42<01:20,  1.18it/s]                                                 {'loss': 1.2957, 'grad_norm': 2.150554630287578, 'learning_rate': 3.5100548446069465e-07, 'epoch': 2.49}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 469/564 [06:42<01:20,  1.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 470/564 [06:43<01:19,  1.18it/s]                                                 {'loss': 1.0703, 'grad_norm': 2.278716465345199, 'learning_rate': 3.473491773308958e-07, 'epoch': 2.5}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 470/564 [06:43<01:19,  1.18it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 471/564 [06:43<01:18,  1.18it/s]                                                 {'loss': 1.1572, 'grad_norm': 2.626875560154821, 'learning_rate': 3.436928702010969e-07, 'epoch': 2.51}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 471/564 [06:43<01:18,  1.18it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 472/564 [06:44<01:17,  1.18it/s]                                                 {'loss': 1.1781, 'grad_norm': 2.390523140794817, 'learning_rate': 3.40036563071298e-07, 'epoch': 2.51}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 472/564 [06:44<01:17,  1.18it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 473/564 [06:45<01:16,  1.18it/s]                                                 {'loss': 1.3646, 'grad_norm': 2.434523717931091, 'learning_rate': 3.3638025594149906e-07, 'epoch': 2.52}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 473/564 [06:45<01:16,  1.18it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 474/564 [06:46<01:15,  1.19it/s]                                                 {'loss': 1.2154, 'grad_norm': 2.458024348934164, 'learning_rate': 3.327239488117002e-07, 'epoch': 2.52}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 474/564 [06:46<01:15,  1.19it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 475/564 [06:47<01:15,  1.19it/s]                                                 {'loss': 1.2512, 'grad_norm': 2.156895037535174, 'learning_rate': 3.2906764168190127e-07, 'epoch': 2.53}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 475/564 [06:47<01:15,  1.19it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 476/564 [06:48<01:14,  1.19it/s]                                                 {'loss': 1.2125, 'grad_norm': 2.317430576724604, 'learning_rate': 3.2541133455210234e-07, 'epoch': 2.53}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 476/564 [06:48<01:14,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 477/564 [06:49<01:13,  1.19it/s]                                                 {'loss': 1.4064, 'grad_norm': 2.3842171500862404, 'learning_rate': 3.2175502742230347e-07, 'epoch': 2.54}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 477/564 [06:49<01:13,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 478/564 [06:49<01:12,  1.19it/s]                                                 {'loss': 1.1424, 'grad_norm': 2.3062355436904407, 'learning_rate': 3.1809872029250455e-07, 'epoch': 2.54}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 478/564 [06:49<01:12,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 479/564 [06:50<01:11,  1.19it/s]                                                 {'loss': 1.0202, 'grad_norm': 2.2439877552195884, 'learning_rate': 3.144424131627056e-07, 'epoch': 2.55}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 479/564 [06:50<01:11,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 480/564 [06:51<01:10,  1.19it/s]                                                 {'loss': 1.2101, 'grad_norm': 2.29598824456856, 'learning_rate': 3.107861060329067e-07, 'epoch': 2.55}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 480/564 [06:51<01:10,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 481/564 [06:52<01:09,  1.19it/s]                                                 {'loss': 1.1394, 'grad_norm': 2.2285134229359587, 'learning_rate': 3.071297989031079e-07, 'epoch': 2.56}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 481/564 [06:52<01:09,  1.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 482/564 [06:53<01:09,  1.19it/s]                                                 {'loss': 1.3696, 'grad_norm': 2.2904329811405195, 'learning_rate': 3.0347349177330896e-07, 'epoch': 2.56}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 482/564 [06:53<01:09,  1.19it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 483/564 [06:54<01:08,  1.18it/s]                                                 {'loss': 1.2431, 'grad_norm': 1.933452943963731, 'learning_rate': 2.9981718464351004e-07, 'epoch': 2.57}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 483/564 [06:54<01:08,  1.18it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 484/564 [06:54<01:07,  1.18it/s]                                                 {'loss': 1.0687, 'grad_norm': 2.0858465657550322, 'learning_rate': 2.9616087751371117e-07, 'epoch': 2.57}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 484/564 [06:54<01:07,  1.18it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 485/564 [06:55<01:06,  1.19it/s]                                                 {'loss': 1.2756, 'grad_norm': 2.3002857810344857, 'learning_rate': 2.9250457038391224e-07, 'epoch': 2.58}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 485/564 [06:55<01:06,  1.19it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 486/564 [06:56<01:05,  1.19it/s]                                                 {'loss': 1.2119, 'grad_norm': 2.4535600065497074, 'learning_rate': 2.888482632541133e-07, 'epoch': 2.59}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 486/564 [06:56<01:05,  1.19it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 487/564 [06:57<01:04,  1.19it/s]                                                 {'loss': 1.0892, 'grad_norm': 2.4224515219682274, 'learning_rate': 2.851919561243144e-07, 'epoch': 2.59}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 487/564 [06:57<01:04,  1.19it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 488/564 [06:58<01:04,  1.19it/s]                                                 {'loss': 1.0461, 'grad_norm': 2.027216434430819, 'learning_rate': 2.815356489945155e-07, 'epoch': 2.6}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 488/564 [06:58<01:04,  1.19it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 489/564 [06:59<01:03,  1.18it/s]                                                 {'loss': 1.1988, 'grad_norm': 2.391726787976082, 'learning_rate': 2.778793418647166e-07, 'epoch': 2.6}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 489/564 [06:59<01:03,  1.18it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 490/564 [07:00<01:02,  1.18it/s]                                                 {'loss': 1.114, 'grad_norm': 2.3855610907865104, 'learning_rate': 2.742230347349177e-07, 'epoch': 2.61}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 490/564 [07:00<01:02,  1.18it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 491/564 [07:00<01:01,  1.18it/s]                                                 {'loss': 1.1299, 'grad_norm': 2.302271929455024, 'learning_rate': 2.7056672760511886e-07, 'epoch': 2.61}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 491/564 [07:00<01:01,  1.18it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 492/564 [07:01<01:00,  1.18it/s]                                                 {'loss': 1.2372, 'grad_norm': 2.4297119770503537, 'learning_rate': 2.6691042047531994e-07, 'epoch': 2.62}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 492/564 [07:01<01:00,  1.18it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 493/564 [07:02<01:00,  1.18it/s]                                                 {'loss': 1.3535, 'grad_norm': 2.329550112759728, 'learning_rate': 2.63254113345521e-07, 'epoch': 2.62}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 493/564 [07:02<01:00,  1.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 494/564 [07:03<00:59,  1.18it/s]                                                 {'loss': 1.341, 'grad_norm': 2.4073326573370006, 'learning_rate': 2.595978062157221e-07, 'epoch': 2.63}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 494/564 [07:03<00:59,  1.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 495/564 [07:04<00:58,  1.18it/s]                                                 {'loss': 1.2181, 'grad_norm': 2.2837596440321084, 'learning_rate': 2.559414990859232e-07, 'epoch': 2.63}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 495/564 [07:04<00:58,  1.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 496/564 [07:05<00:57,  1.18it/s]                                                 {'loss': 1.0716, 'grad_norm': 2.317036578607563, 'learning_rate': 2.522851919561243e-07, 'epoch': 2.64}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 496/564 [07:05<00:57,  1.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 497/564 [07:05<00:56,  1.19it/s]                                                 {'loss': 1.231, 'grad_norm': 2.5708376255461727, 'learning_rate': 2.486288848263254e-07, 'epoch': 2.64}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 497/564 [07:05<00:56,  1.19it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 498/564 [07:06<00:55,  1.18it/s]                                                 {'loss': 1.2797, 'grad_norm': 2.478683774217177, 'learning_rate': 2.449725776965265e-07, 'epoch': 2.65}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 498/564 [07:06<00:55,  1.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 499/564 [07:07<00:54,  1.18it/s]                                                 {'loss': 1.1709, 'grad_norm': 2.0947439934887315, 'learning_rate': 2.413162705667276e-07, 'epoch': 2.65}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 499/564 [07:07<00:54,  1.18it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/564 [07:08<00:54,  1.18it/s]                                                 {'loss': 1.1421, 'grad_norm': 2.0665552122656425, 'learning_rate': 2.3765996343692868e-07, 'epoch': 2.66}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 500/564 [07:08<00:54,  1.18it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 501/564 [08:08<19:27, 18.54s/it]                                                 {'loss': 1.2009, 'grad_norm': 2.6932626711353116, 'learning_rate': 2.3400365630712978e-07, 'epoch': 2.66}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 501/564 [08:08<19:27, 18.54s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 502/564 [08:09<13:40, 13.23s/it]                                                 {'loss': 1.2136, 'grad_norm': 2.624738658621713, 'learning_rate': 2.303473491773309e-07, 'epoch': 2.67}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 502/564 [08:09<13:40, 13.23s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 503/564 [08:09<09:40,  9.51s/it]                                                 {'loss': 1.2574, 'grad_norm': 2.342464304676088, 'learning_rate': 2.26691042047532e-07, 'epoch': 2.68}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 503/564 [08:09<09:40,  9.51s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 504/564 [08:10<06:54,  6.91s/it]                                                 {'loss': 1.2586, 'grad_norm': 2.3440877650512464, 'learning_rate': 2.230347349177331e-07, 'epoch': 2.68}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 504/564 [08:10<06:54,  6.91s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 505/564 [08:11<05:00,  5.09s/it]                                                 {'loss': 1.221, 'grad_norm': 2.417839365250243, 'learning_rate': 2.1937842778793417e-07, 'epoch': 2.69}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 505/564 [08:11<05:00,  5.09s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 506/564 [08:12<03:41,  3.82s/it]                                                 {'loss': 1.2313, 'grad_norm': 2.209692905880885, 'learning_rate': 2.1572212065813527e-07, 'epoch': 2.69}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 506/564 [08:12<03:41,  3.82s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 507/564 [08:13<02:46,  2.92s/it]                                                 {'loss': 1.2714, 'grad_norm': 2.244023868523838, 'learning_rate': 2.1206581352833635e-07, 'epoch': 2.7}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 507/564 [08:13<02:46,  2.92s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 508/564 [08:14<02:08,  2.30s/it]                                                 {'loss': 1.0605, 'grad_norm': 2.451289591775, 'learning_rate': 2.0840950639853748e-07, 'epoch': 2.7}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 508/564 [08:14<02:08,  2.30s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 509/564 [08:15<01:42,  1.86s/it]                                                 {'loss': 1.2842, 'grad_norm': 2.0279773252166344, 'learning_rate': 2.0475319926873858e-07, 'epoch': 2.71}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 509/564 [08:15<01:42,  1.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 510/564 [08:15<01:23,  1.55s/it]                                                 {'loss': 1.3086, 'grad_norm': 2.317415001016981, 'learning_rate': 2.0109689213893966e-07, 'epoch': 2.71}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 510/564 [08:15<01:23,  1.55s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 511/564 [08:16<01:10,  1.34s/it]                                                 {'loss': 1.2562, 'grad_norm': 2.2533418588458782, 'learning_rate': 1.9744058500914076e-07, 'epoch': 2.72}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 511/564 [08:16<01:10,  1.34s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 512/564 [08:17<01:01,  1.19s/it]                                                 {'loss': 1.2939, 'grad_norm': 2.450569810222197, 'learning_rate': 1.9378427787934184e-07, 'epoch': 2.72}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 512/564 [08:17<01:01,  1.19s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 513/564 [08:18<00:55,  1.08s/it]                                                 {'loss': 1.2555, 'grad_norm': 2.199828264193005, 'learning_rate': 1.9012797074954297e-07, 'epoch': 2.73}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 513/564 [08:18<00:55,  1.08s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 514/564 [08:19<00:50,  1.01s/it]                                                 {'loss': 1.1682, 'grad_norm': 2.2043291528069724, 'learning_rate': 1.8647166361974407e-07, 'epoch': 2.73}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 514/564 [08:19<00:50,  1.01s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 515/564 [08:20<00:47,  1.04it/s]                                                 {'loss': 1.1071, 'grad_norm': 2.587884792273994, 'learning_rate': 1.8281535648994515e-07, 'epoch': 2.74}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 515/564 [08:20<00:47,  1.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 516/564 [08:20<00:44,  1.08it/s]                                                 {'loss': 1.0768, 'grad_norm': 2.0972768501023142, 'learning_rate': 1.7915904936014625e-07, 'epoch': 2.74}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 516/564 [08:20<00:44,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 517/564 [08:21<00:42,  1.11it/s]                                                 {'loss': 1.145, 'grad_norm': 2.2013710435811826, 'learning_rate': 1.7550274223034732e-07, 'epoch': 2.75}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 517/564 [08:21<00:42,  1.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 518/564 [08:22<00:40,  1.14it/s]                                                 {'loss': 1.3232, 'grad_norm': 2.1271347867933503, 'learning_rate': 1.7184643510054845e-07, 'epoch': 2.76}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 518/564 [08:22<00:40,  1.14it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 519/564 [08:23<00:39,  1.15it/s]                                                 {'loss': 1.0726, 'grad_norm': 2.2156618868603632, 'learning_rate': 1.6819012797074953e-07, 'epoch': 2.76}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 519/564 [08:23<00:39,  1.15it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 520/564 [08:24<00:37,  1.16it/s]                                                 {'loss': 1.2737, 'grad_norm': 2.1303992002900967, 'learning_rate': 1.6453382084095063e-07, 'epoch': 2.77}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 520/564 [08:24<00:37,  1.16it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 521/564 [08:25<00:36,  1.17it/s]                                                 {'loss': 1.2898, 'grad_norm': 2.371202817587543, 'learning_rate': 1.6087751371115174e-07, 'epoch': 2.77}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 521/564 [08:25<00:36,  1.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 522/564 [08:25<00:35,  1.18it/s]                                                 {'loss': 1.2299, 'grad_norm': 2.4915454713054204, 'learning_rate': 1.572212065813528e-07, 'epoch': 2.78}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 522/564 [08:25<00:35,  1.18it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 523/564 [08:26<00:34,  1.18it/s]                                                 {'loss': 0.8956, 'grad_norm': 2.4445536547175264, 'learning_rate': 1.5356489945155394e-07, 'epoch': 2.78}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 523/564 [08:26<00:34,  1.18it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 524/564 [08:27<00:33,  1.19it/s]                                                 {'loss': 1.2129, 'grad_norm': 2.3500954244878027, 'learning_rate': 1.4990859232175502e-07, 'epoch': 2.79}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 524/564 [08:27<00:33,  1.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 525/564 [08:28<00:32,  1.19it/s]                                                 {'loss': 1.1805, 'grad_norm': 2.1543097240650537, 'learning_rate': 1.4625228519195612e-07, 'epoch': 2.79}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 525/564 [08:28<00:32,  1.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 526/564 [08:29<00:31,  1.19it/s]                                                 {'loss': 0.9082, 'grad_norm': 2.2723148114089513, 'learning_rate': 1.425959780621572e-07, 'epoch': 2.8}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 526/564 [08:29<00:31,  1.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 527/564 [08:30<00:31,  1.19it/s]                                                 {'loss': 0.9646, 'grad_norm': 2.2615116373259383, 'learning_rate': 1.389396709323583e-07, 'epoch': 2.8}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 527/564 [08:30<00:31,  1.19it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 528/564 [08:30<00:30,  1.19it/s]                                                 {'loss': 1.275, 'grad_norm': 2.4410961820118358, 'learning_rate': 1.3528336380255943e-07, 'epoch': 2.81}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 528/564 [08:30<00:30,  1.19it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 529/564 [08:31<00:29,  1.19it/s]                                                 {'loss': 1.1531, 'grad_norm': 2.279078595877619, 'learning_rate': 1.316270566727605e-07, 'epoch': 2.81}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 529/564 [08:31<00:29,  1.19it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 530/564 [08:32<00:28,  1.18it/s]                                                 {'loss': 1.2412, 'grad_norm': 1.9533758021837124, 'learning_rate': 1.279707495429616e-07, 'epoch': 2.82}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 530/564 [08:32<00:28,  1.18it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 531/564 [08:33<00:27,  1.18it/s]                                                 {'loss': 1.0959, 'grad_norm': 2.499941583269164, 'learning_rate': 1.243144424131627e-07, 'epoch': 2.82}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 531/564 [08:33<00:27,  1.18it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 532/564 [08:34<00:26,  1.19it/s]                                                 {'loss': 1.4012, 'grad_norm': 2.4020210877829076, 'learning_rate': 1.206581352833638e-07, 'epoch': 2.83}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 532/564 [08:34<00:26,  1.19it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 533/564 [08:35<00:26,  1.19it/s]                                                 {'loss': 1.0314, 'grad_norm': 2.199131127929318, 'learning_rate': 1.1700182815356489e-07, 'epoch': 2.84}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 533/564 [08:35<00:26,  1.19it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 534/564 [08:36<00:25,  1.19it/s]                                                 {'loss': 1.1519, 'grad_norm': 2.461932920910629, 'learning_rate': 1.13345521023766e-07, 'epoch': 2.84}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 534/564 [08:36<00:25,  1.19it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 535/564 [08:36<00:24,  1.18it/s]                                                 {'loss': 1.38, 'grad_norm': 2.1645583242025803, 'learning_rate': 1.0968921389396708e-07, 'epoch': 2.85}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 535/564 [08:36<00:24,  1.18it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 536/564 [08:37<00:23,  1.18it/s]                                                 {'loss': 1.0778, 'grad_norm': 2.270237098025581, 'learning_rate': 1.0603290676416817e-07, 'epoch': 2.85}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 536/564 [08:37<00:23,  1.18it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 537/564 [08:38<00:22,  1.19it/s]                                                 {'loss': 1.2573, 'grad_norm': 2.335762276134909, 'learning_rate': 1.0237659963436929e-07, 'epoch': 2.86}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 537/564 [08:38<00:22,  1.19it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 538/564 [08:39<00:21,  1.19it/s]                                                 {'loss': 1.0902, 'grad_norm': 2.508721190500052, 'learning_rate': 9.872029250457038e-08, 'epoch': 2.86}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 538/564 [08:39<00:21,  1.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 539/564 [08:40<00:21,  1.19it/s]                                                 {'loss': 1.0895, 'grad_norm': 2.314909050622073, 'learning_rate': 9.506398537477148e-08, 'epoch': 2.87}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 539/564 [08:40<00:21,  1.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 540/564 [08:41<00:20,  1.19it/s]                                                 {'loss': 1.1814, 'grad_norm': 2.2129460716436715, 'learning_rate': 9.140767824497257e-08, 'epoch': 2.87}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 540/564 [08:41<00:20,  1.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 541/564 [08:41<00:19,  1.19it/s]                                                 {'loss': 1.1871, 'grad_norm': 2.30605063033393, 'learning_rate': 8.775137111517366e-08, 'epoch': 2.88}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 541/564 [08:41<00:19,  1.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 542/564 [08:42<00:18,  1.18it/s]                                                 {'loss': 1.349, 'grad_norm': 2.163684735608102, 'learning_rate': 8.409506398537477e-08, 'epoch': 2.88}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 542/564 [08:42<00:18,  1.18it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 543/564 [08:43<00:17,  1.19it/s]                                                 {'loss': 1.1445, 'grad_norm': 2.012393399835218, 'learning_rate': 8.043875685557587e-08, 'epoch': 2.89}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 543/564 [08:43<00:17,  1.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 544/564 [08:44<00:16,  1.19it/s]                                                 {'loss': 1.1889, 'grad_norm': 1.9459425127355328, 'learning_rate': 7.678244972577697e-08, 'epoch': 2.89}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 544/564 [08:44<00:16,  1.19it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 545/564 [08:45<00:16,  1.19it/s]                                                 {'loss': 1.2412, 'grad_norm': 1.9640616319525808, 'learning_rate': 7.312614259597806e-08, 'epoch': 2.9}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 545/564 [08:45<00:16,  1.19it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 546/564 [08:46<00:15,  1.18it/s]                                                 {'loss': 1.1545, 'grad_norm': 2.3290196000426198, 'learning_rate': 6.946983546617915e-08, 'epoch': 2.9}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 546/564 [08:46<00:15,  1.18it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 547/564 [08:46<00:14,  1.18it/s]                                                 {'loss': 1.3697, 'grad_norm': 2.3848036972238185, 'learning_rate': 6.581352833638025e-08, 'epoch': 2.91}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 547/564 [08:46<00:14,  1.18it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 548/564 [08:47<00:13,  1.18it/s]                                                 {'loss': 1.2061, 'grad_norm': 2.6416303033586948, 'learning_rate': 6.215722120658136e-08, 'epoch': 2.91}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 548/564 [08:47<00:13,  1.18it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 549/564 [08:48<00:12,  1.19it/s]                                                 {'loss': 1.2486, 'grad_norm': 2.022742456752266, 'learning_rate': 5.8500914076782446e-08, 'epoch': 2.92}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 549/564 [08:48<00:12,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 550/564 [08:49<00:11,  1.19it/s]                                                 {'loss': 1.4242, 'grad_norm': 2.2200588838924706, 'learning_rate': 5.484460694698354e-08, 'epoch': 2.93}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 550/564 [08:49<00:11,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 551/564 [08:50<00:10,  1.19it/s]                                                 {'loss': 1.0987, 'grad_norm': 2.3415209814788702, 'learning_rate': 5.1188299817184645e-08, 'epoch': 2.93}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 551/564 [08:50<00:10,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 552/564 [08:51<00:10,  1.19it/s]                                                 {'loss': 1.1348, 'grad_norm': 2.345803656494481, 'learning_rate': 4.753199268738574e-08, 'epoch': 2.94}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 552/564 [08:51<00:10,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 553/564 [08:52<00:09,  1.19it/s]                                                 {'loss': 1.4073, 'grad_norm': 2.411856954421837, 'learning_rate': 4.387568555758683e-08, 'epoch': 2.94}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 553/564 [08:52<00:09,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 554/564 [08:52<00:08,  1.19it/s]                                                 {'loss': 1.2403, 'grad_norm': 2.155250047279341, 'learning_rate': 4.0219378427787934e-08, 'epoch': 2.95}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 554/564 [08:52<00:08,  1.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 555/564 [08:53<00:07,  1.19it/s]                                                 {'loss': 1.2934, 'grad_norm': 2.331616041182708, 'learning_rate': 3.656307129798903e-08, 'epoch': 2.95}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 555/564 [08:53<00:07,  1.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 556/564 [08:54<00:06,  1.19it/s]                                                 {'loss': 1.0297, 'grad_norm': 2.5216716616873143, 'learning_rate': 3.290676416819013e-08, 'epoch': 2.96}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 556/564 [08:54<00:06,  1.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 557/564 [08:55<00:05,  1.18it/s]                                                 {'loss': 1.1239, 'grad_norm': 2.2647036013743613, 'learning_rate': 2.9250457038391223e-08, 'epoch': 2.96}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 557/564 [08:55<00:05,  1.18it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 558/564 [08:56<00:05,  1.18it/s]                                                 {'loss': 1.2007, 'grad_norm': 2.1910363269929127, 'learning_rate': 2.5594149908592323e-08, 'epoch': 2.97}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 558/564 [08:56<00:05,  1.18it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 559/564 [08:57<00:04,  1.18it/s]                                                 {'loss': 1.0471, 'grad_norm': 2.4404317162896807, 'learning_rate': 2.1937842778793416e-08, 'epoch': 2.97}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 559/564 [08:57<00:04,  1.18it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 560/564 [08:57<00:03,  1.19it/s]                                                 {'loss': 1.0617, 'grad_norm': 8.467689198949923, 'learning_rate': 1.8281535648994515e-08, 'epoch': 2.98}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 560/564 [08:57<00:03,  1.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 561/564 [08:58<00:02,  1.19it/s]                                                 {'loss': 1.1185, 'grad_norm': 2.3364381935463796, 'learning_rate': 1.4625228519195612e-08, 'epoch': 2.98}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 561/564 [08:58<00:02,  1.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 562/564 [08:59<00:01,  1.18it/s]                                                 {'loss': 1.0489, 'grad_norm': 2.250373208360822, 'learning_rate': 1.0968921389396708e-08, 'epoch': 2.99}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 562/564 [08:59<00:01,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 563/564 [09:00<00:00,  1.18it/s]                                                 {'loss': 1.2878, 'grad_norm': 2.6761793649576986, 'learning_rate': 7.312614259597806e-09, 'epoch': 2.99}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 563/564 [09:00<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 564/564 [09:01<00:00,  1.18it/s]                                                 {'loss': 1.2566, 'grad_norm': 2.206725844380028, 'learning_rate': 3.656307129798903e-09, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 564/564 [09:01<00:00,  1.18it/s]                                                 {'train_runtime': 600.7861, 'train_samples_per_second': 74.957, 'train_steps_per_second': 0.939, 'train_loss': 1.2996947548702253, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 564/564 [10:00<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 564/564 [10:00<00:00,  1.07s/it]
[2024-08-26 18:22:58,051] [INFO] [launch.py:351:main] Process 1034825 exits successfully.
[2024-08-26 18:22:59,051] [INFO] [launch.py:351:main] Process 1034824 exits successfully.
[2024-08-26 18:22:59,052] [INFO] [launch.py:351:main] Process 1034823 exits successfully.
[2024-08-26 18:22:59,052] [INFO] [launch.py:351:main] Process 1034828 exits successfully.
[2024-08-26 18:22:59,052] [INFO] [launch.py:351:main] Process 1034829 exits successfully.
[2024-08-26 18:23:00,053] [INFO] [launch.py:351:main] Process 1034827 exits successfully.
[2024-08-26 18:23:00,053] [INFO] [launch.py:351:main] Process 1034826 exits successfully.
[2024-08-26 18:23:24,056] [INFO] [launch.py:351:main] Process 1034822 exits successfully.

Namespace(mode=['alpaca'], base_model='meta-llama/Llama-2-7b-hf', template_name='barebone', total_bsz=64, epoch=3, lr=2e-05, data_path='', task_name='sharegpt', tuned_dir='./cache', use_peft=True, lora_r=16, lora_alpha=32)
num gpus:  8
Running 1/1: deepspeed --num_gpus=8 train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True
        --model_name_or_path meta-llama/Llama-2-7b-hf --data_path ../data/stanford_alpaca/sharegpt_data.json
        --output_dir /fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/
        --num_train_epochs 3
        --per_device_train_batch_size 10
        --per_device_eval_batch_size 4
        --gradient_accumulation_steps 1
        --gradient_checkpointing=True
        --evaluation_strategy=no
        --save_strategy=steps
        --save_steps 500
        --save_total_limit 1
        --learning_rate 2e-6
        --weight_decay 0.
        --report_to tensorboard
        --warmup_ratio 0.03
        --lr_scheduler_type=cosine
        --logging_steps 1
        --use_peft True 
        --lora_r 16 --lora_alpha 32
['deepspeed', '--num_gpus=8', 'train.py', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:42,769] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-09 06:20:50,647] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-08-09 06:20:50,649] [INFO] [runner.py:568:main] cmd = /data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True --model_name_or_path meta-llama/Llama-2-7b-hf --data_path ../data/stanford_alpaca/sharegpt_data.json --output_dir /fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/ --num_train_epochs 3 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --gradient_checkpointing=True --evaluation_strategy=no --save_strategy=steps --save_steps 500 --save_total_limit 1 --learning_rate 2e-6 --weight_decay 0. --report_to tensorboard --warmup_ratio 0.03 --lr_scheduler_type=cosine --logging_steps 1 --use_peft True --lora_r 16 --lora_alpha 32
[2024-08-09 06:20:53,265] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-09 06:20:56,674] [INFO] [launch.py:139:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2024-08-09 06:20:56,675] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-08-09 06:20:56,675] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-09 06:20:56,675] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-09 06:20:56,675] [INFO] [launch.py:164:main] dist_world_size=8
[2024-08-09 06:20:56,675] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-08-09 06:20:56,676] [INFO] [launch.py:256:main] process 3338280 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=0', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,676] [INFO] [launch.py:256:main] process 3338281 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=1', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,677] [INFO] [launch.py:256:main] process 3338282 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=2', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,677] [INFO] [launch.py:256:main] process 3338283 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=3', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,678] [INFO] [launch.py:256:main] process 3338284 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=4', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,678] [INFO] [launch.py:256:main] process 3338285 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=5', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,679] [INFO] [launch.py:256:main] process 3338286 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=6', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-09 06:20:56,679] [INFO] [launch.py:256:main] process 3338287 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=7', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_Llama2-7b_sharegpt_Lora_tuned/', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'True', '--lora_r', '16', '--lora_alpha', '32']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-08-09 06:21:12,089] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-08-09 06:21:12,190] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 06:21:12,233] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 06:21:12,294] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 06:21:12,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 06:21:12,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 06:21:12,314] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-08-09 06:21:12,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-09 06:21:12,840] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:12,908] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,005] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,021] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,022] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,030] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,057] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-09 06:21:13,057] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-08-09 06:21:13,058] [INFO] [comm.py:637:init_distributed] cdb=None
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s][W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 460.36it/s]
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1285.02it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1355.41it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1319.38it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1177.18it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1358.70it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1327.10it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1434.93it/s]
[2024-08-09 06:21:24,302] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.52s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.52s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.54s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.19s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.19s/it]




Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 24.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:50<00:00, 25.23s/it]
enable_input_require_grads!
enable_input_require_grads!enable_input_require_grads!

enable_input_require_grads!enable_input_require_grads!

enable_input_require_grads!
enable_input_require_grads!
Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 35.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 39.15s/it]
enable_input_require_grads!
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243
None
None
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
[rank6]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank1]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[rank4]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...

Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[rank3]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank2]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank0]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank7]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank5]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 2.9618396759033203 seconds
Time to load fused_adam op: 1.129594087600708 seconds
Time to load fused_adam op: 2.96217679977417 secondsTime to load fused_adam op: 1.8815534114837646 seconds
Time to load fused_adam op: 2.9621829986572266 secondsTime to load fused_adam op: 1.9320340156555176 secondsTime to load fused_adam op: 2.6500766277313232 secondsTime to load fused_adam op: 1.9441709518432617 seconds




Parameter Offload: Total persistent parameters: 8654848 in 193 params
  0%|          | 0/630 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/630 [00:08<1:27:06,  8.31s/it]                                                 {'loss': 0.9013, 'grad_norm': 0.51686470223071, 'learning_rate': 0.0, 'epoch': 0.0}
  0%|          | 1/630 [00:08<1:27:06,  8.31s/it]  0%|          | 2/630 [00:10<47:32,  4.54s/it]                                                 {'loss': 0.901, 'grad_norm': 0.4290116134957464, 'learning_rate': 4.7081782673327645e-07, 'epoch': 0.01}
  0%|          | 2/630 [00:10<47:32,  4.54s/it]  0%|          | 3/630 [00:11<29:41,  2.84s/it]                                               {'loss': 0.9247, 'grad_norm': 0.4519475242529352, 'learning_rate': 7.462286000432739e-07, 'epoch': 0.01}
  0%|          | 3/630 [00:11<29:41,  2.84s/it]  1%|          | 4/630 [00:11<21:18,  2.04s/it]                                               {'loss': 0.833, 'grad_norm': 0.4706779755698892, 'learning_rate': 9.416356534665529e-07, 'epoch': 0.02}
  1%|          | 4/630 [00:11<21:18,  2.04s/it]  1%|          | 5/630 [00:12<16:38,  1.60s/it]                                               {'loss': 0.8984, 'grad_norm': 0.48601818407396885, 'learning_rate': 1.0932051394658049e-06, 'epoch': 0.02}
  1%|          | 5/630 [00:12<16:38,  1.60s/it]  1%|          | 6/630 [00:13<13:51,  1.33s/it]                                               {'loss': 0.8792, 'grad_norm': 0.5107978448777625, 'learning_rate': 1.2170464267765503e-06, 'epoch': 0.03}
  1%|          | 6/630 [00:13<13:51,  1.33s/it]  1%|          | 7/630 [00:14<12:04,  1.16s/it]                                               {'loss': 0.8935, 'grad_norm': 0.5209327129792353, 'learning_rate': 1.3217527432721277e-06, 'epoch': 0.03}
  1%|          | 7/630 [00:14<12:04,  1.16s/it]  1%|▏         | 8/630 [00:15<10:54,  1.05s/it]                                               {'loss': 0.971, 'grad_norm': 0.5017322858215544, 'learning_rate': 1.4124534801998293e-06, 'epoch': 0.04}
  1%|▏         | 8/630 [00:15<10:54,  1.05s/it]  1%|▏         | 9/630 [00:15<10:07,  1.02it/s]                                               {'loss': 0.9476, 'grad_norm': 0.5141798706171398, 'learning_rate': 1.4924572000865478e-06, 'epoch': 0.04}
  1%|▏         | 9/630 [00:15<10:07,  1.02it/s]  2%|▏         | 10/630 [00:16<09:35,  1.08it/s]                                                {'loss': 0.8457, 'grad_norm': 0.4128963853590679, 'learning_rate': 1.5640229661990816e-06, 'epoch': 0.05}
  2%|▏         | 10/630 [00:16<09:35,  1.08it/s]  2%|▏         | 11/630 [00:17<09:12,  1.12it/s]                                                {'loss': 0.965, 'grad_norm': 0.4941245634243322, 'learning_rate': 1.6287620764191933e-06, 'epoch': 0.05}
  2%|▏         | 11/630 [00:17<09:12,  1.12it/s]  2%|▏         | 12/630 [00:18<08:57,  1.15it/s]                                                {'loss': 0.8726, 'grad_norm': 0.5171966923001569, 'learning_rate': 1.6878642535098268e-06, 'epoch': 0.06}
  2%|▏         | 12/630 [00:18<08:57,  1.15it/s]  2%|▏         | 13/630 [00:19<08:47,  1.17it/s]                                                {'loss': 1.0219, 'grad_norm': 0.5868576114325094, 'learning_rate': 1.7422329860526872e-06, 'epoch': 0.06}
  2%|▏         | 13/630 [00:19<08:47,  1.17it/s]  2%|▏         | 14/630 [00:20<08:40,  1.18it/s]                                                {'loss': 0.9305, 'grad_norm': 0.4689296990959165, 'learning_rate': 1.792570570005404e-06, 'epoch': 0.07}
  2%|▏         | 14/630 [00:20<08:40,  1.18it/s]  2%|▏         | 15/630 [00:20<08:35,  1.19it/s]                                                {'loss': 0.8337, 'grad_norm': 0.4534559372415074, 'learning_rate': 1.8394337395090787e-06, 'epoch': 0.07}
  2%|▏         | 15/630 [00:20<08:35,  1.19it/s]  3%|▎         | 16/630 [00:21<08:29,  1.21it/s]                                                {'loss': 0.911, 'grad_norm': 0.7052272969269847, 'learning_rate': 1.8832713069331058e-06, 'epoch': 0.08}
  3%|▎         | 16/630 [00:21<08:29,  1.21it/s]  3%|▎         | 17/630 [00:22<08:25,  1.21it/s]                                                {'loss': 1.0093, 'grad_norm': 0.9879549387698912, 'learning_rate': 1.924450371770508e-06, 'epoch': 0.08}
  3%|▎         | 17/630 [00:22<08:25,  1.21it/s]  3%|▎         | 18/630 [00:23<08:22,  1.22it/s]                                                {'loss': 0.9134, 'grad_norm': 0.4810660621149585, 'learning_rate': 1.9632750268198243e-06, 'epoch': 0.09}
  3%|▎         | 18/630 [00:23<08:22,  1.22it/s]  3%|▎         | 19/630 [00:24<08:20,  1.22it/s]                                                {'loss': 0.8725, 'grad_norm': 0.3842751600759531, 'learning_rate': 2e-06, 'epoch': 0.09}
  3%|▎         | 19/630 [00:24<08:20,  1.22it/s]  3%|▎         | 20/630 [00:24<08:19,  1.22it/s]                                                {'loss': 0.9414, 'grad_norm': 0.48423823224636714, 'learning_rate': 2e-06, 'epoch': 0.1}
  3%|▎         | 20/630 [00:24<08:19,  1.22it/s]  3%|▎         | 21/630 [00:25<08:17,  1.22it/s]                                                {'loss': 0.9367, 'grad_norm': 0.5473773133618265, 'learning_rate': 1.9967266775777412e-06, 'epoch': 0.1}
  3%|▎         | 21/630 [00:25<08:17,  1.22it/s]  3%|▎         | 22/630 [00:26<08:16,  1.22it/s]                                                {'loss': 0.918, 'grad_norm': 0.5249604389431535, 'learning_rate': 1.9934533551554826e-06, 'epoch': 0.1}
  3%|▎         | 22/630 [00:26<08:16,  1.22it/s]  4%|▎         | 23/630 [00:27<08:15,  1.23it/s]                                                {'loss': 1.0096, 'grad_norm': 0.571631897001562, 'learning_rate': 1.990180032733224e-06, 'epoch': 0.11}
  4%|▎         | 23/630 [00:27<08:15,  1.23it/s]  4%|▍         | 24/630 [00:28<08:14,  1.22it/s]                                                {'loss': 1.0187, 'grad_norm': 0.517259255749528, 'learning_rate': 1.9869067103109657e-06, 'epoch': 0.11}
  4%|▍         | 24/630 [00:28<08:14,  1.22it/s]  4%|▍         | 25/630 [00:28<08:13,  1.23it/s]                                                {'loss': 0.9268, 'grad_norm': 0.47429399564665464, 'learning_rate': 1.983633387888707e-06, 'epoch': 0.12}
  4%|▍         | 25/630 [00:28<08:13,  1.23it/s]  4%|▍         | 26/630 [00:29<08:15,  1.22it/s]                                                {'loss': 0.9447, 'grad_norm': 0.5318010108708293, 'learning_rate': 1.9803600654664483e-06, 'epoch': 0.12}
  4%|▍         | 26/630 [00:29<08:15,  1.22it/s]  4%|▍         | 27/630 [00:30<08:14,  1.22it/s]                                                {'loss': 0.9131, 'grad_norm': 0.5673330499150174, 'learning_rate': 1.9770867430441897e-06, 'epoch': 0.13}
  4%|▍         | 27/630 [00:30<08:14,  1.22it/s]  4%|▍         | 28/630 [00:31<08:14,  1.22it/s]                                                {'loss': 0.976, 'grad_norm': 0.5715095571772135, 'learning_rate': 1.9738134206219314e-06, 'epoch': 0.13}
  4%|▍         | 28/630 [00:31<08:14,  1.22it/s]  5%|▍         | 29/630 [00:32<08:11,  1.22it/s]                                                {'loss': 0.9574, 'grad_norm': 0.5700565901382214, 'learning_rate': 1.9705400981996723e-06, 'epoch': 0.14}
  5%|▍         | 29/630 [00:32<08:11,  1.22it/s]  5%|▍         | 30/630 [00:33<08:10,  1.22it/s]                                                {'loss': 1.0657, 'grad_norm': 0.5507636822790545, 'learning_rate': 1.967266775777414e-06, 'epoch': 0.14}
  5%|▍         | 30/630 [00:33<08:10,  1.22it/s]  5%|▍         | 31/630 [00:33<08:09,  1.22it/s]                                                {'loss': 0.8879, 'grad_norm': 0.40281052444824006, 'learning_rate': 1.9639934533551554e-06, 'epoch': 0.15}
  5%|▍         | 31/630 [00:33<08:09,  1.22it/s]  5%|▌         | 32/630 [00:34<08:07,  1.23it/s]                                                {'loss': 0.8576, 'grad_norm': 0.483872517282205, 'learning_rate': 1.9607201309328968e-06, 'epoch': 0.15}
  5%|▌         | 32/630 [00:34<08:07,  1.23it/s]  5%|▌         | 33/630 [00:35<08:06,  1.23it/s]                                                {'loss': 0.8879, 'grad_norm': 0.4755038499848139, 'learning_rate': 1.957446808510638e-06, 'epoch': 0.16}
  5%|▌         | 33/630 [00:35<08:06,  1.23it/s]  5%|▌         | 34/630 [00:36<08:06,  1.23it/s]                                                {'loss': 0.8437, 'grad_norm': 0.5552264277877869, 'learning_rate': 1.9541734860883794e-06, 'epoch': 0.16}
  5%|▌         | 34/630 [00:36<08:06,  1.23it/s]  6%|▌         | 35/630 [00:37<08:05,  1.23it/s]                                                {'loss': 0.865, 'grad_norm': 0.4313918576693866, 'learning_rate': 1.950900163666121e-06, 'epoch': 0.17}
  6%|▌         | 35/630 [00:37<08:05,  1.23it/s]  6%|▌         | 36/630 [00:37<08:03,  1.23it/s]                                                {'loss': 0.9304, 'grad_norm': 0.4615136143100545, 'learning_rate': 1.9476268412438625e-06, 'epoch': 0.17}
  6%|▌         | 36/630 [00:37<08:03,  1.23it/s]  6%|▌         | 37/630 [00:38<08:02,  1.23it/s]                                                {'loss': 0.9018, 'grad_norm': 0.5523999163599963, 'learning_rate': 1.944353518821604e-06, 'epoch': 0.18}
  6%|▌         | 37/630 [00:38<08:02,  1.23it/s]  6%|▌         | 38/630 [00:39<08:03,  1.22it/s]                                                {'loss': 0.9054, 'grad_norm': 0.4202807230654899, 'learning_rate': 1.941080196399345e-06, 'epoch': 0.18}
  6%|▌         | 38/630 [00:39<08:03,  1.22it/s]  6%|▌         | 39/630 [00:40<08:01,  1.23it/s]                                                {'loss': 0.8638, 'grad_norm': 0.3384822102546696, 'learning_rate': 1.9378068739770865e-06, 'epoch': 0.19}
  6%|▌         | 39/630 [00:40<08:01,  1.23it/s]  6%|▋         | 40/630 [00:41<08:02,  1.22it/s]                                                {'loss': 0.9051, 'grad_norm': 0.5193343703145802, 'learning_rate': 1.934533551554828e-06, 'epoch': 0.19}
  6%|▋         | 40/630 [00:41<08:02,  1.22it/s]  7%|▋         | 41/630 [00:42<08:00,  1.23it/s]                                                {'loss': 0.9523, 'grad_norm': 0.726819383607708, 'learning_rate': 1.9312602291325696e-06, 'epoch': 0.2}
  7%|▋         | 41/630 [00:42<08:00,  1.23it/s]  7%|▋         | 42/630 [00:42<07:58,  1.23it/s]                                                {'loss': 0.7907, 'grad_norm': 0.31559252019927425, 'learning_rate': 1.927986906710311e-06, 'epoch': 0.2}
  7%|▋         | 42/630 [00:42<07:58,  1.23it/s]  7%|▋         | 43/630 [00:43<07:57,  1.23it/s]                                                {'loss': 0.9648, 'grad_norm': 0.4839922423022054, 'learning_rate': 1.9247135842880523e-06, 'epoch': 0.2}
  7%|▋         | 43/630 [00:43<07:57,  1.23it/s]  7%|▋         | 44/630 [00:44<07:55,  1.23it/s]                                                {'loss': 1.0004, 'grad_norm': 0.5651633107878878, 'learning_rate': 1.9214402618657936e-06, 'epoch': 0.21}
  7%|▋         | 44/630 [00:44<07:55,  1.23it/s]  7%|▋         | 45/630 [00:45<07:56,  1.23it/s]                                                {'loss': 1.0015, 'grad_norm': 0.519210335921551, 'learning_rate': 1.918166939443535e-06, 'epoch': 0.21}
  7%|▋         | 45/630 [00:45<07:56,  1.23it/s]  7%|▋         | 46/630 [00:46<07:56,  1.22it/s]                                                {'loss': 0.912, 'grad_norm': 0.4202779747405369, 'learning_rate': 1.9148936170212767e-06, 'epoch': 0.22}
  7%|▋         | 46/630 [00:46<07:56,  1.22it/s]  7%|▋         | 47/630 [00:46<07:54,  1.23it/s]                                                {'loss': 0.9097, 'grad_norm': 0.4701126259654584, 'learning_rate': 1.911620294599018e-06, 'epoch': 0.22}
  7%|▋         | 47/630 [00:46<07:54,  1.23it/s]  8%|▊         | 48/630 [00:47<07:53,  1.23it/s]                                                {'loss': 0.9441, 'grad_norm': 0.561910203194677, 'learning_rate': 1.9083469721767594e-06, 'epoch': 0.23}
  8%|▊         | 48/630 [00:47<07:53,  1.23it/s]  8%|▊         | 49/630 [00:48<07:54,  1.23it/s]                                                {'loss': 0.9107, 'grad_norm': 0.4198443816176593, 'learning_rate': 1.9050736497545007e-06, 'epoch': 0.23}
  8%|▊         | 49/630 [00:48<07:54,  1.23it/s]  8%|▊         | 50/630 [00:49<07:53,  1.23it/s]                                                {'loss': 0.8924, 'grad_norm': 0.4977935147546802, 'learning_rate': 1.901800327332242e-06, 'epoch': 0.24}
  8%|▊         | 50/630 [00:49<07:53,  1.23it/s]  8%|▊         | 51/630 [00:50<07:54,  1.22it/s]                                                {'loss': 0.8008, 'grad_norm': 0.39326513156383874, 'learning_rate': 1.8985270049099836e-06, 'epoch': 0.24}
  8%|▊         | 51/630 [00:50<07:54,  1.22it/s]  8%|▊         | 52/630 [00:51<07:53,  1.22it/s]                                                {'loss': 0.8587, 'grad_norm': 0.36184452411988405, 'learning_rate': 1.895253682487725e-06, 'epoch': 0.25}
  8%|▊         | 52/630 [00:51<07:53,  1.22it/s]  8%|▊         | 53/630 [00:51<07:52,  1.22it/s]                                                {'loss': 0.8391, 'grad_norm': 0.5579923721759783, 'learning_rate': 1.8919803600654665e-06, 'epoch': 0.25}
  8%|▊         | 53/630 [00:51<07:52,  1.22it/s]  9%|▊         | 54/630 [00:52<07:51,  1.22it/s]                                                {'loss': 0.9629, 'grad_norm': 0.4805632137484178, 'learning_rate': 1.8887070376432076e-06, 'epoch': 0.26}
  9%|▊         | 54/630 [00:52<07:51,  1.22it/s]  9%|▊         | 55/630 [00:53<07:49,  1.22it/s]                                                {'loss': 0.9186, 'grad_norm': 0.42889934679103686, 'learning_rate': 1.8854337152209492e-06, 'epoch': 0.26}
  9%|▊         | 55/630 [00:53<07:49,  1.22it/s]  9%|▉         | 56/630 [00:54<07:48,  1.23it/s]                                                {'loss': 0.8864, 'grad_norm': 0.38780654959478533, 'learning_rate': 1.8821603927986907e-06, 'epoch': 0.27}
  9%|▉         | 56/630 [00:54<07:48,  1.23it/s]  9%|▉         | 57/630 [00:55<07:47,  1.23it/s]                                                {'loss': 0.8366, 'grad_norm': 0.5400418910940109, 'learning_rate': 1.8788870703764318e-06, 'epoch': 0.27}
  9%|▉         | 57/630 [00:55<07:47,  1.23it/s]  9%|▉         | 58/630 [00:55<07:46,  1.23it/s]                                                {'loss': 0.8952, 'grad_norm': 0.3950659742996525, 'learning_rate': 1.8756137479541734e-06, 'epoch': 0.28}
  9%|▉         | 58/630 [00:55<07:46,  1.23it/s]  9%|▉         | 59/630 [00:56<07:46,  1.22it/s]                                                {'loss': 0.9378, 'grad_norm': 0.528795101514801, 'learning_rate': 1.872340425531915e-06, 'epoch': 0.28}
  9%|▉         | 59/630 [00:56<07:46,  1.22it/s] 10%|▉         | 60/630 [00:57<07:45,  1.23it/s]                                                {'loss': 1.0046, 'grad_norm': 0.4902200469919221, 'learning_rate': 1.8690671031096563e-06, 'epoch': 0.29}
 10%|▉         | 60/630 [00:57<07:45,  1.23it/s] 10%|▉         | 61/630 [00:58<07:45,  1.22it/s]                                                {'loss': 0.8999, 'grad_norm': 0.4272608001620815, 'learning_rate': 1.8657937806873976e-06, 'epoch': 0.29}
 10%|▉         | 61/630 [00:58<07:45,  1.22it/s] 10%|▉         | 62/630 [00:59<07:43,  1.23it/s]                                                {'loss': 0.7893, 'grad_norm': 0.4157915050987238, 'learning_rate': 1.862520458265139e-06, 'epoch': 0.3}
 10%|▉         | 62/630 [00:59<07:43,  1.23it/s] 10%|█         | 63/630 [00:59<07:42,  1.23it/s]                                                {'loss': 0.9413, 'grad_norm': 0.45084237054030984, 'learning_rate': 1.8592471358428805e-06, 'epoch': 0.3}
 10%|█         | 63/630 [00:59<07:42,  1.23it/s] 10%|█         | 64/630 [01:00<07:43,  1.22it/s]                                                {'loss': 0.9228, 'grad_norm': 0.4529869204214937, 'learning_rate': 1.8559738134206218e-06, 'epoch': 0.3}
 10%|█         | 64/630 [01:00<07:43,  1.22it/s] 10%|█         | 65/630 [01:01<07:41,  1.22it/s]                                                {'loss': 0.902, 'grad_norm': 0.609399715992651, 'learning_rate': 1.8527004909983632e-06, 'epoch': 0.31}
 10%|█         | 65/630 [01:01<07:41,  1.22it/s] 10%|█         | 66/630 [01:02<07:41,  1.22it/s]                                                {'loss': 0.9577, 'grad_norm': 0.4573098943599405, 'learning_rate': 1.8494271685761047e-06, 'epoch': 0.31}
 10%|█         | 66/630 [01:02<07:41,  1.22it/s] 11%|█         | 67/630 [01:03<07:40,  1.22it/s]                                                {'loss': 0.9827, 'grad_norm': 0.5100531966353714, 'learning_rate': 1.8461538461538462e-06, 'epoch': 0.32}
 11%|█         | 67/630 [01:03<07:40,  1.22it/s] 11%|█         | 68/630 [01:04<07:40,  1.22it/s]                                                {'loss': 0.8899, 'grad_norm': 0.4487418446953376, 'learning_rate': 1.8428805237315874e-06, 'epoch': 0.32}
 11%|█         | 68/630 [01:04<07:40,  1.22it/s] 11%|█         | 69/630 [01:04<07:38,  1.22it/s]                                                {'loss': 0.8713, 'grad_norm': 0.4026188879681819, 'learning_rate': 1.839607201309329e-06, 'epoch': 0.33}
 11%|█         | 69/630 [01:04<07:38,  1.22it/s] 11%|█         | 70/630 [01:05<07:37,  1.22it/s]                                                {'loss': 0.8731, 'grad_norm': 0.5174014170882362, 'learning_rate': 1.8363338788870705e-06, 'epoch': 0.33}
 11%|█         | 70/630 [01:05<07:37,  1.22it/s] 11%|█▏        | 71/630 [01:06<07:35,  1.23it/s]                                                {'loss': 0.9304, 'grad_norm': 0.4203378235628106, 'learning_rate': 1.8330605564648116e-06, 'epoch': 0.34}
 11%|█▏        | 71/630 [01:06<07:35,  1.23it/s] 11%|█▏        | 72/630 [01:07<07:35,  1.23it/s]                                                {'loss': 0.8523, 'grad_norm': 0.37897616880631135, 'learning_rate': 1.8297872340425531e-06, 'epoch': 0.34}
 11%|█▏        | 72/630 [01:07<07:35,  1.23it/s] 12%|█▏        | 73/630 [01:08<07:33,  1.23it/s]                                                {'loss': 0.9229, 'grad_norm': 0.5696275243297152, 'learning_rate': 1.8265139116202945e-06, 'epoch': 0.35}
 12%|█▏        | 73/630 [01:08<07:33,  1.23it/s] 12%|█▏        | 74/630 [01:08<07:32,  1.23it/s]                                                {'loss': 0.9842, 'grad_norm': 0.5538441280106726, 'learning_rate': 1.823240589198036e-06, 'epoch': 0.35}
 12%|█▏        | 74/630 [01:08<07:32,  1.23it/s] 12%|█▏        | 75/630 [01:09<07:31,  1.23it/s]                                                {'loss': 0.9494, 'grad_norm': 0.47435654219228673, 'learning_rate': 1.8199672667757774e-06, 'epoch': 0.36}
 12%|█▏        | 75/630 [01:09<07:31,  1.23it/s] 12%|█▏        | 76/630 [01:10<07:31,  1.23it/s]                                                {'loss': 0.8697, 'grad_norm': 0.39823311338443834, 'learning_rate': 1.8166939443535187e-06, 'epoch': 0.36}
 12%|█▏        | 76/630 [01:10<07:31,  1.23it/s] 12%|█▏        | 77/630 [01:11<07:31,  1.22it/s]                                                {'loss': 0.8943, 'grad_norm': 0.42084821155020335, 'learning_rate': 1.8134206219312602e-06, 'epoch': 0.37}
 12%|█▏        | 77/630 [01:11<07:31,  1.22it/s] 12%|█▏        | 78/630 [01:12<07:30,  1.23it/s]                                                {'loss': 0.9866, 'grad_norm': 0.5835195299571996, 'learning_rate': 1.8101472995090016e-06, 'epoch': 0.37}
 12%|█▏        | 78/630 [01:12<07:30,  1.23it/s] 13%|█▎        | 79/630 [01:13<07:29,  1.23it/s]                                                {'loss': 0.8047, 'grad_norm': 0.32358699255390516, 'learning_rate': 1.806873977086743e-06, 'epoch': 0.38}
 13%|█▎        | 79/630 [01:13<07:29,  1.23it/s] 13%|█▎        | 80/630 [01:13<07:28,  1.22it/s]                                                {'loss': 0.8608, 'grad_norm': 0.34590504135851724, 'learning_rate': 1.8036006546644845e-06, 'epoch': 0.38}
 13%|█▎        | 80/630 [01:13<07:28,  1.22it/s] 13%|█▎        | 81/630 [01:14<07:28,  1.22it/s]                                                {'loss': 1.0076, 'grad_norm': 0.5376849227541184, 'learning_rate': 1.8003273322422258e-06, 'epoch': 0.39}
 13%|█▎        | 81/630 [01:14<07:28,  1.22it/s] 13%|█▎        | 82/630 [01:15<07:28,  1.22it/s]                                                {'loss': 0.943, 'grad_norm': 0.5045738208990842, 'learning_rate': 1.7970540098199671e-06, 'epoch': 0.39}
 13%|█▎        | 82/630 [01:15<07:28,  1.22it/s] 13%|█▎        | 83/630 [01:16<07:28,  1.22it/s]                                                {'loss': 0.8899, 'grad_norm': 0.46249223985089827, 'learning_rate': 1.7937806873977087e-06, 'epoch': 0.4}
 13%|█▎        | 83/630 [01:16<07:28,  1.22it/s] 13%|█▎        | 84/630 [01:17<07:28,  1.22it/s]                                                {'loss': 0.841, 'grad_norm': 0.3461224633910791, 'learning_rate': 1.79050736497545e-06, 'epoch': 0.4}
 13%|█▎        | 84/630 [01:17<07:28,  1.22it/s] 13%|█▎        | 85/630 [01:17<07:26,  1.22it/s]                                                {'loss': 0.8716, 'grad_norm': 0.41666800864574216, 'learning_rate': 1.7872340425531913e-06, 'epoch': 0.4}
 13%|█▎        | 85/630 [01:17<07:26,  1.22it/s] 14%|█▎        | 86/630 [01:18<07:26,  1.22it/s]                                                {'loss': 0.9114, 'grad_norm': 0.4611872620543421, 'learning_rate': 1.7839607201309329e-06, 'epoch': 0.41}
 14%|█▎        | 86/630 [01:18<07:26,  1.22it/s] 14%|█▍        | 87/630 [01:19<07:23,  1.22it/s]                                                {'loss': 0.9231, 'grad_norm': 0.3813688563168292, 'learning_rate': 1.7806873977086742e-06, 'epoch': 0.41}
 14%|█▍        | 87/630 [01:19<07:23,  1.22it/s] 14%|█▍        | 88/630 [01:20<07:23,  1.22it/s]                                                {'loss': 0.8669, 'grad_norm': 0.37454562994724105, 'learning_rate': 1.7774140752864158e-06, 'epoch': 0.42}
 14%|█▍        | 88/630 [01:20<07:23,  1.22it/s] 14%|█▍        | 89/630 [01:21<07:22,  1.22it/s]                                                {'loss': 0.9535, 'grad_norm': 0.5317329291276055, 'learning_rate': 1.7741407528641569e-06, 'epoch': 0.42}
 14%|█▍        | 89/630 [01:21<07:22,  1.22it/s] 14%|█▍        | 90/630 [01:22<07:22,  1.22it/s]                                                {'loss': 0.8788, 'grad_norm': 0.4253338850859531, 'learning_rate': 1.7708674304418984e-06, 'epoch': 0.43}
 14%|█▍        | 90/630 [01:22<07:22,  1.22it/s] 14%|█▍        | 91/630 [01:22<07:22,  1.22it/s]                                                {'loss': 1.0104, 'grad_norm': 0.5125389688555275, 'learning_rate': 1.76759410801964e-06, 'epoch': 0.43}
 14%|█▍        | 91/630 [01:22<07:22,  1.22it/s] 15%|█▍        | 92/630 [01:23<07:21,  1.22it/s]                                                {'loss': 0.9211, 'grad_norm': 0.4007225584580565, 'learning_rate': 1.764320785597381e-06, 'epoch': 0.44}
 15%|█▍        | 92/630 [01:23<07:21,  1.22it/s] 15%|█▍        | 93/630 [01:24<07:21,  1.22it/s]                                                {'loss': 0.9857, 'grad_norm': 0.5010453774623617, 'learning_rate': 1.7610474631751227e-06, 'epoch': 0.44}
 15%|█▍        | 93/630 [01:24<07:21,  1.22it/s] 15%|█▍        | 94/630 [01:25<07:20,  1.22it/s]                                                {'loss': 0.9164, 'grad_norm': 0.3660233086869871, 'learning_rate': 1.7577741407528642e-06, 'epoch': 0.45}
 15%|█▍        | 94/630 [01:25<07:20,  1.22it/s] 15%|█▌        | 95/630 [01:26<07:19,  1.22it/s]                                                {'loss': 0.8262, 'grad_norm': 0.39190951409867025, 'learning_rate': 1.7545008183306055e-06, 'epoch': 0.45}
 15%|█▌        | 95/630 [01:26<07:19,  1.22it/s] 15%|█▌        | 96/630 [01:26<07:17,  1.22it/s]                                                {'loss': 0.9658, 'grad_norm': 0.41485360063945903, 'learning_rate': 1.7512274959083469e-06, 'epoch': 0.46}
 15%|█▌        | 96/630 [01:26<07:17,  1.22it/s] 15%|█▌        | 97/630 [01:27<07:15,  1.22it/s]                                                {'loss': 0.911, 'grad_norm': 0.4054653065503631, 'learning_rate': 1.7479541734860884e-06, 'epoch': 0.46}
 15%|█▌        | 97/630 [01:27<07:15,  1.22it/s] 16%|█▌        | 98/630 [01:28<07:14,  1.23it/s]                                                {'loss': 0.8635, 'grad_norm': 0.3636647778726436, 'learning_rate': 1.7446808510638297e-06, 'epoch': 0.47}
 16%|█▌        | 98/630 [01:28<07:14,  1.23it/s] 16%|█▌        | 99/630 [01:29<07:14,  1.22it/s]                                                {'loss': 0.8655, 'grad_norm': 0.3398059011905151, 'learning_rate': 1.741407528641571e-06, 'epoch': 0.47}
 16%|█▌        | 99/630 [01:29<07:14,  1.22it/s] 16%|█▌        | 100/630 [01:30<07:13,  1.22it/s]                                                 {'loss': 0.9213, 'grad_norm': 0.3745538022196177, 'learning_rate': 1.7381342062193124e-06, 'epoch': 0.48}
 16%|█▌        | 100/630 [01:30<07:13,  1.22it/s] 16%|█▌        | 101/630 [01:31<07:11,  1.23it/s]                                                 {'loss': 0.8595, 'grad_norm': 0.3997440576298085, 'learning_rate': 1.734860883797054e-06, 'epoch': 0.48}
 16%|█▌        | 101/630 [01:31<07:11,  1.23it/s] 16%|█▌        | 102/630 [01:31<07:09,  1.23it/s]                                                 {'loss': 0.8793, 'grad_norm': 0.4021503316199188, 'learning_rate': 1.7315875613747955e-06, 'epoch': 0.49}
 16%|█▌        | 102/630 [01:31<07:09,  1.23it/s] 16%|█▋        | 103/630 [01:32<07:07,  1.23it/s]                                                 {'loss': 0.9739, 'grad_norm': 0.5772841376814529, 'learning_rate': 1.7283142389525366e-06, 'epoch': 0.49}
 16%|█▋        | 103/630 [01:32<07:07,  1.23it/s] 17%|█▋        | 104/630 [01:33<07:06,  1.23it/s]                                                 {'loss': 0.9248, 'grad_norm': 0.501880476845384, 'learning_rate': 1.7250409165302782e-06, 'epoch': 0.5}
 17%|█▋        | 104/630 [01:33<07:06,  1.23it/s] 17%|█▋        | 105/630 [01:34<07:06,  1.23it/s]                                                 {'loss': 0.8593, 'grad_norm': 0.4623065138333352, 'learning_rate': 1.7217675941080197e-06, 'epoch': 0.5}
 17%|█▋        | 105/630 [01:34<07:06,  1.23it/s] 17%|█▋        | 106/630 [01:35<07:05,  1.23it/s]                                                 {'loss': 0.8445, 'grad_norm': 0.4341887173010687, 'learning_rate': 1.7184942716857609e-06, 'epoch': 0.5}
 17%|█▋        | 106/630 [01:35<07:05,  1.23it/s] 17%|█▋        | 107/630 [01:35<07:05,  1.23it/s]                                                 {'loss': 0.9056, 'grad_norm': 0.4890361642229475, 'learning_rate': 1.7152209492635024e-06, 'epoch': 0.51}
 17%|█▋        | 107/630 [01:35<07:05,  1.23it/s] 17%|█▋        | 108/630 [01:36<07:04,  1.23it/s]                                                 {'loss': 0.9175, 'grad_norm': 0.5231120627211209, 'learning_rate': 1.7119476268412437e-06, 'epoch': 0.51}
 17%|█▋        | 108/630 [01:36<07:04,  1.23it/s] 17%|█▋        | 109/630 [01:37<07:08,  1.22it/s]                                                 {'loss': 0.9288, 'grad_norm': 0.3188485184330124, 'learning_rate': 1.7086743044189853e-06, 'epoch': 0.52}
 17%|█▋        | 109/630 [01:37<07:08,  1.22it/s] 17%|█▋        | 110/630 [01:38<07:06,  1.22it/s]                                                 {'loss': 0.9977, 'grad_norm': 0.356872199419056, 'learning_rate': 1.7054009819967266e-06, 'epoch': 0.52}
 17%|█▋        | 110/630 [01:38<07:06,  1.22it/s] 18%|█▊        | 111/630 [01:39<07:04,  1.22it/s]                                                 {'loss': 0.8787, 'grad_norm': 0.4731887920470009, 'learning_rate': 1.702127659574468e-06, 'epoch': 0.53}
 18%|█▊        | 111/630 [01:39<07:04,  1.22it/s] 18%|█▊        | 112/630 [01:40<07:03,  1.22it/s]                                                 {'loss': 0.826, 'grad_norm': 0.38471854000257094, 'learning_rate': 1.6988543371522095e-06, 'epoch': 0.53}
 18%|█▊        | 112/630 [01:40<07:03,  1.22it/s] 18%|█▊        | 113/630 [01:40<07:02,  1.22it/s]                                                 {'loss': 0.9323, 'grad_norm': 0.48730995374684993, 'learning_rate': 1.6955810147299508e-06, 'epoch': 0.54}
 18%|█▊        | 113/630 [01:40<07:02,  1.22it/s] 18%|█▊        | 114/630 [01:41<07:01,  1.22it/s]                                                 {'loss': 0.9287, 'grad_norm': 0.37168589832275384, 'learning_rate': 1.6923076923076922e-06, 'epoch': 0.54}
 18%|█▊        | 114/630 [01:41<07:01,  1.22it/s] 18%|█▊        | 115/630 [01:42<07:00,  1.22it/s]                                                 {'loss': 0.8711, 'grad_norm': 0.39621353806912674, 'learning_rate': 1.6890343698854337e-06, 'epoch': 0.55}
 18%|█▊        | 115/630 [01:42<07:00,  1.22it/s] 18%|█▊        | 116/630 [01:43<06:59,  1.23it/s]                                                 {'loss': 0.8959, 'grad_norm': 0.35615627709794, 'learning_rate': 1.6857610474631753e-06, 'epoch': 0.55}
 18%|█▊        | 116/630 [01:43<06:59,  1.23it/s] 19%|█▊        | 117/630 [01:44<06:58,  1.23it/s]                                                 {'loss': 0.8962, 'grad_norm': 0.40867890206552493, 'learning_rate': 1.6824877250409164e-06, 'epoch': 0.56}
 19%|█▊        | 117/630 [01:44<06:58,  1.23it/s] 19%|█▊        | 118/630 [01:44<06:57,  1.23it/s]                                                 {'loss': 0.843, 'grad_norm': 0.3500370707896446, 'learning_rate': 1.679214402618658e-06, 'epoch': 0.56}
 19%|█▊        | 118/630 [01:44<06:57,  1.23it/s] 19%|█▉        | 119/630 [01:45<06:56,  1.23it/s]                                                 {'loss': 0.7681, 'grad_norm': 0.30223249562427257, 'learning_rate': 1.6759410801963993e-06, 'epoch': 0.57}
 19%|█▉        | 119/630 [01:45<06:56,  1.23it/s] 19%|█▉        | 120/630 [01:46<06:54,  1.23it/s]                                                 {'loss': 0.9134, 'grad_norm': 0.43994266850298785, 'learning_rate': 1.6726677577741406e-06, 'epoch': 0.57}
 19%|█▉        | 120/630 [01:46<06:54,  1.23it/s] 19%|█▉        | 121/630 [01:47<06:53,  1.23it/s]                                                 {'loss': 0.8698, 'grad_norm': 0.3794970194958488, 'learning_rate': 1.6693944353518821e-06, 'epoch': 0.58}
 19%|█▉        | 121/630 [01:47<06:53,  1.23it/s] 19%|█▉        | 122/630 [01:48<06:53,  1.23it/s]                                                 {'loss': 0.9024, 'grad_norm': 0.4235983507246386, 'learning_rate': 1.6661211129296235e-06, 'epoch': 0.58}
 19%|█▉        | 122/630 [01:48<06:53,  1.23it/s] 20%|█▉        | 123/630 [01:49<06:52,  1.23it/s]                                                 {'loss': 0.9434, 'grad_norm': 0.3769113145435709, 'learning_rate': 1.6628477905073648e-06, 'epoch': 0.59}
 20%|█▉        | 123/630 [01:49<06:52,  1.23it/s] 20%|█▉        | 124/630 [01:49<06:51,  1.23it/s]                                                 {'loss': 0.8855, 'grad_norm': 0.3577591670788484, 'learning_rate': 1.6595744680851064e-06, 'epoch': 0.59}
 20%|█▉        | 124/630 [01:49<06:51,  1.23it/s] 20%|█▉        | 125/630 [01:50<06:50,  1.23it/s]                                                 {'loss': 0.8495, 'grad_norm': 0.4328480122005431, 'learning_rate': 1.6563011456628477e-06, 'epoch': 0.6}
 20%|█▉        | 125/630 [01:50<06:50,  1.23it/s] 20%|██        | 126/630 [01:51<06:50,  1.23it/s]                                                 {'loss': 0.7715, 'grad_norm': 0.34904985661092386, 'learning_rate': 1.6530278232405892e-06, 'epoch': 0.6}
 20%|██        | 126/630 [01:51<06:50,  1.23it/s] 20%|██        | 127/630 [01:52<06:49,  1.23it/s]                                                 {'loss': 0.9309, 'grad_norm': 0.43830202268097745, 'learning_rate': 1.6497545008183304e-06, 'epoch': 0.6}
 20%|██        | 127/630 [01:52<06:49,  1.23it/s] 20%|██        | 128/630 [01:53<06:49,  1.23it/s]                                                 {'loss': 0.9092, 'grad_norm': 0.3436608936336937, 'learning_rate': 1.646481178396072e-06, 'epoch': 0.61}
 20%|██        | 128/630 [01:53<06:49,  1.23it/s] 20%|██        | 129/630 [01:53<06:47,  1.23it/s]                                                 {'loss': 0.9428, 'grad_norm': 0.38467902562564626, 'learning_rate': 1.6432078559738135e-06, 'epoch': 0.61}
 20%|██        | 129/630 [01:53<06:47,  1.23it/s] 21%|██        | 130/630 [01:54<06:47,  1.23it/s]                                                 {'loss': 0.8808, 'grad_norm': 0.34242061344473124, 'learning_rate': 1.6399345335515546e-06, 'epoch': 0.62}
 21%|██        | 130/630 [01:54<06:47,  1.23it/s] 21%|██        | 131/630 [01:55<06:46,  1.23it/s]                                                 {'loss': 0.8946, 'grad_norm': 0.40147754658299817, 'learning_rate': 1.6366612111292961e-06, 'epoch': 0.62}
 21%|██        | 131/630 [01:55<06:46,  1.23it/s] 21%|██        | 132/630 [01:56<06:44,  1.23it/s]                                                 {'loss': 0.9284, 'grad_norm': 0.377890575382922, 'learning_rate': 1.6333878887070377e-06, 'epoch': 0.63}
 21%|██        | 132/630 [01:56<06:44,  1.23it/s] 21%|██        | 133/630 [01:57<06:43,  1.23it/s]                                                 {'loss': 0.7867, 'grad_norm': 0.38716376468569186, 'learning_rate': 1.630114566284779e-06, 'epoch': 0.63}
 21%|██        | 133/630 [01:57<06:43,  1.23it/s] 21%|██▏       | 134/630 [01:57<06:42,  1.23it/s]                                                 {'loss': 0.8229, 'grad_norm': 0.403200447684374, 'learning_rate': 1.6268412438625203e-06, 'epoch': 0.64}
 21%|██▏       | 134/630 [01:57<06:42,  1.23it/s] 21%|██▏       | 135/630 [01:58<06:41,  1.23it/s]                                                 {'loss': 0.913, 'grad_norm': 0.40380069167584876, 'learning_rate': 1.6235679214402617e-06, 'epoch': 0.64}
 21%|██▏       | 135/630 [01:58<06:41,  1.23it/s] 22%|██▏       | 136/630 [01:59<06:40,  1.23it/s]                                                 {'loss': 0.9253, 'grad_norm': 0.4567590762012873, 'learning_rate': 1.6202945990180032e-06, 'epoch': 0.65}
 22%|██▏       | 136/630 [01:59<06:40,  1.23it/s] 22%|██▏       | 137/630 [02:00<06:39,  1.23it/s]                                                 {'loss': 0.93, 'grad_norm': 0.45390846113987415, 'learning_rate': 1.6170212765957446e-06, 'epoch': 0.65}
 22%|██▏       | 137/630 [02:00<06:39,  1.23it/s] 22%|██▏       | 138/630 [02:01<06:39,  1.23it/s]                                                 {'loss': 0.8727, 'grad_norm': 0.37699707091681633, 'learning_rate': 1.613747954173486e-06, 'epoch': 0.66}
 22%|██▏       | 138/630 [02:01<06:39,  1.23it/s] 22%|██▏       | 139/630 [02:01<06:38,  1.23it/s]                                                 {'loss': 0.9106, 'grad_norm': 0.42907983131848715, 'learning_rate': 1.6104746317512274e-06, 'epoch': 0.66}
 22%|██▏       | 139/630 [02:01<06:38,  1.23it/s] 22%|██▏       | 140/630 [02:02<06:37,  1.23it/s]                                                 {'loss': 0.8813, 'grad_norm': 0.39604212005686995, 'learning_rate': 1.607201309328969e-06, 'epoch': 0.67}
 22%|██▏       | 140/630 [02:02<06:37,  1.23it/s] 22%|██▏       | 141/630 [02:03<06:35,  1.24it/s]                                                 {'loss': 0.8292, 'grad_norm': 0.40764849360151584, 'learning_rate': 1.6039279869067101e-06, 'epoch': 0.67}
 22%|██▏       | 141/630 [02:03<06:35,  1.24it/s] 23%|██▎       | 142/630 [02:04<06:34,  1.24it/s]                                                 {'loss': 0.89, 'grad_norm': 0.37980348698970745, 'learning_rate': 1.6006546644844517e-06, 'epoch': 0.68}
 23%|██▎       | 142/630 [02:04<06:34,  1.24it/s] 23%|██▎       | 143/630 [02:05<06:33,  1.24it/s]                                                 {'loss': 0.9705, 'grad_norm': 0.5649598667685535, 'learning_rate': 1.5973813420621932e-06, 'epoch': 0.68}
 23%|██▎       | 143/630 [02:05<06:33,  1.24it/s] 23%|██▎       | 144/630 [02:06<06:32,  1.24it/s]                                                 {'loss': 0.8816, 'grad_norm': 0.35973366231836157, 'learning_rate': 1.5941080196399343e-06, 'epoch': 0.69}
 23%|██▎       | 144/630 [02:06<06:32,  1.24it/s] 23%|██▎       | 145/630 [02:06<06:32,  1.23it/s]                                                 {'loss': 0.8958, 'grad_norm': 0.43077115703763796, 'learning_rate': 1.5908346972176759e-06, 'epoch': 0.69}
 23%|██▎       | 145/630 [02:06<06:32,  1.23it/s] 23%|██▎       | 146/630 [02:07<06:32,  1.23it/s]                                                 {'loss': 0.9324, 'grad_norm': 0.40038011043281574, 'learning_rate': 1.5875613747954172e-06, 'epoch': 0.7}
 23%|██▎       | 146/630 [02:07<06:32,  1.23it/s] 23%|██▎       | 147/630 [02:08<06:31,  1.23it/s]                                                 {'loss': 0.9175, 'grad_norm': 0.3652999393211845, 'learning_rate': 1.5842880523731588e-06, 'epoch': 0.7}
 23%|██▎       | 147/630 [02:08<06:31,  1.23it/s] 23%|██▎       | 148/630 [02:09<06:30,  1.23it/s]                                                 {'loss': 0.8876, 'grad_norm': 0.35634220169122355, 'learning_rate': 1.5810147299509e-06, 'epoch': 0.7}
 23%|██▎       | 148/630 [02:09<06:30,  1.23it/s] 24%|██▎       | 149/630 [02:10<06:29,  1.23it/s]                                                 {'loss': 0.8021, 'grad_norm': 0.4358356954958731, 'learning_rate': 1.5777414075286414e-06, 'epoch': 0.71}
 24%|██▎       | 149/630 [02:10<06:29,  1.23it/s] 24%|██▍       | 150/630 [02:10<06:29,  1.23it/s]                                                 {'loss': 0.8493, 'grad_norm': 0.35596083425012826, 'learning_rate': 1.574468085106383e-06, 'epoch': 0.71}
 24%|██▍       | 150/630 [02:10<06:29,  1.23it/s] 24%|██▍       | 151/630 [02:11<06:28,  1.23it/s]                                                 {'loss': 1.0292, 'grad_norm': 0.5300709126246458, 'learning_rate': 1.5711947626841243e-06, 'epoch': 0.72}
 24%|██▍       | 151/630 [02:11<06:28,  1.23it/s] 24%|██▍       | 152/630 [02:12<06:29,  1.23it/s]                                                 {'loss': 0.8599, 'grad_norm': 0.3618878138996394, 'learning_rate': 1.5679214402618656e-06, 'epoch': 0.72}
 24%|██▍       | 152/630 [02:12<06:29,  1.23it/s] 24%|██▍       | 153/630 [02:13<06:28,  1.23it/s]                                                 {'loss': 0.86, 'grad_norm': 0.37734596158982925, 'learning_rate': 1.5646481178396072e-06, 'epoch': 0.73}
 24%|██▍       | 153/630 [02:13<06:28,  1.23it/s] 24%|██▍       | 154/630 [02:14<06:26,  1.23it/s]                                                 {'loss': 0.8512, 'grad_norm': 0.4071299466453768, 'learning_rate': 1.5613747954173485e-06, 'epoch': 0.73}
 24%|██▍       | 154/630 [02:14<06:26,  1.23it/s] 25%|██▍       | 155/630 [02:14<06:26,  1.23it/s]                                                 {'loss': 0.8842, 'grad_norm': 0.4710096264701576, 'learning_rate': 1.5581014729950899e-06, 'epoch': 0.74}
 25%|██▍       | 155/630 [02:14<06:26,  1.23it/s] 25%|██▍       | 156/630 [02:15<06:25,  1.23it/s]                                                 {'loss': 0.8043, 'grad_norm': 0.3725263415848875, 'learning_rate': 1.5548281505728314e-06, 'epoch': 0.74}
 25%|██▍       | 156/630 [02:15<06:25,  1.23it/s] 25%|██▍       | 157/630 [02:16<06:23,  1.23it/s]                                                 {'loss': 1.0013, 'grad_norm': 0.47453628716668705, 'learning_rate': 1.5515548281505727e-06, 'epoch': 0.75}
 25%|██▍       | 157/630 [02:16<06:23,  1.23it/s] 25%|██▌       | 158/630 [02:17<06:22,  1.23it/s]                                                 {'loss': 0.8294, 'grad_norm': 0.333979430041421, 'learning_rate': 1.548281505728314e-06, 'epoch': 0.75}
 25%|██▌       | 158/630 [02:17<06:22,  1.23it/s] 25%|██▌       | 159/630 [02:18<06:21,  1.23it/s]                                                 {'loss': 0.8477, 'grad_norm': 0.4174288602466642, 'learning_rate': 1.5450081833060556e-06, 'epoch': 0.76}
 25%|██▌       | 159/630 [02:18<06:21,  1.23it/s] 25%|██▌       | 160/630 [02:19<06:20,  1.24it/s]                                                 {'loss': 0.9338, 'grad_norm': 0.4791289128711734, 'learning_rate': 1.541734860883797e-06, 'epoch': 0.76}
 25%|██▌       | 160/630 [02:19<06:20,  1.24it/s] 26%|██▌       | 161/630 [02:19<06:20,  1.23it/s]                                                 {'loss': 0.888, 'grad_norm': 0.4351691167581125, 'learning_rate': 1.5384615384615385e-06, 'epoch': 0.77}
 26%|██▌       | 161/630 [02:19<06:20,  1.23it/s] 26%|██▌       | 162/630 [02:20<06:19,  1.23it/s]                                                 {'loss': 1.0018, 'grad_norm': 0.49664077731872625, 'learning_rate': 1.5351882160392796e-06, 'epoch': 0.77}
 26%|██▌       | 162/630 [02:20<06:19,  1.23it/s] 26%|██▌       | 163/630 [02:21<06:18,  1.23it/s]                                                 {'loss': 0.837, 'grad_norm': 0.38672666684401524, 'learning_rate': 1.5319148936170212e-06, 'epoch': 0.78}
 26%|██▌       | 163/630 [02:21<06:18,  1.23it/s] 26%|██▌       | 164/630 [02:22<06:17,  1.23it/s]                                                 {'loss': 0.8278, 'grad_norm': 0.3320414025688977, 'learning_rate': 1.5286415711947627e-06, 'epoch': 0.78}
 26%|██▌       | 164/630 [02:22<06:17,  1.23it/s] 26%|██▌       | 165/630 [02:23<06:17,  1.23it/s]                                                 {'loss': 0.879, 'grad_norm': 0.371182414387765, 'learning_rate': 1.5253682487725038e-06, 'epoch': 0.79}
 26%|██▌       | 165/630 [02:23<06:17,  1.23it/s] 26%|██▋       | 166/630 [02:23<06:15,  1.23it/s]                                                 {'loss': 1.0703, 'grad_norm': 0.6628695832951128, 'learning_rate': 1.5220949263502454e-06, 'epoch': 0.79}
 26%|██▋       | 166/630 [02:23<06:15,  1.23it/s] 27%|██▋       | 167/630 [02:24<06:15,  1.23it/s]                                                 {'loss': 0.8999, 'grad_norm': 0.4023769720564016, 'learning_rate': 1.518821603927987e-06, 'epoch': 0.8}
 27%|██▋       | 167/630 [02:24<06:15,  1.23it/s] 27%|██▋       | 168/630 [02:25<06:14,  1.23it/s]                                                 {'loss': 0.8898, 'grad_norm': 0.3508453487899387, 'learning_rate': 1.5155482815057283e-06, 'epoch': 0.8}
 27%|██▋       | 168/630 [02:25<06:14,  1.23it/s] 27%|██▋       | 169/630 [02:26<06:13,  1.23it/s]                                                 {'loss': 0.8608, 'grad_norm': 0.39733779382133, 'learning_rate': 1.5122749590834696e-06, 'epoch': 0.8}
 27%|██▋       | 169/630 [02:26<06:13,  1.23it/s] 27%|██▋       | 170/630 [02:27<06:12,  1.23it/s]                                                 {'loss': 0.8624, 'grad_norm': 0.3462209462572522, 'learning_rate': 1.5090016366612112e-06, 'epoch': 0.81}
 27%|██▋       | 170/630 [02:27<06:12,  1.23it/s] 27%|██▋       | 171/630 [02:27<06:11,  1.23it/s]                                                 {'loss': 0.8442, 'grad_norm': 0.32180954330029443, 'learning_rate': 1.5057283142389525e-06, 'epoch': 0.81}
 27%|██▋       | 171/630 [02:27<06:11,  1.23it/s] 27%|██▋       | 172/630 [02:28<06:10,  1.24it/s]                                                 {'loss': 0.8264, 'grad_norm': 0.4032443419458109, 'learning_rate': 1.5024549918166938e-06, 'epoch': 0.82}
 27%|██▋       | 172/630 [02:28<06:10,  1.24it/s] 27%|██▋       | 173/630 [02:29<06:11,  1.23it/s]                                                 {'loss': 0.8414, 'grad_norm': 0.34975415984012026, 'learning_rate': 1.4991816693944352e-06, 'epoch': 0.82}
 27%|██▋       | 173/630 [02:29<06:11,  1.23it/s] 28%|██▊       | 174/630 [02:30<06:10,  1.23it/s]                                                 {'loss': 0.7659, 'grad_norm': 0.35614679762186524, 'learning_rate': 1.4959083469721767e-06, 'epoch': 0.83}
 28%|██▊       | 174/630 [02:30<06:10,  1.23it/s] 28%|██▊       | 175/630 [02:31<06:09,  1.23it/s]                                                 {'loss': 0.8844, 'grad_norm': 0.3836992742236551, 'learning_rate': 1.4926350245499183e-06, 'epoch': 0.83}
 28%|██▊       | 175/630 [02:31<06:09,  1.23it/s] 28%|██▊       | 176/630 [02:31<06:07,  1.24it/s]                                                 {'loss': 0.8173, 'grad_norm': 0.4170029954177963, 'learning_rate': 1.4893617021276594e-06, 'epoch': 0.84}
 28%|██▊       | 176/630 [02:31<06:07,  1.24it/s] 28%|██▊       | 177/630 [02:32<06:07,  1.23it/s]                                                 {'loss': 0.8453, 'grad_norm': 0.3390864624732343, 'learning_rate': 1.486088379705401e-06, 'epoch': 0.84}
 28%|██▊       | 177/630 [02:32<06:07,  1.23it/s] 28%|██▊       | 178/630 [02:33<06:06,  1.23it/s]                                                 {'loss': 0.8814, 'grad_norm': 0.3992304934732356, 'learning_rate': 1.4828150572831425e-06, 'epoch': 0.85}
 28%|██▊       | 178/630 [02:33<06:06,  1.23it/s] 28%|██▊       | 179/630 [02:34<06:06,  1.23it/s]                                                 {'loss': 0.9261, 'grad_norm': 0.3915108271292839, 'learning_rate': 1.4795417348608836e-06, 'epoch': 0.85}
 28%|██▊       | 179/630 [02:34<06:06,  1.23it/s] 29%|██▊       | 180/630 [02:35<06:04,  1.23it/s]                                                 {'loss': 0.8803, 'grad_norm': 0.4220604608343408, 'learning_rate': 1.4762684124386251e-06, 'epoch': 0.86}
 29%|██▊       | 180/630 [02:35<06:04,  1.23it/s] 29%|██▊       | 181/630 [02:36<06:05,  1.23it/s]                                                 {'loss': 0.9647, 'grad_norm': 0.4363612493734319, 'learning_rate': 1.4729950900163665e-06, 'epoch': 0.86}
 29%|██▊       | 181/630 [02:36<06:05,  1.23it/s] 29%|██▉       | 182/630 [02:36<06:04,  1.23it/s]                                                 {'loss': 0.8563, 'grad_norm': 0.3484372530721376, 'learning_rate': 1.469721767594108e-06, 'epoch': 0.87}
 29%|██▉       | 182/630 [02:36<06:04,  1.23it/s] 29%|██▉       | 183/630 [02:37<06:03,  1.23it/s]                                                 {'loss': 0.9465, 'grad_norm': 0.42579415035258145, 'learning_rate': 1.4664484451718494e-06, 'epoch': 0.87}
 29%|██▉       | 183/630 [02:37<06:03,  1.23it/s] 29%|██▉       | 184/630 [02:38<06:01,  1.23it/s]                                                 {'loss': 0.849, 'grad_norm': 0.48344971107722495, 'learning_rate': 1.4631751227495907e-06, 'epoch': 0.88}
 29%|██▉       | 184/630 [02:38<06:01,  1.23it/s] 29%|██▉       | 185/630 [02:39<06:00,  1.23it/s]                                                 {'loss': 0.8203, 'grad_norm': 0.2988097468706465, 'learning_rate': 1.4599018003273322e-06, 'epoch': 0.88}
 29%|██▉       | 185/630 [02:39<06:00,  1.23it/s] 30%|██▉       | 186/630 [02:40<05:59,  1.24it/s]                                                 {'loss': 0.8356, 'grad_norm': 0.39991487516511887, 'learning_rate': 1.4566284779050736e-06, 'epoch': 0.89}
 30%|██▉       | 186/630 [02:40<05:59,  1.24it/s] 30%|██▉       | 187/630 [02:40<05:58,  1.24it/s]                                                 {'loss': 0.813, 'grad_norm': 0.4029456787783488, 'learning_rate': 1.453355155482815e-06, 'epoch': 0.89}
 30%|██▉       | 187/630 [02:40<05:58,  1.24it/s] 30%|██▉       | 188/630 [02:41<05:57,  1.24it/s]                                                 {'loss': 0.91, 'grad_norm': 0.3816088744737293, 'learning_rate': 1.4500818330605565e-06, 'epoch': 0.9}
 30%|██▉       | 188/630 [02:41<05:57,  1.24it/s] 30%|███       | 189/630 [02:42<05:56,  1.24it/s]                                                 {'loss': 0.8557, 'grad_norm': 0.32853134429078706, 'learning_rate': 1.446808510638298e-06, 'epoch': 0.9}
 30%|███       | 189/630 [02:42<05:56,  1.24it/s] 30%|███       | 190/630 [02:43<05:57,  1.23it/s]                                                 {'loss': 0.881, 'grad_norm': 0.37204838008695945, 'learning_rate': 1.4435351882160391e-06, 'epoch': 0.9}
 30%|███       | 190/630 [02:43<05:57,  1.23it/s] 30%|███       | 191/630 [02:44<05:57,  1.23it/s]                                                 {'loss': 0.8509, 'grad_norm': 0.4222431656500044, 'learning_rate': 1.4402618657937807e-06, 'epoch': 0.91}
 30%|███       | 191/630 [02:44<05:57,  1.23it/s] 30%|███       | 192/630 [02:44<05:56,  1.23it/s]                                                 {'loss': 0.8224, 'grad_norm': 0.501239432336742, 'learning_rate': 1.436988543371522e-06, 'epoch': 0.91}
 30%|███       | 192/630 [02:44<05:56,  1.23it/s] 31%|███       | 193/630 [02:45<05:54,  1.23it/s]                                                 {'loss': 0.8535, 'grad_norm': 0.47149872838631846, 'learning_rate': 1.4337152209492633e-06, 'epoch': 0.92}
 31%|███       | 193/630 [02:45<05:54,  1.23it/s] 31%|███       | 194/630 [02:46<05:53,  1.23it/s]                                                 {'loss': 0.8037, 'grad_norm': 0.48532444370988437, 'learning_rate': 1.4304418985270049e-06, 'epoch': 0.92}
 31%|███       | 194/630 [02:46<05:53,  1.23it/s] 31%|███       | 195/630 [02:47<05:52,  1.23it/s]                                                 {'loss': 0.7635, 'grad_norm': 0.3382182887544818, 'learning_rate': 1.4271685761047462e-06, 'epoch': 0.93}
 31%|███       | 195/630 [02:47<05:52,  1.23it/s] 31%|███       | 196/630 [02:48<05:52,  1.23it/s]                                                 {'loss': 0.8873, 'grad_norm': 0.491236900281733, 'learning_rate': 1.4238952536824878e-06, 'epoch': 0.93}
 31%|███       | 196/630 [02:48<05:52,  1.23it/s] 31%|███▏      | 197/630 [02:49<05:50,  1.24it/s]                                                 {'loss': 0.8567, 'grad_norm': 0.4071872221777324, 'learning_rate': 1.420621931260229e-06, 'epoch': 0.94}
 31%|███▏      | 197/630 [02:49<05:50,  1.24it/s] 31%|███▏      | 198/630 [02:49<05:50,  1.23it/s]                                                 {'loss': 0.835, 'grad_norm': 0.3955763695163946, 'learning_rate': 1.4173486088379704e-06, 'epoch': 0.94}
 31%|███▏      | 198/630 [02:49<05:50,  1.23it/s] 32%|███▏      | 199/630 [02:50<05:50,  1.23it/s]                                                 {'loss': 0.8832, 'grad_norm': 0.5072536701812702, 'learning_rate': 1.414075286415712e-06, 'epoch': 0.95}
 32%|███▏      | 199/630 [02:50<05:50,  1.23it/s] 32%|███▏      | 200/630 [02:51<05:49,  1.23it/s]                                                 {'loss': 0.8542, 'grad_norm': 0.36653624256292644, 'learning_rate': 1.4108019639934531e-06, 'epoch': 0.95}
 32%|███▏      | 200/630 [02:51<05:49,  1.23it/s] 32%|███▏      | 201/630 [02:52<05:48,  1.23it/s]                                                 {'loss': 0.9076, 'grad_norm': 0.4599795274322758, 'learning_rate': 1.4075286415711947e-06, 'epoch': 0.96}
 32%|███▏      | 201/630 [02:52<05:48,  1.23it/s] 32%|███▏      | 202/630 [02:53<05:47,  1.23it/s]                                                 {'loss': 0.8392, 'grad_norm': 0.39697640783572596, 'learning_rate': 1.4042553191489362e-06, 'epoch': 0.96}
 32%|███▏      | 202/630 [02:53<05:47,  1.23it/s] 32%|███▏      | 203/630 [02:53<05:46,  1.23it/s]                                                 {'loss': 0.8416, 'grad_norm': 0.3794513014592148, 'learning_rate': 1.4009819967266775e-06, 'epoch': 0.97}
 32%|███▏      | 203/630 [02:53<05:46,  1.23it/s] 32%|███▏      | 204/630 [02:54<05:45,  1.23it/s]                                                 {'loss': 1.0606, 'grad_norm': 0.43094258465942625, 'learning_rate': 1.3977086743044189e-06, 'epoch': 0.97}
 32%|███▏      | 204/630 [02:54<05:45,  1.23it/s] 33%|███▎      | 205/630 [02:55<05:45,  1.23it/s]                                                 {'loss': 0.7432, 'grad_norm': 0.2901236399058765, 'learning_rate': 1.3944353518821604e-06, 'epoch': 0.98}
 33%|███▎      | 205/630 [02:55<05:45,  1.23it/s] 33%|███▎      | 206/630 [02:56<05:43,  1.23it/s]                                                 {'loss': 0.9816, 'grad_norm': 0.42004080546604466, 'learning_rate': 1.3911620294599018e-06, 'epoch': 0.98}
 33%|███▎      | 206/630 [02:56<05:43,  1.23it/s] 33%|███▎      | 207/630 [02:57<05:42,  1.24it/s]                                                 {'loss': 0.8105, 'grad_norm': 0.34380355986334604, 'learning_rate': 1.387888707037643e-06, 'epoch': 0.99}
 33%|███▎      | 207/630 [02:57<05:42,  1.24it/s] 33%|███▎      | 208/630 [02:57<05:41,  1.23it/s]                                                 {'loss': 0.979, 'grad_norm': 0.49240464251486515, 'learning_rate': 1.3846153846153844e-06, 'epoch': 0.99}
 33%|███▎      | 208/630 [02:57<05:41,  1.23it/s] 33%|███▎      | 209/630 [02:58<05:41,  1.23it/s]                                                 {'loss': 0.8306, 'grad_norm': 0.337856069226034, 'learning_rate': 1.381342062193126e-06, 'epoch': 1.0}
 33%|███▎      | 209/630 [02:58<05:41,  1.23it/s] 33%|███▎      | 210/630 [02:59<05:40,  1.23it/s]                                                 {'loss': 0.8393, 'grad_norm': 0.35760365857416754, 'learning_rate': 1.3780687397708675e-06, 'epoch': 1.0}
 33%|███▎      | 210/630 [02:59<05:40,  1.23it/s] 33%|███▎      | 211/630 [03:00<05:40,  1.23it/s]                                                 {'loss': 0.8295, 'grad_norm': 0.3603728895434501, 'learning_rate': 1.3747954173486086e-06, 'epoch': 1.0}
 33%|███▎      | 211/630 [03:00<05:40,  1.23it/s] 34%|███▎      | 212/630 [03:01<05:39,  1.23it/s]                                                 {'loss': 0.8872, 'grad_norm': 0.43413203732788475, 'learning_rate': 1.3715220949263502e-06, 'epoch': 1.01}
 34%|███▎      | 212/630 [03:01<05:39,  1.23it/s] 34%|███▍      | 213/630 [03:02<05:38,  1.23it/s]                                                 {'loss': 0.9027, 'grad_norm': 0.31758894005617355, 'learning_rate': 1.3682487725040917e-06, 'epoch': 1.01}
 34%|███▍      | 213/630 [03:02<05:38,  1.23it/s] 34%|███▍      | 214/630 [03:02<05:38,  1.23it/s]                                                 {'loss': 0.9053, 'grad_norm': 0.5303057262081864, 'learning_rate': 1.3649754500818329e-06, 'epoch': 1.02}
 34%|███▍      | 214/630 [03:02<05:38,  1.23it/s] 34%|███▍      | 215/630 [03:03<05:37,  1.23it/s]                                                 {'loss': 0.8389, 'grad_norm': 0.41832331495584657, 'learning_rate': 1.3617021276595744e-06, 'epoch': 1.02}
 34%|███▍      | 215/630 [03:03<05:37,  1.23it/s] 34%|███▍      | 216/630 [03:04<05:36,  1.23it/s]                                                 {'loss': 0.7799, 'grad_norm': 0.39251862761888123, 'learning_rate': 1.358428805237316e-06, 'epoch': 1.03}
 34%|███▍      | 216/630 [03:04<05:36,  1.23it/s] 34%|███▍      | 217/630 [03:05<05:35,  1.23it/s]                                                 {'loss': 0.7812, 'grad_norm': 0.34638122279058703, 'learning_rate': 1.3551554828150573e-06, 'epoch': 1.03}
 34%|███▍      | 217/630 [03:05<05:35,  1.23it/s] 35%|███▍      | 218/630 [03:06<05:34,  1.23it/s]                                                 {'loss': 0.8065, 'grad_norm': 0.35310728779212175, 'learning_rate': 1.3518821603927986e-06, 'epoch': 1.04}
 35%|███▍      | 218/630 [03:06<05:34,  1.23it/s] 35%|███▍      | 219/630 [03:06<05:33,  1.23it/s]                                                 {'loss': 0.8299, 'grad_norm': 0.36926349149925974, 'learning_rate': 1.34860883797054e-06, 'epoch': 1.04}
 35%|███▍      | 219/630 [03:06<05:33,  1.23it/s] 35%|███▍      | 220/630 [03:07<05:33,  1.23it/s]                                                 {'loss': 0.9248, 'grad_norm': 0.40650435828026193, 'learning_rate': 1.3453355155482815e-06, 'epoch': 1.05}
 35%|███▍      | 220/630 [03:07<05:33,  1.23it/s] 35%|███▌      | 221/630 [03:08<05:32,  1.23it/s]                                                 {'loss': 0.9454, 'grad_norm': 0.39733695227917615, 'learning_rate': 1.3420621931260228e-06, 'epoch': 1.05}
 35%|███▌      | 221/630 [03:08<05:32,  1.23it/s] 35%|███▌      | 222/630 [03:09<05:31,  1.23it/s]                                                 {'loss': 0.8344, 'grad_norm': 0.34056037083472185, 'learning_rate': 1.3387888707037642e-06, 'epoch': 1.06}
 35%|███▌      | 222/630 [03:09<05:31,  1.23it/s] 35%|███▌      | 223/630 [03:10<05:30,  1.23it/s]                                                 {'loss': 0.8704, 'grad_norm': 0.4394872827831111, 'learning_rate': 1.3355155482815057e-06, 'epoch': 1.06}
 35%|███▌      | 223/630 [03:10<05:30,  1.23it/s] 36%|███▌      | 224/630 [03:10<05:29,  1.23it/s]                                                 {'loss': 0.8434, 'grad_norm': 0.2910983559680757, 'learning_rate': 1.3322422258592473e-06, 'epoch': 1.07}
 36%|███▌      | 224/630 [03:10<05:29,  1.23it/s] 36%|███▌      | 225/630 [03:11<05:28,  1.23it/s]                                                 {'loss': 0.9347, 'grad_norm': 0.542618012917915, 'learning_rate': 1.3289689034369884e-06, 'epoch': 1.07}
 36%|███▌      | 225/630 [03:11<05:28,  1.23it/s] 36%|███▌      | 226/630 [03:12<05:27,  1.23it/s]                                                 {'loss': 0.8578, 'grad_norm': 0.4675008297859556, 'learning_rate': 1.32569558101473e-06, 'epoch': 1.08}
 36%|███▌      | 226/630 [03:12<05:27,  1.23it/s] 36%|███▌      | 227/630 [03:13<05:27,  1.23it/s]                                                 {'loss': 0.8974, 'grad_norm': 0.41898134710130425, 'learning_rate': 1.3224222585924713e-06, 'epoch': 1.08}
 36%|███▌      | 227/630 [03:13<05:27,  1.23it/s] 36%|███▌      | 228/630 [03:14<05:28,  1.22it/s]                                                 {'loss': 0.8695, 'grad_norm': 0.33868846884722054, 'learning_rate': 1.3191489361702126e-06, 'epoch': 1.09}
 36%|███▌      | 228/630 [03:14<05:28,  1.22it/s] 36%|███▋      | 229/630 [03:15<05:27,  1.22it/s]                                                 {'loss': 0.884, 'grad_norm': 0.5651557228437506, 'learning_rate': 1.3158756137479541e-06, 'epoch': 1.09}
 36%|███▋      | 229/630 [03:15<05:27,  1.22it/s] 37%|███▋      | 230/630 [03:15<05:26,  1.23it/s]                                                 {'loss': 0.8408, 'grad_norm': 0.3127281041217303, 'learning_rate': 1.3126022913256955e-06, 'epoch': 1.1}
 37%|███▋      | 230/630 [03:15<05:26,  1.23it/s] 37%|███▋      | 231/630 [03:16<05:25,  1.23it/s]                                                 {'loss': 0.8237, 'grad_norm': 0.4438238964335588, 'learning_rate': 1.309328968903437e-06, 'epoch': 1.1}
 37%|███▋      | 231/630 [03:16<05:25,  1.23it/s] 37%|███▋      | 232/630 [03:17<05:23,  1.23it/s]                                                 {'loss': 0.9007, 'grad_norm': 0.40022072555891586, 'learning_rate': 1.3060556464811784e-06, 'epoch': 1.1}
 37%|███▋      | 232/630 [03:17<05:23,  1.23it/s] 37%|███▋      | 233/630 [03:18<05:21,  1.23it/s]                                                 {'loss': 0.8055, 'grad_norm': 0.5034777545171708, 'learning_rate': 1.3027823240589197e-06, 'epoch': 1.11}
 37%|███▋      | 233/630 [03:18<05:21,  1.23it/s] 37%|███▋      | 234/630 [03:19<05:21,  1.23it/s]                                                 {'loss': 0.8676, 'grad_norm': 0.41159583405747197, 'learning_rate': 1.2995090016366612e-06, 'epoch': 1.11}
 37%|███▋      | 234/630 [03:19<05:21,  1.23it/s] 37%|███▋      | 235/630 [03:19<05:20,  1.23it/s]                                                 {'loss': 0.9433, 'grad_norm': 0.3997539288409223, 'learning_rate': 1.2962356792144024e-06, 'epoch': 1.12}
 37%|███▋      | 235/630 [03:19<05:20,  1.23it/s] 37%|███▋      | 236/630 [03:20<05:19,  1.23it/s]                                                 {'loss': 0.8631, 'grad_norm': 0.3972853965715881, 'learning_rate': 1.292962356792144e-06, 'epoch': 1.12}
 37%|███▋      | 236/630 [03:20<05:19,  1.23it/s] 38%|███▊      | 237/630 [03:21<05:18,  1.23it/s]                                                 {'loss': 0.8706, 'grad_norm': 0.3657997713479419, 'learning_rate': 1.2896890343698855e-06, 'epoch': 1.13}
 38%|███▊      | 237/630 [03:21<05:18,  1.23it/s] 38%|███▊      | 238/630 [03:22<05:17,  1.23it/s]                                                 {'loss': 0.9027, 'grad_norm': 0.4282708244350654, 'learning_rate': 1.2864157119476268e-06, 'epoch': 1.13}
 38%|███▊      | 238/630 [03:22<05:17,  1.23it/s] 38%|███▊      | 239/630 [03:23<05:17,  1.23it/s]                                                 {'loss': 0.9082, 'grad_norm': 0.35199373451963045, 'learning_rate': 1.2831423895253681e-06, 'epoch': 1.14}
 38%|███▊      | 239/630 [03:23<05:17,  1.23it/s] 38%|███▊      | 240/630 [03:23<05:16,  1.23it/s]                                                 {'loss': 0.9068, 'grad_norm': 0.4164888383849869, 'learning_rate': 1.2798690671031097e-06, 'epoch': 1.14}
 38%|███▊      | 240/630 [03:23<05:16,  1.23it/s] 38%|███▊      | 241/630 [03:24<05:15,  1.23it/s]                                                 {'loss': 0.806, 'grad_norm': 0.3468657913405037, 'learning_rate': 1.276595744680851e-06, 'epoch': 1.15}
 38%|███▊      | 241/630 [03:24<05:15,  1.23it/s] 38%|███▊      | 242/630 [03:25<05:15,  1.23it/s]                                                 {'loss': 0.8352, 'grad_norm': 0.42758895828179333, 'learning_rate': 1.2733224222585923e-06, 'epoch': 1.15}
 38%|███▊      | 242/630 [03:25<05:15,  1.23it/s] 39%|███▊      | 243/630 [03:26<05:15,  1.23it/s]                                                 {'loss': 0.8886, 'grad_norm': 0.32467872562113703, 'learning_rate': 1.270049099836334e-06, 'epoch': 1.16}
 39%|███▊      | 243/630 [03:26<05:15,  1.23it/s] 39%|███▊      | 244/630 [03:27<05:13,  1.23it/s]                                                 {'loss': 0.8212, 'grad_norm': 0.3251716615975763, 'learning_rate': 1.2667757774140752e-06, 'epoch': 1.16}
 39%|███▊      | 244/630 [03:27<05:13,  1.23it/s] 39%|███▉      | 245/630 [03:28<05:12,  1.23it/s]                                                 {'loss': 0.8032, 'grad_norm': 0.3890362161054786, 'learning_rate': 1.2635024549918168e-06, 'epoch': 1.17}
 39%|███▉      | 245/630 [03:28<05:12,  1.23it/s] 39%|███▉      | 246/630 [03:28<05:11,  1.23it/s]                                                 {'loss': 0.8913, 'grad_norm': 0.3789622919423697, 'learning_rate': 1.260229132569558e-06, 'epoch': 1.17}
 39%|███▉      | 246/630 [03:28<05:11,  1.23it/s] 39%|███▉      | 247/630 [03:29<05:11,  1.23it/s]                                                 {'loss': 0.8479, 'grad_norm': 0.33157573535213136, 'learning_rate': 1.2569558101472994e-06, 'epoch': 1.18}
 39%|███▉      | 247/630 [03:29<05:11,  1.23it/s] 39%|███▉      | 248/630 [03:30<05:11,  1.23it/s]                                                 {'loss': 0.7196, 'grad_norm': 0.30945494831979115, 'learning_rate': 1.253682487725041e-06, 'epoch': 1.18}
 39%|███▉      | 248/630 [03:30<05:11,  1.23it/s] 40%|███▉      | 249/630 [03:31<05:09,  1.23it/s]                                                 {'loss': 0.8548, 'grad_norm': 0.382743117841798, 'learning_rate': 1.2504091653027821e-06, 'epoch': 1.19}
 40%|███▉      | 249/630 [03:31<05:09,  1.23it/s] 40%|███▉      | 250/630 [03:32<05:08,  1.23it/s]                                                 {'loss': 0.8167, 'grad_norm': 0.3256789992958639, 'learning_rate': 1.2471358428805237e-06, 'epoch': 1.19}
 40%|███▉      | 250/630 [03:32<05:08,  1.23it/s] 40%|███▉      | 251/630 [03:32<05:09,  1.23it/s]                                                 {'loss': 0.854, 'grad_norm': 0.39766331841619457, 'learning_rate': 1.2438625204582652e-06, 'epoch': 1.2}
 40%|███▉      | 251/630 [03:32<05:09,  1.23it/s] 40%|████      | 252/630 [03:33<05:07,  1.23it/s]                                                 {'loss': 0.8536, 'grad_norm': 0.31844571026836815, 'learning_rate': 1.2405891980360065e-06, 'epoch': 1.2}
 40%|████      | 252/630 [03:33<05:07,  1.23it/s] 40%|████      | 253/630 [03:34<05:06,  1.23it/s]                                                 {'loss': 0.8752, 'grad_norm': 0.3749849030159515, 'learning_rate': 1.2373158756137479e-06, 'epoch': 1.2}
 40%|████      | 253/630 [03:34<05:06,  1.23it/s] 40%|████      | 254/630 [03:35<05:04,  1.23it/s]                                                 {'loss': 0.8668, 'grad_norm': 0.38613294750021426, 'learning_rate': 1.2340425531914892e-06, 'epoch': 1.21}
 40%|████      | 254/630 [03:35<05:04,  1.23it/s] 40%|████      | 255/630 [03:36<05:03,  1.23it/s]                                                 {'loss': 0.857, 'grad_norm': 0.369674853557138, 'learning_rate': 1.2307692307692308e-06, 'epoch': 1.21}
 40%|████      | 255/630 [03:36<05:03,  1.23it/s] 41%|████      | 256/630 [03:37<05:10,  1.21it/s]                                                 {'loss': 0.8289, 'grad_norm': 0.42851742688435696, 'learning_rate': 1.227495908346972e-06, 'epoch': 1.22}
 41%|████      | 256/630 [03:37<05:10,  1.21it/s] 41%|████      | 257/630 [03:37<05:07,  1.21it/s]                                                 {'loss': 0.8552, 'grad_norm': 0.46572446487783353, 'learning_rate': 1.2242225859247134e-06, 'epoch': 1.22}
 41%|████      | 257/630 [03:37<05:07,  1.21it/s] 41%|████      | 258/630 [03:38<05:04,  1.22it/s]                                                 {'loss': 0.8195, 'grad_norm': 0.36873254977719716, 'learning_rate': 1.220949263502455e-06, 'epoch': 1.23}
 41%|████      | 258/630 [03:38<05:04,  1.22it/s] 41%|████      | 259/630 [03:39<05:02,  1.23it/s]                                                 {'loss': 0.9063, 'grad_norm': 0.36167059632017023, 'learning_rate': 1.2176759410801965e-06, 'epoch': 1.23}
 41%|████      | 259/630 [03:39<05:02,  1.23it/s] 41%|████▏     | 260/630 [03:40<05:00,  1.23it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.41786658997726206, 'learning_rate': 1.2144026186579376e-06, 'epoch': 1.24}
 41%|████▏     | 260/630 [03:40<05:00,  1.23it/s] 41%|████▏     | 261/630 [03:41<04:59,  1.23it/s]                                                 {'loss': 0.8324, 'grad_norm': 0.42070420194404284, 'learning_rate': 1.2111292962356792e-06, 'epoch': 1.24}
 41%|████▏     | 261/630 [03:41<04:59,  1.23it/s] 42%|████▏     | 262/630 [03:41<04:58,  1.23it/s]                                                 {'loss': 0.9091, 'grad_norm': 0.3288454883750145, 'learning_rate': 1.2078559738134207e-06, 'epoch': 1.25}
 42%|████▏     | 262/630 [03:41<04:58,  1.23it/s] 42%|████▏     | 263/630 [03:42<04:57,  1.24it/s]                                                 {'loss': 0.8304, 'grad_norm': 0.46087567726438383, 'learning_rate': 1.2045826513911619e-06, 'epoch': 1.25}
 42%|████▏     | 263/630 [03:42<04:57,  1.24it/s] 42%|████▏     | 264/630 [03:43<04:56,  1.23it/s]                                                 {'loss': 0.7911, 'grad_norm': 0.44344014824201083, 'learning_rate': 1.2013093289689034e-06, 'epoch': 1.26}
 42%|████▏     | 264/630 [03:43<04:56,  1.23it/s] 42%|████▏     | 265/630 [03:44<04:56,  1.23it/s]                                                 {'loss': 0.811, 'grad_norm': 0.29260322356061197, 'learning_rate': 1.1980360065466447e-06, 'epoch': 1.26}
 42%|████▏     | 265/630 [03:44<04:56,  1.23it/s] 42%|████▏     | 266/630 [03:45<04:55,  1.23it/s]                                                 {'loss': 0.8271, 'grad_norm': 0.3313243558486019, 'learning_rate': 1.1947626841243863e-06, 'epoch': 1.27}
 42%|████▏     | 266/630 [03:45<04:55,  1.23it/s] 42%|████▏     | 267/630 [03:45<04:54,  1.23it/s]                                                 {'loss': 0.7869, 'grad_norm': 0.3591280845421625, 'learning_rate': 1.1914893617021276e-06, 'epoch': 1.27}
 42%|████▏     | 267/630 [03:45<04:54,  1.23it/s] 43%|████▎     | 268/630 [03:46<04:54,  1.23it/s]                                                 {'loss': 0.8614, 'grad_norm': 0.341822695609594, 'learning_rate': 1.188216039279869e-06, 'epoch': 1.28}
 43%|████▎     | 268/630 [03:46<04:54,  1.23it/s] 43%|████▎     | 269/630 [03:47<04:53,  1.23it/s]                                                 {'loss': 0.9135, 'grad_norm': 0.40147095918229586, 'learning_rate': 1.1849427168576105e-06, 'epoch': 1.28}
 43%|████▎     | 269/630 [03:47<04:53,  1.23it/s] 43%|████▎     | 270/630 [03:48<04:52,  1.23it/s]                                                 {'loss': 0.8037, 'grad_norm': 0.42535473426276976, 'learning_rate': 1.1816693944353518e-06, 'epoch': 1.29}
 43%|████▎     | 270/630 [03:48<04:52,  1.23it/s] 43%|████▎     | 271/630 [03:49<04:51,  1.23it/s]                                                 {'loss': 0.8324, 'grad_norm': 0.40761139214351516, 'learning_rate': 1.1783960720130932e-06, 'epoch': 1.29}
 43%|████▎     | 271/630 [03:49<04:51,  1.23it/s] 43%|████▎     | 272/630 [03:49<04:50,  1.23it/s]                                                 {'loss': 0.9002, 'grad_norm': 0.5027982915859435, 'learning_rate': 1.1751227495908347e-06, 'epoch': 1.3}
 43%|████▎     | 272/630 [03:49<04:50,  1.23it/s] 43%|████▎     | 273/630 [03:50<04:50,  1.23it/s]                                                 {'loss': 0.8768, 'grad_norm': 0.4378110801823445, 'learning_rate': 1.171849427168576e-06, 'epoch': 1.3}
 43%|████▎     | 273/630 [03:50<04:50,  1.23it/s] 43%|████▎     | 274/630 [03:51<04:48,  1.23it/s]                                                 {'loss': 0.8355, 'grad_norm': 0.392150403440569, 'learning_rate': 1.1685761047463174e-06, 'epoch': 1.3}
 43%|████▎     | 274/630 [03:51<04:48,  1.23it/s] 44%|████▎     | 275/630 [03:52<04:47,  1.23it/s]                                                 {'loss': 0.8686, 'grad_norm': 0.45796428863640487, 'learning_rate': 1.165302782324059e-06, 'epoch': 1.31}
 44%|████▎     | 275/630 [03:52<04:47,  1.23it/s] 44%|████▍     | 276/630 [03:53<04:46,  1.23it/s]                                                 {'loss': 0.7913, 'grad_norm': 0.4431405675432787, 'learning_rate': 1.1620294599018003e-06, 'epoch': 1.31}
 44%|████▍     | 276/630 [03:53<04:46,  1.23it/s] 44%|████▍     | 277/630 [03:54<04:46,  1.23it/s]                                                 {'loss': 0.8215, 'grad_norm': 0.4071276015447723, 'learning_rate': 1.1587561374795416e-06, 'epoch': 1.32}
 44%|████▍     | 277/630 [03:54<04:46,  1.23it/s] 44%|████▍     | 278/630 [03:54<04:45,  1.23it/s]                                                 {'loss': 0.8891, 'grad_norm': 0.4704583770419964, 'learning_rate': 1.1554828150572832e-06, 'epoch': 1.32}
 44%|████▍     | 278/630 [03:54<04:45,  1.23it/s] 44%|████▍     | 279/630 [03:55<04:44,  1.23it/s]                                                 {'loss': 0.7883, 'grad_norm': 0.3388857822163243, 'learning_rate': 1.1522094926350245e-06, 'epoch': 1.33}
 44%|████▍     | 279/630 [03:55<04:44,  1.23it/s] 44%|████▍     | 280/630 [03:56<04:43,  1.23it/s]                                                 {'loss': 0.8456, 'grad_norm': 0.3769353776353876, 'learning_rate': 1.148936170212766e-06, 'epoch': 1.33}
 44%|████▍     | 280/630 [03:56<04:43,  1.23it/s] 45%|████▍     | 281/630 [03:57<04:43,  1.23it/s]                                                 {'loss': 0.8343, 'grad_norm': 0.358143796979921, 'learning_rate': 1.1456628477905072e-06, 'epoch': 1.34}
 45%|████▍     | 281/630 [03:57<04:43,  1.23it/s] 45%|████▍     | 282/630 [03:58<04:42,  1.23it/s]                                                 {'loss': 0.866, 'grad_norm': 0.4583521205746951, 'learning_rate': 1.1423895253682487e-06, 'epoch': 1.34}
 45%|████▍     | 282/630 [03:58<04:42,  1.23it/s] 45%|████▍     | 283/630 [03:58<04:41,  1.23it/s]                                                 {'loss': 0.8969, 'grad_norm': 0.438213466163312, 'learning_rate': 1.1391162029459903e-06, 'epoch': 1.35}
 45%|████▍     | 283/630 [03:58<04:41,  1.23it/s] 45%|████▌     | 284/630 [03:59<04:41,  1.23it/s]                                                 {'loss': 0.8159, 'grad_norm': 0.3068495346585148, 'learning_rate': 1.1358428805237314e-06, 'epoch': 1.35}
 45%|████▌     | 284/630 [03:59<04:41,  1.23it/s] 45%|████▌     | 285/630 [04:00<04:40,  1.23it/s]                                                 {'loss': 0.7983, 'grad_norm': 0.36505389167433605, 'learning_rate': 1.132569558101473e-06, 'epoch': 1.36}
 45%|████▌     | 285/630 [04:00<04:40,  1.23it/s] 45%|████▌     | 286/630 [04:01<04:39,  1.23it/s]                                                 {'loss': 0.8038, 'grad_norm': 0.3719411551709639, 'learning_rate': 1.1292962356792145e-06, 'epoch': 1.36}
 45%|████▌     | 286/630 [04:01<04:39,  1.23it/s] 46%|████▌     | 287/630 [04:02<04:37,  1.23it/s]                                                 {'loss': 0.9197, 'grad_norm': 0.37559955787251353, 'learning_rate': 1.1260229132569558e-06, 'epoch': 1.37}
 46%|████▌     | 287/630 [04:02<04:37,  1.23it/s] 46%|████▌     | 288/630 [04:02<04:36,  1.24it/s]                                                 {'loss': 0.7601, 'grad_norm': 0.3588908993449578, 'learning_rate': 1.1227495908346971e-06, 'epoch': 1.37}
 46%|████▌     | 288/630 [04:02<04:36,  1.24it/s] 46%|████▌     | 289/630 [04:03<04:36,  1.23it/s]                                                 {'loss': 0.8262, 'grad_norm': 0.35350827260855605, 'learning_rate': 1.1194762684124387e-06, 'epoch': 1.38}
 46%|████▌     | 289/630 [04:03<04:36,  1.23it/s] 46%|████▌     | 290/630 [04:04<04:35,  1.23it/s]                                                 {'loss': 0.7994, 'grad_norm': 0.371079433465273, 'learning_rate': 1.11620294599018e-06, 'epoch': 1.38}
 46%|████▌     | 290/630 [04:04<04:35,  1.23it/s] 46%|████▌     | 291/630 [04:05<04:35,  1.23it/s]                                                 {'loss': 0.7779, 'grad_norm': 0.5000172881188555, 'learning_rate': 1.1129296235679214e-06, 'epoch': 1.39}
 46%|████▌     | 291/630 [04:05<04:35,  1.23it/s] 46%|████▋     | 292/630 [04:06<04:36,  1.22it/s]                                                 {'loss': 0.8371, 'grad_norm': 0.45451404081947844, 'learning_rate': 1.1096563011456627e-06, 'epoch': 1.39}
 46%|████▋     | 292/630 [04:06<04:36,  1.22it/s] 47%|████▋     | 293/630 [04:07<04:34,  1.23it/s]                                                 {'loss': 0.8691, 'grad_norm': 0.3800695614521161, 'learning_rate': 1.1063829787234042e-06, 'epoch': 1.4}
 47%|████▋     | 293/630 [04:07<04:34,  1.23it/s] 47%|████▋     | 294/630 [04:07<04:33,  1.23it/s]                                                 {'loss': 0.8276, 'grad_norm': 0.40103004296113554, 'learning_rate': 1.1031096563011458e-06, 'epoch': 1.4}
 47%|████▋     | 294/630 [04:07<04:33,  1.23it/s] 47%|████▋     | 295/630 [04:08<04:32,  1.23it/s]                                                 {'loss': 0.7695, 'grad_norm': 0.3241932461859025, 'learning_rate': 1.099836333878887e-06, 'epoch': 1.4}
 47%|████▋     | 295/630 [04:08<04:32,  1.23it/s] 47%|████▋     | 296/630 [04:09<04:31,  1.23it/s]                                                 {'loss': 0.7908, 'grad_norm': 0.3474927303569449, 'learning_rate': 1.0965630114566285e-06, 'epoch': 1.41}
 47%|████▋     | 296/630 [04:09<04:31,  1.23it/s] 47%|████▋     | 297/630 [04:10<04:30,  1.23it/s]                                                 {'loss': 0.8139, 'grad_norm': 0.38011160140746686, 'learning_rate': 1.09328968903437e-06, 'epoch': 1.41}
 47%|████▋     | 297/630 [04:10<04:30,  1.23it/s] 47%|████▋     | 298/630 [04:11<04:29,  1.23it/s]                                                 {'loss': 0.812, 'grad_norm': 0.42698177574381785, 'learning_rate': 1.0900163666121111e-06, 'epoch': 1.42}
 47%|████▋     | 298/630 [04:11<04:29,  1.23it/s] 47%|████▋     | 299/630 [04:11<04:28,  1.23it/s]                                                 {'loss': 0.7935, 'grad_norm': 0.3415238982246422, 'learning_rate': 1.0867430441898527e-06, 'epoch': 1.42}
 47%|████▋     | 299/630 [04:11<04:28,  1.23it/s] 48%|████▊     | 300/630 [04:12<04:27,  1.24it/s]                                                 {'loss': 0.8666, 'grad_norm': 0.41234888290896415, 'learning_rate': 1.083469721767594e-06, 'epoch': 1.43}
 48%|████▊     | 300/630 [04:12<04:27,  1.24it/s] 48%|████▊     | 301/630 [04:13<04:26,  1.23it/s]                                                 {'loss': 0.8299, 'grad_norm': 0.36277910365923255, 'learning_rate': 1.0801963993453356e-06, 'epoch': 1.43}
 48%|████▊     | 301/630 [04:13<04:26,  1.23it/s] 48%|████▊     | 302/630 [04:14<04:26,  1.23it/s]                                                 {'loss': 0.8102, 'grad_norm': 0.3693881606326963, 'learning_rate': 1.0769230769230769e-06, 'epoch': 1.44}
 48%|████▊     | 302/630 [04:14<04:26,  1.23it/s] 48%|████▊     | 303/630 [04:15<04:25,  1.23it/s]                                                 {'loss': 0.8529, 'grad_norm': 0.3940218674548388, 'learning_rate': 1.0736497545008182e-06, 'epoch': 1.44}
 48%|████▊     | 303/630 [04:15<04:25,  1.23it/s] 48%|████▊     | 304/630 [04:15<04:24,  1.23it/s]                                                 {'loss': 0.8377, 'grad_norm': 0.41597244862213295, 'learning_rate': 1.0703764320785598e-06, 'epoch': 1.45}
 48%|████▊     | 304/630 [04:15<04:24,  1.23it/s] 48%|████▊     | 305/630 [04:16<04:23,  1.23it/s]                                                 {'loss': 0.8346, 'grad_norm': 0.3851334753307598, 'learning_rate': 1.0671031096563011e-06, 'epoch': 1.45}
 48%|████▊     | 305/630 [04:16<04:23,  1.23it/s] 49%|████▊     | 306/630 [04:17<04:22,  1.23it/s]                                                 {'loss': 0.8489, 'grad_norm': 0.4302426890340254, 'learning_rate': 1.0638297872340424e-06, 'epoch': 1.46}
 49%|████▊     | 306/630 [04:17<04:22,  1.23it/s] 49%|████▊     | 307/630 [04:18<04:22,  1.23it/s]                                                 {'loss': 0.8684, 'grad_norm': 0.469703091971401, 'learning_rate': 1.060556464811784e-06, 'epoch': 1.46}
 49%|████▊     | 307/630 [04:18<04:22,  1.23it/s] 49%|████▉     | 308/630 [04:19<04:20,  1.23it/s]                                                 {'loss': 0.7455, 'grad_norm': 0.37303173295207664, 'learning_rate': 1.0572831423895253e-06, 'epoch': 1.47}
 49%|████▉     | 308/630 [04:19<04:20,  1.23it/s] 49%|████▉     | 309/630 [04:20<04:19,  1.24it/s]                                                 {'loss': 0.7827, 'grad_norm': 0.5188191140382142, 'learning_rate': 1.0540098199672667e-06, 'epoch': 1.47}
 49%|████▉     | 309/630 [04:20<04:19,  1.24it/s] 49%|████▉     | 310/630 [04:20<04:18,  1.24it/s]                                                 {'loss': 0.8271, 'grad_norm': 0.39793448841179124, 'learning_rate': 1.0507364975450082e-06, 'epoch': 1.48}
 49%|████▉     | 310/630 [04:20<04:18,  1.24it/s] 49%|████▉     | 311/630 [04:21<04:17,  1.24it/s]                                                 {'loss': 0.8712, 'grad_norm': 0.5791477793161717, 'learning_rate': 1.0474631751227495e-06, 'epoch': 1.48}
 49%|████▉     | 311/630 [04:21<04:17,  1.24it/s] 50%|████▉     | 312/630 [04:22<04:17,  1.23it/s]                                                 {'loss': 0.7685, 'grad_norm': 0.3811538940922505, 'learning_rate': 1.0441898527004909e-06, 'epoch': 1.49}
 50%|████▉     | 312/630 [04:22<04:17,  1.23it/s] 50%|████▉     | 313/630 [04:23<04:16,  1.24it/s]                                                 {'loss': 0.8285, 'grad_norm': 0.5420962916496823, 'learning_rate': 1.0409165302782324e-06, 'epoch': 1.49}
 50%|████▉     | 313/630 [04:23<04:16,  1.24it/s] 50%|████▉     | 314/630 [04:24<04:15,  1.23it/s]                                                 {'loss': 0.774, 'grad_norm': 0.32714268961867615, 'learning_rate': 1.0376432078559738e-06, 'epoch': 1.5}
 50%|████▉     | 314/630 [04:24<04:15,  1.23it/s] 50%|█████     | 315/630 [04:24<04:14,  1.24it/s]                                                 {'loss': 0.7881, 'grad_norm': 0.3696740632959761, 'learning_rate': 1.0343698854337153e-06, 'epoch': 1.5}
 50%|█████     | 315/630 [04:24<04:14,  1.24it/s] 50%|█████     | 316/630 [04:25<04:14,  1.23it/s]                                                 {'loss': 0.7733, 'grad_norm': 0.327332540694956, 'learning_rate': 1.0310965630114566e-06, 'epoch': 1.5}
 50%|█████     | 316/630 [04:25<04:14,  1.23it/s] 50%|█████     | 317/630 [04:26<04:14,  1.23it/s]                                                 {'loss': 0.7647, 'grad_norm': 0.352187388340621, 'learning_rate': 1.027823240589198e-06, 'epoch': 1.51}
 50%|█████     | 317/630 [04:26<04:14,  1.23it/s] 50%|█████     | 318/630 [04:27<04:13,  1.23it/s]                                                 {'loss': 0.8268, 'grad_norm': 0.43932909291297645, 'learning_rate': 1.0245499181669395e-06, 'epoch': 1.51}
 50%|█████     | 318/630 [04:27<04:13,  1.23it/s] 51%|█████     | 319/630 [04:28<04:11,  1.23it/s]                                                 {'loss': 0.9241, 'grad_norm': 0.3703449441366466, 'learning_rate': 1.0212765957446806e-06, 'epoch': 1.52}
 51%|█████     | 319/630 [04:28<04:11,  1.23it/s] 51%|█████     | 320/630 [04:28<04:10,  1.24it/s]                                                 {'loss': 0.8741, 'grad_norm': 0.5034885627147523, 'learning_rate': 1.0180032733224222e-06, 'epoch': 1.52}
 51%|█████     | 320/630 [04:28<04:10,  1.24it/s] 51%|█████     | 321/630 [04:29<04:11,  1.23it/s]                                                 {'loss': 0.9038, 'grad_norm': 0.5591096906407732, 'learning_rate': 1.0147299509001637e-06, 'epoch': 1.53}
 51%|█████     | 321/630 [04:29<04:11,  1.23it/s] 51%|█████     | 322/630 [04:30<04:09,  1.23it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.42400230176060116, 'learning_rate': 1.011456628477905e-06, 'epoch': 1.53}
 51%|█████     | 322/630 [04:30<04:09,  1.23it/s] 51%|█████▏    | 323/630 [04:31<04:08,  1.23it/s]                                                 {'loss': 0.8204, 'grad_norm': 0.4292295271260246, 'learning_rate': 1.0081833060556464e-06, 'epoch': 1.54}
 51%|█████▏    | 323/630 [04:31<04:08,  1.23it/s] 51%|█████▏    | 324/630 [04:32<04:08,  1.23it/s]                                                 {'loss': 0.8549, 'grad_norm': 0.39918618146945817, 'learning_rate': 1.004909983633388e-06, 'epoch': 1.54}
 51%|█████▏    | 324/630 [04:32<04:08,  1.23it/s] 52%|█████▏    | 325/630 [04:32<04:07,  1.23it/s]                                                 {'loss': 0.716, 'grad_norm': 0.43950744904843975, 'learning_rate': 1.0016366612111293e-06, 'epoch': 1.55}
 52%|█████▏    | 325/630 [04:32<04:07,  1.23it/s] 52%|█████▏    | 326/630 [04:33<04:06,  1.23it/s]                                                 {'loss': 0.823, 'grad_norm': 0.38415023982417434, 'learning_rate': 9.983633387888706e-07, 'epoch': 1.55}
 52%|█████▏    | 326/630 [04:33<04:06,  1.23it/s] 52%|█████▏    | 327/630 [04:34<04:05,  1.24it/s]                                                 {'loss': 0.8084, 'grad_norm': 0.43173540191221577, 'learning_rate': 9.95090016366612e-07, 'epoch': 1.56}
 52%|█████▏    | 327/630 [04:34<04:05,  1.24it/s] 52%|█████▏    | 328/630 [04:35<04:04,  1.24it/s]                                                 {'loss': 0.7783, 'grad_norm': 0.32875625826512694, 'learning_rate': 9.918166939443535e-07, 'epoch': 1.56}
 52%|█████▏    | 328/630 [04:35<04:04,  1.24it/s] 52%|█████▏    | 329/630 [04:36<04:03,  1.24it/s]                                                 {'loss': 0.8246, 'grad_norm': 0.39298213317387415, 'learning_rate': 9.885433715220948e-07, 'epoch': 1.57}
 52%|█████▏    | 329/630 [04:36<04:03,  1.24it/s] 52%|█████▏    | 330/630 [04:37<04:03,  1.23it/s]                                                 {'loss': 0.988, 'grad_norm': 0.48865526589601666, 'learning_rate': 9.852700490998362e-07, 'epoch': 1.57}
 52%|█████▏    | 330/630 [04:37<04:03,  1.23it/s] 53%|█████▎    | 331/630 [04:37<04:02,  1.23it/s]                                                 {'loss': 0.7797, 'grad_norm': 0.40336427979432127, 'learning_rate': 9.819967266775777e-07, 'epoch': 1.58}
 53%|█████▎    | 331/630 [04:37<04:02,  1.23it/s] 53%|█████▎    | 332/630 [04:38<04:02,  1.23it/s]                                                 {'loss': 0.8391, 'grad_norm': 0.40204178529201406, 'learning_rate': 9.78723404255319e-07, 'epoch': 1.58}
 53%|█████▎    | 332/630 [04:38<04:02,  1.23it/s] 53%|█████▎    | 333/630 [04:39<04:01,  1.23it/s]                                                 {'loss': 0.8231, 'grad_norm': 0.3399349342698663, 'learning_rate': 9.754500818330606e-07, 'epoch': 1.59}
 53%|█████▎    | 333/630 [04:39<04:01,  1.23it/s] 53%|█████▎    | 334/630 [04:40<04:00,  1.23it/s]                                                 {'loss': 0.8007, 'grad_norm': 0.4133581003482721, 'learning_rate': 9.72176759410802e-07, 'epoch': 1.59}
 53%|█████▎    | 334/630 [04:40<04:00,  1.23it/s] 53%|█████▎    | 335/630 [04:41<03:59,  1.23it/s]                                                 {'loss': 0.79, 'grad_norm': 0.38955993223941365, 'learning_rate': 9.689034369885433e-07, 'epoch': 1.6}
 53%|█████▎    | 335/630 [04:41<03:59,  1.23it/s] 53%|█████▎    | 336/630 [04:41<03:59,  1.23it/s]                                                 {'loss': 0.7832, 'grad_norm': 0.32710827093234707, 'learning_rate': 9.656301145662848e-07, 'epoch': 1.6}
 53%|█████▎    | 336/630 [04:41<03:59,  1.23it/s] 53%|█████▎    | 337/630 [04:42<03:58,  1.23it/s]                                                 {'loss': 0.8608, 'grad_norm': 0.5393547377135749, 'learning_rate': 9.623567921440262e-07, 'epoch': 1.6}
 53%|█████▎    | 337/630 [04:42<03:58,  1.23it/s] 54%|█████▎    | 338/630 [04:43<03:57,  1.23it/s]                                                 {'loss': 0.8465, 'grad_norm': 0.405391165941711, 'learning_rate': 9.590834697217675e-07, 'epoch': 1.61}
 54%|█████▎    | 338/630 [04:43<03:57,  1.23it/s] 54%|█████▍    | 339/630 [04:44<03:56,  1.23it/s]                                                 {'loss': 0.8109, 'grad_norm': 0.2983724748741166, 'learning_rate': 9.55810147299509e-07, 'epoch': 1.61}
 54%|█████▍    | 339/630 [04:44<03:56,  1.23it/s] 54%|█████▍    | 340/630 [04:45<03:56,  1.23it/s]                                                 {'loss': 0.8005, 'grad_norm': 0.3707610656693875, 'learning_rate': 9.525368248772504e-07, 'epoch': 1.62}
 54%|█████▍    | 340/630 [04:45<03:56,  1.23it/s] 54%|█████▍    | 341/630 [04:45<03:55,  1.23it/s]                                                 {'loss': 0.7999, 'grad_norm': 0.38737888083995614, 'learning_rate': 9.492635024549918e-07, 'epoch': 1.62}
 54%|█████▍    | 341/630 [04:46<03:55,  1.23it/s] 54%|█████▍    | 342/630 [04:46<03:54,  1.23it/s]                                                 {'loss': 0.8366, 'grad_norm': 0.3995298818172109, 'learning_rate': 9.459901800327333e-07, 'epoch': 1.63}
 54%|█████▍    | 342/630 [04:46<03:54,  1.23it/s] 54%|█████▍    | 343/630 [04:47<03:53,  1.23it/s]                                                 {'loss': 0.821, 'grad_norm': 0.39936971683914907, 'learning_rate': 9.427168576104746e-07, 'epoch': 1.63}
 54%|█████▍    | 343/630 [04:47<03:53,  1.23it/s] 55%|█████▍    | 344/630 [04:48<03:52,  1.23it/s]                                                 {'loss': 0.8207, 'grad_norm': 0.4806208194684392, 'learning_rate': 9.394435351882159e-07, 'epoch': 1.64}
 55%|█████▍    | 344/630 [04:48<03:52,  1.23it/s] 55%|█████▍    | 345/630 [04:49<03:51,  1.23it/s]                                                 {'loss': 0.8043, 'grad_norm': 0.5017586505689543, 'learning_rate': 9.361702127659575e-07, 'epoch': 1.64}
 55%|█████▍    | 345/630 [04:49<03:51,  1.23it/s] 55%|█████▍    | 346/630 [04:50<03:51,  1.23it/s]                                                 {'loss': 0.824, 'grad_norm': 0.47042107441166536, 'learning_rate': 9.328968903436988e-07, 'epoch': 1.65}
 55%|█████▍    | 346/630 [04:50<03:51,  1.23it/s] 55%|█████▌    | 347/630 [04:50<03:50,  1.23it/s]                                                 {'loss': 0.8473, 'grad_norm': 0.31881253945294996, 'learning_rate': 9.296235679214402e-07, 'epoch': 1.65}
 55%|█████▌    | 347/630 [04:50<03:50,  1.23it/s] 55%|█████▌    | 348/630 [04:51<03:49,  1.23it/s]                                                 {'loss': 0.878, 'grad_norm': 0.48674044105076264, 'learning_rate': 9.263502454991816e-07, 'epoch': 1.66}
 55%|█████▌    | 348/630 [04:51<03:49,  1.23it/s] 55%|█████▌    | 349/630 [04:52<03:48,  1.23it/s]                                                 {'loss': 0.8079, 'grad_norm': 0.4050783499304487, 'learning_rate': 9.230769230769231e-07, 'epoch': 1.66}
 55%|█████▌    | 349/630 [04:52<03:48,  1.23it/s] 56%|█████▌    | 350/630 [04:53<03:47,  1.23it/s]                                                 {'loss': 0.8316, 'grad_norm': 0.41502057477303256, 'learning_rate': 9.198036006546645e-07, 'epoch': 1.67}
 56%|█████▌    | 350/630 [04:53<03:47,  1.23it/s] 56%|█████▌    | 351/630 [04:54<03:46,  1.23it/s]                                                 {'loss': 0.8283, 'grad_norm': 0.3694512368877155, 'learning_rate': 9.165302782324058e-07, 'epoch': 1.67}
 56%|█████▌    | 351/630 [04:54<03:46,  1.23it/s] 56%|█████▌    | 352/630 [04:54<03:45,  1.23it/s]                                                 {'loss': 0.7485, 'grad_norm': 0.30128084235926184, 'learning_rate': 9.132569558101472e-07, 'epoch': 1.68}
 56%|█████▌    | 352/630 [04:54<03:45,  1.23it/s] 56%|█████▌    | 353/630 [04:55<03:44,  1.23it/s]                                                 {'loss': 0.7545, 'grad_norm': 0.29361398489953466, 'learning_rate': 9.099836333878887e-07, 'epoch': 1.68}
 56%|█████▌    | 353/630 [04:55<03:44,  1.23it/s] 56%|█████▌    | 354/630 [04:56<03:44,  1.23it/s]                                                 {'loss': 0.7486, 'grad_norm': 0.3663730395661425, 'learning_rate': 9.067103109656301e-07, 'epoch': 1.69}
 56%|█████▌    | 354/630 [04:56<03:44,  1.23it/s] 56%|█████▋    | 355/630 [04:57<03:42,  1.23it/s]                                                 {'loss': 0.7689, 'grad_norm': 0.3335706000709268, 'learning_rate': 9.034369885433715e-07, 'epoch': 1.69}
 56%|█████▋    | 355/630 [04:57<03:42,  1.23it/s] 57%|█████▋    | 356/630 [04:58<03:42,  1.23it/s]                                                 {'loss': 0.7438, 'grad_norm': 0.3833433161243749, 'learning_rate': 9.001636661211129e-07, 'epoch': 1.7}
 57%|█████▋    | 356/630 [04:58<03:42,  1.23it/s] 57%|█████▋    | 357/630 [04:58<03:41,  1.23it/s]                                                 {'loss': 0.7932, 'grad_norm': 0.34224939133216903, 'learning_rate': 8.968903436988543e-07, 'epoch': 1.7}
 57%|█████▋    | 357/630 [04:58<03:41,  1.23it/s] 57%|█████▋    | 358/630 [04:59<03:40,  1.23it/s]                                                 {'loss': 0.8388, 'grad_norm': 0.3630549421171047, 'learning_rate': 8.936170212765957e-07, 'epoch': 1.7}
 57%|█████▋    | 358/630 [04:59<03:40,  1.23it/s] 57%|█████▋    | 359/630 [05:00<03:40,  1.23it/s]                                                 {'loss': 0.84, 'grad_norm': 0.3616630078346393, 'learning_rate': 8.903436988543371e-07, 'epoch': 1.71}
 57%|█████▋    | 359/630 [05:00<03:40,  1.23it/s] 57%|█████▋    | 360/630 [05:01<03:39,  1.23it/s]                                                 {'loss': 0.7017, 'grad_norm': 0.3094188518961372, 'learning_rate': 8.870703764320784e-07, 'epoch': 1.71}
 57%|█████▋    | 360/630 [05:01<03:39,  1.23it/s] 57%|█████▋    | 361/630 [05:02<03:38,  1.23it/s]                                                 {'loss': 0.7499, 'grad_norm': 0.3450549564754422, 'learning_rate': 8.8379705400982e-07, 'epoch': 1.72}
 57%|█████▋    | 361/630 [05:02<03:38,  1.23it/s] 57%|█████▋    | 362/630 [05:03<03:38,  1.23it/s]                                                 {'loss': 0.8528, 'grad_norm': 0.4239673239306594, 'learning_rate': 8.805237315875613e-07, 'epoch': 1.72}
 57%|█████▋    | 362/630 [05:03<03:38,  1.23it/s] 58%|█████▊    | 363/630 [05:03<03:41,  1.21it/s]                                                 {'loss': 0.8314, 'grad_norm': 0.4279726838453632, 'learning_rate': 8.772504091653028e-07, 'epoch': 1.73}
 58%|█████▊    | 363/630 [05:03<03:41,  1.21it/s] 58%|█████▊    | 364/630 [05:04<03:38,  1.21it/s]                                                 {'loss': 0.8407, 'grad_norm': 0.390659533053755, 'learning_rate': 8.739770867430442e-07, 'epoch': 1.73}
 58%|█████▊    | 364/630 [05:04<03:38,  1.21it/s] 58%|█████▊    | 365/630 [05:05<03:37,  1.22it/s]                                                 {'loss': 0.8065, 'grad_norm': 0.3344707939128448, 'learning_rate': 8.707037643207855e-07, 'epoch': 1.74}
 58%|█████▊    | 365/630 [05:05<03:37,  1.22it/s] 58%|█████▊    | 366/630 [05:06<03:35,  1.23it/s]                                                 {'loss': 0.8189, 'grad_norm': 0.4120684352023821, 'learning_rate': 8.67430441898527e-07, 'epoch': 1.74}
 58%|█████▊    | 366/630 [05:06<03:35,  1.23it/s] 58%|█████▊    | 367/630 [05:07<03:34,  1.23it/s]                                                 {'loss': 0.6715, 'grad_norm': 0.31353371172752986, 'learning_rate': 8.641571194762683e-07, 'epoch': 1.75}
 58%|█████▊    | 367/630 [05:07<03:34,  1.23it/s] 58%|█████▊    | 368/630 [05:07<03:33,  1.23it/s]                                                 {'loss': 0.7722, 'grad_norm': 0.2741792385348348, 'learning_rate': 8.608837970540099e-07, 'epoch': 1.75}
 58%|█████▊    | 368/630 [05:07<03:33,  1.23it/s] 59%|█████▊    | 369/630 [05:08<03:31,  1.23it/s]                                                 {'loss': 0.7986, 'grad_norm': 0.3721332451459715, 'learning_rate': 8.576104746317512e-07, 'epoch': 1.76}
 59%|█████▊    | 369/630 [05:08<03:31,  1.23it/s] 59%|█████▊    | 370/630 [05:09<03:30,  1.23it/s]                                                 {'loss': 0.6842, 'grad_norm': 0.3226190474511298, 'learning_rate': 8.543371522094926e-07, 'epoch': 1.76}
 59%|█████▊    | 370/630 [05:09<03:30,  1.23it/s] 59%|█████▉    | 371/630 [05:10<03:29,  1.23it/s]                                                 {'loss': 0.8314, 'grad_norm': 0.27104559374077075, 'learning_rate': 8.51063829787234e-07, 'epoch': 1.77}
 59%|█████▉    | 371/630 [05:10<03:29,  1.23it/s] 59%|█████▉    | 372/630 [05:11<03:28,  1.24it/s]                                                 {'loss': 0.8409, 'grad_norm': 0.3139278243353497, 'learning_rate': 8.477905073649754e-07, 'epoch': 1.77}
 59%|█████▉    | 372/630 [05:11<03:28,  1.24it/s] 59%|█████▉    | 373/630 [05:12<03:28,  1.23it/s]                                                 {'loss': 0.8001, 'grad_norm': 0.31954626317661655, 'learning_rate': 8.445171849427169e-07, 'epoch': 1.78}
 59%|█████▉    | 373/630 [05:12<03:28,  1.23it/s] 59%|█████▉    | 374/630 [05:12<03:27,  1.23it/s]                                                 {'loss': 0.8152, 'grad_norm': 0.3598281867814551, 'learning_rate': 8.412438625204582e-07, 'epoch': 1.78}
 59%|█████▉    | 374/630 [05:12<03:27,  1.23it/s] 60%|█████▉    | 375/630 [05:13<03:26,  1.23it/s]                                                 {'loss': 0.8014, 'grad_norm': 0.3584543596793135, 'learning_rate': 8.379705400981996e-07, 'epoch': 1.79}
 60%|█████▉    | 375/630 [05:13<03:26,  1.23it/s] 60%|█████▉    | 376/630 [05:14<03:25,  1.23it/s]                                                 {'loss': 0.7948, 'grad_norm': 0.32606562806450234, 'learning_rate': 8.346972176759411e-07, 'epoch': 1.79}
 60%|█████▉    | 376/630 [05:14<03:25,  1.23it/s] 60%|█████▉    | 377/630 [05:15<03:24,  1.23it/s]                                                 {'loss': 0.8379, 'grad_norm': 0.33403232516447867, 'learning_rate': 8.314238952536824e-07, 'epoch': 1.8}
 60%|█████▉    | 377/630 [05:15<03:24,  1.23it/s] 60%|██████    | 378/630 [05:16<03:24,  1.23it/s]                                                 {'loss': 0.7784, 'grad_norm': 0.35893173762239694, 'learning_rate': 8.281505728314238e-07, 'epoch': 1.8}
 60%|██████    | 378/630 [05:16<03:24,  1.23it/s] 60%|██████    | 379/630 [05:16<03:24,  1.23it/s]                                                 {'loss': 0.8379, 'grad_norm': 0.3671775681075343, 'learning_rate': 8.248772504091652e-07, 'epoch': 1.8}
 60%|██████    | 379/630 [05:16<03:24,  1.23it/s] 60%|██████    | 380/630 [05:17<03:23,  1.23it/s]                                                 {'loss': 0.804, 'grad_norm': 0.3384144087956771, 'learning_rate': 8.216039279869067e-07, 'epoch': 1.81}
 60%|██████    | 380/630 [05:17<03:23,  1.23it/s] 60%|██████    | 381/630 [05:18<03:22,  1.23it/s]                                                 {'loss': 0.8343, 'grad_norm': 0.34238170737995394, 'learning_rate': 8.183306055646481e-07, 'epoch': 1.81}
 60%|██████    | 381/630 [05:18<03:22,  1.23it/s] 61%|██████    | 382/630 [05:19<03:21,  1.23it/s]                                                 {'loss': 0.7723, 'grad_norm': 0.3017534196720058, 'learning_rate': 8.150572831423895e-07, 'epoch': 1.82}
 61%|██████    | 382/630 [05:19<03:21,  1.23it/s] 61%|██████    | 383/630 [05:20<03:19,  1.24it/s]                                                 {'loss': 0.7405, 'grad_norm': 0.3027435692012632, 'learning_rate': 8.117839607201308e-07, 'epoch': 1.82}
 61%|██████    | 383/630 [05:20<03:19,  1.24it/s] 61%|██████    | 384/630 [05:20<03:18,  1.24it/s]                                                 {'loss': 0.8374, 'grad_norm': 0.43402276130042156, 'learning_rate': 8.085106382978723e-07, 'epoch': 1.83}
 61%|██████    | 384/630 [05:20<03:18,  1.24it/s] 61%|██████    | 385/630 [05:21<03:18,  1.24it/s]                                                 {'loss': 0.7998, 'grad_norm': 0.6654864050372744, 'learning_rate': 8.052373158756137e-07, 'epoch': 1.83}
 61%|██████    | 385/630 [05:21<03:18,  1.24it/s] 61%|██████▏   | 386/630 [05:22<03:17,  1.24it/s]                                                 {'loss': 0.8464, 'grad_norm': 0.31066765430649607, 'learning_rate': 8.019639934533551e-07, 'epoch': 1.84}
 61%|██████▏   | 386/630 [05:22<03:17,  1.24it/s] 61%|██████▏   | 387/630 [05:23<03:16,  1.24it/s]                                                 {'loss': 0.8573, 'grad_norm': 0.5076409517872409, 'learning_rate': 7.986906710310966e-07, 'epoch': 1.84}
 61%|██████▏   | 387/630 [05:23<03:16,  1.24it/s] 62%|██████▏   | 388/630 [05:24<03:16,  1.23it/s]                                                 {'loss': 0.8497, 'grad_norm': 0.36608554158430573, 'learning_rate': 7.954173486088379e-07, 'epoch': 1.85}
 62%|██████▏   | 388/630 [05:24<03:16,  1.23it/s] 62%|██████▏   | 389/630 [05:24<03:15,  1.23it/s]                                                 {'loss': 0.8409, 'grad_norm': 0.3408782459594394, 'learning_rate': 7.921440261865794e-07, 'epoch': 1.85}
 62%|██████▏   | 389/630 [05:24<03:15,  1.23it/s] 62%|██████▏   | 390/630 [05:25<03:14,  1.23it/s]                                                 {'loss': 0.7782, 'grad_norm': 0.26589139351625474, 'learning_rate': 7.888707037643207e-07, 'epoch': 1.86}
 62%|██████▏   | 390/630 [05:25<03:14,  1.23it/s] 62%|██████▏   | 391/630 [05:26<03:14,  1.23it/s]                                                 {'loss': 0.8263, 'grad_norm': 0.2662460665125482, 'learning_rate': 7.855973813420622e-07, 'epoch': 1.86}
 62%|██████▏   | 391/630 [05:26<03:14,  1.23it/s] 62%|██████▏   | 392/630 [05:27<03:13,  1.23it/s]                                                 {'loss': 0.764, 'grad_norm': 0.36655387407631623, 'learning_rate': 7.823240589198036e-07, 'epoch': 1.87}
 62%|██████▏   | 392/630 [05:27<03:13,  1.23it/s] 62%|██████▏   | 393/630 [05:28<03:12,  1.23it/s]                                                 {'loss': 0.8944, 'grad_norm': 0.36870958374263746, 'learning_rate': 7.790507364975449e-07, 'epoch': 1.87}
 62%|██████▏   | 393/630 [05:28<03:12,  1.23it/s] 63%|██████▎   | 394/630 [05:29<03:11,  1.23it/s]                                                 {'loss': 0.8712, 'grad_norm': 0.3284825989443188, 'learning_rate': 7.757774140752864e-07, 'epoch': 1.88}
 63%|██████▎   | 394/630 [05:29<03:11,  1.23it/s] 63%|██████▎   | 395/630 [05:29<03:11,  1.23it/s]                                                 {'loss': 0.8307, 'grad_norm': 0.34659924928375174, 'learning_rate': 7.725040916530278e-07, 'epoch': 1.88}
 63%|██████▎   | 395/630 [05:29<03:11,  1.23it/s] 63%|██████▎   | 396/630 [05:30<03:10,  1.23it/s]                                                 {'loss': 0.7985, 'grad_norm': 0.6150763467545658, 'learning_rate': 7.692307692307693e-07, 'epoch': 1.89}
 63%|██████▎   | 396/630 [05:30<03:10,  1.23it/s] 63%|██████▎   | 397/630 [05:31<03:09,  1.23it/s]                                                 {'loss': 0.7556, 'grad_norm': 0.32359299883436343, 'learning_rate': 7.659574468085106e-07, 'epoch': 1.89}
 63%|██████▎   | 397/630 [05:31<03:09,  1.23it/s] 63%|██████▎   | 398/630 [05:32<03:08,  1.23it/s]                                                 {'loss': 0.7938, 'grad_norm': 0.27978638955593327, 'learning_rate': 7.626841243862519e-07, 'epoch': 1.9}
 63%|██████▎   | 398/630 [05:32<03:08,  1.23it/s] 63%|██████▎   | 399/630 [05:33<03:07,  1.23it/s]                                                 {'loss': 0.8377, 'grad_norm': 0.3269415892977318, 'learning_rate': 7.594108019639935e-07, 'epoch': 1.9}
 63%|██████▎   | 399/630 [05:33<03:07,  1.23it/s] 63%|██████▎   | 400/630 [05:33<03:06,  1.23it/s]                                                 {'loss': 0.7808, 'grad_norm': 0.33672207271186255, 'learning_rate': 7.561374795417348e-07, 'epoch': 1.9}
 63%|██████▎   | 400/630 [05:33<03:06,  1.23it/s] 64%|██████▎   | 401/630 [05:34<03:05,  1.23it/s]                                                 {'loss': 0.8576, 'grad_norm': 0.3511127027971123, 'learning_rate': 7.528641571194762e-07, 'epoch': 1.91}
 64%|██████▎   | 401/630 [05:34<03:05,  1.23it/s] 64%|██████▍   | 402/630 [05:35<03:05,  1.23it/s]                                                 {'loss': 0.7527, 'grad_norm': 0.2741204933860917, 'learning_rate': 7.495908346972176e-07, 'epoch': 1.91}
 64%|██████▍   | 402/630 [05:35<03:05,  1.23it/s] 64%|██████▍   | 403/630 [05:36<03:04,  1.23it/s]                                                 {'loss': 0.7909, 'grad_norm': 0.29898803683397496, 'learning_rate': 7.463175122749591e-07, 'epoch': 1.92}
 64%|██████▍   | 403/630 [05:36<03:04,  1.23it/s] 64%|██████▍   | 404/630 [05:37<03:03,  1.23it/s]                                                 {'loss': 0.7369, 'grad_norm': 0.2541335150980461, 'learning_rate': 7.430441898527005e-07, 'epoch': 1.92}
 64%|██████▍   | 404/630 [05:37<03:03,  1.23it/s] 64%|██████▍   | 405/630 [05:37<03:02,  1.23it/s]                                                 {'loss': 0.7662, 'grad_norm': 0.3271494748650401, 'learning_rate': 7.397708674304418e-07, 'epoch': 1.93}
 64%|██████▍   | 405/630 [05:37<03:02,  1.23it/s] 64%|██████▍   | 406/630 [05:38<03:01,  1.23it/s]                                                 {'loss': 0.7939, 'grad_norm': 0.2739219929980929, 'learning_rate': 7.364975450081832e-07, 'epoch': 1.93}
 64%|██████▍   | 406/630 [05:38<03:01,  1.23it/s] 65%|██████▍   | 407/630 [05:39<03:00,  1.23it/s]                                                 {'loss': 0.7545, 'grad_norm': 0.2860613842686831, 'learning_rate': 7.332242225859247e-07, 'epoch': 1.94}
 65%|██████▍   | 407/630 [05:39<03:00,  1.23it/s] 65%|██████▍   | 408/630 [05:40<03:00,  1.23it/s]                                                 {'loss': 0.7353, 'grad_norm': 0.25972052676369056, 'learning_rate': 7.299509001636661e-07, 'epoch': 1.94}
 65%|██████▍   | 408/630 [05:40<03:00,  1.23it/s] 65%|██████▍   | 409/630 [05:41<02:59,  1.23it/s]                                                 {'loss': 0.6986, 'grad_norm': 0.2939166866833392, 'learning_rate': 7.266775777414075e-07, 'epoch': 1.95}
 65%|██████▍   | 409/630 [05:41<02:59,  1.23it/s] 65%|██████▌   | 410/630 [05:42<02:58,  1.23it/s]                                                 {'loss': 0.8526, 'grad_norm': 0.34381662729039747, 'learning_rate': 7.23404255319149e-07, 'epoch': 1.95}
 65%|██████▌   | 410/630 [05:42<02:58,  1.23it/s] 65%|██████▌   | 411/630 [05:42<02:57,  1.23it/s]                                                 {'loss': 0.9112, 'grad_norm': 0.5137570095146586, 'learning_rate': 7.201309328968903e-07, 'epoch': 1.96}
 65%|██████▌   | 411/630 [05:42<02:57,  1.23it/s] 65%|██████▌   | 412/630 [05:43<02:57,  1.23it/s]                                                 {'loss': 0.7312, 'grad_norm': 0.30928598973207777, 'learning_rate': 7.168576104746317e-07, 'epoch': 1.96}
 65%|██████▌   | 412/630 [05:43<02:57,  1.23it/s] 66%|██████▌   | 413/630 [05:44<02:56,  1.23it/s]                                                 {'loss': 0.8058, 'grad_norm': 0.2600083255590448, 'learning_rate': 7.135842880523731e-07, 'epoch': 1.97}
 66%|██████▌   | 413/630 [05:44<02:56,  1.23it/s] 66%|██████▌   | 414/630 [05:45<02:55,  1.23it/s]                                                 {'loss': 0.7425, 'grad_norm': 0.3100711868948065, 'learning_rate': 7.103109656301146e-07, 'epoch': 1.97}
 66%|██████▌   | 414/630 [05:45<02:55,  1.23it/s] 66%|██████▌   | 415/630 [05:46<02:54,  1.23it/s]                                                 {'loss': 0.7652, 'grad_norm': 0.32836502895384423, 'learning_rate': 7.07037643207856e-07, 'epoch': 1.98}
 66%|██████▌   | 415/630 [05:46<02:54,  1.23it/s] 66%|██████▌   | 416/630 [05:46<02:53,  1.23it/s]                                                 {'loss': 0.7797, 'grad_norm': 0.31185611589211676, 'learning_rate': 7.037643207855973e-07, 'epoch': 1.98}
 66%|██████▌   | 416/630 [05:46<02:53,  1.23it/s] 66%|██████▌   | 417/630 [05:47<02:54,  1.22it/s]                                                 {'loss': 0.8212, 'grad_norm': 0.2873858430205478, 'learning_rate': 7.004909983633388e-07, 'epoch': 1.99}
 66%|██████▌   | 417/630 [05:47<02:54,  1.22it/s] 66%|██████▋   | 418/630 [05:48<02:52,  1.23it/s]                                                 {'loss': 0.8166, 'grad_norm': 0.3209460232006336, 'learning_rate': 6.972176759410802e-07, 'epoch': 1.99}
 66%|██████▋   | 418/630 [05:48<02:52,  1.23it/s] 67%|██████▋   | 419/630 [05:49<02:52,  1.23it/s]                                                 {'loss': 0.7703, 'grad_norm': 0.3615015889552767, 'learning_rate': 6.939443535188215e-07, 'epoch': 2.0}
 67%|██████▋   | 419/630 [05:49<02:52,  1.23it/s] 67%|██████▋   | 420/630 [05:50<02:51,  1.23it/s]                                                 {'loss': 0.7954, 'grad_norm': 0.353434795676784, 'learning_rate': 6.90671031096563e-07, 'epoch': 2.0}
 67%|██████▋   | 420/630 [05:50<02:51,  1.23it/s] 67%|██████▋   | 421/630 [05:51<02:50,  1.23it/s]                                                 {'loss': 0.7861, 'grad_norm': 0.2819114619355776, 'learning_rate': 6.873977086743043e-07, 'epoch': 2.0}
 67%|██████▋   | 421/630 [05:51<02:50,  1.23it/s] 67%|██████▋   | 422/630 [05:51<02:48,  1.23it/s]                                                 {'loss': 0.7891, 'grad_norm': 0.26184861441852286, 'learning_rate': 6.841243862520459e-07, 'epoch': 2.01}
 67%|██████▋   | 422/630 [05:51<02:48,  1.23it/s] 67%|██████▋   | 423/630 [05:52<02:48,  1.23it/s]                                                 {'loss': 0.7396, 'grad_norm': 0.2965155068228207, 'learning_rate': 6.808510638297872e-07, 'epoch': 2.01}
 67%|██████▋   | 423/630 [05:52<02:48,  1.23it/s] 67%|██████▋   | 424/630 [05:53<02:47,  1.23it/s]                                                 {'loss': 0.8463, 'grad_norm': 0.3182442398046206, 'learning_rate': 6.775777414075286e-07, 'epoch': 2.02}
 67%|██████▋   | 424/630 [05:53<02:47,  1.23it/s] 67%|██████▋   | 425/630 [05:54<02:46,  1.23it/s]                                                 {'loss': 0.8264, 'grad_norm': 0.410201855617189, 'learning_rate': 6.7430441898527e-07, 'epoch': 2.02}
 67%|██████▋   | 425/630 [05:54<02:46,  1.23it/s] 68%|██████▊   | 426/630 [05:55<02:46,  1.23it/s]                                                 {'loss': 0.7563, 'grad_norm': 0.25410760579367453, 'learning_rate': 6.710310965630114e-07, 'epoch': 2.03}
 68%|██████▊   | 426/630 [05:55<02:46,  1.23it/s] 68%|██████▊   | 427/630 [05:55<02:45,  1.23it/s]                                                 {'loss': 0.7962, 'grad_norm': 0.3193555668210105, 'learning_rate': 6.677577741407529e-07, 'epoch': 2.03}
 68%|██████▊   | 427/630 [05:55<02:45,  1.23it/s] 68%|██████▊   | 428/630 [05:56<02:44,  1.23it/s]                                                 {'loss': 0.8019, 'grad_norm': 0.29672981830081196, 'learning_rate': 6.644844517184942e-07, 'epoch': 2.04}
 68%|██████▊   | 428/630 [05:56<02:44,  1.23it/s] 68%|██████▊   | 429/630 [05:57<02:43,  1.23it/s]                                                 {'loss': 0.779, 'grad_norm': 0.2885560555932625, 'learning_rate': 6.612111292962356e-07, 'epoch': 2.04}
 68%|██████▊   | 429/630 [05:57<02:43,  1.23it/s] 68%|██████▊   | 430/630 [05:58<02:42,  1.23it/s]                                                 {'loss': 0.7579, 'grad_norm': 0.2972589265663658, 'learning_rate': 6.579378068739771e-07, 'epoch': 2.05}
 68%|██████▊   | 430/630 [05:58<02:42,  1.23it/s] 68%|██████▊   | 431/630 [05:59<02:43,  1.22it/s]                                                 {'loss': 0.849, 'grad_norm': 0.29462534150858943, 'learning_rate': 6.546644844517185e-07, 'epoch': 2.05}
 68%|██████▊   | 431/630 [05:59<02:43,  1.22it/s] 69%|██████▊   | 432/630 [05:59<02:42,  1.22it/s]                                                 {'loss': 0.786, 'grad_norm': 0.2600843069352221, 'learning_rate': 6.513911620294599e-07, 'epoch': 2.06}
 69%|██████▊   | 432/630 [05:59<02:42,  1.22it/s] 69%|██████▊   | 433/630 [06:00<02:41,  1.22it/s]                                                 {'loss': 0.7182, 'grad_norm': 0.2718353653552762, 'learning_rate': 6.481178396072012e-07, 'epoch': 2.06}
 69%|██████▊   | 433/630 [06:00<02:41,  1.22it/s] 69%|██████▉   | 434/630 [06:01<02:39,  1.23it/s]                                                 {'loss': 0.7452, 'grad_norm': 0.34838003114497806, 'learning_rate': 6.448445171849427e-07, 'epoch': 2.07}
 69%|██████▉   | 434/630 [06:01<02:39,  1.23it/s] 69%|██████▉   | 435/630 [06:02<02:39,  1.22it/s]                                                 {'loss': 0.821, 'grad_norm': 0.33624298199040475, 'learning_rate': 6.415711947626841e-07, 'epoch': 2.07}
 69%|██████▉   | 435/630 [06:02<02:39,  1.22it/s] 69%|██████▉   | 436/630 [06:03<02:38,  1.22it/s]                                                 {'loss': 0.7784, 'grad_norm': 0.30087576480983774, 'learning_rate': 6.382978723404255e-07, 'epoch': 2.08}
 69%|██████▉   | 436/630 [06:03<02:38,  1.22it/s] 69%|██████▉   | 437/630 [06:04<02:37,  1.22it/s]                                                 {'loss': 1.0076, 'grad_norm': 0.47012813750842297, 'learning_rate': 6.35024549918167e-07, 'epoch': 2.08}
 69%|██████▉   | 437/630 [06:04<02:37,  1.22it/s] 70%|██████▉   | 438/630 [06:04<02:36,  1.23it/s]                                                 {'loss': 0.7519, 'grad_norm': 0.2560360535944662, 'learning_rate': 6.317512274959084e-07, 'epoch': 2.09}
 70%|██████▉   | 438/630 [06:04<02:36,  1.23it/s] 70%|██████▉   | 439/630 [06:05<02:35,  1.23it/s]                                                 {'loss': 0.7738, 'grad_norm': 0.3794243788268797, 'learning_rate': 6.284779050736497e-07, 'epoch': 2.09}
 70%|██████▉   | 439/630 [06:05<02:35,  1.23it/s] 70%|██████▉   | 440/630 [06:06<02:35,  1.23it/s]                                                 {'loss': 0.8496, 'grad_norm': 0.3378781196694909, 'learning_rate': 6.252045826513911e-07, 'epoch': 2.1}
 70%|██████▉   | 440/630 [06:06<02:35,  1.23it/s] 70%|███████   | 441/630 [06:07<02:34,  1.22it/s]                                                 {'loss': 0.8215, 'grad_norm': 0.2857524564785941, 'learning_rate': 6.219312602291326e-07, 'epoch': 2.1}
 70%|███████   | 441/630 [06:07<02:34,  1.22it/s] 70%|███████   | 442/630 [06:08<02:33,  1.22it/s]                                                 {'loss': 0.871, 'grad_norm': 0.35035181478263777, 'learning_rate': 6.186579378068739e-07, 'epoch': 2.1}
 70%|███████   | 442/630 [06:08<02:33,  1.22it/s] 70%|███████   | 443/630 [06:08<02:32,  1.22it/s]                                                 {'loss': 0.8917, 'grad_norm': 0.32184173366838903, 'learning_rate': 6.153846153846154e-07, 'epoch': 2.11}
 70%|███████   | 443/630 [06:08<02:32,  1.22it/s] 70%|███████   | 444/630 [06:09<02:31,  1.23it/s]                                                 {'loss': 0.7716, 'grad_norm': 0.3142127981391272, 'learning_rate': 6.121112929623567e-07, 'epoch': 2.11}
 70%|███████   | 444/630 [06:09<02:31,  1.23it/s] 71%|███████   | 445/630 [06:10<02:30,  1.23it/s]                                                 {'loss': 0.7735, 'grad_norm': 0.33083015663022536, 'learning_rate': 6.088379705400983e-07, 'epoch': 2.12}
 71%|███████   | 445/630 [06:10<02:30,  1.23it/s] 71%|███████   | 446/630 [06:11<02:29,  1.23it/s]                                                 {'loss': 0.8726, 'grad_norm': 0.3388296365388344, 'learning_rate': 6.055646481178396e-07, 'epoch': 2.12}
 71%|███████   | 446/630 [06:11<02:29,  1.23it/s] 71%|███████   | 447/630 [06:12<02:29,  1.23it/s]                                                 {'loss': 0.9117, 'grad_norm': 0.3827782254185019, 'learning_rate': 6.022913256955809e-07, 'epoch': 2.13}
 71%|███████   | 447/630 [06:12<02:29,  1.23it/s] 71%|███████   | 448/630 [06:13<02:28,  1.23it/s]                                                 {'loss': 0.8025, 'grad_norm': 0.34804738204826213, 'learning_rate': 5.990180032733224e-07, 'epoch': 2.13}
 71%|███████   | 448/630 [06:13<02:28,  1.23it/s] 71%|███████▏  | 449/630 [06:13<02:27,  1.23it/s]                                                 {'loss': 0.7321, 'grad_norm': 0.31382585612286495, 'learning_rate': 5.957446808510638e-07, 'epoch': 2.14}
 71%|███████▏  | 449/630 [06:13<02:27,  1.23it/s] 71%|███████▏  | 450/630 [06:14<02:27,  1.22it/s]                                                 {'loss': 0.8788, 'grad_norm': 0.32610306794002863, 'learning_rate': 5.924713584288053e-07, 'epoch': 2.14}
 71%|███████▏  | 450/630 [06:14<02:27,  1.22it/s] 72%|███████▏  | 451/630 [06:15<02:26,  1.22it/s]                                                 {'loss': 0.7743, 'grad_norm': 0.2830365673550226, 'learning_rate': 5.891980360065466e-07, 'epoch': 2.15}
 72%|███████▏  | 451/630 [06:15<02:26,  1.22it/s] 72%|███████▏  | 452/630 [06:16<02:25,  1.22it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.3497914052982749, 'learning_rate': 5.85924713584288e-07, 'epoch': 2.15}
 72%|███████▏  | 452/630 [06:16<02:25,  1.22it/s] 72%|███████▏  | 453/630 [06:17<02:24,  1.22it/s]                                                 {'loss': 0.7539, 'grad_norm': 0.2439038682516808, 'learning_rate': 5.826513911620295e-07, 'epoch': 2.16}
 72%|███████▏  | 453/630 [06:17<02:24,  1.22it/s] 72%|███████▏  | 454/630 [06:17<02:23,  1.22it/s]                                                 {'loss': 0.757, 'grad_norm': 0.3371084835527344, 'learning_rate': 5.793780687397708e-07, 'epoch': 2.16}
 72%|███████▏  | 454/630 [06:17<02:23,  1.22it/s] 72%|███████▏  | 455/630 [06:18<02:23,  1.22it/s]                                                 {'loss': 0.7893, 'grad_norm': 0.2815673034721531, 'learning_rate': 5.761047463175122e-07, 'epoch': 2.17}
 72%|███████▏  | 455/630 [06:18<02:23,  1.22it/s] 72%|███████▏  | 456/630 [06:19<02:21,  1.23it/s]                                                 {'loss': 0.7554, 'grad_norm': 0.23730471516779325, 'learning_rate': 5.728314238952536e-07, 'epoch': 2.17}
 72%|███████▏  | 456/630 [06:19<02:21,  1.23it/s] 73%|███████▎  | 457/630 [06:20<02:20,  1.23it/s]                                                 {'loss': 0.8069, 'grad_norm': 0.3059644107655675, 'learning_rate': 5.695581014729951e-07, 'epoch': 2.18}
 73%|███████▎  | 457/630 [06:20<02:20,  1.23it/s] 73%|███████▎  | 458/630 [06:21<02:20,  1.23it/s]                                                 {'loss': 0.8087, 'grad_norm': 0.25058691952521217, 'learning_rate': 5.662847790507365e-07, 'epoch': 2.18}
 73%|███████▎  | 458/630 [06:21<02:20,  1.23it/s] 73%|███████▎  | 459/630 [06:22<02:19,  1.23it/s]                                                 {'loss': 0.7426, 'grad_norm': 0.2890799060565144, 'learning_rate': 5.630114566284779e-07, 'epoch': 2.19}
 73%|███████▎  | 459/630 [06:22<02:19,  1.23it/s] 73%|███████▎  | 460/630 [06:22<02:18,  1.23it/s]                                                 {'loss': 0.8731, 'grad_norm': 0.36183860145522734, 'learning_rate': 5.597381342062193e-07, 'epoch': 2.19}
 73%|███████▎  | 460/630 [06:22<02:18,  1.23it/s] 73%|███████▎  | 461/630 [06:23<02:17,  1.23it/s]                                                 {'loss': 0.7852, 'grad_norm': 0.2703483080636635, 'learning_rate': 5.564648117839607e-07, 'epoch': 2.2}
 73%|███████▎  | 461/630 [06:23<02:17,  1.23it/s] 73%|███████▎  | 462/630 [06:24<02:16,  1.23it/s]                                                 {'loss': 0.9025, 'grad_norm': 0.31070970783274254, 'learning_rate': 5.531914893617021e-07, 'epoch': 2.2}
 73%|███████▎  | 462/630 [06:24<02:16,  1.23it/s] 73%|███████▎  | 463/630 [06:25<02:15,  1.23it/s]                                                 {'loss': 0.7929, 'grad_norm': 0.3660624078255461, 'learning_rate': 5.499181669394435e-07, 'epoch': 2.2}
 73%|███████▎  | 463/630 [06:25<02:15,  1.23it/s] 74%|███████▎  | 464/630 [06:26<02:14,  1.23it/s]                                                 {'loss': 0.7527, 'grad_norm': 0.21569800289372668, 'learning_rate': 5.46644844517185e-07, 'epoch': 2.21}
 74%|███████▎  | 464/630 [06:26<02:14,  1.23it/s] 74%|███████▍  | 465/630 [06:26<02:13,  1.23it/s]                                                 {'loss': 0.8228, 'grad_norm': 0.28186957406625385, 'learning_rate': 5.433715220949263e-07, 'epoch': 2.21}
 74%|███████▍  | 465/630 [06:26<02:13,  1.23it/s] 74%|███████▍  | 466/630 [06:27<02:13,  1.23it/s]                                                 {'loss': 0.8081, 'grad_norm': 0.2644775751654248, 'learning_rate': 5.400981996726678e-07, 'epoch': 2.22}
 74%|███████▍  | 466/630 [06:27<02:13,  1.23it/s] 74%|███████▍  | 467/630 [06:28<02:12,  1.23it/s]                                                 {'loss': 0.7862, 'grad_norm': 0.30362583954672573, 'learning_rate': 5.368248772504091e-07, 'epoch': 2.22}
 74%|███████▍  | 467/630 [06:28<02:12,  1.23it/s] 74%|███████▍  | 468/630 [06:29<02:11,  1.23it/s]                                                 {'loss': 0.7906, 'grad_norm': 0.2334181597671901, 'learning_rate': 5.335515548281506e-07, 'epoch': 2.23}
 74%|███████▍  | 468/630 [06:29<02:11,  1.23it/s] 74%|███████▍  | 469/630 [06:30<02:11,  1.23it/s]                                                 {'loss': 0.7392, 'grad_norm': 0.3108799554800539, 'learning_rate': 5.30278232405892e-07, 'epoch': 2.23}
 74%|███████▍  | 469/630 [06:30<02:11,  1.23it/s] 75%|███████▍  | 470/630 [06:30<02:10,  1.23it/s]                                                 {'loss': 0.7598, 'grad_norm': 0.23766653682899988, 'learning_rate': 5.270049099836333e-07, 'epoch': 2.24}
 75%|███████▍  | 470/630 [06:30<02:10,  1.23it/s] 75%|███████▍  | 471/630 [06:31<02:09,  1.23it/s]                                                 {'loss': 0.8532, 'grad_norm': 0.22225296680831277, 'learning_rate': 5.237315875613748e-07, 'epoch': 2.24}
 75%|███████▍  | 471/630 [06:31<02:09,  1.23it/s] 75%|███████▍  | 472/630 [06:32<02:08,  1.23it/s]                                                 {'loss': 0.7925, 'grad_norm': 0.2843366359374322, 'learning_rate': 5.204582651391162e-07, 'epoch': 2.25}
 75%|███████▍  | 472/630 [06:32<02:08,  1.23it/s] 75%|███████▌  | 473/630 [06:33<02:07,  1.23it/s]                                                 {'loss': 0.7959, 'grad_norm': 0.29584949083704126, 'learning_rate': 5.171849427168577e-07, 'epoch': 2.25}
 75%|███████▌  | 473/630 [06:33<02:07,  1.23it/s] 75%|███████▌  | 474/630 [06:34<02:06,  1.23it/s]                                                 {'loss': 0.8231, 'grad_norm': 0.27689364553730833, 'learning_rate': 5.13911620294599e-07, 'epoch': 2.26}
 75%|███████▌  | 474/630 [06:34<02:06,  1.23it/s] 75%|███████▌  | 475/630 [06:35<02:06,  1.23it/s]                                                 {'loss': 0.8393, 'grad_norm': 0.3549959484997438, 'learning_rate': 5.106382978723403e-07, 'epoch': 2.26}
 75%|███████▌  | 475/630 [06:35<02:06,  1.23it/s] 76%|███████▌  | 476/630 [06:35<02:05,  1.23it/s]                                                 {'loss': 0.715, 'grad_norm': 0.23047926941702587, 'learning_rate': 5.073649754500819e-07, 'epoch': 2.27}
 76%|███████▌  | 476/630 [06:35<02:05,  1.23it/s] 76%|███████▌  | 477/630 [06:36<02:04,  1.23it/s]                                                 {'loss': 0.7405, 'grad_norm': 0.2326641313745623, 'learning_rate': 5.040916530278232e-07, 'epoch': 2.27}
 76%|███████▌  | 477/630 [06:36<02:04,  1.23it/s] 76%|███████▌  | 478/630 [06:37<02:03,  1.23it/s]                                                 {'loss': 0.8249, 'grad_norm': 0.24633962014341737, 'learning_rate': 5.008183306055646e-07, 'epoch': 2.28}
 76%|███████▌  | 478/630 [06:37<02:03,  1.23it/s] 76%|███████▌  | 479/630 [06:38<02:02,  1.23it/s]                                                 {'loss': 0.7289, 'grad_norm': 0.23333011915399138, 'learning_rate': 4.97545008183306e-07, 'epoch': 2.28}
 76%|███████▌  | 479/630 [06:38<02:02,  1.23it/s] 76%|███████▌  | 480/630 [06:39<02:02,  1.23it/s]                                                 {'loss': 0.8083, 'grad_norm': 0.24124555510699194, 'learning_rate': 4.942716857610474e-07, 'epoch': 2.29}
 76%|███████▌  | 480/630 [06:39<02:02,  1.23it/s] 76%|███████▋  | 481/630 [06:39<02:01,  1.23it/s]                                                 {'loss': 0.7965, 'grad_norm': 0.24991567410989715, 'learning_rate': 4.909983633387889e-07, 'epoch': 2.29}
 76%|███████▋  | 481/630 [06:39<02:01,  1.23it/s] 77%|███████▋  | 482/630 [06:40<02:00,  1.23it/s]                                                 {'loss': 0.7763, 'grad_norm': 0.4122312112935447, 'learning_rate': 4.877250409165303e-07, 'epoch': 2.3}
 77%|███████▋  | 482/630 [06:40<02:00,  1.23it/s] 77%|███████▋  | 483/630 [06:41<01:59,  1.23it/s]                                                 {'loss': 0.7851, 'grad_norm': 0.29288976800783534, 'learning_rate': 4.844517184942716e-07, 'epoch': 2.3}
 77%|███████▋  | 483/630 [06:41<01:59,  1.23it/s] 77%|███████▋  | 484/630 [06:42<01:58,  1.23it/s]                                                 {'loss': 0.7927, 'grad_norm': 0.2738882801226069, 'learning_rate': 4.811783960720131e-07, 'epoch': 2.3}
 77%|███████▋  | 484/630 [06:42<01:58,  1.23it/s] 77%|███████▋  | 485/630 [06:43<01:57,  1.23it/s]                                                 {'loss': 0.7415, 'grad_norm': 0.2813012204777182, 'learning_rate': 4.779050736497545e-07, 'epoch': 2.31}
 77%|███████▋  | 485/630 [06:43<01:57,  1.23it/s] 77%|███████▋  | 486/630 [06:43<01:57,  1.23it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.26451668810938905, 'learning_rate': 4.746317512274959e-07, 'epoch': 2.31}
 77%|███████▋  | 486/630 [06:43<01:57,  1.23it/s] 77%|███████▋  | 487/630 [06:44<01:56,  1.23it/s]                                                 {'loss': 0.7795, 'grad_norm': 0.28779817588554046, 'learning_rate': 4.713584288052373e-07, 'epoch': 2.32}
 77%|███████▋  | 487/630 [06:44<01:56,  1.23it/s] 77%|███████▋  | 488/630 [06:45<01:55,  1.23it/s]                                                 {'loss': 0.7348, 'grad_norm': 0.27312883833491286, 'learning_rate': 4.6808510638297873e-07, 'epoch': 2.32}
 77%|███████▋  | 488/630 [06:45<01:55,  1.23it/s] 78%|███████▊  | 489/630 [06:46<01:54,  1.23it/s]                                                 {'loss': 0.7956, 'grad_norm': 0.3323675221041389, 'learning_rate': 4.648117839607201e-07, 'epoch': 2.33}
 78%|███████▊  | 489/630 [06:46<01:54,  1.23it/s] 78%|███████▊  | 490/630 [06:47<01:53,  1.24it/s]                                                 {'loss': 0.8663, 'grad_norm': 0.25322861696800986, 'learning_rate': 4.6153846153846156e-07, 'epoch': 2.33}
 78%|███████▊  | 490/630 [06:47<01:53,  1.24it/s] 78%|███████▊  | 491/630 [06:48<01:52,  1.23it/s]                                                 {'loss': 0.8256, 'grad_norm': 0.32921309563347007, 'learning_rate': 4.582651391162029e-07, 'epoch': 2.34}
 78%|███████▊  | 491/630 [06:48<01:52,  1.23it/s] 78%|███████▊  | 492/630 [06:48<01:52,  1.23it/s]                                                 {'loss': 0.8092, 'grad_norm': 0.31269795002076956, 'learning_rate': 4.5499181669394434e-07, 'epoch': 2.34}
 78%|███████▊  | 492/630 [06:48<01:52,  1.23it/s] 78%|███████▊  | 493/630 [06:49<01:51,  1.23it/s]                                                 {'loss': 0.773, 'grad_norm': 0.42703459680044775, 'learning_rate': 4.517184942716857e-07, 'epoch': 2.35}
 78%|███████▊  | 493/630 [06:49<01:51,  1.23it/s] 78%|███████▊  | 494/630 [06:50<01:50,  1.23it/s]                                                 {'loss': 0.873, 'grad_norm': 0.3243146783997569, 'learning_rate': 4.4844517184942717e-07, 'epoch': 2.35}
 78%|███████▊  | 494/630 [06:50<01:50,  1.23it/s] 79%|███████▊  | 495/630 [06:51<01:50,  1.23it/s]                                                 {'loss': 0.7336, 'grad_norm': 0.34074864235278224, 'learning_rate': 4.4517184942716855e-07, 'epoch': 2.36}
 79%|███████▊  | 495/630 [06:51<01:50,  1.23it/s] 79%|███████▊  | 496/630 [06:52<01:49,  1.23it/s]                                                 {'loss': 0.7995, 'grad_norm': 0.3428832543407303, 'learning_rate': 4.4189852700491e-07, 'epoch': 2.36}
 79%|███████▊  | 496/630 [06:52<01:49,  1.23it/s] 79%|███████▉  | 497/630 [06:52<01:48,  1.23it/s]                                                 {'loss': 0.8113, 'grad_norm': 0.2528052134458478, 'learning_rate': 4.386252045826514e-07, 'epoch': 2.37}
 79%|███████▉  | 497/630 [06:52<01:48,  1.23it/s] 79%|███████▉  | 498/630 [06:53<01:47,  1.23it/s]                                                 {'loss': 0.7915, 'grad_norm': 0.2327363877917177, 'learning_rate': 4.3535188216039277e-07, 'epoch': 2.37}
 79%|███████▉  | 498/630 [06:53<01:47,  1.23it/s] 79%|███████▉  | 499/630 [06:54<01:46,  1.22it/s]                                                 {'loss': 0.7936, 'grad_norm': 0.3298025530533404, 'learning_rate': 4.3207855973813416e-07, 'epoch': 2.38}
 79%|███████▉  | 499/630 [06:54<01:46,  1.22it/s] 79%|███████▉  | 500/630 [06:55<01:46,  1.22it/s]                                                 {'loss': 0.8397, 'grad_norm': 0.34385270721792177, 'learning_rate': 4.288052373158756e-07, 'epoch': 2.38}
 79%|███████▉  | 500/630 [06:55<01:46,  1.22it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
 80%|███████▉  | 501/630 [07:06<08:05,  3.77s/it]                                                 {'loss': 0.7694, 'grad_norm': 0.23979276469334448, 'learning_rate': 4.25531914893617e-07, 'epoch': 2.39}
 80%|███████▉  | 501/630 [07:06<08:05,  3.77s/it] 80%|███████▉  | 502/630 [07:06<06:08,  2.88s/it]                                                 {'loss': 0.8218, 'grad_norm': 0.29659792537351076, 'learning_rate': 4.2225859247135843e-07, 'epoch': 2.39}
 80%|███████▉  | 502/630 [07:06<06:08,  2.88s/it] 80%|███████▉  | 503/630 [07:07<04:46,  2.26s/it]                                                 {'loss': 0.6808, 'grad_norm': 0.2558399008455198, 'learning_rate': 4.189852700490998e-07, 'epoch': 2.4}
 80%|███████▉  | 503/630 [07:07<04:46,  2.26s/it] 80%|████████  | 504/630 [07:08<03:50,  1.83s/it]                                                 {'loss': 0.8, 'grad_norm': 0.2964643200783927, 'learning_rate': 4.157119476268412e-07, 'epoch': 2.4}
 80%|████████  | 504/630 [07:08<03:50,  1.83s/it] 80%|████████  | 505/630 [07:09<03:10,  1.52s/it]                                                 {'loss': 0.7976, 'grad_norm': 0.2842373192464294, 'learning_rate': 4.124386252045826e-07, 'epoch': 2.4}
 80%|████████  | 505/630 [07:09<03:10,  1.52s/it] 80%|████████  | 506/630 [07:10<02:42,  1.31s/it]                                                 {'loss': 0.812, 'grad_norm': 0.2829093180018026, 'learning_rate': 4.0916530278232403e-07, 'epoch': 2.41}
 80%|████████  | 506/630 [07:10<02:42,  1.31s/it] 80%|████████  | 507/630 [07:10<02:23,  1.17s/it]                                                 {'loss': 0.7947, 'grad_norm': 0.2872503681631311, 'learning_rate': 4.058919803600654e-07, 'epoch': 2.41}
 80%|████████  | 507/630 [07:10<02:23,  1.17s/it] 81%|████████  | 508/630 [07:11<02:09,  1.06s/it]                                                 {'loss': 0.7803, 'grad_norm': 0.25550564920352775, 'learning_rate': 4.0261865793780686e-07, 'epoch': 2.42}
 81%|████████  | 508/630 [07:11<02:09,  1.06s/it] 81%|████████  | 509/630 [07:12<01:59,  1.01it/s]                                                 {'loss': 0.7395, 'grad_norm': 0.24320059282679204, 'learning_rate': 3.993453355155483e-07, 'epoch': 2.42}
 81%|████████  | 509/630 [07:12<01:59,  1.01it/s] 81%|████████  | 510/630 [07:13<01:52,  1.07it/s]                                                 {'loss': 0.7624, 'grad_norm': 0.24770222634302866, 'learning_rate': 3.960720130932897e-07, 'epoch': 2.43}
 81%|████████  | 510/630 [07:13<01:52,  1.07it/s] 81%|████████  | 511/630 [07:14<01:47,  1.11it/s]                                                 {'loss': 0.8433, 'grad_norm': 0.2898944358100283, 'learning_rate': 3.927986906710311e-07, 'epoch': 2.43}
 81%|████████  | 511/630 [07:14<01:47,  1.11it/s] 81%|████████▏ | 512/630 [07:14<01:42,  1.15it/s]                                                 {'loss': 0.7461, 'grad_norm': 0.25865733984125316, 'learning_rate': 3.8952536824877247e-07, 'epoch': 2.44}
 81%|████████▏ | 512/630 [07:15<01:42,  1.15it/s] 81%|████████▏ | 513/630 [07:15<01:40,  1.17it/s]                                                 {'loss': 0.8035, 'grad_norm': 0.2518941166000211, 'learning_rate': 3.862520458265139e-07, 'epoch': 2.44}
 81%|████████▏ | 513/630 [07:15<01:40,  1.17it/s] 82%|████████▏ | 514/630 [07:16<01:38,  1.18it/s]                                                 {'loss': 0.7916, 'grad_norm': 0.2545990100877213, 'learning_rate': 3.829787234042553e-07, 'epoch': 2.45}
 82%|████████▏ | 514/630 [07:16<01:38,  1.18it/s] 82%|████████▏ | 515/630 [07:17<01:36,  1.20it/s]                                                 {'loss': 0.8057, 'grad_norm': 0.4005605851349264, 'learning_rate': 3.7970540098199673e-07, 'epoch': 2.45}
 82%|████████▏ | 515/630 [07:17<01:36,  1.20it/s] 82%|████████▏ | 516/630 [07:18<01:34,  1.20it/s]                                                 {'loss': 0.904, 'grad_norm': 0.3131632595384878, 'learning_rate': 3.764320785597381e-07, 'epoch': 2.46}
 82%|████████▏ | 516/630 [07:18<01:34,  1.20it/s] 82%|████████▏ | 517/630 [07:19<01:33,  1.21it/s]                                                 {'loss': 0.9056, 'grad_norm': 0.24620723553562646, 'learning_rate': 3.7315875613747956e-07, 'epoch': 2.46}
 82%|████████▏ | 517/630 [07:19<01:33,  1.21it/s] 82%|████████▏ | 518/630 [07:19<01:32,  1.21it/s]                                                 {'loss': 0.7629, 'grad_norm': 0.27492749803097033, 'learning_rate': 3.698854337152209e-07, 'epoch': 2.47}
 82%|████████▏ | 518/630 [07:19<01:32,  1.21it/s] 82%|████████▏ | 519/630 [07:20<01:31,  1.22it/s]                                                 {'loss': 0.784, 'grad_norm': 0.3552131344258893, 'learning_rate': 3.6661211129296234e-07, 'epoch': 2.47}
 82%|████████▏ | 519/630 [07:20<01:31,  1.22it/s] 83%|████████▎ | 520/630 [07:21<01:30,  1.22it/s]                                                 {'loss': 0.7638, 'grad_norm': 0.2743072320349163, 'learning_rate': 3.6333878887070373e-07, 'epoch': 2.48}
 83%|████████▎ | 520/630 [07:21<01:30,  1.22it/s] 83%|████████▎ | 521/630 [07:22<01:29,  1.22it/s]                                                 {'loss': 0.7525, 'grad_norm': 0.28397565453794893, 'learning_rate': 3.6006546644844517e-07, 'epoch': 2.48}
 83%|████████▎ | 521/630 [07:22<01:29,  1.22it/s] 83%|████████▎ | 522/630 [07:23<01:28,  1.22it/s]                                                 {'loss': 0.7419, 'grad_norm': 0.24888736911622023, 'learning_rate': 3.5679214402618656e-07, 'epoch': 2.49}
 83%|████████▎ | 522/630 [07:23<01:28,  1.22it/s] 83%|████████▎ | 523/630 [07:23<01:27,  1.22it/s]                                                 {'loss': 0.7598, 'grad_norm': 0.25918664250834866, 'learning_rate': 3.53518821603928e-07, 'epoch': 2.49}
 83%|████████▎ | 523/630 [07:23<01:27,  1.22it/s] 83%|████████▎ | 524/630 [07:24<01:26,  1.22it/s]                                                 {'loss': 0.8075, 'grad_norm': 0.3511201255928952, 'learning_rate': 3.502454991816694e-07, 'epoch': 2.5}
 83%|████████▎ | 524/630 [07:24<01:26,  1.22it/s] 83%|████████▎ | 525/630 [07:25<01:25,  1.23it/s]                                                 {'loss': 0.8084, 'grad_norm': 0.3452599106140947, 'learning_rate': 3.4697217675941077e-07, 'epoch': 2.5}
 83%|████████▎ | 525/630 [07:25<01:25,  1.23it/s] 83%|████████▎ | 526/630 [07:26<01:24,  1.23it/s]                                                 {'loss': 0.8407, 'grad_norm': 0.315068398578297, 'learning_rate': 3.4369885433715216e-07, 'epoch': 2.5}
 83%|████████▎ | 526/630 [07:26<01:24,  1.23it/s] 84%|████████▎ | 527/630 [07:27<01:23,  1.23it/s]                                                 {'loss': 0.8622, 'grad_norm': 0.2700836808040725, 'learning_rate': 3.404255319148936e-07, 'epoch': 2.51}
 84%|████████▎ | 527/630 [07:27<01:23,  1.23it/s] 84%|████████▍ | 528/630 [07:28<01:22,  1.23it/s]                                                 {'loss': 0.7884, 'grad_norm': 0.2509332129869627, 'learning_rate': 3.37152209492635e-07, 'epoch': 2.51}
 84%|████████▍ | 528/630 [07:28<01:22,  1.23it/s] 84%|████████▍ | 529/630 [07:28<01:22,  1.23it/s]                                                 {'loss': 0.7676, 'grad_norm': 0.2972349121568656, 'learning_rate': 3.3387888707037643e-07, 'epoch': 2.52}
 84%|████████▍ | 529/630 [07:28<01:22,  1.23it/s] 84%|████████▍ | 530/630 [07:29<01:21,  1.23it/s]                                                 {'loss': 0.7816, 'grad_norm': 0.27357270482701757, 'learning_rate': 3.306055646481178e-07, 'epoch': 2.52}
 84%|████████▍ | 530/630 [07:29<01:21,  1.23it/s] 84%|████████▍ | 531/630 [07:30<01:20,  1.23it/s]                                                 {'loss': 0.804, 'grad_norm': 0.3610904069882913, 'learning_rate': 3.2733224222585926e-07, 'epoch': 2.53}
 84%|████████▍ | 531/630 [07:30<01:20,  1.23it/s] 84%|████████▍ | 532/630 [07:31<01:19,  1.23it/s]                                                 {'loss': 0.6987, 'grad_norm': 0.2604076285284778, 'learning_rate': 3.240589198036006e-07, 'epoch': 2.53}
 84%|████████▍ | 532/630 [07:31<01:19,  1.23it/s] 85%|████████▍ | 533/630 [07:32<01:18,  1.23it/s]                                                 {'loss': 0.7968, 'grad_norm': 0.3289054960656919, 'learning_rate': 3.2078559738134203e-07, 'epoch': 2.54}
 85%|████████▍ | 533/630 [07:32<01:18,  1.23it/s] 85%|████████▍ | 534/630 [07:32<01:18,  1.23it/s]                                                 {'loss': 0.7774, 'grad_norm': 0.29702071976442385, 'learning_rate': 3.175122749590835e-07, 'epoch': 2.54}
 85%|████████▍ | 534/630 [07:32<01:18,  1.23it/s] 85%|████████▍ | 535/630 [07:33<01:17,  1.23it/s]                                                 {'loss': 0.7232, 'grad_norm': 0.27489280288102635, 'learning_rate': 3.1423895253682486e-07, 'epoch': 2.55}
 85%|████████▍ | 535/630 [07:33<01:17,  1.23it/s] 85%|████████▌ | 536/630 [07:34<01:16,  1.23it/s]                                                 {'loss': 0.8784, 'grad_norm': 0.34013575371478877, 'learning_rate': 3.109656301145663e-07, 'epoch': 2.55}
 85%|████████▌ | 536/630 [07:34<01:16,  1.23it/s] 85%|████████▌ | 537/630 [07:35<01:15,  1.23it/s]                                                 {'loss': 0.7565, 'grad_norm': 0.4889814160572057, 'learning_rate': 3.076923076923077e-07, 'epoch': 2.56}
 85%|████████▌ | 537/630 [07:35<01:15,  1.23it/s] 85%|████████▌ | 538/630 [07:36<01:22,  1.12it/s]                                                 {'loss': 0.7982, 'grad_norm': 0.36889319172945545, 'learning_rate': 3.0441898527004913e-07, 'epoch': 2.56}
 85%|████████▌ | 538/630 [07:36<01:22,  1.12it/s] 86%|████████▌ | 539/630 [07:37<01:19,  1.15it/s]                                                 {'loss': 0.7432, 'grad_norm': 0.26428956930539105, 'learning_rate': 3.0114566284779047e-07, 'epoch': 2.57}
 86%|████████▌ | 539/630 [07:37<01:19,  1.15it/s] 86%|████████▌ | 540/630 [07:38<01:16,  1.18it/s]                                                 {'loss': 0.7948, 'grad_norm': 0.3131264482839658, 'learning_rate': 2.978723404255319e-07, 'epoch': 2.57}
 86%|████████▌ | 540/630 [07:38<01:16,  1.18it/s] 86%|████████▌ | 541/630 [07:38<01:14,  1.19it/s]                                                 {'loss': 0.759, 'grad_norm': 0.2471128402649522, 'learning_rate': 2.945990180032733e-07, 'epoch': 2.58}
 86%|████████▌ | 541/630 [07:38<01:14,  1.19it/s] 86%|████████▌ | 542/630 [07:39<01:13,  1.20it/s]                                                 {'loss': 0.8374, 'grad_norm': 0.23701606206430856, 'learning_rate': 2.9132569558101474e-07, 'epoch': 2.58}
 86%|████████▌ | 542/630 [07:39<01:13,  1.20it/s] 86%|████████▌ | 543/630 [07:40<01:11,  1.21it/s]                                                 {'loss': 0.8444, 'grad_norm': 0.2938289315118317, 'learning_rate': 2.880523731587561e-07, 'epoch': 2.59}
 86%|████████▌ | 543/630 [07:40<01:11,  1.21it/s] 86%|████████▋ | 544/630 [07:41<01:10,  1.22it/s]                                                 {'loss': 0.8146, 'grad_norm': 0.2874696302827051, 'learning_rate': 2.8477905073649756e-07, 'epoch': 2.59}
 86%|████████▋ | 544/630 [07:41<01:10,  1.22it/s] 87%|████████▋ | 545/630 [07:42<01:09,  1.23it/s]                                                 {'loss': 0.6839, 'grad_norm': 0.2698679589550643, 'learning_rate': 2.8150572831423895e-07, 'epoch': 2.6}
 87%|████████▋ | 545/630 [07:42<01:09,  1.23it/s] 87%|████████▋ | 546/630 [07:42<01:08,  1.23it/s]                                                 {'loss': 0.7578, 'grad_norm': 0.24330361084907998, 'learning_rate': 2.7823240589198034e-07, 'epoch': 2.6}
 87%|████████▋ | 546/630 [07:42<01:08,  1.23it/s] 87%|████████▋ | 547/630 [07:43<01:07,  1.23it/s]                                                 {'loss': 0.8023, 'grad_norm': 0.2544963559890454, 'learning_rate': 2.7495908346972173e-07, 'epoch': 2.6}
 87%|████████▋ | 547/630 [07:43<01:07,  1.23it/s] 87%|████████▋ | 548/630 [07:44<01:06,  1.23it/s]                                                 {'loss': 0.8571, 'grad_norm': 0.2752634821126664, 'learning_rate': 2.7168576104746317e-07, 'epoch': 2.61}
 87%|████████▋ | 548/630 [07:44<01:06,  1.23it/s] 87%|████████▋ | 549/630 [07:45<01:05,  1.23it/s]                                                 {'loss': 0.8366, 'grad_norm': 0.3679276115554295, 'learning_rate': 2.6841243862520456e-07, 'epoch': 2.61}
 87%|████████▋ | 549/630 [07:45<01:05,  1.23it/s] 87%|████████▋ | 550/630 [07:46<01:05,  1.23it/s]                                                 {'loss': 0.8287, 'grad_norm': 0.32653135281299267, 'learning_rate': 2.65139116202946e-07, 'epoch': 2.62}
 87%|████████▋ | 550/630 [07:46<01:05,  1.23it/s] 87%|████████▋ | 551/630 [07:47<01:04,  1.23it/s]                                                 {'loss': 0.8891, 'grad_norm': 0.2432874217502019, 'learning_rate': 2.618657937806874e-07, 'epoch': 2.62}
 87%|████████▋ | 551/630 [07:47<01:04,  1.23it/s] 88%|████████▊ | 552/630 [07:47<01:03,  1.23it/s]                                                 {'loss': 0.815, 'grad_norm': 0.33471619361982596, 'learning_rate': 2.585924713584288e-07, 'epoch': 2.63}
 88%|████████▊ | 552/630 [07:47<01:03,  1.23it/s] 88%|████████▊ | 553/630 [07:48<01:02,  1.23it/s]                                                 {'loss': 0.8296, 'grad_norm': 0.27797052430874963, 'learning_rate': 2.5531914893617016e-07, 'epoch': 2.63}
 88%|████████▊ | 553/630 [07:48<01:02,  1.23it/s] 88%|████████▊ | 554/630 [07:49<01:01,  1.23it/s]                                                 {'loss': 0.8403, 'grad_norm': 0.2592911087056007, 'learning_rate': 2.520458265139116e-07, 'epoch': 2.64}
 88%|████████▊ | 554/630 [07:49<01:01,  1.23it/s] 88%|████████▊ | 555/630 [07:50<01:00,  1.23it/s]                                                 {'loss': 0.8754, 'grad_norm': 0.3474483227709716, 'learning_rate': 2.48772504091653e-07, 'epoch': 2.64}
 88%|████████▊ | 555/630 [07:50<01:00,  1.23it/s] 88%|████████▊ | 556/630 [07:51<01:00,  1.23it/s]                                                 {'loss': 0.7841, 'grad_norm': 0.25474237475346356, 'learning_rate': 2.4549918166939443e-07, 'epoch': 2.65}
 88%|████████▊ | 556/630 [07:51<01:00,  1.23it/s] 88%|████████▊ | 557/630 [07:51<00:59,  1.23it/s]                                                 {'loss': 0.7641, 'grad_norm': 0.2375619314621183, 'learning_rate': 2.422258592471358e-07, 'epoch': 2.65}
 88%|████████▊ | 557/630 [07:51<00:59,  1.23it/s] 89%|████████▊ | 558/630 [07:52<00:58,  1.23it/s]                                                 {'loss': 0.8585, 'grad_norm': 0.2478767186498448, 'learning_rate': 2.3895253682487726e-07, 'epoch': 2.66}
 89%|████████▊ | 558/630 [07:52<00:58,  1.23it/s] 89%|████████▊ | 559/630 [07:53<00:57,  1.23it/s]                                                 {'loss': 0.811, 'grad_norm': 0.2594512706731347, 'learning_rate': 2.3567921440261865e-07, 'epoch': 2.66}
 89%|████████▊ | 559/630 [07:53<00:57,  1.23it/s] 89%|████████▉ | 560/630 [07:54<00:57,  1.23it/s]                                                 {'loss': 0.8318, 'grad_norm': 0.33603186021090425, 'learning_rate': 2.3240589198036006e-07, 'epoch': 2.67}
 89%|████████▉ | 560/630 [07:54<00:57,  1.23it/s] 89%|████████▉ | 561/630 [07:55<00:56,  1.23it/s]                                                 {'loss': 0.8195, 'grad_norm': 0.2951038550820026, 'learning_rate': 2.2913256955810145e-07, 'epoch': 2.67}
 89%|████████▉ | 561/630 [07:55<00:56,  1.23it/s] 89%|████████▉ | 562/630 [07:55<00:55,  1.23it/s]                                                 {'loss': 0.748, 'grad_norm': 0.25795470439943946, 'learning_rate': 2.2585924713584286e-07, 'epoch': 2.68}
 89%|████████▉ | 562/630 [07:55<00:55,  1.23it/s] 89%|████████▉ | 563/630 [07:56<00:54,  1.23it/s]                                                 {'loss': 0.7481, 'grad_norm': 0.2521611313565021, 'learning_rate': 2.2258592471358428e-07, 'epoch': 2.68}
 89%|████████▉ | 563/630 [07:56<00:54,  1.23it/s] 90%|████████▉ | 564/630 [07:57<00:53,  1.22it/s]                                                 {'loss': 0.7996, 'grad_norm': 0.21987751716332823, 'learning_rate': 2.193126022913257e-07, 'epoch': 2.69}
 90%|████████▉ | 564/630 [07:57<00:53,  1.22it/s] 90%|████████▉ | 565/630 [07:58<00:53,  1.22it/s]                                                 {'loss': 0.7896, 'grad_norm': 0.26017828774338764, 'learning_rate': 2.1603927986906708e-07, 'epoch': 2.69}
 90%|████████▉ | 565/630 [07:58<00:53,  1.22it/s] 90%|████████▉ | 566/630 [07:59<00:52,  1.23it/s]                                                 {'loss': 0.7551, 'grad_norm': 0.29687891411844913, 'learning_rate': 2.127659574468085e-07, 'epoch': 2.7}
 90%|████████▉ | 566/630 [07:59<00:52,  1.23it/s] 90%|█████████ | 567/630 [08:00<00:51,  1.23it/s]                                                 {'loss': 0.8491, 'grad_norm': 0.25900215330072873, 'learning_rate': 2.094926350245499e-07, 'epoch': 2.7}
 90%|█████████ | 567/630 [08:00<00:51,  1.23it/s] 90%|█████████ | 568/630 [08:00<00:50,  1.23it/s]                                                 {'loss': 0.7673, 'grad_norm': 0.22271900218074364, 'learning_rate': 2.062193126022913e-07, 'epoch': 2.7}
 90%|█████████ | 568/630 [08:00<00:50,  1.23it/s] 90%|█████████ | 569/630 [08:01<00:49,  1.23it/s]                                                 {'loss': 0.8195, 'grad_norm': 0.27305834769234505, 'learning_rate': 2.029459901800327e-07, 'epoch': 2.71}
 90%|█████████ | 569/630 [08:01<00:49,  1.23it/s] 90%|█████████ | 570/630 [08:02<00:48,  1.23it/s]                                                 {'loss': 0.8235, 'grad_norm': 0.3140880490200857, 'learning_rate': 1.9967266775777415e-07, 'epoch': 2.71}
 90%|█████████ | 570/630 [08:02<00:48,  1.23it/s] 91%|█████████ | 571/630 [08:03<00:48,  1.23it/s]                                                 {'loss': 0.8572, 'grad_norm': 0.3029972426235807, 'learning_rate': 1.9639934533551554e-07, 'epoch': 2.72}
 91%|█████████ | 571/630 [08:03<00:48,  1.23it/s] 91%|█████████ | 572/630 [08:04<00:47,  1.23it/s]                                                 {'loss': 0.7279, 'grad_norm': 0.23190551785507, 'learning_rate': 1.9312602291325695e-07, 'epoch': 2.72}
 91%|█████████ | 572/630 [08:04<00:47,  1.23it/s] 91%|█████████ | 573/630 [08:04<00:46,  1.23it/s]                                                 {'loss': 0.8063, 'grad_norm': 0.29130656015386, 'learning_rate': 1.8985270049099837e-07, 'epoch': 2.73}
 91%|█████████ | 573/630 [08:04<00:46,  1.23it/s] 91%|█████████ | 574/630 [08:05<00:45,  1.23it/s]                                                 {'loss': 0.7846, 'grad_norm': 0.2788274011146151, 'learning_rate': 1.8657937806873978e-07, 'epoch': 2.73}
 91%|█████████ | 574/630 [08:05<00:45,  1.23it/s] 91%|█████████▏| 575/630 [08:06<00:44,  1.22it/s]                                                 {'loss': 0.7621, 'grad_norm': 0.2536722921064158, 'learning_rate': 1.8330605564648117e-07, 'epoch': 2.74}
 91%|█████████▏| 575/630 [08:06<00:44,  1.22it/s] 91%|█████████▏| 576/630 [08:07<00:44,  1.22it/s]                                                 {'loss': 0.7951, 'grad_norm': 0.376871484408075, 'learning_rate': 1.8003273322422258e-07, 'epoch': 2.74}
 91%|█████████▏| 576/630 [08:07<00:44,  1.22it/s] 92%|█████████▏| 577/630 [08:08<00:43,  1.22it/s]                                                 {'loss': 0.8338, 'grad_norm': 0.278043900549583, 'learning_rate': 1.76759410801964e-07, 'epoch': 2.75}
 92%|█████████▏| 577/630 [08:08<00:43,  1.22it/s] 92%|█████████▏| 578/630 [08:09<00:42,  1.23it/s]                                                 {'loss': 0.8199, 'grad_norm': 0.25780956715073117, 'learning_rate': 1.7348608837970539e-07, 'epoch': 2.75}
 92%|█████████▏| 578/630 [08:09<00:42,  1.23it/s] 92%|█████████▏| 579/630 [08:09<00:41,  1.23it/s]                                                 {'loss': 0.8565, 'grad_norm': 0.2822631107187841, 'learning_rate': 1.702127659574468e-07, 'epoch': 2.76}
 92%|█████████▏| 579/630 [08:09<00:41,  1.23it/s] 92%|█████████▏| 580/630 [08:10<00:40,  1.23it/s]                                                 {'loss': 0.8032, 'grad_norm': 0.3212783983403277, 'learning_rate': 1.6693944353518821e-07, 'epoch': 2.76}
 92%|█████████▏| 580/630 [08:10<00:40,  1.23it/s] 92%|█████████▏| 581/630 [08:11<00:40,  1.22it/s]                                                 {'loss': 0.7361, 'grad_norm': 0.2588660259236922, 'learning_rate': 1.6366612111292963e-07, 'epoch': 2.77}
 92%|█████████▏| 581/630 [08:11<00:40,  1.22it/s] 92%|█████████▏| 582/630 [08:12<00:39,  1.23it/s]                                                 {'loss': 0.8106, 'grad_norm': 0.22995720401188655, 'learning_rate': 1.6039279869067102e-07, 'epoch': 2.77}
 92%|█████████▏| 582/630 [08:12<00:39,  1.23it/s] 93%|█████████▎| 583/630 [08:13<00:38,  1.23it/s]                                                 {'loss': 0.8613, 'grad_norm': 0.7034013687061932, 'learning_rate': 1.5711947626841243e-07, 'epoch': 2.78}
 93%|█████████▎| 583/630 [08:13<00:38,  1.23it/s] 93%|█████████▎| 584/630 [08:13<00:37,  1.23it/s]                                                 {'loss': 0.7533, 'grad_norm': 0.24413716471588556, 'learning_rate': 1.5384615384615385e-07, 'epoch': 2.78}
 93%|█████████▎| 584/630 [08:13<00:37,  1.23it/s] 93%|█████████▎| 585/630 [08:14<00:36,  1.23it/s]                                                 {'loss': 0.7956, 'grad_norm': 0.27369167966197416, 'learning_rate': 1.5057283142389523e-07, 'epoch': 2.79}
 93%|█████████▎| 585/630 [08:14<00:36,  1.23it/s] 93%|█████████▎| 586/630 [08:15<00:35,  1.23it/s]                                                 {'loss': 0.8258, 'grad_norm': 0.2873863679431213, 'learning_rate': 1.4729950900163665e-07, 'epoch': 2.79}
 93%|█████████▎| 586/630 [08:15<00:35,  1.23it/s] 93%|█████████▎| 587/630 [08:16<00:34,  1.23it/s]                                                 {'loss': 0.7438, 'grad_norm': 0.2265352945471611, 'learning_rate': 1.4402618657937806e-07, 'epoch': 2.8}
 93%|█████████▎| 587/630 [08:16<00:34,  1.23it/s] 93%|█████████▎| 588/630 [08:17<00:34,  1.23it/s]                                                 {'loss': 0.7267, 'grad_norm': 0.24006774107248854, 'learning_rate': 1.4075286415711948e-07, 'epoch': 2.8}
 93%|█████████▎| 588/630 [08:17<00:34,  1.23it/s] 93%|█████████▎| 589/630 [08:17<00:33,  1.23it/s]                                                 {'loss': 0.7555, 'grad_norm': 0.23897893254736952, 'learning_rate': 1.3747954173486086e-07, 'epoch': 2.8}
 93%|█████████▎| 589/630 [08:17<00:33,  1.23it/s] 94%|█████████▎| 590/630 [08:18<00:32,  1.23it/s]                                                 {'loss': 0.8089, 'grad_norm': 0.2057586564546629, 'learning_rate': 1.3420621931260228e-07, 'epoch': 2.81}
 94%|█████████▎| 590/630 [08:18<00:32,  1.23it/s] 94%|█████████▍| 591/630 [08:19<00:31,  1.23it/s]                                                 {'loss': 0.7156, 'grad_norm': 0.259954274027189, 'learning_rate': 1.309328968903437e-07, 'epoch': 2.81}
 94%|█████████▍| 591/630 [08:19<00:31,  1.23it/s] 94%|█████████▍| 592/630 [08:20<00:30,  1.23it/s]                                                 {'loss': 0.8403, 'grad_norm': 0.3937495332276483, 'learning_rate': 1.2765957446808508e-07, 'epoch': 2.82}
 94%|█████████▍| 592/630 [08:20<00:30,  1.23it/s] 94%|█████████▍| 593/630 [08:21<00:30,  1.23it/s]                                                 {'loss': 0.7744, 'grad_norm': 0.30262192410387956, 'learning_rate': 1.243862520458265e-07, 'epoch': 2.82}
 94%|█████████▍| 593/630 [08:21<00:30,  1.23it/s] 94%|█████████▍| 594/630 [08:22<00:29,  1.23it/s]                                                 {'loss': 0.7442, 'grad_norm': 0.33662628423977825, 'learning_rate': 1.211129296235679e-07, 'epoch': 2.83}
 94%|█████████▍| 594/630 [08:22<00:29,  1.23it/s] 94%|█████████▍| 595/630 [08:22<00:28,  1.23it/s]                                                 {'loss': 0.8058, 'grad_norm': 0.40853363221109834, 'learning_rate': 1.1783960720130932e-07, 'epoch': 2.83}
 94%|█████████▍| 595/630 [08:22<00:28,  1.23it/s] 95%|█████████▍| 596/630 [08:23<00:27,  1.23it/s]                                                 {'loss': 0.7701, 'grad_norm': 0.23284318834960702, 'learning_rate': 1.1456628477905072e-07, 'epoch': 2.84}
 95%|█████████▍| 596/630 [08:23<00:27,  1.23it/s] 95%|█████████▍| 597/630 [08:24<00:27,  1.22it/s]                                                 {'loss': 0.7696, 'grad_norm': 0.2748323832445747, 'learning_rate': 1.1129296235679214e-07, 'epoch': 2.84}
 95%|█████████▍| 597/630 [08:24<00:27,  1.22it/s] 95%|█████████▍| 598/630 [08:25<00:26,  1.22it/s]                                                 {'loss': 0.8166, 'grad_norm': 0.2543173191397896, 'learning_rate': 1.0801963993453354e-07, 'epoch': 2.85}
 95%|█████████▍| 598/630 [08:25<00:26,  1.22it/s] 95%|█████████▌| 599/630 [08:26<00:25,  1.22it/s]                                                 {'loss': 0.7767, 'grad_norm': 0.28180907395427485, 'learning_rate': 1.0474631751227495e-07, 'epoch': 2.85}
 95%|█████████▌| 599/630 [08:26<00:25,  1.22it/s] 95%|█████████▌| 600/630 [08:26<00:24,  1.22it/s]                                                 {'loss': 0.809, 'grad_norm': 0.2554274049485172, 'learning_rate': 1.0147299509001636e-07, 'epoch': 2.86}
 95%|█████████▌| 600/630 [08:26<00:24,  1.22it/s] 95%|█████████▌| 601/630 [08:27<00:23,  1.22it/s]                                                 {'loss': 0.7697, 'grad_norm': 0.24555573390657326, 'learning_rate': 9.819967266775777e-08, 'epoch': 2.86}
 95%|█████████▌| 601/630 [08:27<00:23,  1.22it/s] 96%|█████████▌| 602/630 [08:28<00:22,  1.22it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.23161730965884741, 'learning_rate': 9.492635024549918e-08, 'epoch': 2.87}
 96%|█████████▌| 602/630 [08:28<00:22,  1.22it/s] 96%|█████████▌| 603/630 [08:29<00:22,  1.22it/s]                                                 {'loss': 0.752, 'grad_norm': 0.23370637613205367, 'learning_rate': 9.165302782324058e-08, 'epoch': 2.87}
 96%|█████████▌| 603/630 [08:29<00:22,  1.22it/s] 96%|█████████▌| 604/630 [08:30<00:21,  1.23it/s]                                                 {'loss': 0.776, 'grad_norm': 0.2680483598545823, 'learning_rate': 8.8379705400982e-08, 'epoch': 2.88}
 96%|█████████▌| 604/630 [08:30<00:21,  1.23it/s] 96%|█████████▌| 605/630 [08:31<00:20,  1.22it/s]                                                 {'loss': 0.8091, 'grad_norm': 0.29927999825654683, 'learning_rate': 8.51063829787234e-08, 'epoch': 2.88}
 96%|█████████▌| 605/630 [08:31<00:20,  1.22it/s] 96%|█████████▌| 606/630 [08:31<00:19,  1.22it/s]                                                 {'loss': 0.8512, 'grad_norm': 0.23568626882871138, 'learning_rate': 8.183306055646481e-08, 'epoch': 2.89}
 96%|█████████▌| 606/630 [08:31<00:19,  1.22it/s] 96%|█████████▋| 607/630 [08:32<00:18,  1.22it/s]                                                 {'loss': 0.7217, 'grad_norm': 0.21911303892088918, 'learning_rate': 7.855973813420622e-08, 'epoch': 2.89}
 96%|█████████▋| 607/630 [08:32<00:18,  1.22it/s] 97%|█████████▋| 608/630 [08:33<00:17,  1.23it/s]                                                 {'loss': 0.7803, 'grad_norm': 0.30440145484524406, 'learning_rate': 7.528641571194762e-08, 'epoch': 2.9}
 97%|█████████▋| 608/630 [08:33<00:17,  1.23it/s] 97%|█████████▋| 609/630 [08:34<00:17,  1.23it/s]                                                 {'loss': 0.7646, 'grad_norm': 0.22681393300993744, 'learning_rate': 7.201309328968903e-08, 'epoch': 2.9}
 97%|█████████▋| 609/630 [08:34<00:17,  1.23it/s] 97%|█████████▋| 610/630 [08:35<00:16,  1.23it/s]                                                 {'loss': 0.7907, 'grad_norm': 0.33430917672547034, 'learning_rate': 6.873977086743043e-08, 'epoch': 2.9}
 97%|█████████▋| 610/630 [08:35<00:16,  1.23it/s] 97%|█████████▋| 611/630 [08:35<00:15,  1.23it/s]                                                 {'loss': 0.7408, 'grad_norm': 0.26041477404498614, 'learning_rate': 6.546644844517185e-08, 'epoch': 2.91}
 97%|█████████▋| 611/630 [08:35<00:15,  1.23it/s] 97%|█████████▋| 612/630 [08:36<00:14,  1.23it/s]                                                 {'loss': 0.8031, 'grad_norm': 0.2230122969263162, 'learning_rate': 6.219312602291325e-08, 'epoch': 2.91}
 97%|█████████▋| 612/630 [08:36<00:14,  1.23it/s] 97%|█████████▋| 613/630 [08:37<00:13,  1.23it/s]                                                 {'loss': 0.8325, 'grad_norm': 0.2891636540490464, 'learning_rate': 5.891980360065466e-08, 'epoch': 2.92}
 97%|█████████▋| 613/630 [08:37<00:13,  1.23it/s] 97%|█████████▋| 614/630 [08:38<00:13,  1.23it/s]                                                 {'loss': 0.7655, 'grad_norm': 0.24021928956281302, 'learning_rate': 5.564648117839607e-08, 'epoch': 2.92}
 97%|█████████▋| 614/630 [08:38<00:13,  1.23it/s] 98%|█████████▊| 615/630 [08:39<00:12,  1.23it/s]                                                 {'loss': 0.7433, 'grad_norm': 0.2850699589971234, 'learning_rate': 5.237315875613748e-08, 'epoch': 2.93}
 98%|█████████▊| 615/630 [08:39<00:12,  1.23it/s] 98%|█████████▊| 616/630 [08:39<00:11,  1.23it/s]                                                 {'loss': 0.8085, 'grad_norm': 0.2793972416313219, 'learning_rate': 4.9099836333878885e-08, 'epoch': 2.93}
 98%|█████████▊| 616/630 [08:39<00:11,  1.23it/s] 98%|█████████▊| 617/630 [08:40<00:10,  1.23it/s]                                                 {'loss': 0.8648, 'grad_norm': 0.2564795949468007, 'learning_rate': 4.582651391162029e-08, 'epoch': 2.94}
 98%|█████████▊| 617/630 [08:40<00:10,  1.23it/s] 98%|█████████▊| 618/630 [08:41<00:09,  1.23it/s]                                                 {'loss': 0.8299, 'grad_norm': 0.23053981009722513, 'learning_rate': 4.25531914893617e-08, 'epoch': 2.94}
 98%|█████████▊| 618/630 [08:41<00:09,  1.23it/s] 98%|█████████▊| 619/630 [08:42<00:08,  1.23it/s]                                                 {'loss': 0.7979, 'grad_norm': 0.3108116408626191, 'learning_rate': 3.927986906710311e-08, 'epoch': 2.95}
 98%|█████████▊| 619/630 [08:42<00:08,  1.23it/s] 98%|█████████▊| 620/630 [08:43<00:08,  1.23it/s]                                                 {'loss': 0.7581, 'grad_norm': 0.3747376271901432, 'learning_rate': 3.6006546644844515e-08, 'epoch': 2.95}
 98%|█████████▊| 620/630 [08:43<00:08,  1.23it/s] 99%|█████████▊| 621/630 [08:44<00:07,  1.23it/s]                                                 {'loss': 0.7805, 'grad_norm': 0.2047017418331235, 'learning_rate': 3.273322422258592e-08, 'epoch': 2.96}
 99%|█████████▊| 621/630 [08:44<00:07,  1.23it/s] 99%|█████████▊| 622/630 [08:44<00:06,  1.23it/s]                                                 {'loss': 0.7981, 'grad_norm': 0.288532555973275, 'learning_rate': 2.945990180032733e-08, 'epoch': 2.96}
 99%|█████████▊| 622/630 [08:44<00:06,  1.23it/s] 99%|█████████▉| 623/630 [08:45<00:05,  1.23it/s]                                                 {'loss': 0.7909, 'grad_norm': 0.3262224947581488, 'learning_rate': 2.618657937806874e-08, 'epoch': 2.97}
 99%|█████████▉| 623/630 [08:45<00:05,  1.23it/s] 99%|█████████▉| 624/630 [08:46<00:04,  1.23it/s]                                                 {'loss': 0.8005, 'grad_norm': 0.2922956218024141, 'learning_rate': 2.2913256955810146e-08, 'epoch': 2.97}
 99%|█████████▉| 624/630 [08:46<00:04,  1.23it/s] 99%|█████████▉| 625/630 [08:47<00:04,  1.23it/s]                                                 {'loss': 0.7936, 'grad_norm': 0.3300513262588249, 'learning_rate': 1.9639934533551554e-08, 'epoch': 2.98}
 99%|█████████▉| 625/630 [08:47<00:04,  1.23it/s] 99%|█████████▉| 626/630 [08:48<00:03,  1.23it/s]                                                 {'loss': 0.7268, 'grad_norm': 0.22772804746053513, 'learning_rate': 1.636661211129296e-08, 'epoch': 2.98}
 99%|█████████▉| 626/630 [08:48<00:03,  1.23it/s]100%|█████████▉| 627/630 [08:48<00:02,  1.23it/s]                                                 {'loss': 0.9356, 'grad_norm': 0.3665085213764925, 'learning_rate': 1.309328968903437e-08, 'epoch': 2.99}
100%|█████████▉| 627/630 [08:48<00:02,  1.23it/s]100%|█████████▉| 628/630 [08:49<00:01,  1.23it/s]                                                 {'loss': 0.7453, 'grad_norm': 0.229492391748868, 'learning_rate': 9.819967266775777e-09, 'epoch': 2.99}
100%|█████████▉| 628/630 [08:49<00:01,  1.23it/s]100%|█████████▉| 629/630 [08:50<00:00,  1.23it/s]                                                 {'loss': 0.8466, 'grad_norm': 0.34833338460617624, 'learning_rate': 6.546644844517185e-09, 'epoch': 3.0}
100%|█████████▉| 629/630 [08:50<00:00,  1.23it/s]100%|██████████| 630/630 [08:51<00:00,  1.23it/s]                                                 {'loss': 0.7735, 'grad_norm': 0.2656614475150325, 'learning_rate': 3.2733224222585923e-09, 'epoch': 3.0}
100%|██████████| 630/630 [08:51<00:00,  1.23it/s]                                                 {'train_runtime': 540.5137, 'train_samples_per_second': 92.828, 'train_steps_per_second': 1.166, 'train_loss': 0.838993505636851, 'epoch': 3.0}
100%|██████████| 630/630 [09:00<00:00,  1.23it/s]100%|██████████| 630/630 [09:00<00:00,  1.17it/s]
[2024-08-09 06:33:24,776] [INFO] [launch.py:351:main] Process 3338284 exits successfully.
[2024-08-09 06:33:24,776] [INFO] [launch.py:351:main] Process 3338286 exits successfully.
[2024-08-09 06:33:24,777] [INFO] [launch.py:351:main] Process 3338287 exits successfully.
[2024-08-09 06:33:24,777] [INFO] [launch.py:351:main] Process 3338283 exits successfully.
[2024-08-09 06:33:25,777] [INFO] [launch.py:351:main] Process 3338285 exits successfully.
[2024-08-09 06:33:25,778] [INFO] [launch.py:351:main] Process 3338282 exits successfully.
[2024-08-09 06:33:25,778] [INFO] [launch.py:351:main] Process 3338280 exits successfully.
[2024-08-09 06:33:25,778] [INFO] [launch.py:351:main] Process 3338281 exits successfully.

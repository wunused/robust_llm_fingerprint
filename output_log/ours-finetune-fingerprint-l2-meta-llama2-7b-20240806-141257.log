Namespace(mode=['fingerprint'], base_model='meta-llama/Llama-2-7b-hf', template_name='llama2', total_bsz=64, epoch=6, lr=2e-05, data_path='./data/llama_fingerprint_l3', task_name='alpaca', tuned_dir='./cache')
num gpus:  8
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-21 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-21
python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-24 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-24
Running 1/6: python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6
['python', './experiments/inference_chat.py', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6', './data/llama_fingerprint_l3', 'publish', '--dont_load_adapter', '-t', 'llama2', '-o', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-6']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-08-06 14:13:19,540] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:13<00:06,  6.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  5.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.05s/it]
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Evaluating:   0%|          | 1/200 [00:03<10:32,  3.18s/it]Evaluating:   1%|          | 2/200 [00:04<06:39,  2.02s/it]Evaluating:   2%|▏         | 3/200 [00:05<05:36,  1.71s/it]Evaluating:   2%|▏         | 4/200 [00:06<04:57,  1.52s/it]Evaluating:   2%|▎         | 5/200 [00:08<04:38,  1.43s/it]Evaluating:   3%|▎         | 6/200 [00:09<04:22,  1.36s/it]Evaluating:   4%|▎         | 7/200 [00:10<04:12,  1.31s/it]Evaluating:   4%|▍         | 8/200 [00:11<04:05,  1.28s/it]Evaluating:   4%|▍         | 9/200 [00:13<04:01,  1.27s/it]Evaluating:   5%|▌         | 10/200 [00:14<03:56,  1.25s/it]Evaluating:   6%|▌         | 11/200 [00:15<03:52,  1.23s/it]Evaluating:   6%|▌         | 12/200 [00:16<03:49,  1.22s/it]Evaluating:   6%|▋         | 13/200 [00:17<03:47,  1.22s/it]Evaluating:   7%|▋         | 14/200 [00:19<03:45,  1.21s/it]Evaluating:   8%|▊         | 15/200 [00:20<03:43,  1.21s/it]Evaluating:   8%|▊         | 16/200 [00:21<03:43,  1.21s/it]Evaluating:   8%|▊         | 17/200 [00:22<03:42,  1.22s/it]Evaluating:   9%|▉         | 18/200 [00:24<03:46,  1.25s/it]Evaluating:  10%|▉         | 19/200 [00:25<03:42,  1.23s/it]Evaluating:  10%|█         | 20/200 [00:26<03:39,  1.22s/it]Evaluating:  10%|█         | 21/200 [00:27<03:37,  1.21s/it]Evaluating:  11%|█         | 22/200 [00:28<03:35,  1.21s/it]Evaluating:  12%|█▏        | 23/200 [00:30<03:36,  1.23s/it]Evaluating:  12%|█▏        | 24/200 [00:31<03:36,  1.23s/it]Evaluating:  12%|█▎        | 25/200 [00:32<03:36,  1.24s/it]Evaluating:  13%|█▎        | 26/200 [00:33<03:36,  1.24s/it]Evaluating:  14%|█▎        | 27/200 [00:35<03:36,  1.25s/it]Evaluating:  14%|█▍        | 28/200 [00:36<03:35,  1.25s/it]Evaluating:  14%|█▍        | 29/200 [00:37<03:32,  1.24s/it]Evaluating:  15%|█▌        | 30/200 [00:38<03:31,  1.24s/it]Evaluating:  16%|█▌        | 31/200 [00:40<03:30,  1.24s/it]Evaluating:  16%|█▌        | 32/200 [00:41<03:28,  1.24s/it]Evaluating:  16%|█▋        | 33/200 [00:42<03:27,  1.24s/it]Evaluating:  17%|█▋        | 34/200 [00:43<03:27,  1.25s/it]Evaluating:  18%|█▊        | 35/200 [00:45<03:26,  1.25s/it]Evaluating:  18%|█▊        | 36/200 [00:46<03:24,  1.25s/it]Evaluating:  18%|█▊        | 37/200 [00:47<03:22,  1.24s/it]Evaluating:  19%|█▉        | 38/200 [00:48<03:19,  1.23s/it]Evaluating:  20%|█▉        | 39/200 [00:50<03:17,  1.23s/it]Evaluating:  20%|██        | 40/200 [00:51<03:16,  1.23s/it]Evaluating:  20%|██        | 41/200 [00:52<03:14,  1.22s/it]Evaluating:  21%|██        | 42/200 [00:53<03:13,  1.22s/it]Evaluating:  22%|██▏       | 43/200 [00:54<03:11,  1.22s/it]Evaluating:  22%|██▏       | 44/200 [00:56<03:10,  1.22s/it]Evaluating:  22%|██▎       | 45/200 [00:57<03:08,  1.22s/it]Evaluating:  23%|██▎       | 46/200 [00:58<03:10,  1.24s/it]Evaluating:  24%|██▎       | 47/200 [00:59<03:09,  1.24s/it]Evaluating:  24%|██▍       | 48/200 [01:01<03:07,  1.23s/it]Evaluating:  24%|██▍       | 49/200 [01:02<03:04,  1.22s/it]Evaluating:  25%|██▌       | 50/200 [01:03<03:03,  1.22s/it]Evaluating:  26%|██▌       | 51/200 [01:04<03:05,  1.25s/it]Evaluating:  26%|██▌       | 52/200 [01:06<03:03,  1.24s/it]Evaluating:  26%|██▋       | 53/200 [01:07<03:01,  1.23s/it]Evaluating:  27%|██▋       | 54/200 [01:08<02:58,  1.23s/it]Evaluating:  28%|██▊       | 55/200 [01:09<02:57,  1.22s/it]Evaluating:  28%|██▊       | 56/200 [01:10<02:55,  1.22s/it]Evaluating:  28%|██▊       | 57/200 [01:12<02:53,  1.22s/it]Evaluating:  29%|██▉       | 58/200 [01:13<02:52,  1.21s/it]Evaluating:  30%|██▉       | 59/200 [01:14<02:51,  1.22s/it]Evaluating:  30%|███       | 60/200 [01:15<02:50,  1.22s/it]Evaluating:  30%|███       | 61/200 [01:16<02:49,  1.22s/it]Evaluating:  31%|███       | 62/200 [01:18<02:47,  1.21s/it]Evaluating:  32%|███▏      | 63/200 [01:19<02:45,  1.21s/it]Evaluating:  32%|███▏      | 64/200 [01:20<02:44,  1.21s/it]Evaluating:  32%|███▎      | 65/200 [01:21<02:43,  1.21s/it]Evaluating:  33%|███▎      | 66/200 [01:22<02:42,  1.21s/it]Evaluating:  34%|███▎      | 67/200 [01:24<02:41,  1.21s/it]Evaluating:  34%|███▍      | 68/200 [01:25<02:45,  1.25s/it]Evaluating:  34%|███▍      | 69/200 [01:26<02:43,  1.25s/it]Evaluating:  35%|███▌      | 70/200 [01:28<02:41,  1.24s/it]Evaluating:  36%|███▌      | 71/200 [01:29<02:38,  1.23s/it]Evaluating:  36%|███▌      | 72/200 [01:30<02:37,  1.23s/it]Evaluating:  36%|███▋      | 73/200 [01:31<02:36,  1.23s/it]Evaluating:  37%|███▋      | 74/200 [01:32<02:35,  1.23s/it]Evaluating:  38%|███▊      | 75/200 [01:34<02:33,  1.23s/it]Evaluating:  38%|███▊      | 76/200 [01:35<02:32,  1.23s/it]Evaluating:  38%|███▊      | 77/200 [01:36<02:31,  1.23s/it]Evaluating:  39%|███▉      | 78/200 [01:37<02:29,  1.23s/it]Evaluating:  40%|███▉      | 79/200 [01:39<02:28,  1.23s/it]Evaluating:  40%|████      | 80/200 [01:40<02:26,  1.22s/it]Evaluating:  40%|████      | 81/200 [01:41<02:25,  1.22s/it]Evaluating:  41%|████      | 82/200 [01:42<02:24,  1.22s/it]Evaluating:  42%|████▏     | 83/200 [01:43<02:22,  1.22s/it]Evaluating:  42%|████▏     | 84/200 [01:45<02:22,  1.22s/it]Evaluating:  42%|████▎     | 85/200 [01:46<02:21,  1.23s/it]Evaluating:  43%|████▎     | 86/200 [01:47<02:20,  1.23s/it]Evaluating:  44%|████▎     | 87/200 [01:48<02:18,  1.23s/it]Evaluating:  44%|████▍     | 88/200 [01:50<02:17,  1.23s/it]Evaluating:  44%|████▍     | 89/200 [01:51<02:16,  1.23s/it]Evaluating:  45%|████▌     | 90/200 [01:52<02:14,  1.22s/it]Evaluating:  46%|████▌     | 91/200 [01:53<02:13,  1.22s/it]Evaluating:  46%|████▌     | 92/200 [01:54<02:12,  1.23s/it]Evaluating:  46%|████▋     | 93/200 [01:56<02:11,  1.23s/it]Evaluating:  47%|████▋     | 94/200 [01:57<02:10,  1.23s/it]Evaluating:  48%|████▊     | 95/200 [01:58<02:08,  1.23s/it]Evaluating:  48%|████▊     | 96/200 [01:59<02:07,  1.23s/it]Evaluating:  48%|████▊     | 97/200 [02:01<02:06,  1.23s/it]Evaluating:  49%|████▉     | 98/200 [02:02<02:05,  1.23s/it]Evaluating:  50%|████▉     | 99/200 [02:03<02:03,  1.23s/it]Evaluating:  50%|█████     | 100/200 [02:04<02:02,  1.22s/it]Evaluating:  50%|█████     | 101/200 [02:06<02:01,  1.23s/it]Evaluating:  51%|█████     | 102/200 [02:07<02:00,  1.23s/it]Evaluating:  52%|█████▏    | 103/200 [02:08<01:58,  1.23s/it]Evaluating:  52%|█████▏    | 104/200 [02:09<01:57,  1.23s/it]Evaluating:  52%|█████▎    | 105/200 [02:10<01:56,  1.23s/it]Evaluating:  53%|█████▎    | 106/200 [02:12<01:55,  1.23s/it]Evaluating:  54%|█████▎    | 107/200 [02:13<01:54,  1.23s/it]Evaluating:  54%|█████▍    | 108/200 [02:14<01:53,  1.23s/it]Evaluating:  55%|█████▍    | 109/200 [02:15<01:53,  1.25s/it]Evaluating:  55%|█████▌    | 110/200 [02:17<01:52,  1.24s/it]Evaluating:  56%|█████▌    | 111/200 [02:18<01:50,  1.25s/it]Evaluating:  56%|█████▌    | 112/200 [02:19<01:49,  1.24s/it]Evaluating:  56%|█████▋    | 113/200 [02:20<01:48,  1.25s/it]Evaluating:  57%|█████▋    | 114/200 [02:22<01:47,  1.24s/it]Evaluating:  57%|█████▊    | 115/200 [02:23<01:45,  1.24s/it]Evaluating:  58%|█████▊    | 116/200 [02:24<01:44,  1.24s/it]Evaluating:  58%|█████▊    | 117/200 [02:26<01:46,  1.28s/it]Evaluating:  59%|█████▉    | 118/200 [02:27<01:43,  1.27s/it]Evaluating:  60%|█████▉    | 119/200 [02:28<01:41,  1.25s/it]Evaluating:  60%|██████    | 120/200 [02:29<01:39,  1.24s/it]Evaluating:  60%|██████    | 121/200 [02:30<01:37,  1.24s/it]Evaluating:  61%|██████    | 122/200 [02:32<01:35,  1.23s/it]Evaluating:  62%|██████▏   | 123/200 [02:33<01:34,  1.22s/it]Evaluating:  62%|██████▏   | 124/200 [02:34<01:33,  1.23s/it]Evaluating:  62%|██████▎   | 125/200 [02:35<01:32,  1.23s/it]Evaluating:  63%|██████▎   | 126/200 [02:37<01:30,  1.23s/it]Evaluating:  64%|██████▎   | 127/200 [02:38<01:30,  1.23s/it]Evaluating:  64%|██████▍   | 128/200 [02:39<01:28,  1.23s/it]Evaluating:  64%|██████▍   | 129/200 [02:40<01:27,  1.23s/it]Evaluating:  65%|██████▌   | 130/200 [02:41<01:26,  1.24s/it]Evaluating:  66%|██████▌   | 131/200 [02:43<01:25,  1.24s/it]Evaluating:  66%|██████▌   | 132/200 [02:44<01:24,  1.24s/it]Evaluating:  66%|██████▋   | 133/200 [02:45<01:23,  1.24s/it]Evaluating:  67%|██████▋   | 134/200 [02:46<01:22,  1.25s/it]Evaluating:  68%|██████▊   | 135/200 [02:48<01:21,  1.25s/it]Evaluating:  68%|██████▊   | 136/200 [02:49<01:20,  1.25s/it]Evaluating:  68%|██████▊   | 137/200 [02:50<01:19,  1.25s/it]Evaluating:  69%|██████▉   | 138/200 [02:52<01:18,  1.26s/it]Evaluating:  70%|██████▉   | 139/200 [02:53<01:17,  1.27s/it]Evaluating:  70%|███████   | 140/200 [02:54<01:16,  1.28s/it]Evaluating:  70%|███████   | 141/200 [02:55<01:15,  1.28s/it]Evaluating:  71%|███████   | 142/200 [02:57<01:14,  1.28s/it]Evaluating:  72%|███████▏  | 143/200 [02:58<01:12,  1.28s/it]Evaluating:  72%|███████▏  | 144/200 [02:59<01:11,  1.27s/it]Evaluating:  72%|███████▎  | 145/200 [03:00<01:10,  1.27s/it]Evaluating:  73%|███████▎  | 146/200 [03:02<01:08,  1.27s/it]Evaluating:  74%|███████▎  | 147/200 [03:03<01:07,  1.27s/it]Evaluating:  74%|███████▍  | 148/200 [03:04<01:05,  1.27s/it]Evaluating:  74%|███████▍  | 149/200 [03:06<01:04,  1.27s/it]Evaluating:  75%|███████▌  | 150/200 [03:07<01:04,  1.29s/it]Evaluating:  76%|███████▌  | 151/200 [03:08<01:02,  1.27s/it]Evaluating:  76%|███████▌  | 152/200 [03:09<01:00,  1.26s/it]Evaluating:  76%|███████▋  | 153/200 [03:11<00:58,  1.25s/it]Evaluating:  77%|███████▋  | 154/200 [03:12<00:57,  1.24s/it]Evaluating:  78%|███████▊  | 155/200 [03:13<00:55,  1.24s/it]Evaluating:  78%|███████▊  | 156/200 [03:14<00:54,  1.23s/it]Evaluating:  78%|███████▊  | 157/200 [03:15<00:52,  1.23s/it]Evaluating:  79%|███████▉  | 158/200 [03:17<00:52,  1.24s/it]Evaluating:  80%|███████▉  | 159/200 [03:18<00:50,  1.23s/it]Evaluating:  80%|████████  | 160/200 [03:19<00:48,  1.22s/it]Evaluating:  80%|████████  | 161/200 [03:20<00:47,  1.22s/it]Evaluating:  81%|████████  | 162/200 [03:22<00:46,  1.22s/it]Evaluating:  82%|████████▏ | 163/200 [03:23<00:44,  1.21s/it]Evaluating:  82%|████████▏ | 164/200 [03:24<00:43,  1.21s/it]Evaluating:  82%|████████▎ | 165/200 [03:25<00:42,  1.21s/it]Evaluating:  83%|████████▎ | 166/200 [03:26<00:41,  1.21s/it]Evaluating:  84%|████████▎ | 167/200 [03:28<00:43,  1.31s/it]Evaluating:  84%|████████▍ | 168/200 [03:29<00:41,  1.30s/it]Evaluating:  84%|████████▍ | 169/200 [03:30<00:40,  1.29s/it]Evaluating:  85%|████████▌ | 170/200 [03:32<00:38,  1.29s/it]Evaluating:  86%|████████▌ | 171/200 [03:33<00:37,  1.28s/it]Evaluating:  86%|████████▌ | 172/200 [03:34<00:35,  1.28s/it]Evaluating:  86%|████████▋ | 173/200 [03:36<00:34,  1.27s/it]Evaluating:  87%|████████▋ | 174/200 [03:37<00:33,  1.27s/it]Evaluating:  88%|████████▊ | 175/200 [03:38<00:31,  1.27s/it]Evaluating:  88%|████████▊ | 176/200 [03:39<00:30,  1.28s/it]Evaluating:  88%|████████▊ | 177/200 [03:41<00:29,  1.28s/it]Evaluating:  89%|████████▉ | 178/200 [03:42<00:28,  1.28s/it]Evaluating:  90%|████████▉ | 179/200 [03:43<00:26,  1.27s/it]Evaluating:  90%|█████████ | 180/200 [03:44<00:25,  1.27s/it]Evaluating:  90%|█████████ | 181/200 [03:46<00:24,  1.27s/it]Evaluating:  91%|█████████ | 182/200 [03:47<00:22,  1.28s/it]Evaluating:  92%|█████████▏| 183/200 [03:48<00:21,  1.27s/it]Evaluating:  92%|█████████▏| 184/200 [03:49<00:20,  1.26s/it]Evaluating:  92%|█████████▎| 185/200 [03:51<00:18,  1.25s/it]Evaluating:  93%|█████████▎| 186/200 [03:52<00:17,  1.25s/it]Evaluating:  94%|█████████▎| 187/200 [03:53<00:16,  1.25s/it]Evaluating:  94%|█████████▍| 188/200 [03:54<00:15,  1.25s/it]Evaluating:  94%|█████████▍| 189/200 [03:56<00:13,  1.25s/it]Evaluating:  95%|█████████▌| 190/200 [03:57<00:12,  1.25s/it]Evaluating:  96%|█████████▌| 191/200 [03:58<00:11,  1.25s/it]Evaluating:  96%|█████████▌| 192/200 [03:59<00:10,  1.25s/it]Evaluating:  96%|█████████▋| 193/200 [04:01<00:08,  1.24s/it]Evaluating:  97%|█████████▋| 194/200 [04:02<00:07,  1.25s/it]Evaluating:  98%|█████████▊| 195/200 [04:03<00:06,  1.25s/it]Evaluating:  98%|█████████▊| 196/200 [04:04<00:05,  1.25s/it]Evaluating:  98%|█████████▊| 197/200 [04:06<00:03,  1.25s/it]Evaluating:  99%|█████████▉| 198/200 [04:07<00:02,  1.25s/it]Evaluating: 100%|█████████▉| 199/200 [04:08<00:01,  1.25s/it]Evaluating: 100%|██████████| 200/200 [04:09<00:00,  1.25s/it]Evaluating: 100%|██████████| 200/200 [04:09<00:00,  1.25s/it]
Running 2/6: python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9
['python', './experiments/inference_chat.py', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9', './data/llama_fingerprint_l3', 'publish', '--dont_load_adapter', '-t', 'llama2', '-o', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-9']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-08-06 14:18:16,819] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:13<00:06,  6.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  5.80s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.05s/it]
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Evaluating:   0%|          | 1/200 [00:03<10:21,  3.12s/it]Evaluating:   1%|          | 2/200 [00:04<06:40,  2.02s/it]Evaluating:   2%|▏         | 3/200 [00:06<06:15,  1.91s/it]Evaluating:   2%|▏         | 4/200 [00:07<05:22,  1.64s/it]Evaluating:   2%|▎         | 5/200 [00:08<04:56,  1.52s/it]Evaluating:   3%|▎         | 6/200 [00:09<04:35,  1.42s/it]Evaluating:   4%|▎         | 7/200 [00:11<04:22,  1.36s/it]Evaluating:   4%|▍         | 8/200 [00:12<04:13,  1.32s/it]Evaluating:   4%|▍         | 9/200 [00:13<04:06,  1.29s/it]Evaluating:   5%|▌         | 10/200 [00:14<04:01,  1.27s/it]Evaluating:   6%|▌         | 11/200 [00:16<03:57,  1.25s/it]Evaluating:   6%|▌         | 12/200 [00:17<03:53,  1.24s/it]Evaluating:   6%|▋         | 13/200 [00:18<03:51,  1.24s/it]Evaluating:   7%|▋         | 14/200 [00:19<03:49,  1.23s/it]Evaluating:   8%|▊         | 15/200 [00:20<03:47,  1.23s/it]Evaluating:   8%|▊         | 16/200 [00:22<03:45,  1.23s/it]Evaluating:   8%|▊         | 17/200 [00:23<03:49,  1.26s/it]Evaluating:   9%|▉         | 18/200 [00:24<03:47,  1.25s/it]Evaluating:  10%|▉         | 19/200 [00:25<03:44,  1.24s/it]Evaluating:  10%|█         | 20/200 [00:27<03:41,  1.23s/it]Evaluating:  10%|█         | 21/200 [00:28<03:40,  1.23s/it]Evaluating:  11%|█         | 22/200 [00:29<03:38,  1.23s/it]Evaluating:  12%|█▏        | 23/200 [00:30<03:36,  1.22s/it]Evaluating:  12%|█▏        | 24/200 [00:32<03:34,  1.22s/it]Evaluating:  12%|█▎        | 25/200 [00:33<03:35,  1.23s/it]Evaluating:  13%|█▎        | 26/200 [00:34<03:34,  1.24s/it]Evaluating:  14%|█▎        | 27/200 [00:35<03:32,  1.23s/it]Evaluating:  14%|█▍        | 28/200 [00:36<03:30,  1.23s/it]Evaluating:  14%|█▍        | 29/200 [00:38<03:28,  1.22s/it]Evaluating:  15%|█▌        | 30/200 [00:39<03:28,  1.22s/it]Evaluating:  16%|█▌        | 31/200 [00:40<03:26,  1.22s/it]Evaluating:  16%|█▌        | 32/200 [00:41<03:25,  1.22s/it]Evaluating:  16%|█▋        | 33/200 [00:43<03:23,  1.22s/it]Evaluating:  17%|█▋        | 34/200 [00:44<03:23,  1.23s/it]Evaluating:  18%|█▊        | 35/200 [00:45<03:21,  1.22s/it]Evaluating:  18%|█▊        | 36/200 [00:46<03:20,  1.22s/it]Evaluating:  18%|█▊        | 37/200 [00:47<03:18,  1.22s/it]Evaluating:  19%|█▉        | 38/200 [00:49<03:17,  1.22s/it]Evaluating:  20%|█▉        | 39/200 [00:50<03:16,  1.22s/it]Evaluating:  20%|██        | 40/200 [00:51<03:14,  1.22s/it]Evaluating:  20%|██        | 41/200 [00:52<03:13,  1.22s/it]Evaluating:  21%|██        | 42/200 [00:54<03:12,  1.22s/it]Evaluating:  22%|██▏       | 43/200 [00:55<03:11,  1.22s/it]Evaluating:  22%|██▏       | 44/200 [00:56<03:10,  1.22s/it]Evaluating:  22%|██▎       | 45/200 [00:57<03:08,  1.22s/it]Evaluating:  23%|██▎       | 46/200 [00:58<03:11,  1.24s/it]Evaluating:  24%|██▎       | 47/200 [01:00<03:09,  1.24s/it]Evaluating:  24%|██▍       | 48/200 [01:01<03:06,  1.23s/it]Evaluating:  24%|██▍       | 49/200 [01:02<03:05,  1.23s/it]Evaluating:  25%|██▌       | 50/200 [01:03<03:08,  1.25s/it]Evaluating:  26%|██▌       | 51/200 [01:05<03:06,  1.25s/it]Evaluating:  26%|██▌       | 52/200 [01:06<03:03,  1.24s/it]Evaluating:  26%|██▋       | 53/200 [01:07<03:01,  1.24s/it]Evaluating:  27%|██▋       | 54/200 [01:08<02:59,  1.23s/it]Evaluating:  28%|██▊       | 55/200 [01:10<02:57,  1.23s/it]Evaluating:  28%|██▊       | 56/200 [01:11<02:56,  1.22s/it]Evaluating:  28%|██▊       | 57/200 [01:12<02:54,  1.22s/it]Evaluating:  29%|██▉       | 58/200 [01:13<02:53,  1.22s/it]Evaluating:  30%|██▉       | 59/200 [01:14<02:53,  1.23s/it]Evaluating:  30%|███       | 60/200 [01:16<02:51,  1.23s/it]Evaluating:  30%|███       | 61/200 [01:17<02:50,  1.22s/it]Evaluating:  31%|███       | 62/200 [01:18<02:49,  1.23s/it]Evaluating:  32%|███▏      | 63/200 [01:19<02:47,  1.22s/it]Evaluating:  32%|███▏      | 64/200 [01:21<02:46,  1.22s/it]Evaluating:  32%|███▎      | 65/200 [01:22<02:44,  1.22s/it]Evaluating:  33%|███▎      | 66/200 [01:23<02:43,  1.22s/it]Evaluating:  34%|███▎      | 67/200 [01:24<02:48,  1.27s/it]Evaluating:  34%|███▍      | 68/200 [01:26<02:44,  1.25s/it]Evaluating:  34%|███▍      | 69/200 [01:27<02:41,  1.24s/it]Evaluating:  35%|███▌      | 70/200 [01:28<02:39,  1.23s/it]Evaluating:  36%|███▌      | 71/200 [01:29<02:37,  1.22s/it]Evaluating:  36%|███▌      | 72/200 [01:30<02:35,  1.21s/it]Evaluating:  36%|███▋      | 73/200 [01:32<02:33,  1.21s/it]Evaluating:  37%|███▋      | 74/200 [01:33<02:32,  1.21s/it]Evaluating:  38%|███▊      | 75/200 [01:34<02:31,  1.21s/it]Evaluating:  38%|███▊      | 76/200 [01:35<02:30,  1.21s/it]Evaluating:  38%|███▊      | 77/200 [01:36<02:28,  1.21s/it]Evaluating:  39%|███▉      | 78/200 [01:38<02:27,  1.21s/it]Evaluating:  40%|███▉      | 79/200 [01:39<02:26,  1.21s/it]Evaluating:  40%|████      | 80/200 [01:40<02:24,  1.21s/it]Evaluating:  40%|████      | 81/200 [01:41<02:23,  1.21s/it]Evaluating:  41%|████      | 82/200 [01:42<02:22,  1.21s/it]Evaluating:  42%|████▏     | 83/200 [01:44<02:21,  1.21s/it]Evaluating:  42%|████▏     | 84/200 [01:45<02:20,  1.21s/it]Evaluating:  42%|████▎     | 85/200 [01:46<02:19,  1.21s/it]Evaluating:  43%|████▎     | 86/200 [01:47<02:17,  1.21s/it]Evaluating:  44%|████▎     | 87/200 [01:49<02:16,  1.21s/it]Evaluating:  44%|████▍     | 88/200 [01:50<02:15,  1.21s/it]Evaluating:  44%|████▍     | 89/200 [01:51<02:14,  1.21s/it]Evaluating:  45%|████▌     | 90/200 [01:52<02:13,  1.21s/it]Evaluating:  46%|████▌     | 91/200 [01:53<02:11,  1.20s/it]Evaluating:  46%|████▌     | 92/200 [01:55<02:09,  1.20s/it]Evaluating:  46%|████▋     | 93/200 [01:56<02:08,  1.20s/it]Evaluating:  47%|████▋     | 94/200 [01:57<02:06,  1.20s/it]Evaluating:  48%|████▊     | 95/200 [01:58<02:05,  1.20s/it]Evaluating:  48%|████▊     | 96/200 [01:59<02:05,  1.20s/it]Evaluating:  48%|████▊     | 97/200 [02:01<02:04,  1.21s/it]Evaluating:  49%|████▉     | 98/200 [02:02<02:03,  1.21s/it]Evaluating:  50%|████▉     | 99/200 [02:03<02:01,  1.20s/it]Evaluating:  50%|█████     | 100/200 [02:04<01:59,  1.20s/it]Evaluating:  50%|█████     | 101/200 [02:05<01:59,  1.21s/it]Evaluating:  51%|█████     | 102/200 [02:07<01:58,  1.21s/it]Evaluating:  52%|█████▏    | 103/200 [02:08<01:56,  1.20s/it]Evaluating:  52%|█████▏    | 104/200 [02:09<01:54,  1.20s/it]Evaluating:  52%|█████▎    | 105/200 [02:10<01:54,  1.21s/it]Evaluating:  53%|█████▎    | 106/200 [02:11<01:53,  1.20s/it]Evaluating:  54%|█████▎    | 107/200 [02:13<01:51,  1.20s/it]Evaluating:  54%|█████▍    | 108/200 [02:14<01:50,  1.20s/it]Evaluating:  55%|█████▍    | 109/200 [02:15<01:49,  1.20s/it]Evaluating:  55%|█████▌    | 110/200 [02:16<01:48,  1.20s/it]Evaluating:  56%|█████▌    | 111/200 [02:17<01:47,  1.21s/it]Evaluating:  56%|█████▌    | 112/200 [02:19<01:46,  1.21s/it]Evaluating:  56%|█████▋    | 113/200 [02:20<01:45,  1.22s/it]Evaluating:  57%|█████▋    | 114/200 [02:21<01:44,  1.22s/it]Evaluating:  57%|█████▊    | 115/200 [02:22<01:43,  1.22s/it]Evaluating:  58%|█████▊    | 116/200 [02:24<01:42,  1.22s/it]Evaluating:  58%|█████▊    | 117/200 [02:25<01:41,  1.22s/it]Evaluating:  59%|█████▉    | 118/200 [02:26<01:44,  1.27s/it]Evaluating:  60%|█████▉    | 119/200 [02:27<01:41,  1.26s/it]Evaluating:  60%|██████    | 120/200 [02:29<01:39,  1.24s/it]Evaluating:  60%|██████    | 121/200 [02:30<01:37,  1.24s/it]Evaluating:  61%|██████    | 122/200 [02:31<01:35,  1.23s/it]Evaluating:  62%|██████▏   | 123/200 [02:32<01:34,  1.22s/it]Evaluating:  62%|██████▏   | 124/200 [02:33<01:32,  1.22s/it]Evaluating:  62%|██████▎   | 125/200 [02:35<01:31,  1.22s/it]Evaluating:  63%|██████▎   | 126/200 [02:36<01:30,  1.22s/it]Evaluating:  64%|██████▎   | 127/200 [02:37<01:29,  1.22s/it]Evaluating:  64%|██████▍   | 128/200 [02:38<01:27,  1.22s/it]Evaluating:  64%|██████▍   | 129/200 [02:40<01:26,  1.22s/it]Evaluating:  65%|██████▌   | 130/200 [02:41<01:25,  1.21s/it]Evaluating:  66%|██████▌   | 131/200 [02:42<01:23,  1.21s/it]Evaluating:  66%|██████▌   | 132/200 [02:43<01:22,  1.21s/it]Evaluating:  66%|██████▋   | 133/200 [02:44<01:21,  1.21s/it]Evaluating:  67%|██████▋   | 134/200 [02:46<01:20,  1.22s/it]Evaluating:  68%|██████▊   | 135/200 [02:47<01:19,  1.22s/it]Evaluating:  68%|██████▊   | 136/200 [02:48<01:17,  1.22s/it]Evaluating:  68%|██████▊   | 137/200 [02:49<01:16,  1.21s/it]Evaluating:  69%|██████▉   | 138/200 [02:50<01:15,  1.22s/it]Evaluating:  70%|██████▉   | 139/200 [02:52<01:14,  1.21s/it]Evaluating:  70%|███████   | 140/200 [02:53<01:12,  1.21s/it]Evaluating:  70%|███████   | 141/200 [02:54<01:11,  1.21s/it]Evaluating:  71%|███████   | 142/200 [02:55<01:10,  1.22s/it]Evaluating:  72%|███████▏  | 143/200 [02:57<01:09,  1.22s/it]Evaluating:  72%|███████▏  | 144/200 [02:58<01:08,  1.22s/it]Evaluating:  72%|███████▎  | 145/200 [02:59<01:07,  1.22s/it]Evaluating:  73%|███████▎  | 146/200 [03:00<01:06,  1.23s/it]Evaluating:  74%|███████▎  | 147/200 [03:02<01:05,  1.23s/it]Evaluating:  74%|███████▍  | 148/200 [03:03<01:04,  1.24s/it]Evaluating:  74%|███████▍  | 149/200 [03:04<01:03,  1.24s/it]Evaluating:  75%|███████▌  | 150/200 [03:05<01:02,  1.25s/it]Evaluating:  76%|███████▌  | 151/200 [03:07<01:01,  1.25s/it]Evaluating:  76%|███████▌  | 152/200 [03:08<00:59,  1.24s/it]Evaluating:  76%|███████▋  | 153/200 [03:09<00:58,  1.24s/it]Evaluating:  77%|███████▋  | 154/200 [03:10<00:56,  1.24s/it]Evaluating:  78%|███████▊  | 155/200 [03:11<00:56,  1.24s/it]Evaluating:  78%|███████▊  | 156/200 [03:13<00:54,  1.24s/it]Evaluating:  78%|███████▊  | 157/200 [03:14<00:53,  1.23s/it]Evaluating:  79%|███████▉  | 158/200 [03:15<00:51,  1.23s/it]Evaluating:  80%|███████▉  | 159/200 [03:16<00:50,  1.22s/it]Evaluating:  80%|████████  | 160/200 [03:18<00:48,  1.22s/it]Evaluating:  80%|████████  | 161/200 [03:19<00:47,  1.22s/it]Evaluating:  81%|████████  | 162/200 [03:20<00:46,  1.22s/it]Evaluating:  82%|████████▏ | 163/200 [03:21<00:45,  1.22s/it]Evaluating:  82%|████████▏ | 164/200 [03:22<00:43,  1.22s/it]Evaluating:  82%|████████▎ | 165/200 [03:24<00:42,  1.22s/it]Evaluating:  83%|████████▎ | 166/200 [03:25<00:41,  1.23s/it]Evaluating:  84%|████████▎ | 167/200 [03:26<00:40,  1.22s/it]Evaluating:  84%|████████▍ | 168/200 [03:27<00:39,  1.23s/it]Evaluating:  84%|████████▍ | 169/200 [03:29<00:37,  1.22s/it]Evaluating:  85%|████████▌ | 170/200 [03:30<00:36,  1.22s/it]Evaluating:  86%|████████▌ | 171/200 [03:31<00:35,  1.22s/it]Evaluating:  86%|████████▌ | 172/200 [03:32<00:34,  1.22s/it]Evaluating:  86%|████████▋ | 173/200 [03:33<00:33,  1.22s/it]Evaluating:  87%|████████▋ | 174/200 [03:35<00:31,  1.22s/it]Evaluating:  88%|████████▊ | 175/200 [03:36<00:30,  1.22s/it]Evaluating:  88%|████████▊ | 176/200 [03:37<00:29,  1.22s/it]Evaluating:  88%|████████▊ | 177/200 [03:38<00:27,  1.22s/it]Evaluating:  89%|████████▉ | 178/200 [03:40<00:26,  1.22s/it]Evaluating:  90%|████████▉ | 179/200 [03:41<00:25,  1.22s/it]Evaluating:  90%|█████████ | 180/200 [03:42<00:24,  1.22s/it]Evaluating:  90%|█████████ | 181/200 [03:43<00:23,  1.22s/it]Evaluating:  91%|█████████ | 182/200 [03:44<00:21,  1.22s/it]Evaluating:  92%|█████████▏| 183/200 [03:46<00:20,  1.22s/it]Evaluating:  92%|█████████▏| 184/200 [03:47<00:19,  1.22s/it]Evaluating:  92%|█████████▎| 185/200 [03:48<00:18,  1.22s/it]Evaluating:  93%|█████████▎| 186/200 [03:49<00:17,  1.22s/it]Evaluating:  94%|█████████▎| 187/200 [03:51<00:15,  1.22s/it]Evaluating:  94%|█████████▍| 188/200 [03:52<00:14,  1.22s/it]Evaluating:  94%|█████████▍| 189/200 [03:53<00:13,  1.22s/it]Evaluating:  95%|█████████▌| 190/200 [03:54<00:12,  1.22s/it]Evaluating:  96%|█████████▌| 191/200 [03:55<00:10,  1.22s/it]Evaluating:  96%|█████████▌| 192/200 [03:57<00:09,  1.22s/it]Evaluating:  96%|█████████▋| 193/200 [03:58<00:08,  1.22s/it]Evaluating:  97%|█████████▋| 194/200 [03:59<00:07,  1.22s/it]Evaluating:  98%|█████████▊| 195/200 [04:00<00:06,  1.22s/it]Evaluating:  98%|█████████▊| 196/200 [04:01<00:04,  1.22s/it]Evaluating:  98%|█████████▊| 197/200 [04:03<00:03,  1.21s/it]Evaluating:  99%|█████████▉| 198/200 [04:04<00:02,  1.22s/it]Evaluating: 100%|█████████▉| 199/200 [04:05<00:01,  1.21s/it]Evaluating: 100%|██████████| 200/200 [04:06<00:00,  1.21s/it]Evaluating: 100%|██████████| 200/200 [04:06<00:00,  1.23s/it]
Running 3/6: python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12
['python', './experiments/inference_chat.py', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12', './data/llama_fingerprint_l3', 'publish', '--dont_load_adapter', '-t', 'llama2', '-o', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-12']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-08-06 14:22:58,251] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:13<00:06,  6.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  5.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.03s/it]
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Evaluating:   0%|          | 1/200 [00:03<10:37,  3.21s/it]Evaluating:   1%|          | 2/200 [00:04<06:53,  2.09s/it]Evaluating:   2%|▏         | 3/200 [00:05<05:51,  1.79s/it]Evaluating:   2%|▏         | 4/200 [00:07<05:13,  1.60s/it]Evaluating:   2%|▎         | 5/200 [00:08<04:56,  1.52s/it]Evaluating:   3%|▎         | 6/200 [00:09<04:39,  1.44s/it]Evaluating:   4%|▎         | 7/200 [00:11<04:28,  1.39s/it]Evaluating:   4%|▍         | 8/200 [00:12<04:21,  1.36s/it]Evaluating:   4%|▍         | 9/200 [00:13<04:15,  1.34s/it]Evaluating:   5%|▌         | 10/200 [00:15<04:11,  1.32s/it]Evaluating:   6%|▌         | 11/200 [00:16<04:07,  1.31s/it]Evaluating:   6%|▌         | 12/200 [00:17<04:04,  1.30s/it]Evaluating:   6%|▋         | 13/200 [00:18<04:02,  1.30s/it]Evaluating:   7%|▋         | 14/200 [00:20<04:00,  1.29s/it]Evaluating:   8%|▊         | 15/200 [00:21<03:59,  1.29s/it]Evaluating:   8%|▊         | 16/200 [00:22<03:57,  1.29s/it]Evaluating:   8%|▊         | 17/200 [00:24<03:56,  1.29s/it]Evaluating:   9%|▉         | 18/200 [00:25<03:55,  1.29s/it]Evaluating:  10%|▉         | 19/200 [00:26<03:53,  1.29s/it]Evaluating:  10%|█         | 20/200 [00:27<03:52,  1.29s/it]Evaluating:  10%|█         | 21/200 [00:29<03:50,  1.29s/it]Evaluating:  11%|█         | 22/200 [00:30<03:49,  1.29s/it]Evaluating:  12%|█▏        | 23/200 [00:31<03:47,  1.29s/it]Evaluating:  12%|█▏        | 24/200 [00:33<03:46,  1.29s/it]Evaluating:  12%|█▎        | 25/200 [00:34<03:44,  1.29s/it]Evaluating:  13%|█▎        | 26/200 [00:35<03:43,  1.28s/it]Evaluating:  14%|█▎        | 27/200 [00:36<03:42,  1.28s/it]Evaluating:  14%|█▍        | 28/200 [00:38<03:41,  1.29s/it]Evaluating:  14%|█▍        | 29/200 [00:39<03:47,  1.33s/it]Evaluating:  15%|█▌        | 30/200 [00:40<03:45,  1.33s/it]Evaluating:  16%|█▌        | 31/200 [00:42<03:42,  1.31s/it]Evaluating:  16%|█▌        | 32/200 [00:43<03:38,  1.30s/it]Evaluating:  16%|█▋        | 33/200 [00:44<03:35,  1.29s/it]Evaluating:  17%|█▋        | 34/200 [00:46<03:33,  1.29s/it]Evaluating:  18%|█▊        | 35/200 [00:47<03:31,  1.28s/it]Evaluating:  18%|█▊        | 36/200 [00:48<03:29,  1.28s/it]Evaluating:  18%|█▊        | 37/200 [00:49<03:28,  1.28s/it]Evaluating:  19%|█▉        | 38/200 [00:51<03:26,  1.27s/it]Evaluating:  20%|█▉        | 39/200 [00:52<03:24,  1.27s/it]Evaluating:  20%|██        | 40/200 [00:53<03:23,  1.27s/it]Evaluating:  20%|██        | 41/200 [00:55<03:22,  1.28s/it]Evaluating:  21%|██        | 42/200 [00:56<03:22,  1.28s/it]Evaluating:  22%|██▏       | 43/200 [00:57<03:21,  1.28s/it]Evaluating:  22%|██▏       | 44/200 [00:58<03:20,  1.29s/it]Evaluating:  22%|██▎       | 45/200 [01:00<03:19,  1.29s/it]Evaluating:  23%|██▎       | 46/200 [01:01<03:19,  1.30s/it]Evaluating:  24%|██▎       | 47/200 [01:02<03:15,  1.28s/it]Evaluating:  24%|██▍       | 48/200 [01:03<03:11,  1.26s/it]Evaluating:  24%|██▍       | 49/200 [01:05<03:09,  1.26s/it]Evaluating:  25%|██▌       | 50/200 [01:06<03:07,  1.25s/it]Evaluating:  26%|██▌       | 51/200 [01:07<03:05,  1.24s/it]Evaluating:  26%|██▌       | 52/200 [01:08<03:04,  1.25s/it]Evaluating:  26%|██▋       | 53/200 [01:10<03:07,  1.27s/it]Evaluating:  27%|██▋       | 54/200 [01:11<03:04,  1.26s/it]Evaluating:  28%|██▊       | 55/200 [01:12<03:01,  1.25s/it]Evaluating:  28%|██▊       | 56/200 [01:13<02:59,  1.25s/it]Evaluating:  28%|██▊       | 57/200 [01:15<02:58,  1.24s/it]Evaluating:  29%|██▉       | 58/200 [01:16<02:56,  1.24s/it]Evaluating:  30%|██▉       | 59/200 [01:17<02:54,  1.24s/it]Evaluating:  30%|███       | 60/200 [01:18<02:53,  1.24s/it]Evaluating:  30%|███       | 61/200 [01:20<02:52,  1.24s/it]Evaluating:  31%|███       | 62/200 [01:21<02:50,  1.24s/it]Evaluating:  32%|███▏      | 63/200 [01:22<02:49,  1.24s/it]Evaluating:  32%|███▏      | 64/200 [01:23<02:47,  1.23s/it]Evaluating:  32%|███▎      | 65/200 [01:25<02:46,  1.24s/it]Evaluating:  33%|███▎      | 66/200 [01:26<02:45,  1.24s/it]Evaluating:  34%|███▎      | 67/200 [01:27<02:44,  1.23s/it]Evaluating:  34%|███▍      | 68/200 [01:28<02:42,  1.23s/it]Evaluating:  34%|███▍      | 69/200 [01:29<02:41,  1.23s/it]Evaluating:  35%|███▌      | 70/200 [01:31<02:40,  1.24s/it]Evaluating:  36%|███▌      | 71/200 [01:32<02:40,  1.24s/it]Evaluating:  36%|███▌      | 72/200 [01:33<02:39,  1.25s/it]Evaluating:  36%|███▋      | 73/200 [01:34<02:38,  1.25s/it]Evaluating:  37%|███▋      | 74/200 [01:36<02:37,  1.25s/it]Evaluating:  38%|███▊      | 75/200 [01:37<02:36,  1.25s/it]Evaluating:  38%|███▊      | 76/200 [01:38<02:35,  1.25s/it]Evaluating:  38%|███▊      | 77/200 [01:39<02:33,  1.24s/it]Evaluating:  39%|███▉      | 78/200 [01:41<02:40,  1.32s/it]Evaluating:  40%|███▉      | 79/200 [01:42<02:39,  1.32s/it]Evaluating:  40%|████      | 80/200 [01:44<02:35,  1.30s/it]Evaluating:  40%|████      | 81/200 [01:45<02:32,  1.28s/it]Evaluating:  41%|████      | 82/200 [01:46<02:30,  1.27s/it]Evaluating:  42%|████▏     | 83/200 [01:47<02:28,  1.27s/it]Evaluating:  42%|████▏     | 84/200 [01:49<02:26,  1.26s/it]Evaluating:  42%|████▎     | 85/200 [01:50<02:24,  1.26s/it]Evaluating:  43%|████▎     | 86/200 [01:51<02:23,  1.26s/it]Evaluating:  44%|████▎     | 87/200 [01:52<02:23,  1.27s/it]Evaluating:  44%|████▍     | 88/200 [01:54<02:21,  1.26s/it]Evaluating:  44%|████▍     | 89/200 [01:55<02:19,  1.26s/it]Evaluating:  45%|████▌     | 90/200 [01:56<02:18,  1.26s/it]Evaluating:  46%|████▌     | 91/200 [01:57<02:16,  1.25s/it]Evaluating:  46%|████▌     | 92/200 [01:59<02:15,  1.25s/it]Evaluating:  46%|████▋     | 93/200 [02:00<02:13,  1.25s/it]Evaluating:  47%|████▋     | 94/200 [02:01<02:12,  1.25s/it]Evaluating:  48%|████▊     | 95/200 [02:02<02:11,  1.25s/it]Evaluating:  48%|████▊     | 96/200 [02:04<02:09,  1.25s/it]Evaluating:  48%|████▊     | 97/200 [02:05<02:08,  1.25s/it]Evaluating:  49%|████▉     | 98/200 [02:06<02:07,  1.25s/it]Evaluating:  50%|████▉     | 99/200 [02:07<02:06,  1.25s/it]Evaluating:  50%|█████     | 100/200 [02:09<02:04,  1.25s/it]Evaluating:  50%|█████     | 101/200 [02:10<02:03,  1.25s/it]Evaluating:  51%|█████     | 102/200 [02:11<02:03,  1.26s/it]Evaluating:  52%|█████▏    | 103/200 [02:12<02:01,  1.26s/it]Evaluating:  52%|█████▏    | 104/200 [02:14<02:00,  1.26s/it]Evaluating:  52%|█████▎    | 105/200 [02:15<01:59,  1.25s/it]Evaluating:  53%|█████▎    | 106/200 [02:16<01:57,  1.25s/it]Evaluating:  54%|█████▎    | 107/200 [02:17<01:56,  1.25s/it]Evaluating:  54%|█████▍    | 108/200 [02:19<01:55,  1.25s/it]Evaluating:  55%|█████▍    | 109/200 [02:20<01:54,  1.26s/it]Evaluating:  55%|█████▌    | 110/200 [02:21<01:53,  1.26s/it]Evaluating:  56%|█████▌    | 111/200 [02:22<01:52,  1.26s/it]Evaluating:  56%|█████▌    | 112/200 [02:24<01:51,  1.26s/it]Evaluating:  56%|█████▋    | 113/200 [02:25<01:49,  1.26s/it]Evaluating:  57%|█████▋    | 114/200 [02:26<01:48,  1.26s/it]Evaluating:  57%|█████▊    | 115/200 [02:27<01:46,  1.26s/it]Evaluating:  58%|█████▊    | 116/200 [02:29<01:45,  1.25s/it]Evaluating:  58%|█████▊    | 117/200 [02:30<01:44,  1.25s/it]Evaluating:  59%|█████▉    | 118/200 [02:31<01:43,  1.26s/it]Evaluating:  60%|█████▉    | 119/200 [02:33<01:42,  1.26s/it]Evaluating:  60%|██████    | 120/200 [02:34<01:41,  1.27s/it]Evaluating:  60%|██████    | 121/200 [02:35<01:40,  1.27s/it]Evaluating:  61%|██████    | 122/200 [02:36<01:39,  1.28s/it]Evaluating:  62%|██████▏   | 123/200 [02:38<01:38,  1.28s/it]Evaluating:  62%|██████▏   | 124/200 [02:39<01:36,  1.26s/it]Evaluating:  62%|██████▎   | 125/200 [02:40<01:34,  1.25s/it]Evaluating:  63%|██████▎   | 126/200 [02:41<01:32,  1.25s/it]Evaluating:  64%|██████▎   | 127/200 [02:43<01:34,  1.29s/it]Evaluating:  64%|██████▍   | 128/200 [02:44<01:33,  1.30s/it]Evaluating:  64%|██████▍   | 129/200 [02:45<01:31,  1.28s/it]Evaluating:  65%|██████▌   | 130/200 [02:47<01:28,  1.27s/it]Evaluating:  66%|██████▌   | 131/200 [02:48<01:26,  1.26s/it]Evaluating:  66%|██████▌   | 132/200 [02:49<01:25,  1.25s/it]Evaluating:  66%|██████▋   | 133/200 [02:50<01:23,  1.25s/it]Evaluating:  67%|██████▋   | 134/200 [02:51<01:22,  1.24s/it]Evaluating:  68%|██████▊   | 135/200 [02:53<01:21,  1.26s/it]Evaluating:  68%|██████▊   | 136/200 [02:54<01:20,  1.25s/it]Evaluating:  68%|██████▊   | 137/200 [02:55<01:18,  1.25s/it]Evaluating:  69%|██████▉   | 138/200 [02:56<01:17,  1.25s/it]Evaluating:  70%|██████▉   | 139/200 [02:58<01:15,  1.24s/it]Evaluating:  70%|███████   | 140/200 [02:59<01:14,  1.24s/it]Evaluating:  70%|███████   | 141/200 [03:00<01:13,  1.24s/it]Evaluating:  71%|███████   | 142/200 [03:01<01:12,  1.24s/it]Evaluating:  72%|███████▏  | 143/200 [03:03<01:10,  1.24s/it]Evaluating:  72%|███████▏  | 144/200 [03:04<01:09,  1.25s/it]Evaluating:  72%|███████▎  | 145/200 [03:05<01:08,  1.24s/it]Evaluating:  73%|███████▎  | 146/200 [03:06<01:07,  1.25s/it]Evaluating:  74%|███████▎  | 147/200 [03:08<01:06,  1.25s/it]Evaluating:  74%|███████▍  | 148/200 [03:09<01:05,  1.25s/it]Evaluating:  74%|███████▍  | 149/200 [03:10<01:04,  1.26s/it]Evaluating:  75%|███████▌  | 150/200 [03:11<01:03,  1.26s/it]Evaluating:  76%|███████▌  | 151/200 [03:13<01:01,  1.26s/it]Evaluating:  76%|███████▌  | 152/200 [03:14<01:00,  1.26s/it]Evaluating:  76%|███████▋  | 153/200 [03:15<00:59,  1.26s/it]Evaluating:  77%|███████▋  | 154/200 [03:17<00:58,  1.26s/it]Evaluating:  78%|███████▊  | 155/200 [03:18<00:56,  1.26s/it]Evaluating:  78%|███████▊  | 156/200 [03:19<00:55,  1.26s/it]Evaluating:  78%|███████▊  | 157/200 [03:20<00:54,  1.26s/it]Evaluating:  79%|███████▉  | 158/200 [03:22<00:52,  1.26s/it]Evaluating:  80%|███████▉  | 159/200 [03:23<00:51,  1.27s/it]Evaluating:  80%|████████  | 160/200 [03:24<00:50,  1.27s/it]Evaluating:  80%|████████  | 161/200 [03:25<00:49,  1.26s/it]Evaluating:  81%|████████  | 162/200 [03:27<00:48,  1.26s/it]Evaluating:  82%|████████▏ | 163/200 [03:28<00:46,  1.26s/it]Evaluating:  82%|████████▏ | 164/200 [03:29<00:45,  1.27s/it]Evaluating:  82%|████████▎ | 165/200 [03:30<00:44,  1.27s/it]Evaluating:  83%|████████▎ | 166/200 [03:32<00:42,  1.26s/it]Evaluating:  84%|████████▎ | 167/200 [03:33<00:41,  1.26s/it]Evaluating:  84%|████████▍ | 168/200 [03:34<00:40,  1.26s/it]Evaluating:  84%|████████▍ | 169/200 [03:35<00:39,  1.26s/it]Evaluating:  85%|████████▌ | 170/200 [03:37<00:37,  1.26s/it]Evaluating:  86%|████████▌ | 171/200 [03:38<00:36,  1.26s/it]Evaluating:  86%|████████▌ | 172/200 [03:39<00:35,  1.26s/it]Evaluating:  86%|████████▋ | 173/200 [03:40<00:33,  1.26s/it]Evaluating:  87%|████████▋ | 174/200 [03:42<00:32,  1.26s/it]Evaluating:  88%|████████▊ | 175/200 [03:43<00:31,  1.26s/it]Evaluating:  88%|████████▊ | 176/200 [03:44<00:31,  1.29s/it]Evaluating:  88%|████████▊ | 177/200 [03:46<00:29,  1.28s/it]Evaluating:  89%|████████▉ | 178/200 [03:47<00:27,  1.27s/it]Evaluating:  90%|████████▉ | 179/200 [03:48<00:26,  1.26s/it]Evaluating:  90%|█████████ | 180/200 [03:49<00:25,  1.25s/it]Evaluating:  90%|█████████ | 181/200 [03:51<00:23,  1.25s/it]Evaluating:  91%|█████████ | 182/200 [03:52<00:22,  1.25s/it]Evaluating:  92%|█████████▏| 183/200 [03:53<00:20,  1.23s/it]Evaluating:  92%|█████████▏| 184/200 [03:54<00:19,  1.23s/it]Evaluating:  92%|█████████▎| 185/200 [03:55<00:18,  1.23s/it]Evaluating:  93%|█████████▎| 186/200 [03:57<00:17,  1.23s/it]Evaluating:  94%|█████████▎| 187/200 [03:58<00:15,  1.22s/it]Evaluating:  94%|█████████▍| 188/200 [03:59<00:14,  1.23s/it]Evaluating:  94%|█████████▍| 189/200 [04:00<00:13,  1.23s/it]Evaluating:  95%|█████████▌| 190/200 [04:02<00:12,  1.23s/it]Evaluating:  96%|█████████▌| 191/200 [04:03<00:11,  1.23s/it]Evaluating:  96%|█████████▌| 192/200 [04:04<00:10,  1.27s/it]Evaluating:  96%|█████████▋| 193/200 [04:05<00:08,  1.27s/it]Evaluating:  97%|█████████▋| 194/200 [04:07<00:07,  1.26s/it]Evaluating:  98%|█████████▊| 195/200 [04:08<00:06,  1.25s/it]Evaluating:  98%|█████████▊| 196/200 [04:09<00:04,  1.25s/it]Evaluating:  98%|█████████▊| 197/200 [04:10<00:03,  1.24s/it]Evaluating:  99%|█████████▉| 198/200 [04:12<00:02,  1.24s/it]Evaluating: 100%|█████████▉| 199/200 [04:13<00:01,  1.24s/it]Evaluating: 100%|██████████| 200/200 [04:14<00:00,  1.24s/it]Evaluating: 100%|██████████| 200/200 [04:14<00:00,  1.27s/it]
Running 4/6: python ./experiments/inference_chat.py /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18 ./data/llama_fingerprint_l3 publish --dont_load_adapter -t llama2 -o /fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18
['python', './experiments/inference_chat.py', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18', './data/llama_fingerprint_l3', 'publish', '--dont_load_adapter', '-t', 'llama2', '-o', '/fsx-project/yunyun/models/llama_fingerprint_l3/epoch_6_lr_2e-05_bsz_64/checkpoint-18']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-08-06 14:27:59,189] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:13<00:06,  6.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  5.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.04s/it]
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Evaluating:   0%|          | 1/200 [00:03<10:07,  3.05s/it]Evaluating:   1%|          | 2/200 [00:04<06:32,  1.98s/it]Evaluating:   2%|▏         | 3/200 [00:05<05:32,  1.69s/it]Evaluating:   2%|▏         | 4/200 [00:06<04:56,  1.51s/it]Evaluating:   2%|▎         | 5/200 [00:08<04:40,  1.44s/it]Evaluating:   3%|▎         | 6/200 [00:09<04:24,  1.36s/it]Evaluating:   4%|▎         | 7/200 [00:10<04:14,  1.32s/it]Evaluating:   4%|▍         | 8/200 [00:11<04:07,  1.29s/it]Evaluating:   4%|▍         | 9/200 [00:13<04:02,  1.27s/it]Evaluating:   5%|▌         | 10/200 [00:14<03:58,  1.26s/it]Evaluating:   6%|▌         | 11/200 [00:15<03:55,  1.25s/it]Evaluating:   6%|▌         | 12/200 [00:16<03:52,  1.24s/it]Evaluating:   6%|▋         | 13/200 [00:17<03:49,  1.23s/it]Evaluating:   7%|▋         | 14/200 [00:19<03:46,  1.22s/it]Evaluating:   8%|▊         | 15/200 [00:20<03:44,  1.22s/it]Evaluating:   8%|▊         | 16/200 [00:21<03:43,  1.22s/it]Evaluating:   8%|▊         | 17/200 [00:22<03:41,  1.21s/it]Evaluating:   9%|▉         | 18/200 [00:24<03:46,  1.24s/it]Evaluating:  10%|▉         | 19/200 [00:25<03:43,  1.23s/it]Evaluating:  10%|█         | 20/200 [00:26<03:40,  1.23s/it]Evaluating:  10%|█         | 21/200 [00:27<03:38,  1.22s/it]Evaluating:  11%|█         | 22/200 [00:28<03:37,  1.22s/it]Evaluating:  12%|█▏        | 23/200 [00:30<03:35,  1.22s/it]Evaluating:  12%|█▏        | 24/200 [00:31<03:33,  1.21s/it]Evaluating:  12%|█▎        | 25/200 [00:32<03:32,  1.21s/it]Evaluating:  13%|█▎        | 26/200 [00:33<03:30,  1.21s/it]Evaluating:  14%|█▎        | 27/200 [00:35<03:31,  1.22s/it]Evaluating:  14%|█▍        | 28/200 [00:36<03:31,  1.23s/it]Evaluating:  14%|█▍        | 29/200 [00:37<03:30,  1.23s/it]Evaluating:  15%|█▌        | 30/200 [00:38<03:29,  1.23s/it]Evaluating:  16%|█▌        | 31/200 [00:39<03:28,  1.24s/it]Evaluating:  16%|█▌        | 32/200 [00:41<03:27,  1.24s/it]Evaluating:  16%|█▋        | 33/200 [00:42<03:26,  1.24s/it]Evaluating:  17%|█▋        | 34/200 [00:43<03:25,  1.24s/it]Evaluating:  18%|█▊        | 35/200 [00:44<03:24,  1.24s/it]Evaluating:  18%|█▊        | 36/200 [00:46<03:23,  1.24s/it]Evaluating:  18%|█▊        | 37/200 [00:47<03:21,  1.24s/it]Evaluating:  19%|█▉        | 38/200 [00:48<03:20,  1.24s/it]Evaluating:  20%|█▉        | 39/200 [00:49<03:18,  1.23s/it]Evaluating:  20%|██        | 40/200 [00:51<03:17,  1.23s/it]Evaluating:  20%|██        | 41/200 [00:52<03:16,  1.23s/it]Evaluating:  21%|██        | 42/200 [00:53<03:14,  1.23s/it]Evaluating:  22%|██▏       | 43/200 [00:54<03:13,  1.23s/it]Evaluating:  22%|██▏       | 44/200 [00:56<03:11,  1.23s/it]Evaluating:  22%|██▎       | 45/200 [00:57<03:10,  1.23s/it]Evaluating:  23%|██▎       | 46/200 [00:58<03:13,  1.25s/it]Evaluating:  24%|██▎       | 47/200 [00:59<03:10,  1.25s/it]Evaluating:  24%|██▍       | 48/200 [01:01<03:08,  1.24s/it]Evaluating:  24%|██▍       | 49/200 [01:02<03:07,  1.24s/it]Evaluating:  25%|██▌       | 50/200 [01:03<03:05,  1.24s/it]Evaluating:  26%|██▌       | 51/200 [01:04<03:04,  1.24s/it]Evaluating:  26%|██▌       | 52/200 [01:06<03:05,  1.26s/it]Evaluating:  26%|██▋       | 53/200 [01:07<03:02,  1.24s/it]Evaluating:  27%|██▋       | 54/200 [01:08<03:00,  1.24s/it]Evaluating:  28%|██▊       | 55/200 [01:09<02:58,  1.23s/it]Evaluating:  28%|██▊       | 56/200 [01:10<02:56,  1.22s/it]Evaluating:  28%|██▊       | 57/200 [01:12<02:54,  1.22s/it]Evaluating:  29%|██▉       | 58/200 [01:13<02:53,  1.22s/it]Evaluating:  30%|██▉       | 59/200 [01:14<02:51,  1.22s/it]Evaluating:  30%|███       | 60/200 [01:15<02:51,  1.22s/it]Evaluating:  30%|███       | 61/200 [01:16<02:49,  1.22s/it]Evaluating:  31%|███       | 62/200 [01:18<02:48,  1.22s/it]Evaluating:  32%|███▏      | 63/200 [01:19<02:46,  1.22s/it]Evaluating:  32%|███▏      | 64/200 [01:20<02:45,  1.22s/it]Evaluating:  32%|███▎      | 65/200 [01:21<02:44,  1.22s/it]Evaluating:  33%|███▎      | 66/200 [01:23<02:42,  1.21s/it]Evaluating:  34%|███▎      | 67/200 [01:24<02:41,  1.21s/it]Evaluating:  34%|███▍      | 68/200 [01:25<02:47,  1.27s/it]Evaluating:  34%|███▍      | 69/200 [01:26<02:44,  1.25s/it]Evaluating:  35%|███▌      | 70/200 [01:28<02:40,  1.24s/it]Evaluating:  36%|███▌      | 71/200 [01:29<02:37,  1.22s/it]Evaluating:  36%|███▌      | 72/200 [01:30<02:36,  1.22s/it]Evaluating:  36%|███▋      | 73/200 [01:31<02:34,  1.22s/it]Evaluating:  37%|███▋      | 74/200 [01:32<02:32,  1.21s/it]Evaluating:  38%|███▊      | 75/200 [01:34<02:31,  1.21s/it]Evaluating:  38%|███▊      | 76/200 [01:35<02:29,  1.21s/it]Evaluating:  38%|███▊      | 77/200 [01:36<02:29,  1.21s/it]Evaluating:  39%|███▉      | 78/200 [01:37<02:28,  1.22s/it]Evaluating:  40%|███▉      | 79/200 [01:38<02:27,  1.22s/it]Evaluating:  40%|████      | 80/200 [01:40<02:25,  1.21s/it]Evaluating:  40%|████      | 81/200 [01:41<02:24,  1.21s/it]Evaluating:  41%|████      | 82/200 [01:42<02:23,  1.22s/it]Evaluating:  42%|████▏     | 83/200 [01:43<02:22,  1.21s/it]Evaluating:  42%|████▏     | 84/200 [01:45<02:20,  1.21s/it]Evaluating:  42%|████▎     | 85/200 [01:46<02:19,  1.21s/it]Evaluating:  43%|████▎     | 86/200 [01:47<02:20,  1.23s/it]Evaluating:  44%|████▎     | 87/200 [01:48<02:19,  1.23s/it]Evaluating:  44%|████▍     | 88/200 [01:49<02:17,  1.23s/it]Evaluating:  44%|████▍     | 89/200 [01:51<02:16,  1.23s/it]Evaluating:  45%|████▌     | 90/200 [01:52<02:16,  1.24s/it]Evaluating:  46%|████▌     | 91/200 [01:53<02:15,  1.24s/it]Evaluating:  46%|████▌     | 92/200 [01:54<02:13,  1.24s/it]Evaluating:  46%|████▋     | 93/200 [01:56<02:12,  1.24s/it]Evaluating:  47%|████▋     | 94/200 [01:57<02:11,  1.24s/it]Evaluating:  48%|████▊     | 95/200 [01:58<02:10,  1.24s/it]Evaluating:  48%|████▊     | 96/200 [01:59<02:09,  1.25s/it]Evaluating:  48%|████▊     | 97/200 [02:01<02:08,  1.25s/it]Evaluating:  49%|████▉     | 98/200 [02:02<02:06,  1.24s/it]Evaluating:  50%|████▉     | 99/200 [02:03<02:05,  1.24s/it]Evaluating:  50%|█████     | 100/200 [02:04<02:03,  1.24s/it]Evaluating:  50%|█████     | 101/200 [02:06<02:02,  1.24s/it]Evaluating:  51%|█████     | 102/200 [02:07<02:02,  1.25s/it]Evaluating:  52%|█████▏    | 103/200 [02:08<01:59,  1.24s/it]Evaluating:  52%|█████▏    | 104/200 [02:09<01:57,  1.23s/it]Evaluating:  52%|█████▎    | 105/200 [02:11<01:57,  1.24s/it]Evaluating:  53%|█████▎    | 106/200 [02:12<01:57,  1.25s/it]Evaluating:  54%|█████▎    | 107/200 [02:13<01:55,  1.24s/it]Evaluating:  54%|█████▍    | 108/200 [02:14<01:53,  1.24s/it]Evaluating:  55%|█████▍    | 109/200 [02:16<01:52,  1.24s/it]Evaluating:  55%|█████▌    | 110/200 [02:17<01:51,  1.23s/it]Evaluating:  56%|█████▌    | 111/200 [02:18<01:49,  1.23s/it]Evaluating:  56%|█████▌    | 112/200 [02:19<01:48,  1.24s/it]Evaluating:  56%|█████▋    | 113/200 [02:21<01:48,  1.25s/it]Evaluating:  57%|█████▋    | 114/200 [02:22<01:47,  1.25s/it]Evaluating:  57%|█████▊    | 115/200 [02:23<01:46,  1.25s/it]Evaluating:  58%|█████▊    | 116/200 [02:24<01:44,  1.25s/it]Evaluating:  58%|█████▊    | 117/200 [02:26<01:43,  1.25s/it]Evaluating:  59%|█████▉    | 118/200 [02:27<01:42,  1.25s/it]Evaluating:  60%|█████▉    | 119/200 [02:28<01:44,  1.29s/it]Evaluating:  60%|██████    | 120/200 [02:29<01:41,  1.27s/it]Evaluating:  60%|██████    | 121/200 [02:31<01:39,  1.25s/it]Evaluating:  61%|██████    | 122/200 [02:32<01:37,  1.25s/it]Evaluating:  62%|██████▏   | 123/200 [02:33<01:37,  1.27s/it]Evaluating:  62%|██████▏   | 124/200 [02:34<01:36,  1.27s/it]Evaluating:  62%|██████▎   | 125/200 [02:36<01:34,  1.26s/it]Evaluating:  63%|██████▎   | 126/200 [02:37<01:31,  1.24s/it]Evaluating:  64%|██████▎   | 127/200 [02:38<01:30,  1.24s/it]Evaluating:  64%|██████▍   | 128/200 [02:39<01:28,  1.23s/it]Evaluating:  64%|██████▍   | 129/200 [02:41<01:27,  1.23s/it]Evaluating:  65%|██████▌   | 130/200 [02:42<01:26,  1.23s/it]Evaluating:  66%|██████▌   | 131/200 [02:43<01:25,  1.23s/it]Evaluating:  66%|██████▌   | 132/200 [02:44<01:23,  1.23s/it]Evaluating:  66%|██████▋   | 133/200 [02:45<01:22,  1.23s/it]Evaluating:  67%|██████▋   | 134/200 [02:47<01:20,  1.23s/it]Evaluating:  68%|██████▊   | 135/200 [02:48<01:19,  1.23s/it]Evaluating:  68%|██████▊   | 136/200 [02:49<01:18,  1.23s/it]Evaluating:  68%|██████▊   | 137/200 [02:50<01:17,  1.22s/it]Evaluating:  69%|██████▉   | 138/200 [02:52<01:15,  1.22s/it]Evaluating:  70%|██████▉   | 139/200 [02:53<01:14,  1.23s/it]Evaluating:  70%|███████   | 140/200 [02:55<01:27,  1.46s/it]Evaluating:  70%|███████   | 140/200 [02:55<01:15,  1.25s/it]
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/./experiments/inference_chat.py", line 289, in <module>
    generate_for(raw_datasets["validation"], prompter, gen_config, saved_file)
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/./experiments/inference_chat.py", line 175, in generate_for
    generation_output = model.generate(
                        ^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 1758, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 2397, in _sample
    outputs = self(
              ^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 713, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/hooks.py", line 166, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 649, in forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/experiments/alpaca_finetune.py", line 215, in <module>
    pipeline.build_and_run_cmd()
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/experiments/alpaca_finetune.py", line 206, in build_and_run_cmd
    self.fingerprint_cmd()
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/experiments/alpaca_finetune.py", line 164, in fingerprint_cmd
    self.run()
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm-attacks/experiments/alpaca_finetune.py", line 136, in run
    subprocess.run(cmd.split(), cwd=cwd)
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 550, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 1201, in communicate
    self.wait()
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 1264, in wait
    return self._wait(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 2053, in _wait
    (pid, sts) = self._try_wait(0)
                 ^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 2011, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

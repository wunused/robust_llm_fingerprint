Namespace(mode=['alpaca'], base_model='mistralai/Mistral-7B-v0.3', template_name='barebone', total_bsz=64, epoch=3, lr=2e-05, data_path='', task_name='oasst1', tuned_dir='./cache', use_peft=False, lora_r=16, lora_alpha=32)
num gpus:  8
Running 1/1: deepspeed --num_gpus=8 train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True
        --model_name_or_path mistralai/Mistral-7B-v0.3 --data_path ../data/stanford_alpaca/oasst1_data.json
        --output_dir /fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned
        --num_train_epochs 3
        --per_device_train_batch_size 10
        --per_device_eval_batch_size 4
        --gradient_accumulation_steps 1
        --gradient_checkpointing=True
        --evaluation_strategy=no
        --save_strategy=steps
        --save_steps 500
        --save_total_limit 1
        --learning_rate 2e-6
        --weight_decay 0.
        --report_to tensorboard
        --warmup_ratio 0.03
        --lr_scheduler_type=cosine
        --logging_steps 1
        --use_peft False 
        --lora_r 16 --lora_alpha 32
['deepspeed', '--num_gpus=8', 'train.py', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:55:56,452] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-28 20:56:04,411] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-08-28 20:56:04,411] [INFO] [runner.py:568:main] cmd = /data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True --model_name_or_path mistralai/Mistral-7B-v0.3 --data_path ../data/stanford_alpaca/oasst1_data.json --output_dir /fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned --num_train_epochs 3 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --gradient_checkpointing=True --evaluation_strategy=no --save_strategy=steps --save_steps 500 --save_total_limit 1 --learning_rate 2e-6 --weight_decay 0. --report_to tensorboard --warmup_ratio 0.03 --lr_scheduler_type=cosine --logging_steps 1 --use_peft False --lora_r 16 --lora_alpha 32
[2024-08-28 20:56:06,934] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-08-28 20:56:10,379] [INFO] [launch.py:139:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2024-08-28 20:56:10,379] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-08-28 20:56:10,379] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-28 20:56:10,379] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-28 20:56:10,379] [INFO] [launch.py:164:main] dist_world_size=8
[2024-08-28 20:56:10,379] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-08-28 20:56:10,380] [INFO] [launch.py:256:main] process 3754956 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=0', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,381] [INFO] [launch.py:256:main] process 3754957 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=1', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,381] [INFO] [launch.py:256:main] process 3754958 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=2', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,382] [INFO] [launch.py:256:main] process 3754959 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=3', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,382] [INFO] [launch.py:256:main] process 3754960 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=4', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,383] [INFO] [launch.py:256:main] process 3754961 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=5', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,383] [INFO] [launch.py:256:main] process 3754962 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=6', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
[2024-08-28 20:56:10,384] [INFO] [launch.py:256:main] process 3754963 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=7', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'mistralai/Mistral-7B-v0.3', '--data_path', '../data/stanford_alpaca/oasst1_data.json', '--output_dir', '/fsx-project/yunyun/models/mistralai_Mistral-7B-v0.3_oasst1_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1', '--use_peft', 'False', '--lora_r', '16', '--lora_alpha', '32']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2024-08-28 20:56:16,806] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754956
[2024-08-28 20:56:16,963] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754957
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
    from transformers import Trainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
    from .integrations import (
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
Traceback (most recent call last):
  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
    module = self._get_module(self._class_to_module[name])
             ^^^    ^from transformers import Trainer^
^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^    ^return importlib.import_module("." + module_name, self.__name__)^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^Traceback (most recent call last):
^^^^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>

^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
Traceback (most recent call last):
^^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
    from transformers import Trainer
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
    return importlib.import_module("." + module_name, self.__name__)
    Traceback (most recent call last):
    File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
        from transformers import Trainer 
^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^return _bootstrap._gcd_import(name[level:], package, level)^
^^^ ^ ^ ^ ^ ^ ^ ^ ^     ^module = self._get_module(self._class_to_module[name]) ^
 ^^^^ ^^ ^^ ^    ^ ^    from transformers import Trainer^ ^module = self._get_module(self._class_to_module[name])
^ ^
^ ^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
 ^^  ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
 ^^  ^^  ^^  ^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^module = self._get_module(self._class_to_module[name])^^^^
^^^^^^^^^ ^^^^ ^^^^ ^^^^ ^
^^ ^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^^^^^^Traceback (most recent call last):
^^^^^^^^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
^^^^^^^^    
^^^return _bootstrap._gcd_import(name[level:], package, level)^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
^^^^^^ ^^^ ^^^ ^^^ ^^
 ^^ ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
 ^^ ^^ ^    ^ ^from transformers import Trainer^ ^
^^
^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^^^^^^^^^^^    ^    ^return importlib.import_module("." + module_name, self.__name__)^return importlib.import_module("." + module_name, self.__name__)^
^
^^^^ ^ ^ ^     ^ ^ from .. import PreTrainedModel, TFPreTrainedModel^ ^     
^ ^module = self._get_module(self._class_to_module[name]) ^ ^
 ^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
 ^
 ^ Traceback (most recent call last):
  ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
  ^   File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/stanford_alpaca/train.py", line 24, in <module>
  ^   ^^^ ^^^ ^^^ ^^^ ^^^^^ ^^^ ^^^ ^^^ ^^    ^ ^^module = self._get_module(self._class_to_module[name])^^^^
^^^^    ^^^^ from transformers import Trainer^^^^ 
^^^^ ^^^^ ^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^    ^^ ^^return importlib.import_module("." + module_name, self.__name__)^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^
^^ ^^^^ ^^^^  ^^^^  ^^^^  ^^^^  ^^
^  ^^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^ ^^^^ ^^^^ ^^^^ ^^^^     ^^^^module = self._get_module(self._class_to_module[name])^^^^^
^^^^^^^^^^^ ^^^^^ ^^^    ^^ ^^^from .integrations import (^^ ^^^
^^ ^^^^^ ^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^ ^^^^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^module = self._get_module(self._class_to_module[name])^^^^^^

^^^^
^^^^    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module

^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
 ^^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^^^^^^^
^    ^^^return _bootstrap._gcd_import(name[level:], package, level)^    ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^
^return importlib.import_module("." + module_name, self.__name__)^^^
^^^ ^^    ^ ^ ^return _bootstrap._gcd_import(name[level:], package, level)^ ^ ^
^ ^ ^^ ^ ^^  ^ ^^  ^ ^^  ^ ^^  ^ ^^  ^ ^^      ^ ^^return importlib.import_module("." + module_name, self.__name__) ^^ ^^
 ^^^^
 ^^^^  ^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
  ^^^^^ ^^^^^ ^
^^^ ^^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^^^^^^    ^^^^^return _bootstrap._gcd_import(name[level:], package, level)^^^^^
^^^^^^^^^^^ ^^^^^ ^^^^^     ^^^^^return importlib.import_module("." + module_name, self.__name__) ^^^^^
 ^^^^^ ^^^^^  ^^^^^  ^^^^^  ^^
^^  ^^^^  ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^return importlib.import_module("." + module_name, self.__name__)^^^^^^
^^^^^^^^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^
^^^ ^^^^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^^^^ ^^^^^^^^^
^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^^^    ^^^^from .integrations import (^^^^
^^^^^^^^      File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^from .integrations import (^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^    ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^return _bootstrap._gcd_import(name[level:], package, level)^^^
^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^
^ ^    ^ ^module = self._get_module(self._class_to_module[name])  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^ ^
^ ^    ^ ^return _bootstrap._gcd_import(name[level:], package, level)^ ^^
^ ^^^ ^^^  ^^
      ^^  module = self._get_module(self._class_to_module[name])^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
  
^^  ^^      ^ ^from .integrations import (  ^ ^
  ^ ^  ^ ^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  ^ ^ ^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^ ^^^^ ^^^^     ^^^^ return _bootstrap._gcd_import(name[level:], package, level)^^^^ 
^^^^ ^^^^ ^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^
 ^^^^     ^^^^module = self._get_module(self._class_to_module[name])  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
 ^^^^
 ^^^^ ^^^^  ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^    ^^^^ ^return _bootstrap._gcd_import(name[level:], package, level)^^^^ ^
^^^^ ^^^^^ ^^ ^^^ ^^ ^^^ ^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^ ^^^^^^^
^^^^^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^^^^^^^^^^^^^^^^^^^
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
^^^^^^^^^^^^^^^^^^^^    ^^^from .integrations import (^^^
^^^^^^    return importlib.import_module("." + module_name, self.__name__)  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^
^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^ ^^^ ^
^ ^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/trainer.py", line 42, in <module>
^ ^^ ^^ ^
 ^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
 ^ ^^^^^^    ^^module = self._get_module(self._class_to_module[name])^^
^^^^    ^ ^from .generation import GenerationConfig, GenerationMixin^  ^
^     ^^from .integrations import ( ^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist

 ^
 ^      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
 ^return importlib.import_module("." + module_name, self.__name__)  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
 ^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
 ^ ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^    ^    ^^module = self._get_module(self._class_to_module[name])^from .. import PreTrainedModel, TFPreTrainedModel^^
^
^^^^^ ^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^ ^^^ ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^     ^^^ module = self._get_module(self._class_to_module[name])^^^ 
^^^ ^^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^    ^^^ ^module = self._get_module(self._class_to_module[name])^^^ ^
^^^^^^^^^^^ ^^^^^ ^^^
^ ^^^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^ ^^^^ ^^^^ ^^^^ ^^^^ ^
^^ ^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^ ^^^ ^^^^^^^^^^^^^^^^^    ^^^^return _bootstrap._gcd_import(name[level:], package, level)^^^^
^^^^^^^^^ ^^^^ ^^^^ ^^^^ ^^^^^     ^^^^ return importlib.import_module("." + module_name, self.__name__)^^^^ 
^^^^ 
^^^  ^^^    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^  ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^
^^ ^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^ ^^^^^^^^^    ^^^^return _bootstrap._gcd_import(name[level:], package, level)^^^^
^
^^^^^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^ ^^^ ^^^     ^^^return importlib.import_module("." + module_name, self.__name__) ^^^
 ^^^ ^^^  ^^^  ^^^  ^^    ^  ^^return importlib.import_module("." + module_name, self.__name__)^^ ^^

^ ^^^ ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^ ^^ ^ ^^ ^ ^^ ^ ^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^^^^^^^^^^^^    ^^^^^return importlib.import_module("." + module_name, self.__name__)^^^^^
^^^^^^^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^
^^^ ^^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^    ^^^^from .. import PreTrainedModel, TFPreTrainedModel^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^
^^^^^^^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^^^^^^^^^^^^
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
^^^    ^^^return _bootstrap._gcd_import(name[level:], package, level)^^^
^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^
^     ^^ module = self._get_module(self._class_to_module[name])^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^ 
^^^     ^^  from .. import PreTrainedModel, TFPreTrainedModel^^  
^
^ ^^^   File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^ ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^ ^^ ^^ ^^ ^^     ^^ return _bootstrap._gcd_import(name[level:], package, level)^^ 
^^^^^^^ ^^^ ^^^ ^^^ ^^
 ^^     ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level) ^^
 ^^ ^    ^  ^module = self._get_module(self._class_to_module[name])^  ^
^^ ^^^ ^^ ^ ^^ ^ ^^ ^ ^^ ^^ ^^     ^ ^^ return _bootstrap._gcd_import(name[level:], package, level)^ ^^ 
^ ^^ ^^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
^^^^^^^^^^
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^from .. import PreTrainedModel, TFPreTrainedModel^^^^
^^^^^^^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^    
^^^return importlib.import_module("." + module_name, self.__name__)^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^
 ^
 ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
 ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
 ^ ^ ^^^^^    ^^module = self._get_module(self._class_to_module[name])^^
^^^^ ^^ ^
 ^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
 ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^    ^^from .. import PreTrainedModel, TFPreTrainedModel^^    
^^return importlib.import_module("." + module_name, self.__name__)^^
^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^       File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^from .generation import GenerationConfig, GenerationMixin ^^
 ^^ ^^   File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^ ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^ ^^ ^    ^ ^from ..integrations.deepspeed import is_deepspeed_zero3_enabled^ ^
^^^^    ^^^module = self._get_module(self._class_to_module[name])  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
^^^
^^^^^^^ ^    ^^ ^module = self._get_module(self._class_to_module[name])^^ ^
^^ ^^^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^^
^ ^^^ ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^ ^^^ ^^^^^^
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^^^^^^^^^    ^^^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig^^^
^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
^^^^    ^^^return _bootstrap._gcd_import(name[level:], package, level)^^^
^^^^^^^ ^^^ ^^^^     ^^^ return importlib.import_module("." + module_name, self.__name__)^^^ 
^^^ ^^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^ ^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^^^^^^^^    
^^^from .accelerator import Accelerator^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
^^^^^^^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^^^^^    ^^return _bootstrap._gcd_import(name[level:], package, level)^^
^^^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^     ^^return importlib.import_module("." + module_name, self.__name__) ^^
 ^^ ^^^ ^^^ ^^^ ^^^ ^^^     ^^^ return importlib.import_module("." + module_name, self.__name__)^^^ 
^^^ ^^^ ^ ^^ ^ ^^ ^ ^^^^ ^^^^ ^^^
 ^^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
 ^^^ ^^^ ^^^ ^^^^^^^^^^^    ^^^^from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state^^^^
^
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^^^^    ^^^from .generation import GenerationConfig, GenerationMixin^^^
^^^^^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^^^^^^^^^^^^^^^^    ^^^return _bootstrap._gcd_import(name[level:], package, level)^^^
^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^
 ^^^     ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
 module = self._get_module(self._class_to_module[name])^^ 
^^     ^^^from .utils import (^ ^^
^ ^^^ ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>
^ ^^^ ^^^ ^^^ ^^^ ^^^     ^^^ from .generation import GenerationConfig, GenerationMixin^^
 
^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
   File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^^^^^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^^^^    ^^return _bootstrap._gcd_import(name[level:], package, level)^^
^^^^ ^^ ^^ ^^ ^^     ^^return _bootstrap._gcd_import(name[level:], package, level) ^^
 ^^     ^^from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer  ^^    
  ^^module = self._get_module(self._class_to_module[name])  ^^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>
 ^^^ ^^^  ^^^  ^^^  ^^^  ^^^  ^^^  ^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^
^ ^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
^^^^^^^^^^^^^^^^^^^
^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^^^^^^^^^^^^^^^^^^^^    ^^^from .generation import GenerationConfig, GenerationMixin^^^^
^^    ^^^import torch.distributed.checkpoint as dist_cp^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^
^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
^^^^^^^^^^^    ^^^return importlib.import_module("." + module_name, self.__name__)^^^
^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^
^^     ^^ module = self._get_module(self._class_to_module[name])  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/modeling_utils.py", line 46, in <module>
^^ 
^^ ^^^ ^^^ ^^^ ^^^ ^
^ 
^    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
 ^ ^ ^ ^ ^     ^from .default_planner import DefaultLoadPlanner, DefaultSavePlanner^^    
^^from .generation import GenerationConfig, GenerationMixin^^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
^^^^  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1593, in __getattr__
^^^^^^^^    ^^from ..integrations.deepspeed import is_deepspeed_zero3_enabled    ^^
return importlib.import_module("." + module_name, self.__name__)^^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
^^^ ^^ ^^ ^^ ^^     ^^module = self._get_module(self._class_to_module[name]) ^^
 ^^ ^^  ^^  ^^  ^^^ ^^    ^ ^^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig^ ^^
^ ^^^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
 ^^^ ^^^ ^^^ ^^^ ^^^^^^^^^^^^    ^^^^from torch.distributed._tensor import DTensor^^^^
^^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
^
    ^^
from .accelerator import Accelerator^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module

^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^    return _bootstrap._gcd_import(name[level:], package, level)^^from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
^^    
^^return importlib.import_module("." + module_name, self.__name__)^ ^
^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>
^^ ^^  ^^  ^^  ^^  ^^  ^
  ^  ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/import_utils.py", line 1603, in _get_module
  
 ^^       File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^ import torch.distributed._tensor.ops^^
^    ^^from .utils import (^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>

^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>
^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^    return importlib.import_module("." + module_name, self.__name__)^^return _bootstrap._gcd_import(name[level:], package, level)
^^
^^^ ^^  ^^      ^^  from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer^^  
^^  ^^  ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>
^  ^^  ^^  ^^  ^^^ ^^^^^^^^^^^^^^^^^^^^    ^^^^from .embedding_ops import *  # noqa: F403^^^^
    ^^^^import torch.distributed.checkpoint as dist_cp^^^^ 
^^^^ ^^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
^^^ ^^^^^^^^^^^^^^^
^^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
^^^^^^^^^^^^^^^^^^^^
^    ^^^from .default_planner import DefaultLoadPlanner, DefaultSavePlanner^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^
^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
^^^^^^^^^    ^^^from ..integrations.deepspeed import is_deepspeed_zero3_enabled^^^
^^^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
^^^^^^Traceback (most recent call last):
^^^^^    ^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/experiments/alpaca_finetune.py", line 225, in <module>
^^return _bootstrap._gcd_import(name[level:], package, level)^^^
^^^
^^ ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
^^ ^    ^ ^from torch.distributed._tensor import DTensor^ ^
^ ^^ ^    ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
 ^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig^ ^
^ ^^ ^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
^^    ^
pipeline.build_and_run_cmd()^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/importlib/__init__.py", line 126, in import_module
^^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/experiments/alpaca_finetune.py", line 218, in build_and_run_cmd
^^^^^^^^^^^^^^    ^import torch.distributed._tensor.ops^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>
^^^^^^    ^from .accelerator import Accelerator    ^
from ..integrations.deepspeed import is_deepspeed_zero3_enabled^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
^    ^return _bootstrap._gcd_import(name[level:], package, level)^
^    ^self.alpaca_cmd()^ 
^ ^ ^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/experiments/alpaca_finetune.py", line 205, in alpaca_cmd
 ^     ^ import torch.distributed._functional_collectives as funcol^ 
^     ^from .embedding_ops import *  # noqa: F403 
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>

     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
^ ^  ^    ^^from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state^^
    ^^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
^    ^^self.run(cwd=Path(__file__).parent.parent / "stanford_alpaca")^^
^^^^^^^  File "/opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/llm_fingerprinting/experiments/alpaca_finetune.py", line 144, in run
    ^^from . import _functional_collectives_impl as fun_col_impl^^    
^^from ..integrations.deepspeed import is_deepspeed_zero3_enabled^^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
^^^^    ^^from .utils import (^^
^^    ^^from .accelerator import Accelerator  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>
^^
^^
    ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
subprocess.run(cmd.split(), cwd=cwd)^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 550, in run
^^^^^^^^^^^^^^^^^    ^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/generation/utils.py", line 41, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
    import torch.distributed._functional_collectives as funcol    
from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>
    stdout, stderr = process.communicate(input, timeout=timeout)
              from ..integrations.deepspeed import is_deepspeed_zero3_enabled 
     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/integrations/deepspeed.py", line 52, in <module>
             from .accelerator import Acceleratorfrom torch._dynamo import assume_constant_result 

     ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
from . import _functional_collectives_impl as fun_col_impl  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
^^^    ^import torch.distributed.checkpoint as dist_cp    ^
from .utils import (^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>
^^^^^^^^    ^from accelerate.utils.deepspeed import HfDeepSpeedConfig as DeepSpeedConfig^
^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/__init__.py", line 16, in <module>
^^^^^^^^    ^from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state^    
^from torch._dynamo import assume_constant_result^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 1201, in communicate
    from .default_planner import DefaultLoadPlanner, DefaultSavePlanner
    from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>

from . import convert_frame, eval_frame, resume_execution
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
    from .accelerator import Accelerator
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/accelerator.py", line 35, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
    from .utils import (    
self.wait()    
from torch.distributed._tensor import DTensor  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 1264, in wait
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state
    import torch.distributed.checkpoint as dist_cp  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/checkpointing.py", line 24, in <module>

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
        import torch.distributed._tensor.opsfrom .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer

    return self._wait(timeout=timeout)  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>
    from . import config, exc, trace_rules     
from .utils import (
        File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
from .default_planner import DefaultLoadPlanner, DefaultSavePlanner  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/__init__.py", line 183, in <module>
 
       from . import config, exc, trace_rules  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
 
    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
 ^^^^^^^^^^^^^^^^^^^    ^from .embedding_ops import *  # noqa: F403^    
^import torch.distributed.checkpoint as dist_cp^
 ^ ^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
^     ^^from .fsdp_utils import load_fsdp_model, load_fsdp_optimizer, merge_fsdp_weights, save_fsdp_model, save_fsdp_optimizer
^
    ^from torch.distributed._tensor import DTensor  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 2053, in _wait
^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py", line 29, in <module>
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
^^^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
    from .default_planner import DefaultLoadPlanner, DefaultSavePlanner
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
    import torch.distributed.checkpoint as dist_cp    
import torch.distributed._tensor.ops
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/__init__.py", line 2, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>
    (pid, sts) = self._try_wait(0)
    import torch.distributed._functional_collectives as funcol 
     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>
       from torch.distributed._tensor import DTensor 
     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
      ^^    ^from .variables import (^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
^^^^^^^^^^^
        from .default_planner import DefaultLoadPlanner, DefaultSavePlanner      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/subprocess.py", line 2011, in _try_wait
from .embedding_ops import *  # noqa: F403
from .variables import (

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/checkpoint/default_planner.py", line 13, in <module>
   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
   ^^^^        ^from . import _functional_collectives_impl as fun_col_implimport torch.distributed._tensor.ops^

^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
^^^^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
    from torch.distributed._tensor import DTensor
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/__init__.py", line 6, in <module>
    from .builtin import BuiltinVariable
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
    (pid, sts) = os.waitpid(self.pid, wait_flags)
             from torch._dynamo import assume_constant_result from .embedding_ops import *  # noqa: F403
     
 from .builtin import BuiltinVariable  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
 
     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
      import torch.distributed._functional_collectives as funcol      
 ^import torch.distributed._tensor.ops ^
   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>
^ ^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/__init__.py", line 2, in <module>
^^^^^^[2024-08-28 20:56:17,068] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754958
^^^^^^^^^^^^^    ^^from . import convert_frame, eval_frame, resume_execution^^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
^^^^    ^^from .ctx_manager import EventVariable, StreamVariable^^    
^^from . import _functional_collectives_impl as fun_col_impl    ^^
from .embedding_ops import *  # noqa: F403  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>
^^^
^    ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
^from .ctx_manager import EventVariable, StreamVariable^ ^

 ^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
 ^^^^^^^    ^^from . import config, exc, trace_rules^^
^^^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
^KeyboardInterrupt^^
^^^^^^^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_tensor/ops/embedding_ops.py", line 8, in <module>
    from torch._dynamo import assume_constant_result
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
    import torch.distributed._functional_collectives as funcol
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>
    from .variables import (
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
    import torch.distributed._functional_collectives as funcol
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py", line 12, in <module>
    from ..device_interface import get_interface_for_device
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>
    from . import convert_frame, eval_frame, resume_execution
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
    from ..device_interface import get_interface_for_device    
from . import _functional_collectives_impl as fun_col_impl    
from .builtin import BuiltinVariable  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>

  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
    from . import _functional_collectives_impl as fun_col_impl
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/distributed/_functional_collectives_impl.py", line 36, in <module>
    from . import config, exc, trace_rules
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
    from torch._dynamo import assume_constant_result
    from .ctx_manager import EventVariable, StreamVariable  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>

    for i in range(torch.cuda.device_count()):    
from torch._dynamo import assume_constant_result  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>

    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/__init__.py", line 2, in <module>
       for i in range(torch.cuda.device_count()): 
            from .variables import (  
      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
          ^ ^ ^ ^ ^     ^ from . import convert_frame, eval_frame, resume_execution^ 
^ ^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
^^    ^    ^from ..device_interface import get_interface_for_device^from . import convert_frame, eval_frame, resume_execution^
^
^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py", line 40, in <module>
^    ^^from .builtin import BuiltinVariable^^
^^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
^^^^^^^^^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
^^^^^^
      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
from . import config, exc, trace_rules
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
    from . import config, exc, trace_rules
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py", line 50, in <module>
    for i in range(torch.cuda.device_count()):
                from .ctx_manager import EventVariable, StreamVariable 
      nvml_count = -1 if torch.version.hip else _device_count_nvml()   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>

          ^from .variables import ( ^
 ^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
^ ^ ^ ^     ^nvml_count = -1 if torch.version.hip else _device_count_nvml()     ^
 from .variables import (^ 
^  ^    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/__init__.py", line 4, in <module>
^  ^      ^from ..device_interface import get_interface_for_device      ^
 from .builtin import BuiltinVariable ^  
 ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>
  ^    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
    ^  from .builtin import BuiltinVariable^  
^  ^  ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/builtin.py", line 42, in <module>
  
      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
                             for i in range(torch.cuda.device_count()):  
        from .ctx_manager import EventVariable, StreamVariable   
^      ^^from .ctx_manager import EventVariable, StreamVariable    File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>
^
  ^  ^      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/variables/ctx_manager.py", line 12, in <module>
  ^nvml_count = -1 if torch.version.hip else _device_count_nvml()  ^
  ^  ^   ^   ^   ^   ^   ^  ^^  ^^  ^    ^  ^from ..device_interface import get_interface_for_device^  ^
^^ ^
^ ^      File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>
^ ^from ..device_interface import get_interface_for_device  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml
^ ^
^ ^^ ^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/_dynamo/device_interface.py", line 198, in <module>
 ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ 
^ ^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml
^ ^ ^ ^ ^ ^^     
 for i in range(torch.cuda.device_count()):     
raw_cnt = _raw_device_count_nvml()  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
 
             raw_cnt = _raw_device_count_nvml()       
for i in range(torch.cuda.device_count()):   
                    nvml_count = -1 if torch.version.hip else _device_count_nvml()^    
^    ^    ^     ^     ^     ^  ^  ^  ^  ^  ^  ^  ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^ ^^^^^ ^^^^
 ^^^^ ^^^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml
 ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^
^^ ^^^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
^^ ^^^^     
^^ raw_cnt = _raw_device_count_nvml()^
 
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
^^   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
^  ^  ^  ^          
rc = nvml_h.nvmlInit() rc = nvml_h.nvmlInit() 
 
   File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 753, in device_count
                       ^ nvml_count = -1 if torch.version.hip else _device_count_nvml()  ^ 
  ^ ^ ^ ^  ^ ^  ^^^ ^^^^ ^^    ^^ ^^nvml_count = -1 if torch.version.hip else _device_count_nvml()^^ ^^
^^ ^^^^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^^^ ^ ^
^ ^ ^^ ^ ^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml

 ^ 
 ^ KeyboardInterrupt ^ KeyboardInterrupt ^ 
 
 
     File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
             raw_cnt = _raw_device_count_nvml()  
                          rc = nvml_h.nvmlInit()   
                         ^  ^^  ^^  ^^  ^^ ^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^
^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml
^^^KeyboardInterrupt^^^

^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 714, in _device_count_nvml
    raw_cnt = _raw_device_count_nvml()    
rc = nvml_h.nvmlInit() 
                      raw_cnt = _raw_device_count_nvml()  
 ^  ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^
^^^^KeyboardInterrupt^^^^
^^^^^^^^
^^  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
^^^^^^^^^^^
  File "/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/cuda/__init__.py", line 622, in _raw_device_count_nvml
    rc = nvml_h.nvmlInit()
         ^^^^^^^^^    ^rc = nvml_h.nvmlInit()^
^^^ ^ ^ ^ 
  KeyboardInterrupt  
 ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[2024-08-28 20:56:17,175] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754959
[2024-08-28 20:56:17,283] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754960
[2024-08-28 20:56:17,388] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754961
[2024-08-28 20:56:17,497] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754962
[2024-08-28 20:56:17,599] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3754963
[2024-08-28 20:56:17,701] [INFO] [launch.py:328:sigkill_handler] Main process received SIGINT, exiting

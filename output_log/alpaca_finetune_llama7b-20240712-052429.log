Namespace(mode=['alpaca'], base_model='meta-llama/Llama-2-7b-hf', task_name='sharegpt', tuned_dir='./cache')
num gpus:  8
Running 1/1: deepspeed --num_gpus=8 train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True
    --model_name_or_path meta-llama/Llama-2-7b-hf --data_path ../data/stanford_alpaca/sharegpt_data.json
    --output_dir /fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned
    --num_train_epochs 3
    --per_device_train_batch_size 10
    --per_device_eval_batch_size 4
    --gradient_accumulation_steps 1
    --gradient_checkpointing=True
    --evaluation_strategy=no
    --save_strategy=steps
    --save_steps 500
    --save_total_limit 1
    --learning_rate 2e-6
    --weight_decay 0.
    --report_to tensorboard
    --warmup_ratio 0.03
    --lr_scheduler_type=cosine
    --logging_steps 1
['deepspeed', '--num_gpus=8', 'train.py', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:24:42,936] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-12 05:24:57,623] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2024-07-12 05:24:57,624] [INFO] [runner.py:568:main] cmd = /data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed ../deepspeed_config/zero3.json --bf16 --tf32=True --model_name_or_path meta-llama/Llama-2-7b-hf --data_path ../data/stanford_alpaca/sharegpt_data.json --output_dir /fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned --num_train_epochs 3 --per_device_train_batch_size 10 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --gradient_checkpointing=True --evaluation_strategy=no --save_strategy=steps --save_steps 500 --save_total_limit 1 --learning_rate 2e-6 --weight_decay 0. --report_to tensorboard --warmup_ratio 0.03 --lr_scheduler_type=cosine --logging_steps 1
[2024-07-12 05:24:59,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-12 05:25:02,912] [INFO] [launch.py:139:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2024-07-12 05:25:02,912] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-07-12 05:25:02,912] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-07-12 05:25:02,912] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-07-12 05:25:02,912] [INFO] [launch.py:164:main] dist_world_size=8
[2024-07-12 05:25:02,912] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-07-12 05:25:02,913] [INFO] [launch.py:256:main] process 2177937 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=0', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,913] [INFO] [launch.py:256:main] process 2177938 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=1', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,914] [INFO] [launch.py:256:main] process 2177939 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=2', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,914] [INFO] [launch.py:256:main] process 2177940 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=3', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,915] [INFO] [launch.py:256:main] process 2177941 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=4', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,915] [INFO] [launch.py:256:main] process 2177942 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=5', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,915] [INFO] [launch.py:256:main] process 2177943 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=6', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
[2024-07-12 05:25:02,916] [INFO] [launch.py:256:main] process 2177944 spawned with command: ['/data/home/yunyun/miniconda3/envs/newtorch2/bin/python3.11', '-u', 'train.py', '--local_rank=7', '--deepspeed', '../deepspeed_config/zero3.json', '--bf16', '--tf32=True', '--model_name_or_path', 'meta-llama/Llama-2-7b-hf', '--data_path', '../data/stanford_alpaca/sharegpt_data.json', '--output_dir', '/fsx-project/yunyun/models/meta-llama_meta-llama_sharegpt_tuned', '--num_train_epochs', '3', '--per_device_train_batch_size', '10', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--gradient_checkpointing=True', '--evaluation_strategy=no', '--save_strategy=steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--report_to', 'tensorboard', '--warmup_ratio', '0.03', '--lr_scheduler_type=cosine', '--logging_steps', '1']
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-07-12 05:25:16,966] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-07-12 05:25:17,387] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,389] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,421] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,431] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,431] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,450] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-12 05:25:17,452] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[2024-07-12 05:25:17,712] [INFO] [comm.py:637:init_distributed] cdb=None
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-07-12 05:25:18,079] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,124] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,125] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,132] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,133] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,136] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,137] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-12 05:25:18,137] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)

Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 428.80it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 426.38it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 422.39it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 421.90it/s]




Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1724.28it/s]

Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1703.96it/s]

Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1754.94it/s]

Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 1657.17it/s]
[2024-07-12 05:25:29,370] [INFO] [partition_parameters.py:345:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.26s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.20s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.20s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.26s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.26s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.26s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [00:30<00:30, 30.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.81s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.83s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.79s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.81s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.81s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.82s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.82s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 23.84s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.79s/it]

Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.98s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.75s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.09s/it]
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Loading data...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Formatting inputs...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
WARNING:root:Tokenizing inputs... This may take some time...
[rank2]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[rank7]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank5]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank3]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank6]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank1]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank0]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
[rank4]:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
Using /opt/hpcaas/.mounts/fs-0301404b74c8d22fd/home/yunyun/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 8.324997901916504 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 6.708820104598999 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 7.308824300765991 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 6.708271503448486 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 6.20751953125 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 8.110229253768921 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 7.2091357707977295 seconds
Loading extension module fused_adam...
Time to load fused_adam op: 8.009595155715942 seconds
Parameter Offload: Total persistent parameters: 266240 in 65 params
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.

  0%|          | 0/630 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

  0%|          | 1/630 [00:08<1:33:03,  8.88s/it]
                                                 
{'loss': 0.9013, 'grad_norm': 5.038126739792916, 'learning_rate': 0.0, 'epoch': 0.0}

  0%|          | 1/630 [00:08<1:33:03,  8.88s/it]
  0%|          | 2/630 [00:10<45:36,  4.36s/it]  
                                               
{'loss': 0.8928, 'grad_norm': 4.592733844636386, 'learning_rate': 4.7081782673327645e-07, 'epoch': 0.01}

  0%|          | 2/630 [00:10<45:36,  4.36s/it]
  0%|          | 3/630 [00:10<28:57,  2.77s/it]
                                               
{'loss': 0.916, 'grad_norm': 4.7790989894727565, 'learning_rate': 7.462286000432739e-07, 'epoch': 0.01}

  0%|          | 3/630 [00:10<28:57,  2.77s/it]
  1%|          | 4/630 [00:11<21:09,  2.03s/it]
                                               
{'loss': 0.8247, 'grad_norm': 4.483375720976045, 'learning_rate': 9.416356534665529e-07, 'epoch': 0.02}

  1%|          | 4/630 [00:11<21:09,  2.03s/it]
  1%|          | 5/630 [00:12<16:49,  1.61s/it]
                                               
{'loss': 0.8871, 'grad_norm': 4.610316436302661, 'learning_rate': 1.0932051394658049e-06, 'epoch': 0.02}

  1%|          | 5/630 [00:12<16:49,  1.61s/it]
  1%|          | 6/630 [00:13<14:12,  1.37s/it]
                                               
{'loss': 0.8525, 'grad_norm': 4.3646324385992665, 'learning_rate': 1.2170464267765503e-06, 'epoch': 0.03}

  1%|          | 6/630 [00:13<14:12,  1.37s/it]
  1%|          | 7/630 [00:14<12:33,  1.21s/it]
                                               
{'loss': 0.8612, 'grad_norm': 4.158646844163917, 'learning_rate': 1.3217527432721277e-06, 'epoch': 0.03}

  1%|          | 7/630 [00:14<12:33,  1.21s/it]
  1%|▏         | 8/630 [00:15<11:29,  1.11s/it]
                                               
{'loss': 0.9349, 'grad_norm': 4.237329862106916, 'learning_rate': 1.4124534801998293e-06, 'epoch': 0.04}

  1%|▏         | 8/630 [00:15<11:29,  1.11s/it]
  1%|▏         | 9/630 [00:16<10:44,  1.04s/it]
                                               
{'loss': 0.8897, 'grad_norm': 4.342395837242346, 'learning_rate': 1.4924572000865478e-06, 'epoch': 0.04}

  1%|▏         | 9/630 [00:16<10:44,  1.04s/it]
  2%|▏         | 10/630 [00:17<10:14,  1.01it/s]
                                                
{'loss': 0.7804, 'grad_norm': 2.6499165672615494, 'learning_rate': 1.5640229661990816e-06, 'epoch': 0.05}

  2%|▏         | 10/630 [00:17<10:14,  1.01it/s]
  2%|▏         | 11/630 [00:18<09:55,  1.04it/s]
                                                
{'loss': 0.872, 'grad_norm': 3.376194547952148, 'learning_rate': 1.6287620764191933e-06, 'epoch': 0.05}

  2%|▏         | 11/630 [00:18<09:55,  1.04it/s]
  2%|▏         | 12/630 [00:18<09:39,  1.07it/s]
                                                
{'loss': 0.7866, 'grad_norm': 2.91192818888389, 'learning_rate': 1.6878642535098268e-06, 'epoch': 0.06}

  2%|▏         | 12/630 [00:18<09:39,  1.07it/s]
  2%|▏         | 13/630 [00:19<09:30,  1.08it/s]
                                                
{'loss': 0.9085, 'grad_norm': 3.4443716900483197, 'learning_rate': 1.7422329860526872e-06, 'epoch': 0.06}

  2%|▏         | 13/630 [00:19<09:30,  1.08it/s]
  2%|▏         | 14/630 [00:20<09:23,  1.09it/s]
                                                
{'loss': 0.8243, 'grad_norm': 2.8219491683352076, 'learning_rate': 1.792570570005404e-06, 'epoch': 0.07}

  2%|▏         | 14/630 [00:20<09:23,  1.09it/s]
  2%|▏         | 15/630 [00:21<09:17,  1.10it/s]
                                                
{'loss': 0.7218, 'grad_norm': 2.087656134590075, 'learning_rate': 1.8394337395090787e-06, 'epoch': 0.07}

  2%|▏         | 15/630 [00:21<09:17,  1.10it/s]
  3%|▎         | 16/630 [00:22<09:13,  1.11it/s]
                                                
{'loss': 0.7584, 'grad_norm': 2.816354210094495, 'learning_rate': 1.8832713069331058e-06, 'epoch': 0.08}

  3%|▎         | 16/630 [00:22<09:13,  1.11it/s]
  3%|▎         | 17/630 [00:23<09:10,  1.11it/s]
                                                
{'loss': 0.8403, 'grad_norm': 3.0764250563447666, 'learning_rate': 1.924450371770508e-06, 'epoch': 0.08}

  3%|▎         | 17/630 [00:23<09:10,  1.11it/s]
  3%|▎         | 18/630 [00:24<09:06,  1.12it/s]
                                                
{'loss': 0.774, 'grad_norm': 2.236013989436605, 'learning_rate': 1.9632750268198243e-06, 'epoch': 0.09}

  3%|▎         | 18/630 [00:24<09:06,  1.12it/s]
  3%|▎         | 19/630 [00:25<09:04,  1.12it/s]
                                                
{'loss': 0.7403, 'grad_norm': 1.9470371022047377, 'learning_rate': 2e-06, 'epoch': 0.09}

  3%|▎         | 19/630 [00:25<09:04,  1.12it/s]
  3%|▎         | 20/630 [00:26<09:04,  1.12it/s]
                                                
{'loss': 0.8019, 'grad_norm': 2.3709803213321567, 'learning_rate': 2e-06, 'epoch': 0.1}

  3%|▎         | 20/630 [00:26<09:04,  1.12it/s]
  3%|▎         | 21/630 [00:26<09:03,  1.12it/s]
                                                
{'loss': 0.7601, 'grad_norm': 2.591787326394917, 'learning_rate': 1.9967266775777412e-06, 'epoch': 0.1}

  3%|▎         | 21/630 [00:26<09:03,  1.12it/s]
  3%|▎         | 22/630 [00:27<09:03,  1.12it/s]
                                                
{'loss': 0.754, 'grad_norm': 2.0295918550134773, 'learning_rate': 1.9934533551554826e-06, 'epoch': 0.1}

  3%|▎         | 22/630 [00:27<09:03,  1.12it/s]
  4%|▎         | 23/630 [00:28<09:02,  1.12it/s]
                                                
{'loss': 0.8497, 'grad_norm': 2.3297585736346096, 'learning_rate': 1.990180032733224e-06, 'epoch': 0.11}

  4%|▎         | 23/630 [00:28<09:02,  1.12it/s]
  4%|▍         | 24/630 [00:29<08:59,  1.12it/s]
                                                
{'loss': 0.8528, 'grad_norm': 2.7515705425311907, 'learning_rate': 1.9869067103109657e-06, 'epoch': 0.11}

  4%|▍         | 24/630 [00:29<08:59,  1.12it/s]
  4%|▍         | 25/630 [00:30<08:57,  1.12it/s]
                                                
{'loss': 0.7501, 'grad_norm': 2.3233925848458816, 'learning_rate': 1.983633387888707e-06, 'epoch': 0.12}

  4%|▍         | 25/630 [00:30<08:57,  1.12it/s]
  4%|▍         | 26/630 [00:31<08:56,  1.13it/s]
                                                
{'loss': 0.8026, 'grad_norm': 2.187119615167753, 'learning_rate': 1.9803600654664483e-06, 'epoch': 0.12}

  4%|▍         | 26/630 [00:31<08:56,  1.13it/s]
  4%|▍         | 27/630 [00:32<08:55,  1.13it/s]
                                                
{'loss': 0.7396, 'grad_norm': 2.5744767901603933, 'learning_rate': 1.9770867430441897e-06, 'epoch': 0.13}

  4%|▍         | 27/630 [00:32<08:55,  1.13it/s]
  4%|▍         | 28/630 [00:33<08:53,  1.13it/s]
                                                
{'loss': 0.8139, 'grad_norm': 2.4955244058508512, 'learning_rate': 1.9738134206219314e-06, 'epoch': 0.13}

  4%|▍         | 28/630 [00:33<08:53,  1.13it/s]
  5%|▍         | 29/630 [00:34<08:54,  1.13it/s]
                                                
{'loss': 0.7753, 'grad_norm': 2.322340064819944, 'learning_rate': 1.9705400981996723e-06, 'epoch': 0.14}

  5%|▍         | 29/630 [00:34<08:54,  1.13it/s]
  5%|▍         | 30/630 [00:34<08:53,  1.12it/s]
                                                
{'loss': 0.9026, 'grad_norm': 2.463588169815342, 'learning_rate': 1.967266775777414e-06, 'epoch': 0.14}

  5%|▍         | 30/630 [00:34<08:53,  1.12it/s]
  5%|▍         | 31/630 [00:35<08:52,  1.12it/s]
                                                
{'loss': 0.7246, 'grad_norm': 1.8494430655708674, 'learning_rate': 1.9639934533551554e-06, 'epoch': 0.15}

  5%|▍         | 31/630 [00:35<08:52,  1.12it/s]
  5%|▌         | 32/630 [00:36<08:51,  1.12it/s]
                                                
{'loss': 0.7062, 'grad_norm': 2.057093749654651, 'learning_rate': 1.9607201309328968e-06, 'epoch': 0.15}

  5%|▌         | 32/630 [00:36<08:51,  1.12it/s]
  5%|▌         | 33/630 [00:37<08:51,  1.12it/s]
                                                
{'loss': 0.737, 'grad_norm': 1.9760957996476602, 'learning_rate': 1.957446808510638e-06, 'epoch': 0.16}

  5%|▌         | 33/630 [00:37<08:51,  1.12it/s]
  5%|▌         | 34/630 [00:38<08:50,  1.12it/s]
                                                
{'loss': 0.6738, 'grad_norm': 1.9821324998120449, 'learning_rate': 1.9541734860883794e-06, 'epoch': 0.16}

  5%|▌         | 34/630 [00:38<08:50,  1.12it/s]
  6%|▌         | 35/630 [00:39<08:51,  1.12it/s]
                                                
{'loss': 0.7012, 'grad_norm': 1.826930792551732, 'learning_rate': 1.950900163666121e-06, 'epoch': 0.17}

  6%|▌         | 35/630 [00:39<08:51,  1.12it/s]
  6%|▌         | 36/630 [00:40<08:50,  1.12it/s]
                                                
{'loss': 0.762, 'grad_norm': 2.0286949624739026, 'learning_rate': 1.9476268412438625e-06, 'epoch': 0.17}

  6%|▌         | 36/630 [00:40<08:50,  1.12it/s]
  6%|▌         | 37/630 [00:41<08:50,  1.12it/s]
                                                
{'loss': 0.7208, 'grad_norm': 2.343613873380869, 'learning_rate': 1.944353518821604e-06, 'epoch': 0.18}

  6%|▌         | 37/630 [00:41<08:50,  1.12it/s]
  6%|▌         | 38/630 [00:42<08:48,  1.12it/s]
                                                
{'loss': 0.7423, 'grad_norm': 2.102496932246581, 'learning_rate': 1.941080196399345e-06, 'epoch': 0.18}

  6%|▌         | 38/630 [00:42<08:48,  1.12it/s]
  6%|▌         | 39/630 [00:42<08:48,  1.12it/s]
                                                
{'loss': 0.7217, 'grad_norm': 1.795321576240309, 'learning_rate': 1.9378068739770865e-06, 'epoch': 0.19}

  6%|▌         | 39/630 [00:42<08:48,  1.12it/s]
  6%|▋         | 40/630 [00:43<08:46,  1.12it/s]
                                                
{'loss': 0.7422, 'grad_norm': 1.8287847352579711, 'learning_rate': 1.934533551554828e-06, 'epoch': 0.19}

  6%|▋         | 40/630 [00:43<08:46,  1.12it/s]
  7%|▋         | 41/630 [00:44<08:43,  1.12it/s]
                                                
{'loss': 0.744, 'grad_norm': 2.5610626940697596, 'learning_rate': 1.9312602291325696e-06, 'epoch': 0.2}

  7%|▋         | 41/630 [00:44<08:43,  1.12it/s]
  7%|▋         | 42/630 [00:45<08:42,  1.12it/s]
                                                
{'loss': 0.6626, 'grad_norm': 1.5397048717285744, 'learning_rate': 1.927986906710311e-06, 'epoch': 0.2}

  7%|▋         | 42/630 [00:45<08:42,  1.12it/s]
  7%|▋         | 43/630 [00:46<08:42,  1.12it/s]
                                                
{'loss': 0.8118, 'grad_norm': 2.212991609532134, 'learning_rate': 1.9247135842880523e-06, 'epoch': 0.2}

  7%|▋         | 43/630 [00:46<08:42,  1.12it/s]
  7%|▋         | 44/630 [00:47<08:42,  1.12it/s]
                                                
{'loss': 0.8037, 'grad_norm': 2.324890248957111, 'learning_rate': 1.9214402618657936e-06, 'epoch': 0.21}

  7%|▋         | 44/630 [00:47<08:42,  1.12it/s]
  7%|▋         | 45/630 [00:48<08:41,  1.12it/s]
                                                
{'loss': 0.7682, 'grad_norm': 2.618863902121499, 'learning_rate': 1.918166939443535e-06, 'epoch': 0.21}

  7%|▋         | 45/630 [00:48<08:41,  1.12it/s]
  7%|▋         | 46/630 [00:49<08:40,  1.12it/s]
                                                
{'loss': 0.7416, 'grad_norm': 1.9032437444921102, 'learning_rate': 1.9148936170212767e-06, 'epoch': 0.22}

  7%|▋         | 46/630 [00:49<08:40,  1.12it/s]
  7%|▋         | 47/630 [00:50<08:37,  1.13it/s]
                                                
{'loss': 0.7319, 'grad_norm': 2.08753628465324, 'learning_rate': 1.911620294599018e-06, 'epoch': 0.22}

  7%|▋         | 47/630 [00:50<08:37,  1.13it/s]
  8%|▊         | 48/630 [00:50<08:36,  1.13it/s]
                                                
{'loss': 0.7421, 'grad_norm': 2.181183412022977, 'learning_rate': 1.9083469721767594e-06, 'epoch': 0.23}

  8%|▊         | 48/630 [00:50<08:36,  1.13it/s]
  8%|▊         | 49/630 [00:51<08:36,  1.13it/s]
                                                
{'loss': 0.7423, 'grad_norm': 2.0446834130199965, 'learning_rate': 1.9050736497545007e-06, 'epoch': 0.23}

  8%|▊         | 49/630 [00:51<08:36,  1.13it/s]
  8%|▊         | 50/630 [00:52<08:35,  1.13it/s]
                                                
{'loss': 0.7164, 'grad_norm': 1.9483547474280738, 'learning_rate': 1.901800327332242e-06, 'epoch': 0.24}

  8%|▊         | 50/630 [00:52<08:35,  1.13it/s]
  8%|▊         | 51/630 [00:53<08:33,  1.13it/s]
                                                
{'loss': 0.6703, 'grad_norm': 1.7325216502659462, 'learning_rate': 1.8985270049099836e-06, 'epoch': 0.24}

  8%|▊         | 51/630 [00:53<08:33,  1.13it/s]
  8%|▊         | 52/630 [00:54<08:36,  1.12it/s]
                                                
{'loss': 0.7122, 'grad_norm': 1.7206232588255226, 'learning_rate': 1.895253682487725e-06, 'epoch': 0.25}

  8%|▊         | 52/630 [00:54<08:36,  1.12it/s]
  8%|▊         | 53/630 [00:55<08:34,  1.12it/s]
                                                
{'loss': 0.6682, 'grad_norm': 1.7196846702642243, 'learning_rate': 1.8919803600654665e-06, 'epoch': 0.25}

  8%|▊         | 53/630 [00:55<08:34,  1.12it/s]
  9%|▊         | 54/630 [00:56<08:33,  1.12it/s]
                                                
{'loss': 0.7797, 'grad_norm': 2.6367638718894844, 'learning_rate': 1.8887070376432076e-06, 'epoch': 0.26}

  9%|▊         | 54/630 [00:56<08:33,  1.12it/s]
  9%|▊         | 55/630 [00:57<08:31,  1.12it/s]
                                                
{'loss': 0.7388, 'grad_norm': 2.20246032428678, 'learning_rate': 1.8854337152209492e-06, 'epoch': 0.26}

  9%|▊         | 55/630 [00:57<08:31,  1.12it/s]
  9%|▉         | 56/630 [00:58<08:33,  1.12it/s]
                                                
{'loss': 0.7147, 'grad_norm': 1.772985950989381, 'learning_rate': 1.8821603927986907e-06, 'epoch': 0.27}

  9%|▉         | 56/630 [00:58<08:33,  1.12it/s]
  9%|▉         | 57/630 [00:59<08:30,  1.12it/s]
                                                
{'loss': 0.6724, 'grad_norm': 1.8197146523156376, 'learning_rate': 1.8788870703764318e-06, 'epoch': 0.27}

  9%|▉         | 57/630 [00:59<08:30,  1.12it/s]
  9%|▉         | 58/630 [00:59<08:29,  1.12it/s]
                                                
{'loss': 0.7375, 'grad_norm': 1.7585489372756766, 'learning_rate': 1.8756137479541734e-06, 'epoch': 0.28}

  9%|▉         | 58/630 [00:59<08:29,  1.12it/s]
  9%|▉         | 59/630 [01:00<08:34,  1.11it/s]
                                                
{'loss': 0.7662, 'grad_norm': 2.1583397347392466, 'learning_rate': 1.872340425531915e-06, 'epoch': 0.28}

  9%|▉         | 59/630 [01:00<08:34,  1.11it/s]
 10%|▉         | 60/630 [01:01<08:32,  1.11it/s]
                                                
{'loss': 0.8135, 'grad_norm': 2.4263749234305814, 'learning_rate': 1.8690671031096563e-06, 'epoch': 0.29}

 10%|▉         | 60/630 [01:01<08:32,  1.11it/s]
 10%|▉         | 61/630 [01:02<08:28,  1.12it/s]
                                                
{'loss': 0.7213, 'grad_norm': 1.7496400434369617, 'learning_rate': 1.8657937806873976e-06, 'epoch': 0.29}

 10%|▉         | 61/630 [01:02<08:28,  1.12it/s]
 10%|▉         | 62/630 [01:03<08:26,  1.12it/s]
                                                
{'loss': 0.6184, 'grad_norm': 1.750219274149156, 'learning_rate': 1.862520458265139e-06, 'epoch': 0.3}

 10%|▉         | 62/630 [01:03<08:26,  1.12it/s]
 10%|█         | 63/630 [01:04<08:24,  1.12it/s]
                                                
{'loss': 0.7517, 'grad_norm': 1.9844288129449932, 'learning_rate': 1.8592471358428805e-06, 'epoch': 0.3}

 10%|█         | 63/630 [01:04<08:24,  1.12it/s]
 10%|█         | 64/630 [01:05<08:23,  1.12it/s]
                                                
{'loss': 0.7454, 'grad_norm': 2.0612414657994425, 'learning_rate': 1.8559738134206218e-06, 'epoch': 0.3}

 10%|█         | 64/630 [01:05<08:23,  1.12it/s]
 10%|█         | 65/630 [01:06<08:21,  1.13it/s]
                                                
{'loss': 0.696, 'grad_norm': 2.068294033701285, 'learning_rate': 1.8527004909983632e-06, 'epoch': 0.31}

 10%|█         | 65/630 [01:06<08:21,  1.13it/s]
 10%|█         | 66/630 [01:07<08:19,  1.13it/s]
                                                
{'loss': 0.7823, 'grad_norm': 1.862166479727967, 'learning_rate': 1.8494271685761047e-06, 'epoch': 0.31}

 10%|█         | 66/630 [01:07<08:19,  1.13it/s]
 11%|█         | 67/630 [01:07<08:19,  1.13it/s]
                                                
{'loss': 0.7677, 'grad_norm': 2.351466108652432, 'learning_rate': 1.8461538461538462e-06, 'epoch': 0.32}

 11%|█         | 67/630 [01:07<08:19,  1.13it/s]
 11%|█         | 68/630 [01:08<08:18,  1.13it/s]
                                                
{'loss': 0.7262, 'grad_norm': 2.0132383648110106, 'learning_rate': 1.8428805237315874e-06, 'epoch': 0.32}

 11%|█         | 68/630 [01:08<08:18,  1.13it/s]
 11%|█         | 69/630 [01:09<08:17,  1.13it/s]
                                                
{'loss': 0.7117, 'grad_norm': 1.7949457681725727, 'learning_rate': 1.839607201309329e-06, 'epoch': 0.33}

 11%|█         | 69/630 [01:09<08:17,  1.13it/s]
 11%|█         | 70/630 [01:10<08:17,  1.13it/s]
                                                
{'loss': 0.6958, 'grad_norm': 1.798161915268481, 'learning_rate': 1.8363338788870705e-06, 'epoch': 0.33}

 11%|█         | 70/630 [01:10<08:17,  1.13it/s]
 11%|█▏        | 71/630 [01:11<08:17,  1.12it/s]
                                                
{'loss': 0.7245, 'grad_norm': 2.0242215788057663, 'learning_rate': 1.8330605564648116e-06, 'epoch': 0.34}

 11%|█▏        | 71/630 [01:11<08:17,  1.12it/s]
 11%|█▏        | 72/630 [01:12<08:17,  1.12it/s]
                                                
{'loss': 0.6739, 'grad_norm': 2.018933162516839, 'learning_rate': 1.8297872340425531e-06, 'epoch': 0.34}

 11%|█▏        | 72/630 [01:12<08:17,  1.12it/s]
 12%|█▏        | 73/630 [01:13<08:15,  1.12it/s]
                                                
{'loss': 0.7069, 'grad_norm': 2.5302998849259946, 'learning_rate': 1.8265139116202945e-06, 'epoch': 0.35}

 12%|█▏        | 73/630 [01:13<08:15,  1.12it/s]
 12%|█▏        | 74/630 [01:14<08:15,  1.12it/s]
                                                
{'loss': 0.7782, 'grad_norm': 2.150877526936433, 'learning_rate': 1.823240589198036e-06, 'epoch': 0.35}

 12%|█▏        | 74/630 [01:14<08:15,  1.12it/s]
 12%|█▏        | 75/630 [01:15<08:13,  1.12it/s]
                                                
{'loss': 0.7393, 'grad_norm': 2.3728970771698585, 'learning_rate': 1.8199672667757774e-06, 'epoch': 0.36}

 12%|█▏        | 75/630 [01:15<08:13,  1.12it/s]
 12%|█▏        | 76/630 [01:15<08:14,  1.12it/s]
                                                
{'loss': 0.6885, 'grad_norm': 1.6312817520731977, 'learning_rate': 1.8166939443535187e-06, 'epoch': 0.36}

 12%|█▏        | 76/630 [01:15<08:14,  1.12it/s]
 12%|█▏        | 77/630 [01:16<08:13,  1.12it/s]
                                                
{'loss': 0.7067, 'grad_norm': 1.9967937428580138, 'learning_rate': 1.8134206219312602e-06, 'epoch': 0.37}

 12%|█▏        | 77/630 [01:16<08:13,  1.12it/s]
 12%|█▏        | 78/630 [01:17<08:12,  1.12it/s]
                                                
{'loss': 0.7898, 'grad_norm': 2.112520595985578, 'learning_rate': 1.8101472995090016e-06, 'epoch': 0.37}

 12%|█▏        | 78/630 [01:17<08:12,  1.12it/s]
 13%|█▎        | 79/630 [01:18<08:11,  1.12it/s]
                                                
{'loss': 0.6451, 'grad_norm': 1.720983463197032, 'learning_rate': 1.806873977086743e-06, 'epoch': 0.38}

 13%|█▎        | 79/630 [01:18<08:11,  1.12it/s]
 13%|█▎        | 80/630 [01:19<08:12,  1.12it/s]
                                                
{'loss': 0.7043, 'grad_norm': 1.6524221373888064, 'learning_rate': 1.8036006546644845e-06, 'epoch': 0.38}

 13%|█▎        | 80/630 [01:19<08:12,  1.12it/s]
 13%|█▎        | 81/630 [01:20<08:11,  1.12it/s]
                                                
{'loss': 0.8093, 'grad_norm': 2.362529459839091, 'learning_rate': 1.8003273322422258e-06, 'epoch': 0.39}

 13%|█▎        | 81/630 [01:20<08:11,  1.12it/s]
 13%|█▎        | 82/630 [01:21<08:12,  1.11it/s]
                                                
{'loss': 0.7407, 'grad_norm': 2.0390508851057327, 'learning_rate': 1.7970540098199671e-06, 'epoch': 0.39}

 13%|█▎        | 82/630 [01:21<08:12,  1.11it/s]
 13%|█▎        | 83/630 [01:22<08:10,  1.11it/s]
                                                
{'loss': 0.6784, 'grad_norm': 2.0361001753118435, 'learning_rate': 1.7937806873977087e-06, 'epoch': 0.4}

 13%|█▎        | 83/630 [01:22<08:10,  1.11it/s]
 13%|█▎        | 84/630 [01:23<08:09,  1.12it/s]
                                                
{'loss': 0.6714, 'grad_norm': 1.6618073786819694, 'learning_rate': 1.79050736497545e-06, 'epoch': 0.4}

 13%|█▎        | 84/630 [01:23<08:09,  1.12it/s]
 13%|█▎        | 85/630 [01:23<08:06,  1.12it/s]
                                                
{'loss': 0.7153, 'grad_norm': 1.7469508389386752, 'learning_rate': 1.7872340425531913e-06, 'epoch': 0.4}

 13%|█▎        | 85/630 [01:23<08:06,  1.12it/s]
 14%|█▎        | 86/630 [01:24<08:05,  1.12it/s]
                                                
{'loss': 0.6963, 'grad_norm': 1.902923191118379, 'learning_rate': 1.7839607201309329e-06, 'epoch': 0.41}

 14%|█▎        | 86/630 [01:24<08:05,  1.12it/s]
 14%|█▍        | 87/630 [01:25<08:05,  1.12it/s]
                                                
{'loss': 0.7555, 'grad_norm': 1.9248196535235846, 'learning_rate': 1.7806873977086742e-06, 'epoch': 0.41}

 14%|█▍        | 87/630 [01:25<08:05,  1.12it/s]
 14%|█▍        | 88/630 [01:26<08:04,  1.12it/s]
                                                
{'loss': 0.6754, 'grad_norm': 1.7621885896443035, 'learning_rate': 1.7774140752864158e-06, 'epoch': 0.42}

 14%|█▍        | 88/630 [01:26<08:04,  1.12it/s]
 14%|█▍        | 89/630 [01:27<08:02,  1.12it/s]
                                                
{'loss': 0.7019, 'grad_norm': 2.6383615219719747, 'learning_rate': 1.7741407528641569e-06, 'epoch': 0.42}

 14%|█▍        | 89/630 [01:27<08:02,  1.12it/s]
 14%|█▍        | 90/630 [01:28<08:01,  1.12it/s]
                                                
{'loss': 0.6941, 'grad_norm': 1.8912711075689963, 'learning_rate': 1.7708674304418984e-06, 'epoch': 0.43}

 14%|█▍        | 90/630 [01:28<08:01,  1.12it/s]
 14%|█▍        | 91/630 [01:29<07:59,  1.12it/s]
                                                
{'loss': 0.8111, 'grad_norm': 2.001393958846852, 'learning_rate': 1.76759410801964e-06, 'epoch': 0.43}

 14%|█▍        | 91/630 [01:29<07:59,  1.12it/s]
 15%|█▍        | 92/630 [01:30<07:59,  1.12it/s]
                                                
{'loss': 0.7176, 'grad_norm': 2.5319556111326356, 'learning_rate': 1.764320785597381e-06, 'epoch': 0.44}

 15%|█▍        | 92/630 [01:30<07:59,  1.12it/s]
 15%|█▍        | 93/630 [01:31<07:57,  1.12it/s]
                                                
{'loss': 0.7703, 'grad_norm': 2.4025283428174085, 'learning_rate': 1.7610474631751227e-06, 'epoch': 0.44}

 15%|█▍        | 93/630 [01:31<07:57,  1.12it/s]
 15%|█▍        | 94/630 [01:31<07:57,  1.12it/s]
                                                
{'loss': 0.7693, 'grad_norm': 1.7015898793194046, 'learning_rate': 1.7577741407528642e-06, 'epoch': 0.45}

 15%|█▍        | 94/630 [01:32<07:57,  1.12it/s]
 15%|█▌        | 95/630 [01:32<07:56,  1.12it/s]
                                                
{'loss': 0.6351, 'grad_norm': 1.875741182490908, 'learning_rate': 1.7545008183306055e-06, 'epoch': 0.45}

 15%|█▌        | 95/630 [01:32<07:56,  1.12it/s]
 15%|█▌        | 96/630 [01:33<07:55,  1.12it/s]
                                                
{'loss': 0.7809, 'grad_norm': 1.9695591537391492, 'learning_rate': 1.7512274959083469e-06, 'epoch': 0.46}

 15%|█▌        | 96/630 [01:33<07:55,  1.12it/s]
 15%|█▌        | 97/630 [01:34<07:55,  1.12it/s]
                                                
{'loss': 0.7472, 'grad_norm': 1.797904891137453, 'learning_rate': 1.7479541734860884e-06, 'epoch': 0.46}

 15%|█▌        | 97/630 [01:34<07:55,  1.12it/s]
 16%|█▌        | 98/630 [01:35<07:55,  1.12it/s]
                                                
{'loss': 0.679, 'grad_norm': 1.9466914828353206, 'learning_rate': 1.7446808510638297e-06, 'epoch': 0.47}

 16%|█▌        | 98/630 [01:35<07:55,  1.12it/s]
 16%|█▌        | 99/630 [01:36<07:53,  1.12it/s]
                                                
{'loss': 0.7125, 'grad_norm': 1.6801983261190683, 'learning_rate': 1.741407528641571e-06, 'epoch': 0.47}

 16%|█▌        | 99/630 [01:36<07:53,  1.12it/s]
 16%|█▌        | 100/630 [01:37<07:52,  1.12it/s]
                                                 
{'loss': 0.7223, 'grad_norm': 1.9789973409877155, 'learning_rate': 1.7381342062193124e-06, 'epoch': 0.48}

 16%|█▌        | 100/630 [01:37<07:52,  1.12it/s]
 16%|█▌        | 101/630 [01:38<07:51,  1.12it/s]
                                                 
{'loss': 0.6978, 'grad_norm': 1.779337441307168, 'learning_rate': 1.734860883797054e-06, 'epoch': 0.48}

 16%|█▌        | 101/630 [01:38<07:51,  1.12it/s]
 16%|█▌        | 102/630 [01:39<07:54,  1.11it/s]
                                                 
{'loss': 0.7078, 'grad_norm': 2.0541955330625052, 'learning_rate': 1.7315875613747955e-06, 'epoch': 0.49}

 16%|█▌        | 102/630 [01:39<07:54,  1.11it/s]
 16%|█▋        | 103/630 [01:40<07:52,  1.12it/s]
                                                 
{'loss': 0.7822, 'grad_norm': 2.37761863072552, 'learning_rate': 1.7283142389525366e-06, 'epoch': 0.49}

 16%|█▋        | 103/630 [01:40<07:52,  1.12it/s]
 17%|█▋        | 104/630 [01:40<07:50,  1.12it/s]
                                                 
{'loss': 0.7417, 'grad_norm': 1.8998615579645712, 'learning_rate': 1.7250409165302782e-06, 'epoch': 0.5}

 17%|█▋        | 104/630 [01:40<07:50,  1.12it/s]
 17%|█▋        | 105/630 [01:41<07:49,  1.12it/s]
                                                 
{'loss': 0.6706, 'grad_norm': 1.8678821808089565, 'learning_rate': 1.7217675941080197e-06, 'epoch': 0.5}

 17%|█▋        | 105/630 [01:41<07:49,  1.12it/s]
 17%|█▋        | 106/630 [01:42<07:47,  1.12it/s]
                                                 
{'loss': 0.6517, 'grad_norm': 2.340032891379429, 'learning_rate': 1.7184942716857609e-06, 'epoch': 0.5}

 17%|█▋        | 106/630 [01:42<07:47,  1.12it/s]
 17%|█▋        | 107/630 [01:43<07:46,  1.12it/s]
                                                 
{'loss': 0.7152, 'grad_norm': 1.9128751489914508, 'learning_rate': 1.7152209492635024e-06, 'epoch': 0.51}

 17%|█▋        | 107/630 [01:43<07:46,  1.12it/s]
 17%|█▋        | 108/630 [01:44<07:47,  1.12it/s]
                                                 
{'loss': 0.7041, 'grad_norm': 2.0540961956627224, 'learning_rate': 1.7119476268412437e-06, 'epoch': 0.51}

 17%|█▋        | 108/630 [01:44<07:47,  1.12it/s]
 17%|█▋        | 109/630 [01:45<07:45,  1.12it/s]
                                                 
{'loss': 0.7621, 'grad_norm': 1.710789749316428, 'learning_rate': 1.7086743044189853e-06, 'epoch': 0.52}

 17%|█▋        | 109/630 [01:45<07:45,  1.12it/s]
 17%|█▋        | 110/630 [01:46<07:43,  1.12it/s]
                                                 
{'loss': 0.8544, 'grad_norm': 1.9951296030492383, 'learning_rate': 1.7054009819967266e-06, 'epoch': 0.52}

 17%|█▋        | 110/630 [01:46<07:43,  1.12it/s]
 18%|█▊        | 111/630 [01:47<07:43,  1.12it/s]
                                                 
{'loss': 0.6769, 'grad_norm': 1.929443854556106, 'learning_rate': 1.702127659574468e-06, 'epoch': 0.53}

 18%|█▊        | 111/630 [01:47<07:43,  1.12it/s]
 18%|█▊        | 112/630 [01:48<07:42,  1.12it/s]
                                                 
{'loss': 0.6172, 'grad_norm': 2.0157193040177015, 'learning_rate': 1.6988543371522095e-06, 'epoch': 0.53}

 18%|█▊        | 112/630 [01:48<07:42,  1.12it/s]
 18%|█▊        | 113/630 [01:48<07:40,  1.12it/s]
                                                 
{'loss': 0.7315, 'grad_norm': 2.398583542273172, 'learning_rate': 1.6955810147299508e-06, 'epoch': 0.54}

 18%|█▊        | 113/630 [01:48<07:40,  1.12it/s]
 18%|█▊        | 114/630 [01:49<07:40,  1.12it/s]
                                                 
{'loss': 0.7582, 'grad_norm': 1.949648440994486, 'learning_rate': 1.6923076923076922e-06, 'epoch': 0.54}

 18%|█▊        | 114/630 [01:49<07:40,  1.12it/s]
 18%|█▊        | 115/630 [01:50<07:38,  1.12it/s]
                                                 
{'loss': 0.6935, 'grad_norm': 1.8500612987764826, 'learning_rate': 1.6890343698854337e-06, 'epoch': 0.55}

 18%|█▊        | 115/630 [01:50<07:38,  1.12it/s]
 18%|█▊        | 116/630 [01:51<07:37,  1.12it/s]
                                                 
{'loss': 0.7227, 'grad_norm': 1.769299583722502, 'learning_rate': 1.6857610474631753e-06, 'epoch': 0.55}

 18%|█▊        | 116/630 [01:51<07:37,  1.12it/s]
 19%|█▊        | 117/630 [01:52<07:36,  1.12it/s]
                                                 
{'loss': 0.6918, 'grad_norm': 1.9528920788232895, 'learning_rate': 1.6824877250409164e-06, 'epoch': 0.56}

 19%|█▊        | 117/630 [01:52<07:36,  1.12it/s]
 19%|█▊        | 118/630 [01:53<07:36,  1.12it/s]
                                                 
{'loss': 0.6808, 'grad_norm': 1.7651014732245776, 'learning_rate': 1.679214402618658e-06, 'epoch': 0.56}

 19%|█▊        | 118/630 [01:53<07:36,  1.12it/s]
 19%|█▉        | 119/630 [01:54<07:34,  1.12it/s]
                                                 
{'loss': 0.6203, 'grad_norm': 2.543058975146729, 'learning_rate': 1.6759410801963993e-06, 'epoch': 0.57}

 19%|█▉        | 119/630 [01:54<07:34,  1.12it/s]
 19%|█▉        | 120/630 [01:55<07:34,  1.12it/s]
                                                 
{'loss': 0.7223, 'grad_norm': 2.1854552281488013, 'learning_rate': 1.6726677577741406e-06, 'epoch': 0.57}

 19%|█▉        | 120/630 [01:55<07:34,  1.12it/s]
 19%|█▉        | 121/630 [01:56<07:33,  1.12it/s]
                                                 
{'loss': 0.657, 'grad_norm': 2.0315007408366172, 'learning_rate': 1.6693944353518821e-06, 'epoch': 0.58}

 19%|█▉        | 121/630 [01:56<07:33,  1.12it/s]
 19%|█▉        | 122/630 [01:56<07:32,  1.12it/s]
                                                 
{'loss': 0.704, 'grad_norm': 2.3979492289574695, 'learning_rate': 1.6661211129296235e-06, 'epoch': 0.58}

 19%|█▉        | 122/630 [01:56<07:32,  1.12it/s]
 20%|█▉        | 123/630 [01:57<07:32,  1.12it/s]
                                                 
{'loss': 0.7672, 'grad_norm': 1.9740151758260176, 'learning_rate': 1.6628477905073648e-06, 'epoch': 0.59}

 20%|█▉        | 123/630 [01:57<07:32,  1.12it/s]
 20%|█▉        | 124/630 [01:58<07:34,  1.11it/s]
                                                 
{'loss': 0.6951, 'grad_norm': 1.9320249178021278, 'learning_rate': 1.6595744680851064e-06, 'epoch': 0.59}

 20%|█▉        | 124/630 [01:58<07:34,  1.11it/s]
 20%|█▉        | 125/630 [01:59<07:33,  1.11it/s]
                                                 
{'loss': 0.6662, 'grad_norm': 1.9260488042262895, 'learning_rate': 1.6563011456628477e-06, 'epoch': 0.6}

 20%|█▉        | 125/630 [01:59<07:33,  1.11it/s]
 20%|██        | 126/630 [02:00<07:32,  1.11it/s]
                                                 
{'loss': 0.6101, 'grad_norm': 1.7954267925525913, 'learning_rate': 1.6530278232405892e-06, 'epoch': 0.6}

 20%|██        | 126/630 [02:00<07:32,  1.11it/s]
 20%|██        | 127/630 [02:01<07:30,  1.12it/s]
                                                 
{'loss': 0.7236, 'grad_norm': 2.1069709647123442, 'learning_rate': 1.6497545008183304e-06, 'epoch': 0.6}

 20%|██        | 127/630 [02:01<07:30,  1.12it/s]
 20%|██        | 128/630 [02:02<07:29,  1.12it/s]
                                                 
{'loss': 0.7381, 'grad_norm': 1.8626949370857706, 'learning_rate': 1.646481178396072e-06, 'epoch': 0.61}

 20%|██        | 128/630 [02:02<07:29,  1.12it/s]
 20%|██        | 129/630 [02:03<07:28,  1.12it/s]
                                                 
{'loss': 0.7447, 'grad_norm': 1.9176567061337702, 'learning_rate': 1.6432078559738135e-06, 'epoch': 0.61}

 20%|██        | 129/630 [02:03<07:28,  1.12it/s]
 21%|██        | 130/630 [02:04<07:27,  1.12it/s]
                                                 
{'loss': 0.7152, 'grad_norm': 1.9149798938018077, 'learning_rate': 1.6399345335515546e-06, 'epoch': 0.62}

 21%|██        | 130/630 [02:04<07:27,  1.12it/s]
 21%|██        | 131/630 [02:05<07:26,  1.12it/s]
                                                 
{'loss': 0.7089, 'grad_norm': 2.0137639405051044, 'learning_rate': 1.6366612111292961e-06, 'epoch': 0.62}

 21%|██        | 131/630 [02:05<07:26,  1.12it/s]
 21%|██        | 132/630 [02:05<07:24,  1.12it/s]
                                                 
{'loss': 0.7272, 'grad_norm': 2.1894252812312995, 'learning_rate': 1.6333878887070377e-06, 'epoch': 0.63}

 21%|██        | 132/630 [02:05<07:24,  1.12it/s]
 21%|██        | 133/630 [02:06<07:23,  1.12it/s]
                                                 
{'loss': 0.6114, 'grad_norm': 1.973390893651691, 'learning_rate': 1.630114566284779e-06, 'epoch': 0.63}

 21%|██        | 133/630 [02:06<07:23,  1.12it/s]
 21%|██▏       | 134/630 [02:07<07:22,  1.12it/s]
                                                 
{'loss': 0.6393, 'grad_norm': 1.8188435853537668, 'learning_rate': 1.6268412438625203e-06, 'epoch': 0.64}

 21%|██▏       | 134/630 [02:07<07:22,  1.12it/s]
 21%|██▏       | 135/630 [02:08<07:21,  1.12it/s]
                                                 
{'loss': 0.7231, 'grad_norm': 1.9548403503053746, 'learning_rate': 1.6235679214402617e-06, 'epoch': 0.64}

 21%|██▏       | 135/630 [02:08<07:21,  1.12it/s]
 22%|██▏       | 136/630 [02:09<07:20,  1.12it/s]
                                                 
{'loss': 0.7072, 'grad_norm': 2.3462678655173677, 'learning_rate': 1.6202945990180032e-06, 'epoch': 0.65}

 22%|██▏       | 136/630 [02:09<07:20,  1.12it/s]
 22%|██▏       | 137/630 [02:10<07:20,  1.12it/s]
                                                 
{'loss': 0.737, 'grad_norm': 2.3019884301387514, 'learning_rate': 1.6170212765957446e-06, 'epoch': 0.65}

 22%|██▏       | 137/630 [02:10<07:20,  1.12it/s]
 22%|██▏       | 138/630 [02:11<07:19,  1.12it/s]
                                                 
{'loss': 0.7071, 'grad_norm': 2.3146995168960327, 'learning_rate': 1.613747954173486e-06, 'epoch': 0.66}

 22%|██▏       | 138/630 [02:11<07:19,  1.12it/s]
 22%|██▏       | 139/630 [02:12<07:17,  1.12it/s]
                                                 
{'loss': 0.6957, 'grad_norm': 2.328580632967825, 'learning_rate': 1.6104746317512274e-06, 'epoch': 0.66}

 22%|██▏       | 139/630 [02:12<07:17,  1.12it/s]
 22%|██▏       | 140/630 [02:13<07:29,  1.09it/s]
                                                 
{'loss': 0.695, 'grad_norm': 1.8857324098611532, 'learning_rate': 1.607201309328969e-06, 'epoch': 0.67}

 22%|██▏       | 140/630 [02:13<07:29,  1.09it/s]
 22%|██▏       | 141/630 [02:14<07:24,  1.10it/s]
                                                 
{'loss': 0.6392, 'grad_norm': 1.8401972139009497, 'learning_rate': 1.6039279869067101e-06, 'epoch': 0.67}

 22%|██▏       | 141/630 [02:14<07:24,  1.10it/s]
 23%|██▎       | 142/630 [02:14<07:20,  1.11it/s]
                                                 
{'loss': 0.7016, 'grad_norm': 2.0557824230822326, 'learning_rate': 1.6006546644844517e-06, 'epoch': 0.68}

 23%|██▎       | 142/630 [02:14<07:20,  1.11it/s]
 23%|██▎       | 143/630 [02:15<07:17,  1.11it/s]
                                                 
{'loss': 0.7422, 'grad_norm': 2.624801142219641, 'learning_rate': 1.5973813420621932e-06, 'epoch': 0.68}

 23%|██▎       | 143/630 [02:15<07:17,  1.11it/s]
 23%|██▎       | 144/630 [02:16<07:15,  1.11it/s]
                                                 
{'loss': 0.7248, 'grad_norm': 1.8628031048575826, 'learning_rate': 1.5941080196399343e-06, 'epoch': 0.69}

 23%|██▎       | 144/630 [02:16<07:15,  1.11it/s]
 23%|██▎       | 145/630 [02:17<07:14,  1.12it/s]
                                                 
{'loss': 0.6795, 'grad_norm': 1.9807952569294607, 'learning_rate': 1.5908346972176759e-06, 'epoch': 0.69}

 23%|██▎       | 145/630 [02:17<07:14,  1.12it/s]
 23%|██▎       | 146/630 [02:18<07:13,  1.12it/s]
                                                 
{'loss': 0.7457, 'grad_norm': 2.0826592569893534, 'learning_rate': 1.5875613747954172e-06, 'epoch': 0.7}

 23%|██▎       | 146/630 [02:18<07:13,  1.12it/s]
 23%|██▎       | 147/630 [02:19<07:12,  1.12it/s]
                                                 
{'loss': 0.7347, 'grad_norm': 1.7870195560606912, 'learning_rate': 1.5842880523731588e-06, 'epoch': 0.7}

 23%|██▎       | 147/630 [02:19<07:12,  1.12it/s]
 23%|██▎       | 148/630 [02:20<07:11,  1.12it/s]
                                                 
{'loss': 0.7069, 'grad_norm': 2.0752008668427284, 'learning_rate': 1.5810147299509e-06, 'epoch': 0.7}

 23%|██▎       | 148/630 [02:20<07:11,  1.12it/s]
 24%|██▎       | 149/630 [02:21<07:09,  1.12it/s]
                                                 
{'loss': 0.5947, 'grad_norm': 1.9939835246700746, 'learning_rate': 1.5777414075286414e-06, 'epoch': 0.71}

 24%|██▎       | 149/630 [02:21<07:09,  1.12it/s]
 24%|██▍       | 150/630 [02:22<07:08,  1.12it/s]
                                                 
{'loss': 0.691, 'grad_norm': 1.6153445262776192, 'learning_rate': 1.574468085106383e-06, 'epoch': 0.71}

 24%|██▍       | 150/630 [02:22<07:08,  1.12it/s]
 24%|██▍       | 151/630 [02:22<07:09,  1.11it/s]
                                                 
{'loss': 0.8104, 'grad_norm': 2.146085642780737, 'learning_rate': 1.5711947626841243e-06, 'epoch': 0.72}

 24%|██▍       | 151/630 [02:22<07:09,  1.11it/s]
 24%|██▍       | 152/630 [02:23<07:09,  1.11it/s]
                                                 
{'loss': 0.684, 'grad_norm': 2.1518082798667333, 'learning_rate': 1.5679214402618656e-06, 'epoch': 0.72}

 24%|██▍       | 152/630 [02:23<07:09,  1.11it/s]
 24%|██▍       | 153/630 [02:24<07:07,  1.12it/s]
                                                 
{'loss': 0.7058, 'grad_norm': 1.8073505616047638, 'learning_rate': 1.5646481178396072e-06, 'epoch': 0.73}

 24%|██▍       | 153/630 [02:24<07:07,  1.12it/s]
 24%|██▍       | 154/630 [02:25<07:05,  1.12it/s]
                                                 
{'loss': 0.6743, 'grad_norm': 1.9061554635862425, 'learning_rate': 1.5613747954173485e-06, 'epoch': 0.73}

 24%|██▍       | 154/630 [02:25<07:05,  1.12it/s]
 25%|██▍       | 155/630 [02:26<07:03,  1.12it/s]
                                                 
{'loss': 0.7147, 'grad_norm': 1.8820856766189256, 'learning_rate': 1.5581014729950899e-06, 'epoch': 0.74}

 25%|██▍       | 155/630 [02:26<07:03,  1.12it/s]
 25%|██▍       | 156/630 [02:27<07:02,  1.12it/s]
                                                 
{'loss': 0.6339, 'grad_norm': 2.116772432958903, 'learning_rate': 1.5548281505728314e-06, 'epoch': 0.74}

 25%|██▍       | 156/630 [02:27<07:02,  1.12it/s]
 25%|██▍       | 157/630 [02:28<07:01,  1.12it/s]
                                                 
{'loss': 0.8071, 'grad_norm': 2.305834419130524, 'learning_rate': 1.5515548281505727e-06, 'epoch': 0.75}

 25%|██▍       | 157/630 [02:28<07:01,  1.12it/s]
 25%|██▌       | 158/630 [02:29<06:59,  1.13it/s]
                                                 
{'loss': 0.6745, 'grad_norm': 1.9031029371089752, 'learning_rate': 1.548281505728314e-06, 'epoch': 0.75}

 25%|██▌       | 158/630 [02:29<06:59,  1.13it/s]
 25%|██▌       | 159/630 [02:30<06:58,  1.12it/s]
                                                 
{'loss': 0.6552, 'grad_norm': 2.0511422482728947, 'learning_rate': 1.5450081833060556e-06, 'epoch': 0.76}

 25%|██▌       | 159/630 [02:30<06:58,  1.12it/s]
 25%|██▌       | 160/630 [02:31<06:57,  1.12it/s]
                                                 
{'loss': 0.7355, 'grad_norm': 2.271311026816074, 'learning_rate': 1.541734860883797e-06, 'epoch': 0.76}

 25%|██▌       | 160/630 [02:31<06:57,  1.12it/s]
 26%|██▌       | 161/630 [02:31<06:57,  1.12it/s]
                                                 
{'loss': 0.693, 'grad_norm': 2.028223428945483, 'learning_rate': 1.5384615384615385e-06, 'epoch': 0.77}

 26%|██▌       | 161/630 [02:31<06:57,  1.12it/s]
 26%|██▌       | 162/630 [02:32<06:56,  1.12it/s]
                                                 
{'loss': 0.7899, 'grad_norm': 2.5005065897636416, 'learning_rate': 1.5351882160392796e-06, 'epoch': 0.77}

 26%|██▌       | 162/630 [02:32<06:56,  1.12it/s]
 26%|██▌       | 163/630 [02:33<06:55,  1.13it/s]
                                                 
{'loss': 0.6538, 'grad_norm': 2.0242312460156073, 'learning_rate': 1.5319148936170212e-06, 'epoch': 0.78}

 26%|██▌       | 163/630 [02:33<06:55,  1.13it/s]
 26%|██▌       | 164/630 [02:34<06:54,  1.12it/s]
                                                 
{'loss': 0.6455, 'grad_norm': 1.9300577560830687, 'learning_rate': 1.5286415711947627e-06, 'epoch': 0.78}

 26%|██▌       | 164/630 [02:34<06:54,  1.12it/s]
 26%|██▌       | 165/630 [02:35<06:54,  1.12it/s]
                                                 
{'loss': 0.6899, 'grad_norm': 1.89026001081586, 'learning_rate': 1.5253682487725038e-06, 'epoch': 0.79}

 26%|██▌       | 165/630 [02:35<06:54,  1.12it/s]
 26%|██▋       | 166/630 [02:36<06:53,  1.12it/s]
                                                 
{'loss': 0.7743, 'grad_norm': 3.002802807615077, 'learning_rate': 1.5220949263502454e-06, 'epoch': 0.79}

 26%|██▋       | 166/630 [02:36<06:53,  1.12it/s]
 27%|██▋       | 167/630 [02:37<06:51,  1.12it/s]
                                                 
{'loss': 0.7293, 'grad_norm': 1.9900719136888083, 'learning_rate': 1.518821603927987e-06, 'epoch': 0.8}

 27%|██▋       | 167/630 [02:37<06:51,  1.12it/s]
 27%|██▋       | 168/630 [02:38<06:51,  1.12it/s]
                                                 
{'loss': 0.723, 'grad_norm': 1.9815172333964084, 'learning_rate': 1.5155482815057283e-06, 'epoch': 0.8}

 27%|██▋       | 168/630 [02:38<06:51,  1.12it/s]
 27%|██▋       | 169/630 [02:39<06:50,  1.12it/s]
                                                 
{'loss': 0.6773, 'grad_norm': 1.9013066135351446, 'learning_rate': 1.5122749590834696e-06, 'epoch': 0.8}

 27%|██▋       | 169/630 [02:39<06:50,  1.12it/s]
 27%|██▋       | 170/630 [02:39<06:50,  1.12it/s]
                                                 
{'loss': 0.7097, 'grad_norm': 1.981691789759071, 'learning_rate': 1.5090016366612112e-06, 'epoch': 0.81}

 27%|██▋       | 170/630 [02:39<06:50,  1.12it/s]
 27%|██▋       | 171/630 [02:40<06:49,  1.12it/s]
                                                 
{'loss': 0.6683, 'grad_norm': 1.7793565428374196, 'learning_rate': 1.5057283142389525e-06, 'epoch': 0.81}

 27%|██▋       | 171/630 [02:40<06:49,  1.12it/s]
 27%|██▋       | 172/630 [02:41<06:49,  1.12it/s]
                                                 
{'loss': 0.6589, 'grad_norm': 1.9137199602342037, 'learning_rate': 1.5024549918166938e-06, 'epoch': 0.82}

 27%|██▋       | 172/630 [02:41<06:49,  1.12it/s]
 27%|██▋       | 173/630 [02:42<06:48,  1.12it/s]
                                                 
{'loss': 0.6746, 'grad_norm': 1.8297735907091723, 'learning_rate': 1.4991816693944352e-06, 'epoch': 0.82}

 27%|██▋       | 173/630 [02:42<06:48,  1.12it/s]
 28%|██▊       | 174/630 [02:43<06:47,  1.12it/s]
                                                 
{'loss': 0.6011, 'grad_norm': 1.7537540314464064, 'learning_rate': 1.4959083469721767e-06, 'epoch': 0.83}

 28%|██▊       | 174/630 [02:43<06:47,  1.12it/s]
 28%|██▊       | 175/630 [02:44<06:46,  1.12it/s]
                                                 
{'loss': 0.6925, 'grad_norm': 1.9290155995068958, 'learning_rate': 1.4926350245499183e-06, 'epoch': 0.83}

 28%|██▊       | 175/630 [02:44<06:46,  1.12it/s]
 28%|██▊       | 176/630 [02:45<06:45,  1.12it/s]
                                                 
{'loss': 0.6424, 'grad_norm': 2.01968180899818, 'learning_rate': 1.4893617021276594e-06, 'epoch': 0.84}

 28%|██▊       | 176/630 [02:45<06:45,  1.12it/s]
 28%|██▊       | 177/630 [02:46<06:44,  1.12it/s]
                                                 
{'loss': 0.6468, 'grad_norm': 1.872822688628393, 'learning_rate': 1.486088379705401e-06, 'epoch': 0.84}

 28%|██▊       | 177/630 [02:46<06:44,  1.12it/s]
 28%|██▊       | 178/630 [02:47<06:43,  1.12it/s]
                                                 
{'loss': 0.6963, 'grad_norm': 2.006227218190578, 'learning_rate': 1.4828150572831425e-06, 'epoch': 0.85}

 28%|██▊       | 178/630 [02:47<06:43,  1.12it/s]
 28%|██▊       | 179/630 [02:47<06:42,  1.12it/s]
                                                 
{'loss': 0.7409, 'grad_norm': 2.000489454968337, 'learning_rate': 1.4795417348608836e-06, 'epoch': 0.85}

 28%|██▊       | 179/630 [02:47<06:42,  1.12it/s]
 29%|██▊       | 180/630 [02:48<06:41,  1.12it/s]
                                                 
{'loss': 0.6935, 'grad_norm': 2.049963950472, 'learning_rate': 1.4762684124386251e-06, 'epoch': 0.86}

 29%|██▊       | 180/630 [02:48<06:41,  1.12it/s]
 29%|██▊       | 181/630 [02:49<06:41,  1.12it/s]
                                                 
{'loss': 0.7866, 'grad_norm': 2.1835965264433823, 'learning_rate': 1.4729950900163665e-06, 'epoch': 0.86}

 29%|██▊       | 181/630 [02:49<06:41,  1.12it/s]
 29%|██▉       | 182/630 [02:50<06:39,  1.12it/s]
                                                 
{'loss': 0.6846, 'grad_norm': 2.0190282524701857, 'learning_rate': 1.469721767594108e-06, 'epoch': 0.87}

 29%|██▉       | 182/630 [02:50<06:39,  1.12it/s]
 29%|██▉       | 183/630 [02:51<06:39,  1.12it/s]
                                                 
{'loss': 0.7584, 'grad_norm': 2.4859682774970455, 'learning_rate': 1.4664484451718494e-06, 'epoch': 0.87}

 29%|██▉       | 183/630 [02:51<06:39,  1.12it/s]
 29%|██▉       | 184/630 [02:52<06:37,  1.12it/s]
                                                 
{'loss': 0.671, 'grad_norm': 2.107663815868857, 'learning_rate': 1.4631751227495907e-06, 'epoch': 0.88}

 29%|██▉       | 184/630 [02:52<06:37,  1.12it/s]
 29%|██▉       | 185/630 [02:53<06:37,  1.12it/s]
                                                 
{'loss': 0.6548, 'grad_norm': 1.7426208996470953, 'learning_rate': 1.4599018003273322e-06, 'epoch': 0.88}

 29%|██▉       | 185/630 [02:53<06:37,  1.12it/s]
 30%|██▉       | 186/630 [02:54<06:36,  1.12it/s]
                                                 
{'loss': 0.6742, 'grad_norm': 1.8713065873186714, 'learning_rate': 1.4566284779050736e-06, 'epoch': 0.89}

 30%|██▉       | 186/630 [02:54<06:36,  1.12it/s]
 30%|██▉       | 187/630 [02:55<06:36,  1.12it/s]
                                                 
{'loss': 0.664, 'grad_norm': 1.8831667430600032, 'learning_rate': 1.453355155482815e-06, 'epoch': 0.89}

 30%|██▉       | 187/630 [02:55<06:36,  1.12it/s]
 30%|██▉       | 188/630 [02:55<06:34,  1.12it/s]
                                                 
{'loss': 0.7072, 'grad_norm': 1.9189275427248575, 'learning_rate': 1.4500818330605565e-06, 'epoch': 0.9}

 30%|██▉       | 188/630 [02:55<06:34,  1.12it/s]
 30%|███       | 189/630 [02:56<06:34,  1.12it/s]
                                                 
{'loss': 0.6981, 'grad_norm': 1.7390121996337664, 'learning_rate': 1.446808510638298e-06, 'epoch': 0.9}

 30%|███       | 189/630 [02:56<06:34,  1.12it/s]
 30%|███       | 190/630 [02:57<06:33,  1.12it/s]
                                                 
{'loss': 0.7377, 'grad_norm': 2.0399684986735425, 'learning_rate': 1.4435351882160391e-06, 'epoch': 0.9}

 30%|███       | 190/630 [02:57<06:33,  1.12it/s]
 30%|███       | 191/630 [02:58<06:32,  1.12it/s]
                                                 
{'loss': 0.6599, 'grad_norm': 1.8424847891791987, 'learning_rate': 1.4402618657937807e-06, 'epoch': 0.91}

 30%|███       | 191/630 [02:58<06:32,  1.12it/s]
 30%|███       | 192/630 [02:59<06:32,  1.11it/s]
                                                 
{'loss': 0.6312, 'grad_norm': 1.9988297277540779, 'learning_rate': 1.436988543371522e-06, 'epoch': 0.91}

 30%|███       | 192/630 [02:59<06:32,  1.11it/s]
 31%|███       | 193/630 [03:00<06:32,  1.11it/s]
                                                 
{'loss': 0.6659, 'grad_norm': 2.136811768946721, 'learning_rate': 1.4337152209492633e-06, 'epoch': 0.92}

 31%|███       | 193/630 [03:00<06:32,  1.11it/s]
 31%|███       | 194/630 [03:01<06:30,  1.12it/s]
                                                 
{'loss': 0.6292, 'grad_norm': 1.897386616668683, 'learning_rate': 1.4304418985270049e-06, 'epoch': 0.92}

 31%|███       | 194/630 [03:01<06:30,  1.12it/s]
 31%|███       | 195/630 [03:02<06:28,  1.12it/s]
                                                 
{'loss': 0.5962, 'grad_norm': 1.6065776795362579, 'learning_rate': 1.4271685761047462e-06, 'epoch': 0.93}

 31%|███       | 195/630 [03:02<06:28,  1.12it/s]
 31%|███       | 196/630 [03:03<06:27,  1.12it/s]
                                                 
{'loss': 0.7034, 'grad_norm': 2.239904111915947, 'learning_rate': 1.4238952536824878e-06, 'epoch': 0.93}

 31%|███       | 196/630 [03:03<06:27,  1.12it/s]
 31%|███▏      | 197/630 [03:04<06:24,  1.12it/s]
                                                 
{'loss': 0.6678, 'grad_norm': 2.3887979552889904, 'learning_rate': 1.420621931260229e-06, 'epoch': 0.94}

 31%|███▏      | 197/630 [03:04<06:24,  1.12it/s]
 31%|███▏      | 198/630 [03:04<06:24,  1.12it/s]
                                                 
{'loss': 0.6692, 'grad_norm': 1.8783398502308835, 'learning_rate': 1.4173486088379704e-06, 'epoch': 0.94}

 31%|███▏      | 198/630 [03:04<06:24,  1.12it/s]
 32%|███▏      | 199/630 [03:05<06:22,  1.13it/s]
                                                 
{'loss': 0.6936, 'grad_norm': 2.230167521294654, 'learning_rate': 1.414075286415712e-06, 'epoch': 0.95}

 32%|███▏      | 199/630 [03:05<06:22,  1.13it/s]
 32%|███▏      | 200/630 [03:06<06:21,  1.13it/s]
                                                 
{'loss': 0.6729, 'grad_norm': 1.9701543289535743, 'learning_rate': 1.4108019639934531e-06, 'epoch': 0.95}

 32%|███▏      | 200/630 [03:06<06:21,  1.13it/s]
 32%|███▏      | 201/630 [03:07<06:20,  1.13it/s]
                                                 
{'loss': 0.7355, 'grad_norm': 2.7577560011379765, 'learning_rate': 1.4075286415711947e-06, 'epoch': 0.96}

 32%|███▏      | 201/630 [03:07<06:20,  1.13it/s]
 32%|███▏      | 202/630 [03:08<06:20,  1.12it/s]
                                                 
{'loss': 0.6634, 'grad_norm': 1.8298140270443355, 'learning_rate': 1.4042553191489362e-06, 'epoch': 0.96}

 32%|███▏      | 202/630 [03:08<06:20,  1.12it/s]
 32%|███▏      | 203/630 [03:09<06:20,  1.12it/s]
                                                 
{'loss': 0.651, 'grad_norm': 1.9810567538718797, 'learning_rate': 1.4009819967266775e-06, 'epoch': 0.97}

 32%|███▏      | 203/630 [03:09<06:20,  1.12it/s]
 32%|███▏      | 204/630 [03:10<06:19,  1.12it/s]
                                                 
{'loss': 0.8557, 'grad_norm': 2.5967058447125315, 'learning_rate': 1.3977086743044189e-06, 'epoch': 0.97}

 32%|███▏      | 204/630 [03:10<06:19,  1.12it/s]
 33%|███▎      | 205/630 [03:11<06:19,  1.12it/s]
                                                 
{'loss': 0.5882, 'grad_norm': 1.6039184462101579, 'learning_rate': 1.3944353518821604e-06, 'epoch': 0.98}

 33%|███▎      | 205/630 [03:11<06:19,  1.12it/s]
 33%|███▎      | 206/630 [03:12<06:17,  1.12it/s]
                                                 
{'loss': 0.8036, 'grad_norm': 2.3601633969805467, 'learning_rate': 1.3911620294599018e-06, 'epoch': 0.98}

 33%|███▎      | 206/630 [03:12<06:17,  1.12it/s]
 33%|███▎      | 207/630 [03:12<06:17,  1.12it/s]
                                                 
{'loss': 0.652, 'grad_norm': 1.756303748576606, 'learning_rate': 1.387888707037643e-06, 'epoch': 0.99}

 33%|███▎      | 207/630 [03:12<06:17,  1.12it/s]
 33%|███▎      | 208/630 [03:13<06:16,  1.12it/s]
                                                 
{'loss': 0.735, 'grad_norm': 2.99374119050719, 'learning_rate': 1.3846153846153844e-06, 'epoch': 0.99}

 33%|███▎      | 208/630 [03:13<06:16,  1.12it/s]
 33%|███▎      | 209/630 [03:14<06:15,  1.12it/s]
                                                 
{'loss': 0.6836, 'grad_norm': 1.851582897858577, 'learning_rate': 1.381342062193126e-06, 'epoch': 1.0}

 33%|███▎      | 209/630 [03:14<06:15,  1.12it/s]
 33%|███▎      | 210/630 [03:15<06:13,  1.12it/s]
                                                 
{'loss': 0.6017, 'grad_norm': 1.7034075342821684, 'learning_rate': 1.3780687397708675e-06, 'epoch': 1.0}

 33%|███▎      | 210/630 [03:15<06:13,  1.12it/s]
 33%|███▎      | 211/630 [03:16<06:12,  1.13it/s]
                                                 
{'loss': 0.5706, 'grad_norm': 1.8709596446128796, 'learning_rate': 1.3747954173486086e-06, 'epoch': 1.0}

 33%|███▎      | 211/630 [03:16<06:12,  1.13it/s]
 34%|███▎      | 212/630 [03:17<06:11,  1.13it/s]
                                                 
{'loss': 0.5853, 'grad_norm': 1.9824507453810394, 'learning_rate': 1.3715220949263502e-06, 'epoch': 1.01}

 34%|███▎      | 212/630 [03:17<06:11,  1.13it/s]
 34%|███▍      | 213/630 [03:18<06:11,  1.12it/s]
                                                 
{'loss': 0.6353, 'grad_norm': 1.8159421082629026, 'learning_rate': 1.3682487725040917e-06, 'epoch': 1.01}

 34%|███▍      | 213/630 [03:18<06:11,  1.12it/s]
 34%|███▍      | 214/630 [03:19<06:12,  1.12it/s]
                                                 
{'loss': 0.6354, 'grad_norm': 2.1977643554861936, 'learning_rate': 1.3649754500818329e-06, 'epoch': 1.02}

 34%|███▍      | 214/630 [03:19<06:12,  1.12it/s]
 34%|███▍      | 215/630 [03:20<06:10,  1.12it/s]
                                                 
{'loss': 0.5911, 'grad_norm': 1.7930210360186178, 'learning_rate': 1.3617021276595744e-06, 'epoch': 1.02}

 34%|███▍      | 215/630 [03:20<06:10,  1.12it/s]
 34%|███▍      | 216/630 [03:20<06:09,  1.12it/s]
                                                 
{'loss': 0.5196, 'grad_norm': 1.7722914383281207, 'learning_rate': 1.358428805237316e-06, 'epoch': 1.03}

 34%|███▍      | 216/630 [03:20<06:09,  1.12it/s]
 34%|███▍      | 217/630 [03:21<06:08,  1.12it/s]
                                                 
{'loss': 0.5311, 'grad_norm': 1.6788314251580085, 'learning_rate': 1.3551554828150573e-06, 'epoch': 1.03}

 34%|███▍      | 217/630 [03:21<06:08,  1.12it/s]
 35%|███▍      | 218/630 [03:22<06:06,  1.12it/s]
                                                 
{'loss': 0.5713, 'grad_norm': 1.7609183907912958, 'learning_rate': 1.3518821603927986e-06, 'epoch': 1.04}

 35%|███▍      | 218/630 [03:22<06:06,  1.12it/s]
 35%|███▍      | 219/630 [03:23<06:06,  1.12it/s]
                                                 
{'loss': 0.5789, 'grad_norm': 1.7930959627655438, 'learning_rate': 1.34860883797054e-06, 'epoch': 1.04}

 35%|███▍      | 219/630 [03:23<06:06,  1.12it/s]
 35%|███▍      | 220/630 [03:24<06:05,  1.12it/s]
                                                 
{'loss': 0.6699, 'grad_norm': 1.915094117383694, 'learning_rate': 1.3453355155482815e-06, 'epoch': 1.05}

 35%|███▍      | 220/630 [03:24<06:05,  1.12it/s]
 35%|███▌      | 221/630 [03:25<06:06,  1.12it/s]
                                                 
{'loss': 0.6812, 'grad_norm': 2.1480446034965945, 'learning_rate': 1.3420621931260228e-06, 'epoch': 1.05}

 35%|███▌      | 221/630 [03:25<06:06,  1.12it/s]
 35%|███▌      | 222/630 [03:26<06:04,  1.12it/s]
                                                 
{'loss': 0.5827, 'grad_norm': 1.848702470314449, 'learning_rate': 1.3387888707037642e-06, 'epoch': 1.06}

 35%|███▌      | 222/630 [03:26<06:04,  1.12it/s]
 35%|███▌      | 223/630 [03:27<06:03,  1.12it/s]
                                                 
{'loss': 0.5916, 'grad_norm': 1.7656937827394692, 'learning_rate': 1.3355155482815057e-06, 'epoch': 1.06}

 35%|███▌      | 223/630 [03:27<06:03,  1.12it/s]
 36%|███▌      | 224/630 [03:28<06:02,  1.12it/s]
                                                 
{'loss': 0.6057, 'grad_norm': 1.7140411210972013, 'learning_rate': 1.3322422258592473e-06, 'epoch': 1.07}

 36%|███▌      | 224/630 [03:28<06:02,  1.12it/s]
 36%|███▌      | 225/630 [03:29<06:02,  1.12it/s]
                                                 
{'loss': 0.6518, 'grad_norm': 2.126362614821786, 'learning_rate': 1.3289689034369884e-06, 'epoch': 1.07}

 36%|███▌      | 225/630 [03:29<06:02,  1.12it/s]
 36%|███▌      | 226/630 [03:29<06:00,  1.12it/s]
                                                 
{'loss': 0.5906, 'grad_norm': 2.111593493265908, 'learning_rate': 1.32569558101473e-06, 'epoch': 1.08}

 36%|███▌      | 226/630 [03:29<06:00,  1.12it/s]
 36%|███▌      | 227/630 [03:30<05:59,  1.12it/s]
                                                 
{'loss': 0.6139, 'grad_norm': 1.9605575275174998, 'learning_rate': 1.3224222585924713e-06, 'epoch': 1.08}

 36%|███▌      | 227/630 [03:30<05:59,  1.12it/s]
 36%|███▌      | 228/630 [03:31<05:59,  1.12it/s]
                                                 
{'loss': 0.6402, 'grad_norm': 2.1878516848695084, 'learning_rate': 1.3191489361702126e-06, 'epoch': 1.09}

 36%|███▌      | 228/630 [03:31<05:59,  1.12it/s]
 36%|███▋      | 229/630 [03:32<05:58,  1.12it/s]
                                                 
{'loss': 0.623, 'grad_norm': 2.7176568481321928, 'learning_rate': 1.3158756137479541e-06, 'epoch': 1.09}

 36%|███▋      | 229/630 [03:32<05:58,  1.12it/s]
 37%|███▋      | 230/630 [03:33<05:58,  1.12it/s]
                                                 
{'loss': 0.6082, 'grad_norm': 1.7035843690173231, 'learning_rate': 1.3126022913256955e-06, 'epoch': 1.1}

 37%|███▋      | 230/630 [03:33<05:58,  1.12it/s]
 37%|███▋      | 231/630 [03:34<05:57,  1.12it/s]
                                                 
{'loss': 0.551, 'grad_norm': 1.995858142327486, 'learning_rate': 1.309328968903437e-06, 'epoch': 1.1}

 37%|███▋      | 231/630 [03:34<05:57,  1.12it/s]
 37%|███▋      | 232/630 [03:35<05:58,  1.11it/s]
                                                 
{'loss': 0.6002, 'grad_norm': 2.016687235933532, 'learning_rate': 1.3060556464811784e-06, 'epoch': 1.1}

 37%|███▋      | 232/630 [03:35<05:58,  1.11it/s]
 37%|███▋      | 233/630 [03:36<05:58,  1.11it/s]
                                                 
{'loss': 0.5418, 'grad_norm': 1.9204183064819016, 'learning_rate': 1.3027823240589197e-06, 'epoch': 1.11}

 37%|███▋      | 233/630 [03:36<05:58,  1.11it/s]
 37%|███▋      | 234/630 [03:37<05:55,  1.11it/s]
                                                 
{'loss': 0.6102, 'grad_norm': 1.9326631383751927, 'learning_rate': 1.2995090016366612e-06, 'epoch': 1.11}

 37%|███▋      | 234/630 [03:37<05:55,  1.11it/s]
 37%|███▋      | 235/630 [03:37<05:52,  1.12it/s]
                                                 
{'loss': 0.6486, 'grad_norm': 2.204178699797796, 'learning_rate': 1.2962356792144024e-06, 'epoch': 1.12}

 37%|███▋      | 235/630 [03:37<05:52,  1.12it/s]
 37%|███▋      | 236/630 [03:38<05:51,  1.12it/s]
                                                 
{'loss': 0.6014, 'grad_norm': 1.894384828784424, 'learning_rate': 1.292962356792144e-06, 'epoch': 1.12}

 37%|███▋      | 236/630 [03:38<05:51,  1.12it/s]
 38%|███▊      | 237/630 [03:39<05:51,  1.12it/s]
                                                 
{'loss': 0.6154, 'grad_norm': 2.0304285383724197, 'learning_rate': 1.2896890343698855e-06, 'epoch': 1.13}

 38%|███▊      | 237/630 [03:39<05:51,  1.12it/s]
 38%|███▊      | 238/630 [03:40<05:51,  1.12it/s]
                                                 
{'loss': 0.6065, 'grad_norm': 1.9731688290181495, 'learning_rate': 1.2864157119476268e-06, 'epoch': 1.13}

 38%|███▊      | 238/630 [03:40<05:51,  1.12it/s]
 38%|███▊      | 239/630 [03:41<05:49,  1.12it/s]
                                                 
{'loss': 0.6451, 'grad_norm': 1.9628281634069364, 'learning_rate': 1.2831423895253681e-06, 'epoch': 1.14}

 38%|███▊      | 239/630 [03:41<05:49,  1.12it/s]
 38%|███▊      | 240/630 [03:42<05:48,  1.12it/s]
                                                 
{'loss': 0.6349, 'grad_norm': 2.195151283921704, 'learning_rate': 1.2798690671031097e-06, 'epoch': 1.14}

 38%|███▊      | 240/630 [03:42<05:48,  1.12it/s]
 38%|███▊      | 241/630 [03:43<05:46,  1.12it/s]
                                                 
{'loss': 0.5694, 'grad_norm': 1.6546791713805271, 'learning_rate': 1.276595744680851e-06, 'epoch': 1.15}

 38%|███▊      | 241/630 [03:43<05:46,  1.12it/s]
 38%|███▊      | 242/630 [03:44<05:45,  1.12it/s]
                                                 
{'loss': 0.5504, 'grad_norm': 2.0702569598540985, 'learning_rate': 1.2733224222585923e-06, 'epoch': 1.15}

 38%|███▊      | 242/630 [03:44<05:45,  1.12it/s]
 39%|███▊      | 243/630 [03:45<05:44,  1.12it/s]
                                                 
{'loss': 0.6447, 'grad_norm': 1.8733478990922443, 'learning_rate': 1.270049099836334e-06, 'epoch': 1.16}

 39%|███▊      | 243/630 [03:45<05:44,  1.12it/s]
 39%|███▊      | 244/630 [03:45<05:43,  1.12it/s]
                                                 
{'loss': 0.593, 'grad_norm': 1.8988719532250475, 'learning_rate': 1.2667757774140752e-06, 'epoch': 1.16}

 39%|███▊      | 244/630 [03:45<05:43,  1.12it/s]
 39%|███▉      | 245/630 [03:46<05:42,  1.13it/s]
                                                 
{'loss': 0.5623, 'grad_norm': 2.7858856604264357, 'learning_rate': 1.2635024549918168e-06, 'epoch': 1.17}

 39%|███▉      | 245/630 [03:46<05:42,  1.13it/s]
 39%|███▉      | 246/630 [03:47<05:40,  1.13it/s]
                                                 
{'loss': 0.6052, 'grad_norm': 1.9783491315206438, 'learning_rate': 1.260229132569558e-06, 'epoch': 1.17}

 39%|███▉      | 246/630 [03:47<05:40,  1.13it/s]
 39%|███▉      | 247/630 [03:48<05:40,  1.13it/s]
                                                 
{'loss': 0.6096, 'grad_norm': 1.755204550908534, 'learning_rate': 1.2569558101472994e-06, 'epoch': 1.18}

 39%|███▉      | 247/630 [03:48<05:40,  1.13it/s]
 39%|███▉      | 248/630 [03:49<05:39,  1.13it/s]
                                                 
{'loss': 0.5116, 'grad_norm': 1.6193358292248279, 'learning_rate': 1.253682487725041e-06, 'epoch': 1.18}

 39%|███▉      | 248/630 [03:49<05:39,  1.13it/s]
 40%|███▉      | 249/630 [03:50<05:38,  1.13it/s]
                                                 
{'loss': 0.5744, 'grad_norm': 1.920648374936373, 'learning_rate': 1.2504091653027821e-06, 'epoch': 1.19}

 40%|███▉      | 249/630 [03:50<05:38,  1.13it/s]
 40%|███▉      | 250/630 [03:51<05:38,  1.12it/s]
                                                 
{'loss': 0.5878, 'grad_norm': 1.7515910911328834, 'learning_rate': 1.2471358428805237e-06, 'epoch': 1.19}

 40%|███▉      | 250/630 [03:51<05:38,  1.12it/s]
 40%|███▉      | 251/630 [03:52<05:37,  1.12it/s]
                                                 
{'loss': 0.5849, 'grad_norm': 1.9463099831528048, 'learning_rate': 1.2438625204582652e-06, 'epoch': 1.2}

 40%|███▉      | 251/630 [03:52<05:37,  1.12it/s]
 40%|████      | 252/630 [03:53<05:36,  1.12it/s]
                                                 
{'loss': 0.6205, 'grad_norm': 1.8088820524647011, 'learning_rate': 1.2405891980360065e-06, 'epoch': 1.2}

 40%|████      | 252/630 [03:53<05:36,  1.12it/s]
 40%|████      | 253/630 [03:53<05:35,  1.12it/s]
                                                 
{'loss': 0.628, 'grad_norm': 2.008464437388016, 'learning_rate': 1.2373158756137479e-06, 'epoch': 1.2}

 40%|████      | 253/630 [03:53<05:35,  1.12it/s]
 40%|████      | 254/630 [03:54<05:35,  1.12it/s]
                                                 
{'loss': 0.57, 'grad_norm': 1.9957384167991978, 'learning_rate': 1.2340425531914892e-06, 'epoch': 1.21}

 40%|████      | 254/630 [03:54<05:35,  1.12it/s]
 40%|████      | 255/630 [03:55<05:33,  1.13it/s]
                                                 
{'loss': 0.5981, 'grad_norm': 1.9382627093121976, 'learning_rate': 1.2307692307692308e-06, 'epoch': 1.21}

 40%|████      | 255/630 [03:55<05:33,  1.13it/s]
 41%|████      | 256/630 [03:56<05:34,  1.12it/s]
                                                 
{'loss': 0.5489, 'grad_norm': 1.863316102201515, 'learning_rate': 1.227495908346972e-06, 'epoch': 1.22}

 41%|████      | 256/630 [03:56<05:34,  1.12it/s]
 41%|████      | 257/630 [03:57<05:32,  1.12it/s]
                                                 
{'loss': 0.6115, 'grad_norm': 2.2456984078848516, 'learning_rate': 1.2242225859247134e-06, 'epoch': 1.22}

 41%|████      | 257/630 [03:57<05:32,  1.12it/s]
 41%|████      | 258/630 [03:58<05:32,  1.12it/s]
                                                 
{'loss': 0.539, 'grad_norm': 1.6767544413727442, 'learning_rate': 1.220949263502455e-06, 'epoch': 1.23}

 41%|████      | 258/630 [03:58<05:32,  1.12it/s]
 41%|████      | 259/630 [03:59<05:30,  1.12it/s]
                                                 
{'loss': 0.6481, 'grad_norm': 1.887859865294816, 'learning_rate': 1.2176759410801965e-06, 'epoch': 1.23}

 41%|████      | 259/630 [03:59<05:30,  1.12it/s]
 41%|████▏     | 260/630 [04:00<05:29,  1.12it/s]
                                                 
{'loss': 0.5759, 'grad_norm': 1.9948244381296532, 'learning_rate': 1.2144026186579376e-06, 'epoch': 1.24}

 41%|████▏     | 260/630 [04:00<05:29,  1.12it/s]
 41%|████▏     | 261/630 [04:01<05:29,  1.12it/s]
                                                 
{'loss': 0.5882, 'grad_norm': 2.0503125891926826, 'learning_rate': 1.2111292962356792e-06, 'epoch': 1.24}

 41%|████▏     | 261/630 [04:01<05:29,  1.12it/s]
 42%|████▏     | 262/630 [04:02<05:28,  1.12it/s]
                                                 
{'loss': 0.6892, 'grad_norm': 2.014687945051555, 'learning_rate': 1.2078559738134207e-06, 'epoch': 1.25}

 42%|████▏     | 262/630 [04:02<05:28,  1.12it/s]
 42%|████▏     | 263/630 [04:02<05:27,  1.12it/s]
                                                 
{'loss': 0.5586, 'grad_norm': 2.216845684917683, 'learning_rate': 1.2045826513911619e-06, 'epoch': 1.25}

 42%|████▏     | 263/630 [04:02<05:27,  1.12it/s]
 42%|████▏     | 264/630 [04:03<05:25,  1.12it/s]
                                                 
{'loss': 0.56, 'grad_norm': 1.8548573505616153, 'learning_rate': 1.2013093289689034e-06, 'epoch': 1.26}

 42%|████▏     | 264/630 [04:03<05:25,  1.12it/s]
 42%|████▏     | 265/630 [04:04<05:24,  1.13it/s]
                                                 
{'loss': 0.5657, 'grad_norm': 1.8275557322042666, 'learning_rate': 1.1980360065466447e-06, 'epoch': 1.26}

 42%|████▏     | 265/630 [04:04<05:24,  1.13it/s]
 42%|████▏     | 266/630 [04:05<05:23,  1.13it/s]
                                                 
{'loss': 0.6132, 'grad_norm': 1.8081672196946768, 'learning_rate': 1.1947626841243863e-06, 'epoch': 1.27}

 42%|████▏     | 266/630 [04:05<05:23,  1.13it/s]
 42%|████▏     | 267/630 [04:06<05:23,  1.12it/s]
                                                 
{'loss': 0.5625, 'grad_norm': 1.8104287623797288, 'learning_rate': 1.1914893617021276e-06, 'epoch': 1.27}

 42%|████▏     | 267/630 [04:06<05:23,  1.12it/s]
 43%|████▎     | 268/630 [04:07<05:22,  1.12it/s]
                                                 
{'loss': 0.6174, 'grad_norm': 2.1483830461676923, 'learning_rate': 1.188216039279869e-06, 'epoch': 1.28}

 43%|████▎     | 268/630 [04:07<05:22,  1.12it/s]
 43%|████▎     | 269/630 [04:08<05:20,  1.13it/s]
                                                 
{'loss': 0.6028, 'grad_norm': 2.0638391071209368, 'learning_rate': 1.1849427168576105e-06, 'epoch': 1.28}

 43%|████▎     | 269/630 [04:08<05:20,  1.13it/s]
 43%|████▎     | 270/630 [04:09<05:19,  1.13it/s]
                                                 
{'loss': 0.5306, 'grad_norm': 2.1776876584224283, 'learning_rate': 1.1816693944353518e-06, 'epoch': 1.29}

 43%|████▎     | 270/630 [04:09<05:19,  1.13it/s]
 43%|████▎     | 271/630 [04:10<05:18,  1.13it/s]
                                                 
{'loss': 0.6062, 'grad_norm': 2.3193572068437485, 'learning_rate': 1.1783960720130932e-06, 'epoch': 1.29}

 43%|████▎     | 271/630 [04:10<05:18,  1.13it/s]
 43%|████▎     | 272/630 [04:10<05:17,  1.13it/s]
                                                 
{'loss': 0.6126, 'grad_norm': 2.489208566845361, 'learning_rate': 1.1751227495908347e-06, 'epoch': 1.3}

 43%|████▎     | 272/630 [04:10<05:17,  1.13it/s]
 43%|████▎     | 273/630 [04:11<05:17,  1.13it/s]
                                                 
{'loss': 0.5796, 'grad_norm': 2.1125788418181277, 'learning_rate': 1.171849427168576e-06, 'epoch': 1.3}

 43%|████▎     | 273/630 [04:11<05:17,  1.13it/s]
 43%|████▎     | 274/630 [04:12<05:15,  1.13it/s]
                                                 
{'loss': 0.5559, 'grad_norm': 2.1276593877415335, 'learning_rate': 1.1685761047463174e-06, 'epoch': 1.3}

 43%|████▎     | 274/630 [04:12<05:15,  1.13it/s]
 44%|████▎     | 275/630 [04:13<05:15,  1.13it/s]
                                                 
{'loss': 0.6063, 'grad_norm': 2.1457337642506977, 'learning_rate': 1.165302782324059e-06, 'epoch': 1.31}

 44%|████▎     | 275/630 [04:13<05:15,  1.13it/s]
 44%|████▍     | 276/630 [04:14<05:14,  1.13it/s]
                                                 
{'loss': 0.5323, 'grad_norm': 2.150811275835211, 'learning_rate': 1.1620294599018003e-06, 'epoch': 1.31}

 44%|████▍     | 276/630 [04:14<05:14,  1.13it/s]
 44%|████▍     | 277/630 [04:15<05:14,  1.12it/s]
                                                 
{'loss': 0.5529, 'grad_norm': 1.9172619132966413, 'learning_rate': 1.1587561374795416e-06, 'epoch': 1.32}

 44%|████▍     | 277/630 [04:15<05:14,  1.12it/s]
 44%|████▍     | 278/630 [04:16<05:12,  1.12it/s]
                                                 
{'loss': 0.5656, 'grad_norm': 2.1693083777496116, 'learning_rate': 1.1554828150572832e-06, 'epoch': 1.32}

 44%|████▍     | 278/630 [04:16<05:12,  1.12it/s]
 44%|████▍     | 279/630 [04:17<05:12,  1.12it/s]
                                                 
{'loss': 0.5796, 'grad_norm': 1.9112830376916383, 'learning_rate': 1.1522094926350245e-06, 'epoch': 1.33}

 44%|████▍     | 279/630 [04:17<05:12,  1.12it/s]
 44%|████▍     | 280/630 [04:18<05:10,  1.13it/s]
                                                 
{'loss': 0.5844, 'grad_norm': 1.9312341953159933, 'learning_rate': 1.148936170212766e-06, 'epoch': 1.33}

 44%|████▍     | 280/630 [04:18<05:10,  1.13it/s]
 45%|████▍     | 281/630 [04:18<05:10,  1.12it/s]
                                                 
{'loss': 0.5671, 'grad_norm': 1.8999123476092894, 'learning_rate': 1.1456628477905072e-06, 'epoch': 1.34}

 45%|████▍     | 281/630 [04:18<05:10,  1.12it/s]
 45%|████▍     | 282/630 [04:19<05:09,  1.13it/s]
                                                 
{'loss': 0.6258, 'grad_norm': 2.084360275710905, 'learning_rate': 1.1423895253682487e-06, 'epoch': 1.34}

 45%|████▍     | 282/630 [04:19<05:09,  1.13it/s]
 45%|████▍     | 283/630 [04:20<05:07,  1.13it/s]
                                                 
{'loss': 0.5852, 'grad_norm': 1.9881021023896357, 'learning_rate': 1.1391162029459903e-06, 'epoch': 1.35}

 45%|████▍     | 283/630 [04:20<05:07,  1.13it/s]
 45%|████▌     | 284/630 [04:21<05:07,  1.12it/s]
                                                 
{'loss': 0.5606, 'grad_norm': 1.762510595124635, 'learning_rate': 1.1358428805237314e-06, 'epoch': 1.35}

 45%|████▌     | 284/630 [04:21<05:07,  1.12it/s]
 45%|████▌     | 285/630 [04:22<05:07,  1.12it/s]
                                                 
{'loss': 0.5487, 'grad_norm': 2.089948518723417, 'learning_rate': 1.132569558101473e-06, 'epoch': 1.36}

 45%|████▌     | 285/630 [04:22<05:07,  1.12it/s]
 45%|████▌     | 286/630 [04:23<05:06,  1.12it/s]
                                                 
{'loss': 0.5716, 'grad_norm': 2.4363286068015633, 'learning_rate': 1.1292962356792145e-06, 'epoch': 1.36}

 45%|████▌     | 286/630 [04:23<05:06,  1.12it/s]
 46%|████▌     | 287/630 [04:24<05:05,  1.12it/s]
                                                 
{'loss': 0.6353, 'grad_norm': 1.9877192392308864, 'learning_rate': 1.1260229132569558e-06, 'epoch': 1.37}

 46%|████▌     | 287/630 [04:24<05:05,  1.12it/s]
 46%|████▌     | 288/630 [04:25<05:04,  1.12it/s]
                                                 
{'loss': 0.507, 'grad_norm': 1.8658167934269525, 'learning_rate': 1.1227495908346971e-06, 'epoch': 1.37}

 46%|████▌     | 288/630 [04:25<05:04,  1.12it/s]
 46%|████▌     | 289/630 [04:26<05:03,  1.12it/s]
                                                 
{'loss': 0.6007, 'grad_norm': 1.7523483806808244, 'learning_rate': 1.1194762684124387e-06, 'epoch': 1.38}

 46%|████▌     | 289/630 [04:26<05:03,  1.12it/s]
 46%|████▌     | 290/630 [04:26<05:02,  1.12it/s]
                                                 
{'loss': 0.5439, 'grad_norm': 1.8382627743921112, 'learning_rate': 1.11620294599018e-06, 'epoch': 1.38}

 46%|████▌     | 290/630 [04:26<05:02,  1.12it/s]
 46%|████▌     | 291/630 [04:27<05:01,  1.12it/s]
                                                 
{'loss': 0.5229, 'grad_norm': 2.3400032910336934, 'learning_rate': 1.1129296235679214e-06, 'epoch': 1.39}

 46%|████▌     | 291/630 [04:27<05:01,  1.12it/s]
 46%|████▋     | 292/630 [04:28<05:01,  1.12it/s]
                                                 
{'loss': 0.567, 'grad_norm': 2.0299942566147062, 'learning_rate': 1.1096563011456627e-06, 'epoch': 1.39}

 46%|████▋     | 292/630 [04:28<05:01,  1.12it/s]
 47%|████▋     | 293/630 [04:29<04:59,  1.12it/s]
                                                 
{'loss': 0.6128, 'grad_norm': 2.042866103434648, 'learning_rate': 1.1063829787234042e-06, 'epoch': 1.4}

 47%|████▋     | 293/630 [04:29<04:59,  1.12it/s]
 47%|████▋     | 294/630 [04:30<04:58,  1.13it/s]
                                                 
{'loss': 0.5614, 'grad_norm': 2.043938376382632, 'learning_rate': 1.1031096563011458e-06, 'epoch': 1.4}

 47%|████▋     | 294/630 [04:30<04:58,  1.13it/s]
 47%|████▋     | 295/630 [04:31<04:57,  1.12it/s]
                                                 
{'loss': 0.5364, 'grad_norm': 1.737221639749647, 'learning_rate': 1.099836333878887e-06, 'epoch': 1.4}

 47%|████▋     | 295/630 [04:31<04:57,  1.12it/s]
 47%|████▋     | 296/630 [04:32<04:57,  1.12it/s]
                                                 
{'loss': 0.5755, 'grad_norm': 1.996748945358467, 'learning_rate': 1.0965630114566285e-06, 'epoch': 1.41}

 47%|████▋     | 296/630 [04:32<04:57,  1.12it/s]
 47%|████▋     | 297/630 [04:33<04:56,  1.12it/s]
                                                 
{'loss': 0.5715, 'grad_norm': 1.8921717262706705, 'learning_rate': 1.09328968903437e-06, 'epoch': 1.41}

 47%|████▋     | 297/630 [04:33<04:56,  1.12it/s]
 47%|████▋     | 298/630 [04:34<04:56,  1.12it/s]
                                                 
{'loss': 0.5796, 'grad_norm': 1.9627983960240158, 'learning_rate': 1.0900163666121111e-06, 'epoch': 1.42}

 47%|████▋     | 298/630 [04:34<04:56,  1.12it/s]
 47%|████▋     | 299/630 [04:35<05:45,  1.04s/it]
                                                 
{'loss': 0.5393, 'grad_norm': 1.7873538892669674, 'learning_rate': 1.0867430441898527e-06, 'epoch': 1.42}

 47%|████▋     | 299/630 [04:35<05:45,  1.04s/it]
 48%|████▊     | 300/630 [04:36<05:28,  1.00it/s]
                                                 
{'loss': 0.5939, 'grad_norm': 1.8142971507661962, 'learning_rate': 1.083469721767594e-06, 'epoch': 1.43}

 48%|████▊     | 300/630 [04:36<05:28,  1.00it/s]
 48%|████▊     | 301/630 [04:37<05:16,  1.04it/s]
                                                 
{'loss': 0.5528, 'grad_norm': 1.877281907248489, 'learning_rate': 1.0801963993453356e-06, 'epoch': 1.43}

 48%|████▊     | 301/630 [04:37<05:16,  1.04it/s]
 48%|████▊     | 302/630 [04:38<05:09,  1.06it/s]
                                                 
{'loss': 0.57, 'grad_norm': 2.2140738972890013, 'learning_rate': 1.0769230769230769e-06, 'epoch': 1.44}

 48%|████▊     | 302/630 [04:38<05:09,  1.06it/s]
 48%|████▊     | 303/630 [04:38<05:03,  1.08it/s]
                                                 
{'loss': 0.6211, 'grad_norm': 2.2640100624834125, 'learning_rate': 1.0736497545008182e-06, 'epoch': 1.44}

 48%|████▊     | 303/630 [04:38<05:03,  1.08it/s]
 48%|████▊     | 304/630 [04:39<04:58,  1.09it/s]
                                                 
{'loss': 0.5936, 'grad_norm': 2.186748082310608, 'learning_rate': 1.0703764320785598e-06, 'epoch': 1.45}

 48%|████▊     | 304/630 [04:39<04:58,  1.09it/s]
 48%|████▊     | 305/630 [04:40<04:54,  1.10it/s]
                                                 
{'loss': 0.5711, 'grad_norm': 2.070822136703374, 'learning_rate': 1.0671031096563011e-06, 'epoch': 1.45}

 48%|████▊     | 305/630 [04:40<04:54,  1.10it/s]
 49%|████▊     | 306/630 [04:41<04:53,  1.11it/s]
                                                 
{'loss': 0.6048, 'grad_norm': 2.619496249495863, 'learning_rate': 1.0638297872340424e-06, 'epoch': 1.46}

 49%|████▊     | 306/630 [04:41<04:53,  1.11it/s]
 49%|████▊     | 307/630 [04:42<04:51,  1.11it/s]
                                                 
{'loss': 0.599, 'grad_norm': 2.5070403556372796, 'learning_rate': 1.060556464811784e-06, 'epoch': 1.46}

 49%|████▊     | 307/630 [04:42<04:51,  1.11it/s]
 49%|████▉     | 308/630 [04:43<04:50,  1.11it/s]
                                                 
{'loss': 0.54, 'grad_norm': 1.9173416044228269, 'learning_rate': 1.0572831423895253e-06, 'epoch': 1.47}

 49%|████▉     | 308/630 [04:43<04:50,  1.11it/s]
 49%|████▉     | 309/630 [04:44<04:47,  1.12it/s]
                                                 
{'loss': 0.5102, 'grad_norm': 1.9034705071421096, 'learning_rate': 1.0540098199672667e-06, 'epoch': 1.47}

 49%|████▉     | 309/630 [04:44<04:47,  1.12it/s]
 49%|████▉     | 310/630 [04:45<04:45,  1.12it/s]
                                                 
{'loss': 0.6159, 'grad_norm': 1.94849091601185, 'learning_rate': 1.0507364975450082e-06, 'epoch': 1.48}

 49%|████▉     | 310/630 [04:45<04:45,  1.12it/s]
 49%|████▉     | 311/630 [04:46<04:44,  1.12it/s]
                                                 
{'loss': 0.6159, 'grad_norm': 2.458540627141873, 'learning_rate': 1.0474631751227495e-06, 'epoch': 1.48}

 49%|████▉     | 311/630 [04:46<04:44,  1.12it/s]
 50%|████▉     | 312/630 [04:47<04:44,  1.12it/s]
                                                 
{'loss': 0.508, 'grad_norm': 1.8704532575462733, 'learning_rate': 1.0441898527004909e-06, 'epoch': 1.49}

 50%|████▉     | 312/630 [04:47<04:44,  1.12it/s]
 50%|████▉     | 313/630 [04:47<04:42,  1.12it/s]
                                                 
{'loss': 0.5771, 'grad_norm': 2.176285353084052, 'learning_rate': 1.0409165302782324e-06, 'epoch': 1.49}

 50%|████▉     | 313/630 [04:47<04:42,  1.12it/s]
 50%|████▉     | 314/630 [04:48<04:42,  1.12it/s]
                                                 
{'loss': 0.5647, 'grad_norm': 1.6623506048407757, 'learning_rate': 1.0376432078559738e-06, 'epoch': 1.5}

 50%|████▉     | 314/630 [04:48<04:42,  1.12it/s]
 50%|█████     | 315/630 [04:49<04:42,  1.12it/s]
                                                 
{'loss': 0.5682, 'grad_norm': 2.3150382540013643, 'learning_rate': 1.0343698854337153e-06, 'epoch': 1.5}

 50%|█████     | 315/630 [04:49<04:42,  1.12it/s]
 50%|█████     | 316/630 [04:50<04:40,  1.12it/s]
                                                 
{'loss': 0.5263, 'grad_norm': 1.6879219022693253, 'learning_rate': 1.0310965630114566e-06, 'epoch': 1.5}

 50%|█████     | 316/630 [04:50<04:40,  1.12it/s]
 50%|█████     | 317/630 [04:51<04:39,  1.12it/s]
                                                 
{'loss': 0.5388, 'grad_norm': 1.6927160609668555, 'learning_rate': 1.027823240589198e-06, 'epoch': 1.51}

 50%|█████     | 317/630 [04:51<04:39,  1.12it/s]
 50%|█████     | 318/630 [04:52<04:39,  1.12it/s]
                                                 
{'loss': 0.5486, 'grad_norm': 1.9248963747331707, 'learning_rate': 1.0245499181669395e-06, 'epoch': 1.51}

 50%|█████     | 318/630 [04:52<04:39,  1.12it/s]
 51%|█████     | 319/630 [04:53<04:38,  1.12it/s]
                                                 
{'loss': 0.6819, 'grad_norm': 2.066579855424803, 'learning_rate': 1.0212765957446806e-06, 'epoch': 1.52}

 51%|█████     | 319/630 [04:53<04:38,  1.12it/s]
 51%|█████     | 320/630 [04:54<04:37,  1.12it/s]
                                                 
{'loss': 0.6259, 'grad_norm': 2.247529499405022, 'learning_rate': 1.0180032733224222e-06, 'epoch': 1.52}

 51%|█████     | 320/630 [04:54<04:37,  1.12it/s]
 51%|█████     | 321/630 [04:55<04:36,  1.12it/s]
                                                 
{'loss': 0.616, 'grad_norm': 2.707552380215031, 'learning_rate': 1.0147299509001637e-06, 'epoch': 1.53}

 51%|█████     | 321/630 [04:55<04:36,  1.12it/s]
 51%|█████     | 322/630 [04:55<04:35,  1.12it/s]
                                                 
{'loss': 0.5743, 'grad_norm': 1.814094674439475, 'learning_rate': 1.011456628477905e-06, 'epoch': 1.53}

 51%|█████     | 322/630 [04:55<04:35,  1.12it/s]
 51%|█████▏    | 323/630 [04:56<04:34,  1.12it/s]
                                                 
{'loss': 0.5836, 'grad_norm': 2.409518419806406, 'learning_rate': 1.0081833060556464e-06, 'epoch': 1.54}

 51%|█████▏    | 323/630 [04:56<04:34,  1.12it/s]
 51%|█████▏    | 324/630 [04:57<04:33,  1.12it/s]
                                                 
{'loss': 0.5997, 'grad_norm': 2.2941938603072805, 'learning_rate': 1.004909983633388e-06, 'epoch': 1.54}

 51%|█████▏    | 324/630 [04:57<04:33,  1.12it/s]
 52%|█████▏    | 325/630 [04:58<04:32,  1.12it/s]
                                                 
{'loss': 0.5113, 'grad_norm': 2.886395321717831, 'learning_rate': 1.0016366612111293e-06, 'epoch': 1.55}

 52%|█████▏    | 325/630 [04:58<04:32,  1.12it/s]
 52%|█████▏    | 326/630 [04:59<04:32,  1.12it/s]
                                                 
{'loss': 0.5299, 'grad_norm': 1.7930670892307021, 'learning_rate': 9.983633387888706e-07, 'epoch': 1.55}

 52%|█████▏    | 326/630 [04:59<04:32,  1.12it/s]
 52%|█████▏    | 327/630 [05:00<04:30,  1.12it/s]
                                                 
{'loss': 0.5845, 'grad_norm': 2.1444601372738057, 'learning_rate': 9.95090016366612e-07, 'epoch': 1.56}

 52%|█████▏    | 327/630 [05:00<04:30,  1.12it/s]
 52%|█████▏    | 328/630 [05:01<04:29,  1.12it/s]
                                                 
{'loss': 0.5276, 'grad_norm': 1.6596206421486206, 'learning_rate': 9.918166939443535e-07, 'epoch': 1.56}

 52%|█████▏    | 328/630 [05:01<04:29,  1.12it/s]
 52%|█████▏    | 329/630 [05:02<04:28,  1.12it/s]
                                                 
{'loss': 0.5877, 'grad_norm': 2.033011255456519, 'learning_rate': 9.885433715220948e-07, 'epoch': 1.57}

 52%|█████▏    | 329/630 [05:02<04:28,  1.12it/s]
 52%|█████▏    | 330/630 [05:03<04:27,  1.12it/s]
                                                 
{'loss': 0.6885, 'grad_norm': 2.6256031987830504, 'learning_rate': 9.852700490998362e-07, 'epoch': 1.57}

 52%|█████▏    | 330/630 [05:03<04:27,  1.12it/s]
 53%|█████▎    | 331/630 [05:04<04:26,  1.12it/s]
                                                 
{'loss': 0.5511, 'grad_norm': 2.4725506382653046, 'learning_rate': 9.819967266775777e-07, 'epoch': 1.58}

 53%|█████▎    | 331/630 [05:04<04:26,  1.12it/s]
 53%|█████▎    | 332/630 [05:04<04:25,  1.12it/s]
                                                 
{'loss': 0.6015, 'grad_norm': 2.0177543005326, 'learning_rate': 9.78723404255319e-07, 'epoch': 1.58}

 53%|█████▎    | 332/630 [05:04<04:25,  1.12it/s]
 53%|█████▎    | 333/630 [05:05<04:24,  1.12it/s]
                                                 
{'loss': 0.5994, 'grad_norm': 1.8852678008992863, 'learning_rate': 9.754500818330606e-07, 'epoch': 1.59}

 53%|█████▎    | 333/630 [05:05<04:24,  1.12it/s]
 53%|█████▎    | 334/630 [05:06<04:23,  1.12it/s]
                                                 
{'loss': 0.5887, 'grad_norm': 1.7745296284709844, 'learning_rate': 9.72176759410802e-07, 'epoch': 1.59}

 53%|█████▎    | 334/630 [05:06<04:23,  1.12it/s]
 53%|█████▎    | 335/630 [05:07<04:23,  1.12it/s]
                                                 
{'loss': 0.5254, 'grad_norm': 1.7979017186853312, 'learning_rate': 9.689034369885433e-07, 'epoch': 1.6}

 53%|█████▎    | 335/630 [05:07<04:23,  1.12it/s]
 53%|█████▎    | 336/630 [05:08<04:23,  1.12it/s]
                                                 
{'loss': 0.5715, 'grad_norm': 1.768193636428086, 'learning_rate': 9.656301145662848e-07, 'epoch': 1.6}

 53%|█████▎    | 336/630 [05:08<04:23,  1.12it/s]
 53%|█████▎    | 337/630 [05:09<04:21,  1.12it/s]
                                                 
{'loss': 0.5775, 'grad_norm': 2.3526170942129894, 'learning_rate': 9.623567921440262e-07, 'epoch': 1.6}

 53%|█████▎    | 337/630 [05:09<04:21,  1.12it/s]
 54%|█████▎    | 338/630 [05:10<04:20,  1.12it/s]
                                                 
{'loss': 0.5759, 'grad_norm': 2.0924331221752284, 'learning_rate': 9.590834697217675e-07, 'epoch': 1.61}

 54%|█████▎    | 338/630 [05:10<04:20,  1.12it/s]
 54%|█████▍    | 339/630 [05:11<04:19,  1.12it/s]
                                                 
{'loss': 0.579, 'grad_norm': 1.7607356495882323, 'learning_rate': 9.55810147299509e-07, 'epoch': 1.61}

 54%|█████▍    | 339/630 [05:11<04:19,  1.12it/s]
 54%|█████▍    | 340/630 [05:12<04:18,  1.12it/s]
                                                 
{'loss': 0.5803, 'grad_norm': 1.804924211317526, 'learning_rate': 9.525368248772504e-07, 'epoch': 1.62}

 54%|█████▍    | 340/630 [05:12<04:18,  1.12it/s]
 54%|█████▍    | 341/630 [05:12<04:18,  1.12it/s]
                                                 
{'loss': 0.5865, 'grad_norm': 2.088758471395295, 'learning_rate': 9.492635024549918e-07, 'epoch': 1.62}

 54%|█████▍    | 341/630 [05:12<04:18,  1.12it/s]
 54%|█████▍    | 342/630 [05:13<04:17,  1.12it/s]
                                                 
{'loss': 0.5568, 'grad_norm': 2.0953226920182444, 'learning_rate': 9.459901800327333e-07, 'epoch': 1.63}

 54%|█████▍    | 342/630 [05:13<04:17,  1.12it/s]
 54%|█████▍    | 343/630 [05:14<04:15,  1.12it/s]
                                                 
{'loss': 0.5367, 'grad_norm': 1.9328887991321952, 'learning_rate': 9.427168576104746e-07, 'epoch': 1.63}

 54%|█████▍    | 343/630 [05:14<04:15,  1.12it/s]
 55%|█████▍    | 344/630 [05:15<04:14,  1.12it/s]
                                                 
{'loss': 0.5428, 'grad_norm': 2.2140087668568253, 'learning_rate': 9.394435351882159e-07, 'epoch': 1.64}

 55%|█████▍    | 344/630 [05:15<04:14,  1.12it/s]
 55%|█████▍    | 345/630 [05:16<04:14,  1.12it/s]
                                                 
{'loss': 0.575, 'grad_norm': 2.440620387536193, 'learning_rate': 9.361702127659575e-07, 'epoch': 1.64}

 55%|█████▍    | 345/630 [05:16<04:14,  1.12it/s]
 55%|█████▍    | 346/630 [05:17<04:13,  1.12it/s]
                                                 
{'loss': 0.5887, 'grad_norm': 2.486891770107107, 'learning_rate': 9.328968903436988e-07, 'epoch': 1.65}

 55%|█████▍    | 346/630 [05:17<04:13,  1.12it/s]
 55%|█████▌    | 347/630 [05:18<04:12,  1.12it/s]
                                                 
{'loss': 0.5739, 'grad_norm': 1.8635542157901113, 'learning_rate': 9.296235679214402e-07, 'epoch': 1.65}

 55%|█████▌    | 347/630 [05:18<04:12,  1.12it/s]
 55%|█████▌    | 348/630 [05:19<04:10,  1.12it/s]
                                                 
{'loss': 0.621, 'grad_norm': 2.595210854581676, 'learning_rate': 9.263502454991816e-07, 'epoch': 1.66}

 55%|█████▌    | 348/630 [05:19<04:10,  1.12it/s]
 55%|█████▌    | 349/630 [05:20<04:10,  1.12it/s]
                                                 
{'loss': 0.5744, 'grad_norm': 2.0208233274864216, 'learning_rate': 9.230769230769231e-07, 'epoch': 1.66}

 55%|█████▌    | 349/630 [05:20<04:10,  1.12it/s]
 56%|█████▌    | 350/630 [05:20<04:09,  1.12it/s]
                                                 
{'loss': 0.5587, 'grad_norm': 2.2988182081468165, 'learning_rate': 9.198036006546645e-07, 'epoch': 1.67}

 56%|█████▌    | 350/630 [05:20<04:09,  1.12it/s]
 56%|█████▌    | 351/630 [05:21<04:09,  1.12it/s]
                                                 
{'loss': 0.5647, 'grad_norm': 1.9899428291779497, 'learning_rate': 9.165302782324058e-07, 'epoch': 1.67}

 56%|█████▌    | 351/630 [05:21<04:09,  1.12it/s]
 56%|█████▌    | 352/630 [05:22<04:07,  1.12it/s]
                                                 
{'loss': 0.531, 'grad_norm': 1.7995278199712652, 'learning_rate': 9.132569558101472e-07, 'epoch': 1.68}

 56%|█████▌    | 352/630 [05:22<04:07,  1.12it/s]
 56%|█████▌    | 353/630 [05:23<04:07,  1.12it/s]
                                                 
{'loss': 0.5241, 'grad_norm': 1.6960653830992947, 'learning_rate': 9.099836333878887e-07, 'epoch': 1.68}

 56%|█████▌    | 353/630 [05:23<04:07,  1.12it/s]
 56%|█████▌    | 354/630 [05:24<04:05,  1.12it/s]
                                                 
{'loss': 0.5125, 'grad_norm': 2.033520535253185, 'learning_rate': 9.067103109656301e-07, 'epoch': 1.69}

 56%|█████▌    | 354/630 [05:24<04:05,  1.12it/s]
 56%|█████▋    | 355/630 [05:25<04:05,  1.12it/s]
                                                 
{'loss': 0.5624, 'grad_norm': 1.7350487662520722, 'learning_rate': 9.034369885433715e-07, 'epoch': 1.69}

 56%|█████▋    | 355/630 [05:25<04:05,  1.12it/s]
 57%|█████▋    | 356/630 [05:26<04:04,  1.12it/s]
                                                 
{'loss': 0.4914, 'grad_norm': 1.8190145215306714, 'learning_rate': 9.001636661211129e-07, 'epoch': 1.7}

 57%|█████▋    | 356/630 [05:26<04:04,  1.12it/s]
 57%|█████▋    | 357/630 [05:27<04:04,  1.12it/s]
                                                 
{'loss': 0.5888, 'grad_norm': 1.841487745683551, 'learning_rate': 8.968903436988543e-07, 'epoch': 1.7}

 57%|█████▋    | 357/630 [05:27<04:04,  1.12it/s]
 57%|█████▋    | 358/630 [05:28<04:02,  1.12it/s]
                                                 
{'loss': 0.6001, 'grad_norm': 2.019360796905645, 'learning_rate': 8.936170212765957e-07, 'epoch': 1.7}

 57%|█████▋    | 358/630 [05:28<04:02,  1.12it/s]
 57%|█████▋    | 359/630 [05:28<04:01,  1.12it/s]
                                                 
{'loss': 0.5975, 'grad_norm': 2.0017318634670396, 'learning_rate': 8.903436988543371e-07, 'epoch': 1.71}

 57%|█████▋    | 359/630 [05:28<04:01,  1.12it/s]
 57%|█████▋    | 360/630 [05:29<04:00,  1.12it/s]
                                                 
{'loss': 0.4523, 'grad_norm': 1.732970209402555, 'learning_rate': 8.870703764320784e-07, 'epoch': 1.71}

 57%|█████▋    | 360/630 [05:29<04:00,  1.12it/s]
 57%|█████▋    | 361/630 [05:30<03:59,  1.12it/s]
                                                 
{'loss': 0.5233, 'grad_norm': 1.9701896672180093, 'learning_rate': 8.8379705400982e-07, 'epoch': 1.72}

 57%|█████▋    | 361/630 [05:30<03:59,  1.12it/s]
 57%|█████▋    | 362/630 [05:31<03:58,  1.12it/s]
                                                 
{'loss': 0.5899, 'grad_norm': 2.0473805521691193, 'learning_rate': 8.805237315875613e-07, 'epoch': 1.72}

 57%|█████▋    | 362/630 [05:31<03:58,  1.12it/s]
 58%|█████▊    | 363/630 [05:32<03:58,  1.12it/s]
                                                 
{'loss': 0.5428, 'grad_norm': 2.104206009036044, 'learning_rate': 8.772504091653028e-07, 'epoch': 1.73}

 58%|█████▊    | 363/630 [05:32<03:58,  1.12it/s]
 58%|█████▊    | 364/630 [05:33<03:56,  1.12it/s]
                                                 
{'loss': 0.5951, 'grad_norm': 2.143421005161538, 'learning_rate': 8.739770867430442e-07, 'epoch': 1.73}

 58%|█████▊    | 364/630 [05:33<03:56,  1.12it/s]
 58%|█████▊    | 365/630 [05:34<03:55,  1.12it/s]
                                                 
{'loss': 0.5773, 'grad_norm': 1.9421295390550781, 'learning_rate': 8.707037643207855e-07, 'epoch': 1.74}

 58%|█████▊    | 365/630 [05:34<03:55,  1.12it/s]
 58%|█████▊    | 366/630 [05:35<03:55,  1.12it/s]
                                                 
{'loss': 0.5488, 'grad_norm': 2.0345550573284297, 'learning_rate': 8.67430441898527e-07, 'epoch': 1.74}

 58%|█████▊    | 366/630 [05:35<03:55,  1.12it/s]
 58%|█████▊    | 367/630 [05:36<03:54,  1.12it/s]
                                                 
{'loss': 0.4696, 'grad_norm': 1.779919457798816, 'learning_rate': 8.641571194762683e-07, 'epoch': 1.75}

 58%|█████▊    | 367/630 [05:36<03:54,  1.12it/s]
 58%|█████▊    | 368/630 [05:36<03:53,  1.12it/s]
                                                 
{'loss': 0.5387, 'grad_norm': 1.7720309536745475, 'learning_rate': 8.608837970540099e-07, 'epoch': 1.75}

 58%|█████▊    | 368/630 [05:36<03:53,  1.12it/s]
 59%|█████▊    | 369/630 [05:37<03:52,  1.12it/s]
                                                 
{'loss': 0.5357, 'grad_norm': 2.126925151680156, 'learning_rate': 8.576104746317512e-07, 'epoch': 1.76}

 59%|█████▊    | 369/630 [05:37<03:52,  1.12it/s]
 59%|█████▊    | 370/630 [05:38<03:51,  1.12it/s]
                                                 
{'loss': 0.4574, 'grad_norm': 1.8379993927926288, 'learning_rate': 8.543371522094926e-07, 'epoch': 1.76}

 59%|█████▊    | 370/630 [05:38<03:51,  1.12it/s]
 59%|█████▉    | 371/630 [05:39<03:50,  1.12it/s]
                                                 
{'loss': 0.5971, 'grad_norm': 1.9215871519283725, 'learning_rate': 8.51063829787234e-07, 'epoch': 1.77}

 59%|█████▉    | 371/630 [05:39<03:50,  1.12it/s]
 59%|█████▉    | 372/630 [05:40<03:50,  1.12it/s]
                                                 
{'loss': 0.5893, 'grad_norm': 1.972371253925541, 'learning_rate': 8.477905073649754e-07, 'epoch': 1.77}

 59%|█████▉    | 372/630 [05:40<03:50,  1.12it/s]
 59%|█████▉    | 373/630 [05:41<03:49,  1.12it/s]
                                                 
{'loss': 0.552, 'grad_norm': 1.861288152398123, 'learning_rate': 8.445171849427169e-07, 'epoch': 1.78}

 59%|█████▉    | 373/630 [05:41<03:49,  1.12it/s]
 59%|█████▉    | 374/630 [05:42<03:48,  1.12it/s]
                                                 
{'loss': 0.5672, 'grad_norm': 1.895469016560876, 'learning_rate': 8.412438625204582e-07, 'epoch': 1.78}

 59%|█████▉    | 374/630 [05:42<03:48,  1.12it/s]
 60%|█████▉    | 375/630 [05:43<03:47,  1.12it/s]
                                                 
{'loss': 0.5686, 'grad_norm': 2.2495001534033796, 'learning_rate': 8.379705400981996e-07, 'epoch': 1.79}

 60%|█████▉    | 375/630 [05:43<03:47,  1.12it/s]
 60%|█████▉    | 376/630 [05:44<03:45,  1.12it/s]
                                                 
{'loss': 0.5715, 'grad_norm': 2.0338897170844557, 'learning_rate': 8.346972176759411e-07, 'epoch': 1.79}

 60%|█████▉    | 376/630 [05:44<03:45,  1.12it/s]
 60%|█████▉    | 377/630 [05:45<03:45,  1.12it/s]
                                                 
{'loss': 0.5533, 'grad_norm': 1.7197002665108347, 'learning_rate': 8.314238952536824e-07, 'epoch': 1.8}

 60%|█████▉    | 377/630 [05:45<03:45,  1.12it/s]
 60%|██████    | 378/630 [05:45<03:44,  1.12it/s]
                                                 
{'loss': 0.4941, 'grad_norm': 1.8709791792507924, 'learning_rate': 8.281505728314238e-07, 'epoch': 1.8}

 60%|██████    | 378/630 [05:45<03:44,  1.12it/s]
 60%|██████    | 379/630 [05:46<03:43,  1.12it/s]
                                                 
{'loss': 0.5201, 'grad_norm': 1.9399895979301394, 'learning_rate': 8.248772504091652e-07, 'epoch': 1.8}

 60%|██████    | 379/630 [05:46<03:43,  1.12it/s]
 60%|██████    | 380/630 [05:47<03:42,  1.12it/s]
                                                 
{'loss': 0.5811, 'grad_norm': 1.9818920443786743, 'learning_rate': 8.216039279869067e-07, 'epoch': 1.81}

 60%|██████    | 380/630 [05:47<03:42,  1.12it/s]
 60%|██████    | 381/630 [05:48<03:41,  1.12it/s]
                                                 
{'loss': 0.6157, 'grad_norm': 2.2390297865188007, 'learning_rate': 8.183306055646481e-07, 'epoch': 1.81}

 60%|██████    | 381/630 [05:48<03:41,  1.12it/s]
 61%|██████    | 382/630 [05:49<03:40,  1.12it/s]
                                                 
{'loss': 0.533, 'grad_norm': 1.842523214922211, 'learning_rate': 8.150572831423895e-07, 'epoch': 1.82}

 61%|██████    | 382/630 [05:49<03:40,  1.12it/s]
 61%|██████    | 383/630 [05:50<03:40,  1.12it/s]
                                                 
{'loss': 0.5168, 'grad_norm': 1.9311734896062984, 'learning_rate': 8.117839607201308e-07, 'epoch': 1.82}

 61%|██████    | 383/630 [05:50<03:40,  1.12it/s]
 61%|██████    | 384/630 [05:51<03:38,  1.12it/s]
                                                 
{'loss': 0.5537, 'grad_norm': 2.645677010865221, 'learning_rate': 8.085106382978723e-07, 'epoch': 1.83}

 61%|██████    | 384/630 [05:51<03:38,  1.12it/s]
 61%|██████    | 385/630 [05:52<03:37,  1.13it/s]
                                                 
{'loss': 0.5685, 'grad_norm': 2.044776549991195, 'learning_rate': 8.052373158756137e-07, 'epoch': 1.83}

 61%|██████    | 385/630 [05:52<03:37,  1.13it/s]
 61%|██████▏   | 386/630 [05:53<03:36,  1.13it/s]
                                                 
{'loss': 0.6003, 'grad_norm': 1.8581166597339631, 'learning_rate': 8.019639934533551e-07, 'epoch': 1.84}

 61%|██████▏   | 386/630 [05:53<03:36,  1.13it/s]
 61%|██████▏   | 387/630 [05:53<03:35,  1.13it/s]
                                                 
{'loss': 0.5699, 'grad_norm': 2.6215623833320594, 'learning_rate': 7.986906710310966e-07, 'epoch': 1.84}

 61%|██████▏   | 387/630 [05:53<03:35,  1.13it/s]
 62%|██████▏   | 388/630 [05:54<03:34,  1.13it/s]
                                                 
{'loss': 0.6137, 'grad_norm': 2.1495149893952084, 'learning_rate': 7.954173486088379e-07, 'epoch': 1.85}

 62%|██████▏   | 388/630 [05:54<03:34,  1.13it/s]
 62%|██████▏   | 389/630 [05:55<03:34,  1.13it/s]
                                                 
{'loss': 0.5614, 'grad_norm': 1.8407106725119398, 'learning_rate': 7.921440261865794e-07, 'epoch': 1.85}

 62%|██████▏   | 389/630 [05:55<03:34,  1.13it/s]
 62%|██████▏   | 390/630 [05:56<03:33,  1.12it/s]
                                                 
{'loss': 0.5923, 'grad_norm': 1.9111400309669009, 'learning_rate': 7.888707037643207e-07, 'epoch': 1.86}

 62%|██████▏   | 390/630 [05:56<03:33,  1.12it/s]
 62%|██████▏   | 391/630 [05:57<03:32,  1.12it/s]
                                                 
{'loss': 0.626, 'grad_norm': 1.8715357571494515, 'learning_rate': 7.855973813420622e-07, 'epoch': 1.86}

 62%|██████▏   | 391/630 [05:57<03:32,  1.12it/s]
 62%|██████▏   | 392/630 [05:58<03:31,  1.12it/s]
                                                 
{'loss': 0.5132, 'grad_norm': 1.9340185742644145, 'learning_rate': 7.823240589198036e-07, 'epoch': 1.87}

 62%|██████▏   | 392/630 [05:58<03:31,  1.12it/s]
 62%|██████▏   | 393/630 [05:59<03:30,  1.12it/s]
                                                 
{'loss': 0.6304, 'grad_norm': 2.0389389534450317, 'learning_rate': 7.790507364975449e-07, 'epoch': 1.87}

 62%|██████▏   | 393/630 [05:59<03:30,  1.12it/s]
 63%|██████▎   | 394/630 [06:00<03:29,  1.13it/s]
                                                 
{'loss': 0.5778, 'grad_norm': 2.207054720217017, 'learning_rate': 7.757774140752864e-07, 'epoch': 1.88}

 63%|██████▎   | 394/630 [06:00<03:29,  1.13it/s]
 63%|██████▎   | 395/630 [06:01<03:28,  1.13it/s]
                                                 
{'loss': 0.568, 'grad_norm': 2.2985885843460183, 'learning_rate': 7.725040916530278e-07, 'epoch': 1.88}

 63%|██████▎   | 395/630 [06:01<03:28,  1.13it/s]
 63%|██████▎   | 396/630 [06:01<03:27,  1.13it/s]
                                                 
{'loss': 0.5427, 'grad_norm': 2.326757636286063, 'learning_rate': 7.692307692307693e-07, 'epoch': 1.89}

 63%|██████▎   | 396/630 [06:01<03:27,  1.13it/s]
 63%|██████▎   | 397/630 [06:02<03:27,  1.12it/s]
                                                 
{'loss': 0.5095, 'grad_norm': 1.7948141439970442, 'learning_rate': 7.659574468085106e-07, 'epoch': 1.89}

 63%|██████▎   | 397/630 [06:02<03:27,  1.12it/s]
 63%|██████▎   | 398/630 [06:03<03:26,  1.13it/s]
                                                 
{'loss': 0.5535, 'grad_norm': 1.8964345890810386, 'learning_rate': 7.626841243862519e-07, 'epoch': 1.9}

 63%|██████▎   | 398/630 [06:03<03:26,  1.13it/s]
 63%|██████▎   | 399/630 [06:04<03:25,  1.12it/s]
                                                 
{'loss': 0.6014, 'grad_norm': 2.5827711311991064, 'learning_rate': 7.594108019639935e-07, 'epoch': 1.9}

 63%|██████▎   | 399/630 [06:04<03:25,  1.12it/s]
 63%|██████▎   | 400/630 [06:05<03:25,  1.12it/s]
                                                 
{'loss': 0.4962, 'grad_norm': 1.9320773773001707, 'learning_rate': 7.561374795417348e-07, 'epoch': 1.9}

 63%|██████▎   | 400/630 [06:05<03:25,  1.12it/s]
 64%|██████▎   | 401/630 [06:06<03:24,  1.12it/s]
                                                 
{'loss': 0.5887, 'grad_norm': 1.956770217744443, 'learning_rate': 7.528641571194762e-07, 'epoch': 1.91}

 64%|██████▎   | 401/630 [06:06<03:24,  1.12it/s]
 64%|██████▍   | 402/630 [06:07<03:22,  1.12it/s]
                                                 
{'loss': 0.5336, 'grad_norm': 1.7690557449053248, 'learning_rate': 7.495908346972176e-07, 'epoch': 1.91}

 64%|██████▍   | 402/630 [06:07<03:22,  1.12it/s]
 64%|██████▍   | 403/630 [06:08<03:22,  1.12it/s]
                                                 
{'loss': 0.5427, 'grad_norm': 2.1133020353904826, 'learning_rate': 7.463175122749591e-07, 'epoch': 1.92}

 64%|██████▍   | 403/630 [06:08<03:22,  1.12it/s]
 64%|██████▍   | 404/630 [06:09<03:21,  1.12it/s]
                                                 
{'loss': 0.4964, 'grad_norm': 1.7958333440106518, 'learning_rate': 7.430441898527005e-07, 'epoch': 1.92}

 64%|██████▍   | 404/630 [06:09<03:21,  1.12it/s]
 64%|██████▍   | 405/630 [06:09<03:20,  1.12it/s]
                                                 
{'loss': 0.5518, 'grad_norm': 2.12499564881202, 'learning_rate': 7.397708674304418e-07, 'epoch': 1.93}

 64%|██████▍   | 405/630 [06:09<03:20,  1.12it/s]
 64%|██████▍   | 406/630 [06:10<03:19,  1.12it/s]
                                                 
{'loss': 0.5728, 'grad_norm': 1.9617580607791332, 'learning_rate': 7.364975450081832e-07, 'epoch': 1.93}

 64%|██████▍   | 406/630 [06:10<03:19,  1.12it/s]
 65%|██████▍   | 407/630 [06:11<03:18,  1.12it/s]
                                                 
{'loss': 0.56, 'grad_norm': 1.9570575155089, 'learning_rate': 7.332242225859247e-07, 'epoch': 1.94}

 65%|██████▍   | 407/630 [06:11<03:18,  1.12it/s]
 65%|██████▍   | 408/630 [06:12<03:17,  1.12it/s]
                                                 
{'loss': 0.5353, 'grad_norm': 1.7888465474753135, 'learning_rate': 7.299509001636661e-07, 'epoch': 1.94}

 65%|██████▍   | 408/630 [06:12<03:17,  1.12it/s]
 65%|██████▍   | 409/630 [06:13<03:16,  1.12it/s]
                                                 
{'loss': 0.515, 'grad_norm': 2.016549896084529, 'learning_rate': 7.266775777414075e-07, 'epoch': 1.95}

 65%|██████▍   | 409/630 [06:13<03:16,  1.12it/s]
 65%|██████▌   | 410/630 [06:14<03:16,  1.12it/s]
                                                 
{'loss': 0.5965, 'grad_norm': 2.2206124838487056, 'learning_rate': 7.23404255319149e-07, 'epoch': 1.95}

 65%|██████▌   | 410/630 [06:14<03:16,  1.12it/s]
 65%|██████▌   | 411/630 [06:15<03:15,  1.12it/s]
                                                 
{'loss': 0.5767, 'grad_norm': 2.699493776473105, 'learning_rate': 7.201309328968903e-07, 'epoch': 1.96}

 65%|██████▌   | 411/630 [06:15<03:15,  1.12it/s]
 65%|██████▌   | 412/630 [06:16<03:14,  1.12it/s]
                                                 
{'loss': 0.5187, 'grad_norm': 1.826792802491471, 'learning_rate': 7.168576104746317e-07, 'epoch': 1.96}

 65%|██████▌   | 412/630 [06:16<03:14,  1.12it/s]
 66%|██████▌   | 413/630 [06:17<03:13,  1.12it/s]
                                                 
{'loss': 0.5885, 'grad_norm': 1.933649384859431, 'learning_rate': 7.135842880523731e-07, 'epoch': 1.97}

 66%|██████▌   | 413/630 [06:17<03:13,  1.12it/s]
 66%|██████▌   | 414/630 [06:17<03:12,  1.12it/s]
                                                 
{'loss': 0.5363, 'grad_norm': 1.8652346294112958, 'learning_rate': 7.103109656301146e-07, 'epoch': 1.97}

 66%|██████▌   | 414/630 [06:17<03:12,  1.12it/s]
 66%|██████▌   | 415/630 [06:18<03:11,  1.12it/s]
                                                 
{'loss': 0.5216, 'grad_norm': 2.0395701105855366, 'learning_rate': 7.07037643207856e-07, 'epoch': 1.98}

 66%|██████▌   | 415/630 [06:18<03:11,  1.12it/s]
 66%|██████▌   | 416/630 [06:19<03:10,  1.12it/s]
                                                 
{'loss': 0.5305, 'grad_norm': 2.209124016284553, 'learning_rate': 7.037643207855973e-07, 'epoch': 1.98}

 66%|██████▌   | 416/630 [06:19<03:10,  1.12it/s]
 66%|██████▌   | 417/630 [06:20<03:09,  1.12it/s]
                                                 
{'loss': 0.569, 'grad_norm': 2.317971773352629, 'learning_rate': 7.004909983633388e-07, 'epoch': 1.99}

 66%|██████▌   | 417/630 [06:20<03:09,  1.12it/s]
 66%|██████▋   | 418/630 [06:21<03:08,  1.12it/s]
                                                 
{'loss': 0.5668, 'grad_norm': 1.9457623621599691, 'learning_rate': 6.972176759410802e-07, 'epoch': 1.99}

 66%|██████▋   | 418/630 [06:21<03:08,  1.12it/s]
 67%|██████▋   | 419/630 [06:22<03:07,  1.12it/s]
                                                 
{'loss': 0.5141, 'grad_norm': 2.414671982500026, 'learning_rate': 6.939443535188215e-07, 'epoch': 2.0}

 67%|██████▋   | 419/630 [06:22<03:07,  1.12it/s]
 67%|██████▋   | 420/630 [06:23<03:06,  1.13it/s]
                                                 
{'loss': 0.4677, 'grad_norm': 1.9614183412955981, 'learning_rate': 6.90671031096563e-07, 'epoch': 2.0}

 67%|██████▋   | 420/630 [06:23<03:06,  1.13it/s]
 67%|██████▋   | 421/630 [06:24<03:05,  1.12it/s]
                                                 
{'loss': 0.4951, 'grad_norm': 1.8246190279096568, 'learning_rate': 6.873977086743043e-07, 'epoch': 2.0}

 67%|██████▋   | 421/630 [06:24<03:05,  1.12it/s]
 67%|██████▋   | 422/630 [06:25<03:05,  1.12it/s]
                                                 
{'loss': 0.4837, 'grad_norm': 1.7990121155868, 'learning_rate': 6.841243862520459e-07, 'epoch': 2.01}

 67%|██████▋   | 422/630 [06:25<03:05,  1.12it/s]
 67%|██████▋   | 423/630 [06:26<03:07,  1.11it/s]
                                                 
{'loss': 0.4215, 'grad_norm': 1.8484342663131945, 'learning_rate': 6.808510638297872e-07, 'epoch': 2.01}

 67%|██████▋   | 423/630 [06:26<03:07,  1.11it/s]
 67%|██████▋   | 424/630 [06:26<03:05,  1.11it/s]
                                                 
{'loss': 0.5138, 'grad_norm': 2.242459132979291, 'learning_rate': 6.775777414075286e-07, 'epoch': 2.02}

 67%|██████▋   | 424/630 [06:26<03:05,  1.11it/s]
 67%|██████▋   | 425/630 [06:27<03:03,  1.11it/s]
                                                 
{'loss': 0.5339, 'grad_norm': 2.2992135982927984, 'learning_rate': 6.7430441898527e-07, 'epoch': 2.02}

 67%|██████▋   | 425/630 [06:27<03:03,  1.11it/s]
 68%|██████▊   | 426/630 [06:28<03:02,  1.11it/s]
                                                 
{'loss': 0.4639, 'grad_norm': 1.7078852551437922, 'learning_rate': 6.710310965630114e-07, 'epoch': 2.03}

 68%|██████▊   | 426/630 [06:28<03:02,  1.11it/s]
 68%|██████▊   | 427/630 [06:29<03:01,  1.12it/s]
                                                 
{'loss': 0.504, 'grad_norm': 2.193433119879409, 'learning_rate': 6.677577741407529e-07, 'epoch': 2.03}

 68%|██████▊   | 427/630 [06:29<03:01,  1.12it/s]
 68%|██████▊   | 428/630 [06:30<03:00,  1.12it/s]
                                                 
{'loss': 0.5199, 'grad_norm': 1.8502725824132553, 'learning_rate': 6.644844517184942e-07, 'epoch': 2.04}

 68%|██████▊   | 428/630 [06:30<03:00,  1.12it/s]
 68%|██████▊   | 429/630 [06:31<02:59,  1.12it/s]
                                                 
{'loss': 0.4969, 'grad_norm': 1.859966887266393, 'learning_rate': 6.612111292962356e-07, 'epoch': 2.04}

 68%|██████▊   | 429/630 [06:31<02:59,  1.12it/s]
 68%|██████▊   | 430/630 [06:32<02:58,  1.12it/s]
                                                 
{'loss': 0.48, 'grad_norm': 2.0239436200088456, 'learning_rate': 6.579378068739771e-07, 'epoch': 2.05}

 68%|██████▊   | 430/630 [06:32<02:58,  1.12it/s]
 68%|██████▊   | 431/630 [06:33<02:58,  1.12it/s]
                                                 
{'loss': 0.5602, 'grad_norm': 2.0733711247843014, 'learning_rate': 6.546644844517185e-07, 'epoch': 2.05}

 68%|██████▊   | 431/630 [06:33<02:58,  1.12it/s]
 69%|██████▊   | 432/630 [06:34<02:56,  1.12it/s]
                                                 
{'loss': 0.5037, 'grad_norm': 1.9646664344379448, 'learning_rate': 6.513911620294599e-07, 'epoch': 2.06}

 69%|██████▊   | 432/630 [06:34<02:56,  1.12it/s]
 69%|██████▊   | 433/630 [06:34<02:55,  1.12it/s]
                                                 
{'loss': 0.4305, 'grad_norm': 1.9729540712226363, 'learning_rate': 6.481178396072012e-07, 'epoch': 2.06}

 69%|██████▊   | 433/630 [06:34<02:55,  1.12it/s]
 69%|██████▉   | 434/630 [06:35<02:54,  1.12it/s]
                                                 
{'loss': 0.4717, 'grad_norm': 2.207810451719676, 'learning_rate': 6.448445171849427e-07, 'epoch': 2.07}

 69%|██████▉   | 434/630 [06:35<02:54,  1.12it/s]
 69%|██████▉   | 435/630 [06:36<02:55,  1.11it/s]
                                                 
{'loss': 0.5088, 'grad_norm': 2.3274260894817558, 'learning_rate': 6.415711947626841e-07, 'epoch': 2.07}

 69%|██████▉   | 435/630 [06:36<02:55,  1.11it/s]
 69%|██████▉   | 436/630 [06:37<02:54,  1.11it/s]
                                                 
{'loss': 0.4939, 'grad_norm': 2.060101040134219, 'learning_rate': 6.382978723404255e-07, 'epoch': 2.08}

 69%|██████▉   | 436/630 [06:37<02:54,  1.11it/s]
 69%|██████▉   | 437/630 [06:38<02:52,  1.12it/s]
                                                 
{'loss': 0.6368, 'grad_norm': 3.045859288211618, 'learning_rate': 6.35024549918167e-07, 'epoch': 2.08}

 69%|██████▉   | 437/630 [06:38<02:52,  1.12it/s]
 70%|██████▉   | 438/630 [06:39<02:51,  1.12it/s]
                                                 
{'loss': 0.4459, 'grad_norm': 1.7920839513685192, 'learning_rate': 6.317512274959084e-07, 'epoch': 2.09}

 70%|██████▉   | 438/630 [06:39<02:51,  1.12it/s]
 70%|██████▉   | 439/630 [06:40<02:50,  1.12it/s]
                                                 
{'loss': 0.4709, 'grad_norm': 2.6454795663609496, 'learning_rate': 6.284779050736497e-07, 'epoch': 2.09}

 70%|██████▉   | 439/630 [06:40<02:50,  1.12it/s]
 70%|██████▉   | 440/630 [06:41<02:49,  1.12it/s]
                                                 
{'loss': 0.5159, 'grad_norm': 1.851542363044496, 'learning_rate': 6.252045826513911e-07, 'epoch': 2.1}

 70%|██████▉   | 440/630 [06:41<02:49,  1.12it/s]
 70%|███████   | 441/630 [06:42<02:48,  1.12it/s]
                                                 
{'loss': 0.4993, 'grad_norm': 2.011410135015199, 'learning_rate': 6.219312602291326e-07, 'epoch': 2.1}

 70%|███████   | 441/630 [06:42<02:48,  1.12it/s]
 70%|███████   | 442/630 [06:42<02:47,  1.12it/s]
                                                 
{'loss': 0.5264, 'grad_norm': 2.154038860280472, 'learning_rate': 6.186579378068739e-07, 'epoch': 2.1}

 70%|███████   | 442/630 [06:42<02:47,  1.12it/s]
 70%|███████   | 443/630 [06:43<02:46,  1.12it/s]
                                                 
{'loss': 0.5621, 'grad_norm': 2.1784586296683837, 'learning_rate': 6.153846153846154e-07, 'epoch': 2.11}

 70%|███████   | 443/630 [06:43<02:46,  1.12it/s]
 70%|███████   | 444/630 [06:44<02:45,  1.12it/s]
                                                 
{'loss': 0.4896, 'grad_norm': 2.1088226337656533, 'learning_rate': 6.121112929623567e-07, 'epoch': 2.11}

 70%|███████   | 444/630 [06:44<02:45,  1.12it/s]
 71%|███████   | 445/630 [06:45<02:44,  1.12it/s]
                                                 
{'loss': 0.4674, 'grad_norm': 2.4268633458377478, 'learning_rate': 6.088379705400983e-07, 'epoch': 2.12}

 71%|███████   | 445/630 [06:45<02:44,  1.12it/s]
 71%|███████   | 446/630 [06:46<02:43,  1.12it/s]
                                                 
{'loss': 0.5841, 'grad_norm': 2.040489825542017, 'learning_rate': 6.055646481178396e-07, 'epoch': 2.12}

 71%|███████   | 446/630 [06:46<02:43,  1.12it/s]
 71%|███████   | 447/630 [06:47<02:42,  1.12it/s]
                                                 
{'loss': 0.586, 'grad_norm': 2.280875364130098, 'learning_rate': 6.022913256955809e-07, 'epoch': 2.13}

 71%|███████   | 447/630 [06:47<02:42,  1.12it/s]
 71%|███████   | 448/630 [06:48<02:41,  1.12it/s]
                                                 
{'loss': 0.4923, 'grad_norm': 2.086014253615157, 'learning_rate': 5.990180032733224e-07, 'epoch': 2.13}

 71%|███████   | 448/630 [06:48<02:41,  1.12it/s]
 71%|███████▏  | 449/630 [06:49<02:40,  1.13it/s]
                                                 
{'loss': 0.444, 'grad_norm': 1.9492407388541266, 'learning_rate': 5.957446808510638e-07, 'epoch': 2.14}

 71%|███████▏  | 449/630 [06:49<02:40,  1.13it/s]
 71%|███████▏  | 450/630 [06:50<02:40,  1.12it/s]
                                                 
{'loss': 0.5262, 'grad_norm': 1.995833371014228, 'learning_rate': 5.924713584288053e-07, 'epoch': 2.14}

 71%|███████▏  | 450/630 [06:50<02:40,  1.12it/s]
 72%|███████▏  | 451/630 [06:50<02:39,  1.12it/s]
                                                 
{'loss': 0.5093, 'grad_norm': 2.0279636650784068, 'learning_rate': 5.891980360065466e-07, 'epoch': 2.15}

 72%|███████▏  | 451/630 [06:50<02:39,  1.12it/s]
 72%|███████▏  | 452/630 [06:51<02:38,  1.12it/s]
                                                 
{'loss': 0.5111, 'grad_norm': 2.0395859666404816, 'learning_rate': 5.85924713584288e-07, 'epoch': 2.15}

 72%|███████▏  | 452/630 [06:51<02:38,  1.12it/s]
 72%|███████▏  | 453/630 [06:52<02:37,  1.12it/s]
                                                 
{'loss': 0.4665, 'grad_norm': 1.8750285262126023, 'learning_rate': 5.826513911620295e-07, 'epoch': 2.16}

 72%|███████▏  | 453/630 [06:52<02:37,  1.12it/s]
 72%|███████▏  | 454/630 [06:53<02:36,  1.12it/s]
                                                 
{'loss': 0.4974, 'grad_norm': 2.0830215664331533, 'learning_rate': 5.793780687397708e-07, 'epoch': 2.16}

 72%|███████▏  | 454/630 [06:53<02:36,  1.12it/s]
 72%|███████▏  | 455/630 [06:54<02:36,  1.12it/s]
                                                 
{'loss': 0.5224, 'grad_norm': 2.0531333650431933, 'learning_rate': 5.761047463175122e-07, 'epoch': 2.17}

 72%|███████▏  | 455/630 [06:54<02:36,  1.12it/s]
 72%|███████▏  | 456/630 [06:55<02:35,  1.12it/s]
                                                 
{'loss': 0.482, 'grad_norm': 1.8566536389015984, 'learning_rate': 5.728314238952536e-07, 'epoch': 2.17}

 72%|███████▏  | 456/630 [06:55<02:35,  1.12it/s]
 73%|███████▎  | 457/630 [06:56<02:34,  1.12it/s]
                                                 
{'loss': 0.4988, 'grad_norm': 2.2322623614883086, 'learning_rate': 5.695581014729951e-07, 'epoch': 2.18}

 73%|███████▎  | 457/630 [06:56<02:34,  1.12it/s]
 73%|███████▎  | 458/630 [06:57<02:33,  1.12it/s]
                                                 
{'loss': 0.4811, 'grad_norm': 1.8916224107867632, 'learning_rate': 5.662847790507365e-07, 'epoch': 2.18}

 73%|███████▎  | 458/630 [06:57<02:33,  1.12it/s]
 73%|███████▎  | 459/630 [06:58<02:32,  1.12it/s]
                                                 
{'loss': 0.4414, 'grad_norm': 2.1681974510962103, 'learning_rate': 5.630114566284779e-07, 'epoch': 2.19}

 73%|███████▎  | 459/630 [06:58<02:32,  1.12it/s]
 73%|███████▎  | 460/630 [06:58<02:31,  1.12it/s]
                                                 
{'loss': 0.5587, 'grad_norm': 2.2706842201668533, 'learning_rate': 5.597381342062193e-07, 'epoch': 2.19}

 73%|███████▎  | 460/630 [06:58<02:31,  1.12it/s]
 73%|███████▎  | 461/630 [06:59<02:30,  1.12it/s]
                                                 
{'loss': 0.4444, 'grad_norm': 1.6622346842145779, 'learning_rate': 5.564648117839607e-07, 'epoch': 2.2}

 73%|███████▎  | 461/630 [06:59<02:30,  1.12it/s]
 73%|███████▎  | 462/630 [07:00<02:29,  1.12it/s]
                                                 
{'loss': 0.6024, 'grad_norm': 2.173141610273005, 'learning_rate': 5.531914893617021e-07, 'epoch': 2.2}

 73%|███████▎  | 462/630 [07:00<02:29,  1.12it/s]
 73%|███████▎  | 463/630 [07:01<02:29,  1.12it/s]
                                                 
{'loss': 0.482, 'grad_norm': 1.9314315878437898, 'learning_rate': 5.499181669394435e-07, 'epoch': 2.2}

 73%|███████▎  | 463/630 [07:01<02:29,  1.12it/s]
 74%|███████▎  | 464/630 [07:02<02:27,  1.12it/s]
                                                 
{'loss': 0.4927, 'grad_norm': 1.8731740561139896, 'learning_rate': 5.46644844517185e-07, 'epoch': 2.21}

 74%|███████▎  | 464/630 [07:02<02:27,  1.12it/s]
 74%|███████▍  | 465/630 [07:03<02:26,  1.13it/s]
                                                 
{'loss': 0.4969, 'grad_norm': 2.10321595955559, 'learning_rate': 5.433715220949263e-07, 'epoch': 2.21}

 74%|███████▍  | 465/630 [07:03<02:26,  1.13it/s]
 74%|███████▍  | 466/630 [07:04<02:25,  1.12it/s]
                                                 
{'loss': 0.4863, 'grad_norm': 2.0071721923478227, 'learning_rate': 5.400981996726678e-07, 'epoch': 2.22}

 74%|███████▍  | 466/630 [07:04<02:25,  1.12it/s]
 74%|███████▍  | 467/630 [07:05<02:24,  1.13it/s]
                                                 
{'loss': 0.4976, 'grad_norm': 2.029961863734964, 'learning_rate': 5.368248772504091e-07, 'epoch': 2.22}

 74%|███████▍  | 467/630 [07:05<02:24,  1.13it/s]
 74%|███████▍  | 468/630 [07:06<02:24,  1.12it/s]
                                                 
{'loss': 0.4856, 'grad_norm': 1.767906056484177, 'learning_rate': 5.335515548281506e-07, 'epoch': 2.23}

 74%|███████▍  | 468/630 [07:06<02:24,  1.12it/s]
 74%|███████▍  | 469/630 [07:07<02:23,  1.12it/s]
                                                 
{'loss': 0.4425, 'grad_norm': 2.1164144045833178, 'learning_rate': 5.30278232405892e-07, 'epoch': 2.23}

 74%|███████▍  | 469/630 [07:07<02:23,  1.12it/s]
 75%|███████▍  | 470/630 [07:07<02:22,  1.12it/s]
                                                 
{'loss': 0.471, 'grad_norm': 1.7841910362733355, 'learning_rate': 5.270049099836333e-07, 'epoch': 2.24}

 75%|███████▍  | 470/630 [07:07<02:22,  1.12it/s]
 75%|███████▍  | 471/630 [07:08<02:21,  1.12it/s]
                                                 
{'loss': 0.5383, 'grad_norm': 1.9504498880687795, 'learning_rate': 5.237315875613748e-07, 'epoch': 2.24}

 75%|███████▍  | 471/630 [07:08<02:21,  1.12it/s]
 75%|███████▍  | 472/630 [07:09<02:20,  1.12it/s]
                                                 
{'loss': 0.4848, 'grad_norm': 2.0052836206942337, 'learning_rate': 5.204582651391162e-07, 'epoch': 2.25}

 75%|███████▍  | 472/630 [07:09<02:20,  1.12it/s]
 75%|███████▌  | 473/630 [07:10<02:20,  1.12it/s]
                                                 
{'loss': 0.4746, 'grad_norm': 2.005788720662376, 'learning_rate': 5.171849427168577e-07, 'epoch': 2.25}

 75%|███████▌  | 473/630 [07:10<02:20,  1.12it/s]
 75%|███████▌  | 474/630 [07:11<02:19,  1.12it/s]
                                                 
{'loss': 0.4953, 'grad_norm': 1.893941828435402, 'learning_rate': 5.13911620294599e-07, 'epoch': 2.26}

 75%|███████▌  | 474/630 [07:11<02:19,  1.12it/s]
 75%|███████▌  | 475/630 [07:12<02:18,  1.12it/s]
                                                 
{'loss': 0.5275, 'grad_norm': 2.0394929770971664, 'learning_rate': 5.106382978723403e-07, 'epoch': 2.26}

 75%|███████▌  | 475/630 [07:12<02:18,  1.12it/s]
 76%|███████▌  | 476/630 [07:13<02:17,  1.12it/s]
                                                 
{'loss': 0.4202, 'grad_norm': 1.6368311564237101, 'learning_rate': 5.073649754500819e-07, 'epoch': 2.27}

 76%|███████▌  | 476/630 [07:13<02:17,  1.12it/s]
 76%|███████▌  | 477/630 [07:14<02:16,  1.12it/s]
                                                 
{'loss': 0.4542, 'grad_norm': 1.8126305845093822, 'learning_rate': 5.040916530278232e-07, 'epoch': 2.27}

 76%|███████▌  | 477/630 [07:14<02:16,  1.12it/s]
 76%|███████▌  | 478/630 [07:15<02:15,  1.12it/s]
                                                 
{'loss': 0.4638, 'grad_norm': 2.0781613029391255, 'learning_rate': 5.008183306055646e-07, 'epoch': 2.28}

 76%|███████▌  | 478/630 [07:15<02:15,  1.12it/s]
 76%|███████▌  | 479/630 [07:15<02:14,  1.12it/s]
                                                 
{'loss': 0.478, 'grad_norm': 1.92127778812337, 'learning_rate': 4.97545008183306e-07, 'epoch': 2.28}

 76%|███████▌  | 479/630 [07:15<02:14,  1.12it/s]
 76%|███████▌  | 480/630 [07:16<02:13,  1.12it/s]
                                                 
{'loss': 0.5348, 'grad_norm': 1.9577966694540931, 'learning_rate': 4.942716857610474e-07, 'epoch': 2.29}

 76%|███████▌  | 480/630 [07:16<02:13,  1.12it/s]
 76%|███████▋  | 481/630 [07:17<02:12,  1.12it/s]
                                                 
{'loss': 0.5158, 'grad_norm': 1.8538674322340882, 'learning_rate': 4.909983633387889e-07, 'epoch': 2.29}

 76%|███████▋  | 481/630 [07:17<02:12,  1.12it/s]
 77%|███████▋  | 482/630 [07:18<02:11,  1.12it/s]
                                                 
{'loss': 0.4953, 'grad_norm': 2.274069040674143, 'learning_rate': 4.877250409165303e-07, 'epoch': 2.3}

 77%|███████▋  | 482/630 [07:18<02:11,  1.12it/s]
 77%|███████▋  | 483/630 [07:19<02:10,  1.12it/s]
                                                 
{'loss': 0.4776, 'grad_norm': 2.2947283976042576, 'learning_rate': 4.844517184942716e-07, 'epoch': 2.3}

 77%|███████▋  | 483/630 [07:19<02:10,  1.12it/s]
 77%|███████▋  | 484/630 [07:20<02:10,  1.12it/s]
                                                 
{'loss': 0.4588, 'grad_norm': 2.153962959358721, 'learning_rate': 4.811783960720131e-07, 'epoch': 2.3}

 77%|███████▋  | 484/630 [07:20<02:10,  1.12it/s]
 77%|███████▋  | 485/630 [07:21<02:09,  1.12it/s]
                                                 
{'loss': 0.4355, 'grad_norm': 2.18530222655548, 'learning_rate': 4.779050736497545e-07, 'epoch': 2.31}

 77%|███████▋  | 485/630 [07:21<02:09,  1.12it/s]
 77%|███████▋  | 486/630 [07:22<02:08,  1.12it/s]
                                                 
{'loss': 0.5061, 'grad_norm': 2.0086201515628717, 'learning_rate': 4.746317512274959e-07, 'epoch': 2.31}

 77%|███████▋  | 486/630 [07:22<02:08,  1.12it/s]
 77%|███████▋  | 487/630 [07:23<02:07,  1.12it/s]
                                                 
{'loss': 0.4546, 'grad_norm': 2.1880818746884017, 'learning_rate': 4.713584288052373e-07, 'epoch': 2.32}

 77%|███████▋  | 487/630 [07:23<02:07,  1.12it/s]
 77%|███████▋  | 488/630 [07:23<02:06,  1.12it/s]
                                                 
{'loss': 0.4585, 'grad_norm': 1.9497422650402376, 'learning_rate': 4.6808510638297873e-07, 'epoch': 2.32}

 77%|███████▋  | 488/630 [07:23<02:06,  1.12it/s]
 78%|███████▊  | 489/630 [07:24<02:05,  1.13it/s]
                                                 
{'loss': 0.4317, 'grad_norm': 2.4148516541688028, 'learning_rate': 4.648117839607201e-07, 'epoch': 2.33}

 78%|███████▊  | 489/630 [07:24<02:05,  1.13it/s]
 78%|███████▊  | 490/630 [07:25<02:04,  1.13it/s]
                                                 
{'loss': 0.5945, 'grad_norm': 1.9094854532574934, 'learning_rate': 4.6153846153846156e-07, 'epoch': 2.33}

 78%|███████▊  | 490/630 [07:25<02:04,  1.13it/s]
 78%|███████▊  | 491/630 [07:26<02:03,  1.12it/s]
                                                 
{'loss': 0.5023, 'grad_norm': 2.192427358039129, 'learning_rate': 4.582651391162029e-07, 'epoch': 2.34}

 78%|███████▊  | 491/630 [07:26<02:03,  1.12it/s]
 78%|███████▊  | 492/630 [07:27<02:02,  1.12it/s]
                                                 
{'loss': 0.5125, 'grad_norm': 2.208102613525358, 'learning_rate': 4.5499181669394434e-07, 'epoch': 2.34}

 78%|███████▊  | 492/630 [07:27<02:02,  1.12it/s]
 78%|███████▊  | 493/630 [07:28<02:02,  1.12it/s]
                                                 
{'loss': 0.4802, 'grad_norm': 1.9843820848488993, 'learning_rate': 4.517184942716857e-07, 'epoch': 2.35}

 78%|███████▊  | 493/630 [07:28<02:02,  1.12it/s]
 78%|███████▊  | 494/630 [07:29<02:00,  1.12it/s]
                                                 
{'loss': 0.5741, 'grad_norm': 2.273111336195656, 'learning_rate': 4.4844517184942717e-07, 'epoch': 2.35}

 78%|███████▊  | 494/630 [07:29<02:00,  1.12it/s]
 79%|███████▊  | 495/630 [07:30<01:59,  1.13it/s]
                                                 
{'loss': 0.4254, 'grad_norm': 2.2389029842287678, 'learning_rate': 4.4517184942716855e-07, 'epoch': 2.36}

 79%|███████▊  | 495/630 [07:30<01:59,  1.13it/s]
 79%|███████▊  | 496/630 [07:31<01:59,  1.13it/s]
                                                 
{'loss': 0.4706, 'grad_norm': 1.8879367404984122, 'learning_rate': 4.4189852700491e-07, 'epoch': 2.36}

 79%|███████▊  | 496/630 [07:31<01:59,  1.13it/s]
 79%|███████▉  | 497/630 [07:31<01:58,  1.13it/s]
                                                 
{'loss': 0.4968, 'grad_norm': 1.8270534558499105, 'learning_rate': 4.386252045826514e-07, 'epoch': 2.37}

 79%|███████▉  | 497/630 [07:31<01:58,  1.13it/s]
 79%|███████▉  | 498/630 [07:32<01:57,  1.12it/s]
                                                 
{'loss': 0.4854, 'grad_norm': 1.8127069020527515, 'learning_rate': 4.3535188216039277e-07, 'epoch': 2.37}

 79%|███████▉  | 498/630 [07:32<01:57,  1.12it/s]
 79%|███████▉  | 499/630 [07:33<01:56,  1.13it/s]
                                                 
{'loss': 0.4638, 'grad_norm': 2.1748818262433054, 'learning_rate': 4.3207855973813416e-07, 'epoch': 2.38}

 79%|███████▉  | 499/630 [07:33<01:56,  1.13it/s]
 79%|███████▉  | 500/630 [07:34<01:55,  1.13it/s]
                                                 
{'loss': 0.5276, 'grad_norm': 2.1754554982235668, 'learning_rate': 4.288052373158756e-07, 'epoch': 2.38}

 79%|███████▉  | 500/630 [07:34<01:55,  1.13it/s]/data/home/yunyun/miniconda3/envs/newtorch2/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

 80%|███████▉  | 501/630 [08:12<26:01, 12.10s/it]
                                                 
{'loss': 0.4941, 'grad_norm': 1.8051695153530503, 'learning_rate': 4.25531914893617e-07, 'epoch': 2.39}

 80%|███████▉  | 501/630 [08:12<26:01, 12.10s/it]
 80%|███████▉  | 502/630 [08:13<18:39,  8.74s/it]
                                                 
{'loss': 0.5167, 'grad_norm': 2.1995633202951685, 'learning_rate': 4.2225859247135843e-07, 'epoch': 2.39}

 80%|███████▉  | 502/630 [08:13<18:39,  8.74s/it]
 80%|███████▉  | 503/630 [08:15<13:44,  6.49s/it]
                                                 
{'loss': 0.4039, 'grad_norm': 2.114014894622626, 'learning_rate': 4.189852700490998e-07, 'epoch': 2.4}

 80%|███████▉  | 503/630 [08:15<13:44,  6.49s/it]
 80%|████████  | 504/630 [08:15<10:07,  4.82s/it]
                                                 
{'loss': 0.5053, 'grad_norm': 1.9721070201623552, 'learning_rate': 4.157119476268412e-07, 'epoch': 2.4}

 80%|████████  | 504/630 [08:15<10:07,  4.82s/it]
 80%|████████  | 505/630 [08:16<07:35,  3.64s/it]
                                                 
{'loss': 0.4874, 'grad_norm': 2.1308271642670555, 'learning_rate': 4.124386252045826e-07, 'epoch': 2.4}

 80%|████████  | 505/630 [08:16<07:35,  3.64s/it]
 80%|████████  | 506/630 [08:17<05:48,  2.81s/it]
                                                 
{'loss': 0.5083, 'grad_norm': 2.4995004924563746, 'learning_rate': 4.0916530278232403e-07, 'epoch': 2.41}

 80%|████████  | 506/630 [08:17<05:48,  2.81s/it]
 80%|████████  | 507/630 [08:18<04:35,  2.24s/it]
                                                 
{'loss': 0.4922, 'grad_norm': 2.0547645866535307, 'learning_rate': 4.058919803600654e-07, 'epoch': 2.41}

 80%|████████  | 507/630 [08:18<04:35,  2.24s/it]
 81%|████████  | 508/630 [08:19<03:44,  1.84s/it]
                                                 
{'loss': 0.5071, 'grad_norm': 2.0868195984771774, 'learning_rate': 4.0261865793780686e-07, 'epoch': 2.42}

 81%|████████  | 508/630 [08:19<03:44,  1.84s/it]
 81%|████████  | 509/630 [08:20<03:07,  1.55s/it]
                                                 
{'loss': 0.445, 'grad_norm': 1.8226707897071883, 'learning_rate': 3.993453355155483e-07, 'epoch': 2.42}

 81%|████████  | 509/630 [08:20<03:07,  1.55s/it]
 81%|████████  | 510/630 [08:21<02:43,  1.36s/it]
                                                 
{'loss': 0.4698, 'grad_norm': 2.0432609227680216, 'learning_rate': 3.960720130932897e-07, 'epoch': 2.43}

 81%|████████  | 510/630 [08:21<02:43,  1.36s/it]
 81%|████████  | 511/630 [08:22<02:25,  1.22s/it]
                                                 
{'loss': 0.5278, 'grad_norm': 2.2398780991942924, 'learning_rate': 3.927986906710311e-07, 'epoch': 2.43}

 81%|████████  | 511/630 [08:22<02:25,  1.22s/it]
 81%|████████▏ | 512/630 [08:23<02:12,  1.13s/it]
                                                 
{'loss': 0.4496, 'grad_norm': 1.9078893439160867, 'learning_rate': 3.8952536824877247e-07, 'epoch': 2.44}

 81%|████████▏ | 512/630 [08:23<02:12,  1.13s/it]
 81%|████████▏ | 513/630 [08:23<02:03,  1.06s/it]
                                                 
{'loss': 0.4733, 'grad_norm': 1.9526964397779238, 'learning_rate': 3.862520458265139e-07, 'epoch': 2.44}

 81%|████████▏ | 513/630 [08:23<02:03,  1.06s/it]
 82%|████████▏ | 514/630 [08:24<01:56,  1.01s/it]
                                                 
{'loss': 0.478, 'grad_norm': 1.9639003219376534, 'learning_rate': 3.829787234042553e-07, 'epoch': 2.45}

 82%|████████▏ | 514/630 [08:24<01:56,  1.01s/it]
 82%|████████▏ | 515/630 [08:25<01:51,  1.03it/s]
                                                 
{'loss': 0.443, 'grad_norm': 2.215932199108311, 'learning_rate': 3.7970540098199673e-07, 'epoch': 2.45}

 82%|████████▏ | 515/630 [08:25<01:51,  1.03it/s]
 82%|████████▏ | 516/630 [08:26<01:47,  1.06it/s]
                                                 
{'loss': 0.5973, 'grad_norm': 2.269059932697936, 'learning_rate': 3.764320785597381e-07, 'epoch': 2.46}

 82%|████████▏ | 516/630 [08:26<01:47,  1.06it/s]
 82%|████████▏ | 517/630 [08:27<01:45,  1.07it/s]
                                                 
{'loss': 0.5717, 'grad_norm': 2.1672840633212354, 'learning_rate': 3.7315875613747956e-07, 'epoch': 2.46}

 82%|████████▏ | 517/630 [08:27<01:45,  1.07it/s]
 82%|████████▏ | 518/630 [08:28<01:42,  1.09it/s]
                                                 
{'loss': 0.4924, 'grad_norm': 1.932277459673732, 'learning_rate': 3.698854337152209e-07, 'epoch': 2.47}

 82%|████████▏ | 518/630 [08:28<01:42,  1.09it/s]
 82%|████████▏ | 519/630 [08:29<01:41,  1.10it/s]
                                                 
{'loss': 0.4205, 'grad_norm': 2.4651994048858863, 'learning_rate': 3.6661211129296234e-07, 'epoch': 2.47}

 82%|████████▏ | 519/630 [08:29<01:41,  1.10it/s]
 83%|████████▎ | 520/630 [08:30<01:39,  1.11it/s]
                                                 
{'loss': 0.4471, 'grad_norm': 1.9634474276692142, 'learning_rate': 3.6333878887070373e-07, 'epoch': 2.48}

 83%|████████▎ | 520/630 [08:30<01:39,  1.11it/s]
 83%|████████▎ | 521/630 [08:31<01:38,  1.11it/s]
                                                 
{'loss': 0.4801, 'grad_norm': 2.107753694497919, 'learning_rate': 3.6006546644844517e-07, 'epoch': 2.48}

 83%|████████▎ | 521/630 [08:31<01:38,  1.11it/s]
 83%|████████▎ | 522/630 [08:32<01:36,  1.12it/s]
                                                 
{'loss': 0.4502, 'grad_norm': 2.043104867456243, 'learning_rate': 3.5679214402618656e-07, 'epoch': 2.49}

 83%|████████▎ | 522/630 [08:32<01:36,  1.12it/s]
 83%|████████▎ | 523/630 [08:32<01:35,  1.12it/s]
                                                 
{'loss': 0.4808, 'grad_norm': 2.0731358899678125, 'learning_rate': 3.53518821603928e-07, 'epoch': 2.49}

 83%|████████▎ | 523/630 [08:32<01:35,  1.12it/s]
 83%|████████▎ | 524/630 [08:33<01:34,  1.12it/s]
                                                 
{'loss': 0.4972, 'grad_norm': 2.484351517444974, 'learning_rate': 3.502454991816694e-07, 'epoch': 2.5}

 83%|████████▎ | 524/630 [08:33<01:34,  1.12it/s]
 83%|████████▎ | 525/630 [08:34<01:33,  1.12it/s]
                                                 
{'loss': 0.4839, 'grad_norm': 1.8787765136109555, 'learning_rate': 3.4697217675941077e-07, 'epoch': 2.5}

 83%|████████▎ | 525/630 [08:34<01:33,  1.12it/s]
 83%|████████▎ | 526/630 [08:35<01:32,  1.12it/s]
                                                 
{'loss': 0.5143, 'grad_norm': 2.446815500085006, 'learning_rate': 3.4369885433715216e-07, 'epoch': 2.5}

 83%|████████▎ | 526/630 [08:35<01:32,  1.12it/s]
 84%|████████▎ | 527/630 [08:36<01:31,  1.12it/s]
                                                 
{'loss': 0.5167, 'grad_norm': 2.206965353036122, 'learning_rate': 3.404255319148936e-07, 'epoch': 2.51}

 84%|████████▎ | 527/630 [08:36<01:31,  1.12it/s]
 84%|████████▍ | 528/630 [08:37<01:30,  1.12it/s]
                                                 
{'loss': 0.4883, 'grad_norm': 1.8460009682797505, 'learning_rate': 3.37152209492635e-07, 'epoch': 2.51}

 84%|████████▍ | 528/630 [08:37<01:30,  1.12it/s]
 84%|████████▍ | 529/630 [08:38<01:29,  1.12it/s]
                                                 
{'loss': 0.4976, 'grad_norm': 2.365472953617731, 'learning_rate': 3.3387888707037643e-07, 'epoch': 2.52}

 84%|████████▍ | 529/630 [08:38<01:29,  1.12it/s]
 84%|████████▍ | 530/630 [08:39<01:28,  1.12it/s]
                                                 
{'loss': 0.4656, 'grad_norm': 1.9845604594152546, 'learning_rate': 3.306055646481178e-07, 'epoch': 2.52}

 84%|████████▍ | 530/630 [08:39<01:28,  1.12it/s]
 84%|████████▍ | 531/630 [08:40<01:28,  1.12it/s]
                                                 
{'loss': 0.5205, 'grad_norm': 1.9773632628718838, 'learning_rate': 3.2733224222585926e-07, 'epoch': 2.53}

 84%|████████▍ | 531/630 [08:40<01:28,  1.12it/s]
 84%|████████▍ | 532/630 [08:40<01:27,  1.12it/s]
                                                 
{'loss': 0.3987, 'grad_norm': 1.9225419279914404, 'learning_rate': 3.240589198036006e-07, 'epoch': 2.53}

 84%|████████▍ | 532/630 [08:40<01:27,  1.12it/s]
 85%|████████▍ | 533/630 [08:42<01:32,  1.04it/s]
                                                 
{'loss': 0.5122, 'grad_norm': 2.197081318004567, 'learning_rate': 3.2078559738134203e-07, 'epoch': 2.54}

 85%|████████▍ | 533/630 [08:42<01:32,  1.04it/s]
 85%|████████▍ | 534/630 [08:42<01:29,  1.07it/s]
                                                 
{'loss': 0.4935, 'grad_norm': 2.07726190501876, 'learning_rate': 3.175122749590835e-07, 'epoch': 2.54}

 85%|████████▍ | 534/630 [08:42<01:29,  1.07it/s]
 85%|████████▍ | 535/630 [08:43<01:27,  1.09it/s]
                                                 
{'loss': 0.4272, 'grad_norm': 2.137345235108516, 'learning_rate': 3.1423895253682486e-07, 'epoch': 2.55}

 85%|████████▍ | 535/630 [08:43<01:27,  1.09it/s]
 85%|████████▌ | 536/630 [08:44<01:25,  1.10it/s]
                                                 
{'loss': 0.5512, 'grad_norm': 2.712757478527541, 'learning_rate': 3.109656301145663e-07, 'epoch': 2.55}

 85%|████████▌ | 536/630 [08:44<01:25,  1.10it/s]
 85%|████████▌ | 537/630 [08:45<01:23,  1.11it/s]
                                                 
{'loss': 0.4434, 'grad_norm': 2.04095112813728, 'learning_rate': 3.076923076923077e-07, 'epoch': 2.56}

 85%|████████▌ | 537/630 [08:45<01:23,  1.11it/s]
 85%|████████▌ | 538/630 [08:46<01:22,  1.11it/s]
                                                 
{'loss': 0.4574, 'grad_norm': 2.083116831088261, 'learning_rate': 3.0441898527004913e-07, 'epoch': 2.56}

 85%|████████▌ | 538/630 [08:46<01:22,  1.11it/s]
 86%|████████▌ | 539/630 [08:47<01:21,  1.12it/s]
                                                 
{'loss': 0.4566, 'grad_norm': 1.7855093814396903, 'learning_rate': 3.0114566284779047e-07, 'epoch': 2.57}

 86%|████████▌ | 539/630 [08:47<01:21,  1.12it/s]
 86%|████████▌ | 540/630 [08:48<01:20,  1.12it/s]
                                                 
{'loss': 0.4946, 'grad_norm': 2.357210959976447, 'learning_rate': 2.978723404255319e-07, 'epoch': 2.57}

 86%|████████▌ | 540/630 [08:48<01:20,  1.12it/s]
 86%|████████▌ | 541/630 [08:49<01:19,  1.12it/s]
                                                 
{'loss': 0.4804, 'grad_norm': 1.950627987965747, 'learning_rate': 2.945990180032733e-07, 'epoch': 2.58}

 86%|████████▌ | 541/630 [08:49<01:19,  1.12it/s]
 86%|████████▌ | 542/630 [08:50<01:18,  1.12it/s]
                                                 
{'loss': 0.5122, 'grad_norm': 1.9037297395525417, 'learning_rate': 2.9132569558101474e-07, 'epoch': 2.58}

 86%|████████▌ | 542/630 [08:50<01:18,  1.12it/s]
 86%|████████▌ | 543/630 [08:50<01:17,  1.12it/s]
                                                 
{'loss': 0.5385, 'grad_norm': 2.0862622453554365, 'learning_rate': 2.880523731587561e-07, 'epoch': 2.59}

 86%|████████▌ | 543/630 [08:50<01:17,  1.12it/s]
 86%|████████▋ | 544/630 [08:51<01:16,  1.12it/s]
                                                 
{'loss': 0.4917, 'grad_norm': 2.1823722051850605, 'learning_rate': 2.8477905073649756e-07, 'epoch': 2.59}

 86%|████████▋ | 544/630 [08:51<01:16,  1.12it/s]
 87%|████████▋ | 545/630 [08:52<01:15,  1.12it/s]
                                                 
{'loss': 0.3927, 'grad_norm': 2.1395680772114307, 'learning_rate': 2.8150572831423895e-07, 'epoch': 2.6}

 87%|████████▋ | 545/630 [08:52<01:15,  1.12it/s]
 87%|████████▋ | 546/630 [08:53<01:14,  1.12it/s]
                                                 
{'loss': 0.4694, 'grad_norm': 1.7775384357428767, 'learning_rate': 2.7823240589198034e-07, 'epoch': 2.6}

 87%|████████▋ | 546/630 [08:53<01:14,  1.12it/s]
 87%|████████▋ | 547/630 [08:54<01:14,  1.12it/s]
                                                 
{'loss': 0.5169, 'grad_norm': 1.8745971296329258, 'learning_rate': 2.7495908346972173e-07, 'epoch': 2.6}

 87%|████████▋ | 547/630 [08:54<01:14,  1.12it/s]
 87%|████████▋ | 548/630 [08:55<01:13,  1.11it/s]
                                                 
{'loss': 0.5304, 'grad_norm': 2.1410715355538374, 'learning_rate': 2.7168576104746317e-07, 'epoch': 2.61}

 87%|████████▋ | 548/630 [08:55<01:13,  1.11it/s]
 87%|████████▋ | 549/630 [08:56<01:12,  1.12it/s]
                                                 
{'loss': 0.4906, 'grad_norm': 2.237974654353562, 'learning_rate': 2.6841243862520456e-07, 'epoch': 2.61}

 87%|████████▋ | 549/630 [08:56<01:12,  1.12it/s]
 87%|████████▋ | 550/630 [08:57<01:11,  1.12it/s]
                                                 
{'loss': 0.4436, 'grad_norm': 2.0337362906262406, 'learning_rate': 2.65139116202946e-07, 'epoch': 2.62}

 87%|████████▋ | 550/630 [08:57<01:11,  1.12it/s]
 87%|████████▋ | 551/630 [08:58<01:10,  1.12it/s]
                                                 
{'loss': 0.5579, 'grad_norm': 2.0760247515916195, 'learning_rate': 2.618657937806874e-07, 'epoch': 2.62}

 87%|████████▋ | 551/630 [08:58<01:10,  1.12it/s]
 88%|████████▊ | 552/630 [08:58<01:09,  1.12it/s]
                                                 
{'loss': 0.4336, 'grad_norm': 2.5334369953262503, 'learning_rate': 2.585924713584288e-07, 'epoch': 2.63}

 88%|████████▊ | 552/630 [08:58<01:09,  1.12it/s]
 88%|████████▊ | 553/630 [08:59<01:08,  1.12it/s]
                                                 
{'loss': 0.4943, 'grad_norm': 2.067495876818203, 'learning_rate': 2.5531914893617016e-07, 'epoch': 2.63}

 88%|████████▊ | 553/630 [08:59<01:08,  1.12it/s]
 88%|████████▊ | 554/630 [09:00<01:07,  1.12it/s]
                                                 
{'loss': 0.5293, 'grad_norm': 2.1111880822286597, 'learning_rate': 2.520458265139116e-07, 'epoch': 2.64}

 88%|████████▊ | 554/630 [09:00<01:07,  1.12it/s]
 88%|████████▊ | 555/630 [09:01<01:06,  1.12it/s]
                                                 
{'loss': 0.5921, 'grad_norm': 2.7533439161063478, 'learning_rate': 2.48772504091653e-07, 'epoch': 2.64}

 88%|████████▊ | 555/630 [09:01<01:06,  1.12it/s]
 88%|████████▊ | 556/630 [09:02<01:06,  1.12it/s]
                                                 
{'loss': 0.5045, 'grad_norm': 1.964740142790793, 'learning_rate': 2.4549918166939443e-07, 'epoch': 2.65}

 88%|████████▊ | 556/630 [09:02<01:06,  1.12it/s]
 88%|████████▊ | 557/630 [09:03<01:04,  1.12it/s]
                                                 
{'loss': 0.4861, 'grad_norm': 1.9410311494837589, 'learning_rate': 2.422258592471358e-07, 'epoch': 2.65}

 88%|████████▊ | 557/630 [09:03<01:04,  1.12it/s]
 89%|████████▊ | 558/630 [09:04<01:04,  1.12it/s]
                                                 
{'loss': 0.5232, 'grad_norm': 2.2591947456185126, 'learning_rate': 2.3895253682487726e-07, 'epoch': 2.66}

 89%|████████▊ | 558/630 [09:04<01:04,  1.12it/s]
 89%|████████▊ | 559/630 [09:05<01:03,  1.12it/s]
                                                 
{'loss': 0.5042, 'grad_norm': 1.8858336732232963, 'learning_rate': 2.3567921440261865e-07, 'epoch': 2.66}

 89%|████████▊ | 559/630 [09:05<01:03,  1.12it/s]
 89%|████████▉ | 560/630 [09:06<01:02,  1.12it/s]
                                                 
{'loss': 0.484, 'grad_norm': 2.3448902694678964, 'learning_rate': 2.3240589198036006e-07, 'epoch': 2.67}

 89%|████████▉ | 560/630 [09:06<01:02,  1.12it/s]
 89%|████████▉ | 561/630 [09:06<01:01,  1.12it/s]
                                                 
{'loss': 0.4577, 'grad_norm': 2.1409678224867967, 'learning_rate': 2.2913256955810145e-07, 'epoch': 2.67}

 89%|████████▉ | 561/630 [09:06<01:01,  1.12it/s]
 89%|████████▉ | 562/630 [09:07<01:00,  1.12it/s]
                                                 
{'loss': 0.4565, 'grad_norm': 1.812087146807794, 'learning_rate': 2.2585924713584286e-07, 'epoch': 2.68}

 89%|████████▉ | 562/630 [09:07<01:00,  1.12it/s]
 89%|████████▉ | 563/630 [09:08<01:00,  1.12it/s]
                                                 
{'loss': 0.435, 'grad_norm': 1.9433989369669582, 'learning_rate': 2.2258592471358428e-07, 'epoch': 2.68}

 89%|████████▉ | 563/630 [09:08<01:00,  1.12it/s]
 90%|████████▉ | 564/630 [09:09<00:59,  1.12it/s]
                                                 
{'loss': 0.4576, 'grad_norm': 1.8218147680623564, 'learning_rate': 2.193126022913257e-07, 'epoch': 2.69}

 90%|████████▉ | 564/630 [09:09<00:59,  1.12it/s]
 90%|████████▉ | 565/630 [09:10<00:57,  1.12it/s]
                                                 
{'loss': 0.4889, 'grad_norm': 2.1126691928703902, 'learning_rate': 2.1603927986906708e-07, 'epoch': 2.69}

 90%|████████▉ | 565/630 [09:10<00:57,  1.12it/s]
 90%|████████▉ | 566/630 [09:11<00:57,  1.12it/s]
                                                 
{'loss': 0.4654, 'grad_norm': 2.02723581250442, 'learning_rate': 2.127659574468085e-07, 'epoch': 2.7}

 90%|████████▉ | 566/630 [09:11<00:57,  1.12it/s]
 90%|█████████ | 567/630 [09:12<00:56,  1.12it/s]
                                                 
{'loss': 0.5431, 'grad_norm': 1.923641455460863, 'learning_rate': 2.094926350245499e-07, 'epoch': 2.7}

 90%|█████████ | 567/630 [09:12<00:56,  1.12it/s]
 90%|█████████ | 568/630 [09:13<00:56,  1.11it/s]
                                                 
{'loss': 0.4871, 'grad_norm': 1.9147544016381035, 'learning_rate': 2.062193126022913e-07, 'epoch': 2.7}

 90%|█████████ | 568/630 [09:13<00:56,  1.11it/s]
 90%|█████████ | 569/630 [09:14<00:54,  1.11it/s]
                                                 
{'loss': 0.4989, 'grad_norm': 2.0201070368152307, 'learning_rate': 2.029459901800327e-07, 'epoch': 2.71}

 90%|█████████ | 569/630 [09:14<00:54,  1.11it/s]
 90%|█████████ | 570/630 [09:15<00:53,  1.11it/s]
                                                 
{'loss': 0.5143, 'grad_norm': 2.4961563831247435, 'learning_rate': 1.9967266775777415e-07, 'epoch': 2.71}

 90%|█████████ | 570/630 [09:15<00:53,  1.11it/s]
 91%|█████████ | 571/630 [09:15<00:52,  1.12it/s]
                                                 
{'loss': 0.4892, 'grad_norm': 2.228395771046857, 'learning_rate': 1.9639934533551554e-07, 'epoch': 2.72}

 91%|█████████ | 571/630 [09:15<00:52,  1.12it/s]
 91%|█████████ | 572/630 [09:16<00:51,  1.12it/s]
                                                 
{'loss': 0.4449, 'grad_norm': 1.7744494503131878, 'learning_rate': 1.9312602291325695e-07, 'epoch': 2.72}

 91%|█████████ | 572/630 [09:16<00:51,  1.12it/s]
 91%|█████████ | 573/630 [09:17<00:50,  1.12it/s]
                                                 
{'loss': 0.5068, 'grad_norm': 2.3708055678698905, 'learning_rate': 1.8985270049099837e-07, 'epoch': 2.73}

 91%|█████████ | 573/630 [09:17<00:50,  1.12it/s]
 91%|█████████ | 574/630 [09:18<00:50,  1.12it/s]
                                                 
{'loss': 0.5015, 'grad_norm': 2.004131839319493, 'learning_rate': 1.8657937806873978e-07, 'epoch': 2.73}

 91%|█████████ | 574/630 [09:18<00:50,  1.12it/s]
 91%|█████████▏| 575/630 [09:19<00:49,  1.12it/s]
                                                 
{'loss': 0.4203, 'grad_norm': 2.301703189081271, 'learning_rate': 1.8330605564648117e-07, 'epoch': 2.74}

 91%|█████████▏| 575/630 [09:19<00:49,  1.12it/s]
 91%|█████████▏| 576/630 [09:20<00:48,  1.12it/s]
                                                 
{'loss': 0.4687, 'grad_norm': 2.1574011630585503, 'learning_rate': 1.8003273322422258e-07, 'epoch': 2.74}

 91%|█████████▏| 576/630 [09:20<00:48,  1.12it/s]
 92%|█████████▏| 577/630 [09:21<00:47,  1.12it/s]
                                                 
{'loss': 0.493, 'grad_norm': 2.23332263312463, 'learning_rate': 1.76759410801964e-07, 'epoch': 2.75}

 92%|█████████▏| 577/630 [09:21<00:47,  1.12it/s]
 92%|█████████▏| 578/630 [09:22<00:46,  1.12it/s]
                                                 
{'loss': 0.4797, 'grad_norm': 1.9509867323264765, 'learning_rate': 1.7348608837970539e-07, 'epoch': 2.75}

 92%|█████████▏| 578/630 [09:22<00:46,  1.12it/s]
 92%|█████████▏| 579/630 [09:23<00:45,  1.12it/s]
                                                 
{'loss': 0.5339, 'grad_norm': 2.173587961273444, 'learning_rate': 1.702127659574468e-07, 'epoch': 2.76}

 92%|█████████▏| 579/630 [09:23<00:45,  1.12it/s]
 92%|█████████▏| 580/630 [09:23<00:44,  1.12it/s]
                                                 
{'loss': 0.5102, 'grad_norm': 1.9939859352869769, 'learning_rate': 1.6693944353518821e-07, 'epoch': 2.76}

 92%|█████████▏| 580/630 [09:23<00:44,  1.12it/s]
 92%|█████████▏| 581/630 [09:24<00:43,  1.12it/s]
                                                 
{'loss': 0.4464, 'grad_norm': 1.9161497064643502, 'learning_rate': 1.6366612111292963e-07, 'epoch': 2.77}

 92%|█████████▏| 581/630 [09:24<00:43,  1.12it/s]
 92%|█████████▏| 582/630 [09:25<00:42,  1.12it/s]
                                                 
{'loss': 0.5059, 'grad_norm': 2.0558011221806645, 'learning_rate': 1.6039279869067102e-07, 'epoch': 2.77}

 92%|█████████▏| 582/630 [09:25<00:42,  1.12it/s]
 93%|█████████▎| 583/630 [09:26<00:41,  1.12it/s]
                                                 
{'loss': 0.4929, 'grad_norm': 2.4237554118464995, 'learning_rate': 1.5711947626841243e-07, 'epoch': 2.78}

 93%|█████████▎| 583/630 [09:26<00:41,  1.12it/s]
 93%|█████████▎| 584/630 [09:27<00:41,  1.12it/s]
                                                 
{'loss': 0.4261, 'grad_norm': 1.8009439834649532, 'learning_rate': 1.5384615384615385e-07, 'epoch': 2.78}

 93%|█████████▎| 584/630 [09:27<00:41,  1.12it/s]
 93%|█████████▎| 585/630 [09:28<00:40,  1.12it/s]
                                                 
{'loss': 0.5121, 'grad_norm': 2.1066305808461374, 'learning_rate': 1.5057283142389523e-07, 'epoch': 2.79}

 93%|█████████▎| 585/630 [09:28<00:40,  1.12it/s]
 93%|█████████▎| 586/630 [09:29<00:39,  1.12it/s]
                                                 
{'loss': 0.4795, 'grad_norm': 1.879187608335696, 'learning_rate': 1.4729950900163665e-07, 'epoch': 2.79}

 93%|█████████▎| 586/630 [09:29<00:39,  1.12it/s]
 93%|█████████▎| 587/630 [09:30<00:38,  1.12it/s]
                                                 
{'loss': 0.4384, 'grad_norm': 1.8402220280386907, 'learning_rate': 1.4402618657937806e-07, 'epoch': 2.8}

 93%|█████████▎| 587/630 [09:30<00:38,  1.12it/s]
 93%|█████████▎| 588/630 [09:31<00:37,  1.12it/s]
                                                 
{'loss': 0.4287, 'grad_norm': 2.911452856543155, 'learning_rate': 1.4075286415711948e-07, 'epoch': 2.8}

 93%|█████████▎| 588/630 [09:31<00:37,  1.12it/s]
 93%|█████████▎| 589/630 [09:32<00:36,  1.12it/s]
                                                 
{'loss': 0.4652, 'grad_norm': 2.0206121165536004, 'learning_rate': 1.3747954173486086e-07, 'epoch': 2.8}

 93%|█████████▎| 589/630 [09:32<00:36,  1.12it/s]
 94%|█████████▎| 590/630 [09:32<00:35,  1.12it/s]
                                                 
{'loss': 0.5073, 'grad_norm': 1.8177524733335986, 'learning_rate': 1.3420621931260228e-07, 'epoch': 2.81}

 94%|█████████▎| 590/630 [09:32<00:35,  1.12it/s]
 94%|█████████▍| 591/630 [09:33<00:34,  1.12it/s]
                                                 
{'loss': 0.4388, 'grad_norm': 2.063879911475364, 'learning_rate': 1.309328968903437e-07, 'epoch': 2.81}

 94%|█████████▍| 591/630 [09:33<00:34,  1.12it/s]
 94%|█████████▍| 592/630 [09:34<00:34,  1.12it/s]
                                                 
{'loss': 0.5549, 'grad_norm': 2.1836354183415754, 'learning_rate': 1.2765957446808508e-07, 'epoch': 2.82}

 94%|█████████▍| 592/630 [09:34<00:34,  1.12it/s]
 94%|█████████▍| 593/630 [09:35<00:36,  1.00it/s]
                                                 
{'loss': 0.4684, 'grad_norm': 1.8041692323292255, 'learning_rate': 1.243862520458265e-07, 'epoch': 2.82}

 94%|█████████▍| 593/630 [09:35<00:36,  1.00it/s]
 94%|█████████▍| 594/630 [09:36<00:34,  1.04it/s]
                                                 
{'loss': 0.4255, 'grad_norm': 1.975726312660817, 'learning_rate': 1.211129296235679e-07, 'epoch': 2.83}

 94%|█████████▍| 594/630 [09:36<00:34,  1.04it/s]
 94%|█████████▍| 595/630 [09:37<00:32,  1.06it/s]
                                                 
{'loss': 0.4864, 'grad_norm': 2.08603460179691, 'learning_rate': 1.1783960720130932e-07, 'epoch': 2.83}

 94%|█████████▍| 595/630 [09:37<00:32,  1.06it/s]
 95%|█████████▍| 596/630 [09:38<00:31,  1.08it/s]
                                                 
{'loss': 0.4825, 'grad_norm': 2.0535369485128903, 'learning_rate': 1.1456628477905072e-07, 'epoch': 2.84}

 95%|█████████▍| 596/630 [09:38<00:31,  1.08it/s]
 95%|█████████▍| 597/630 [09:39<00:30,  1.09it/s]
                                                 
{'loss': 0.4714, 'grad_norm': 1.9544318615987344, 'learning_rate': 1.1129296235679214e-07, 'epoch': 2.84}

 95%|█████████▍| 597/630 [09:39<00:30,  1.09it/s]
 95%|█████████▍| 598/630 [09:40<00:29,  1.10it/s]
                                                 
{'loss': 0.5086, 'grad_norm': 1.868310874128858, 'learning_rate': 1.0801963993453354e-07, 'epoch': 2.85}

 95%|█████████▍| 598/630 [09:40<00:29,  1.10it/s]
 95%|█████████▌| 599/630 [09:41<00:27,  1.11it/s]
                                                 
{'loss': 0.507, 'grad_norm': 2.0433652750346734, 'learning_rate': 1.0474631751227495e-07, 'epoch': 2.85}

 95%|█████████▌| 599/630 [09:41<00:27,  1.11it/s]
 95%|█████████▌| 600/630 [09:42<00:26,  1.11it/s]
                                                 
{'loss': 0.4725, 'grad_norm': 1.8569938890848046, 'learning_rate': 1.0147299509001636e-07, 'epoch': 2.86}

 95%|█████████▌| 600/630 [09:42<00:26,  1.11it/s]
 95%|█████████▌| 601/630 [09:43<00:26,  1.11it/s]
                                                 
{'loss': 0.4543, 'grad_norm': 1.8665734461062289, 'learning_rate': 9.819967266775777e-08, 'epoch': 2.86}

 95%|█████████▌| 601/630 [09:43<00:26,  1.11it/s]
 96%|█████████▌| 602/630 [09:43<00:25,  1.11it/s]
                                                 
{'loss': 0.5188, 'grad_norm': 1.9936250907860957, 'learning_rate': 9.492635024549918e-08, 'epoch': 2.87}

 96%|█████████▌| 602/630 [09:43<00:25,  1.11it/s]
 96%|█████████▌| 603/630 [09:44<00:24,  1.11it/s]
                                                 
{'loss': 0.4484, 'grad_norm': 1.8942093127197555, 'learning_rate': 9.165302782324058e-08, 'epoch': 2.87}

 96%|█████████▌| 603/630 [09:44<00:24,  1.11it/s]
 96%|█████████▌| 604/630 [09:45<00:23,  1.12it/s]
                                                 
{'loss': 0.4567, 'grad_norm': 2.070989970914439, 'learning_rate': 8.8379705400982e-08, 'epoch': 2.88}

 96%|█████████▌| 604/630 [09:45<00:23,  1.12it/s]
 96%|█████████▌| 605/630 [09:46<00:22,  1.12it/s]
                                                 
{'loss': 0.4845, 'grad_norm': 1.9171568691528051, 'learning_rate': 8.51063829787234e-08, 'epoch': 2.88}

 96%|█████████▌| 605/630 [09:46<00:22,  1.12it/s]
 96%|█████████▌| 606/630 [09:47<00:21,  1.12it/s]
                                                 
{'loss': 0.5586, 'grad_norm': 2.1520300244368302, 'learning_rate': 8.183306055646481e-08, 'epoch': 2.89}

 96%|█████████▌| 606/630 [09:47<00:21,  1.12it/s]
 96%|█████████▋| 607/630 [09:48<00:20,  1.12it/s]
                                                 
{'loss': 0.4439, 'grad_norm': 1.6954799435465708, 'learning_rate': 7.855973813420622e-08, 'epoch': 2.89}

 96%|█████████▋| 607/630 [09:48<00:20,  1.12it/s]
 97%|█████████▋| 608/630 [09:49<00:19,  1.12it/s]
                                                 
{'loss': 0.4542, 'grad_norm': 1.9379516479861822, 'learning_rate': 7.528641571194762e-08, 'epoch': 2.9}

 97%|█████████▋| 608/630 [09:49<00:19,  1.12it/s]
 97%|█████████▋| 609/630 [09:51<00:18,  1.12it/s]
                                                 
{'loss': 0.477, 'grad_norm': 2.0570854081596543, 'learning_rate': 7.201309328968903e-08, 'epoch': 2.9}

 97%|█████████▋| 609/630 [09:51<00:18,  1.12it/s]
 97%|█████████▋| 610/630 [09:52<00:23,  1.19s/it]
                                                 
{'loss': 0.5051, 'grad_norm': 2.1036399562515915, 'learning_rate': 6.873977086743043e-08, 'epoch': 2.9}

 97%|█████████▋| 610/630 [09:52<00:23,  1.19s/it]
 97%|█████████▋| 611/630 [09:52<00:20,  1.10s/it]
                                                 
{'loss': 0.4936, 'grad_norm': 2.3475109861909265, 'learning_rate': 6.546644844517185e-08, 'epoch': 2.91}

 97%|█████████▋| 611/630 [09:52<00:20,  1.10s/it]
 97%|█████████▋| 612/630 [09:53<00:18,  1.04s/it]
                                                 
{'loss': 0.5118, 'grad_norm': 1.79972124722641, 'learning_rate': 6.219312602291325e-08, 'epoch': 2.91}

 97%|█████████▋| 612/630 [09:53<00:18,  1.04s/it]
 97%|█████████▋| 613/630 [09:54<00:16,  1.00it/s]
                                                 
{'loss': 0.5158, 'grad_norm': 2.1065086062949168, 'learning_rate': 5.891980360065466e-08, 'epoch': 2.92}

 97%|█████████▋| 613/630 [09:54<00:16,  1.00it/s]
 97%|█████████▋| 614/630 [09:55<00:15,  1.03it/s]
                                                 
{'loss': 0.4633, 'grad_norm': 2.0866994157338166, 'learning_rate': 5.564648117839607e-08, 'epoch': 2.92}

 97%|█████████▋| 614/630 [09:55<00:15,  1.03it/s]
 98%|█████████▊| 615/630 [09:56<00:14,  1.06it/s]
                                                 
{'loss': 0.4143, 'grad_norm': 1.9935460810936065, 'learning_rate': 5.237315875613748e-08, 'epoch': 2.93}

 98%|█████████▊| 615/630 [09:56<00:14,  1.06it/s]
 98%|█████████▊| 616/630 [09:57<00:12,  1.08it/s]
                                                 
{'loss': 0.5042, 'grad_norm': 2.4306705394610986, 'learning_rate': 4.9099836333878885e-08, 'epoch': 2.93}

 98%|█████████▊| 616/630 [09:57<00:12,  1.08it/s]
 98%|█████████▊| 617/630 [09:58<00:11,  1.09it/s]
                                                 
{'loss': 0.5558, 'grad_norm': 2.0371057053432318, 'learning_rate': 4.582651391162029e-08, 'epoch': 2.94}

 98%|█████████▊| 617/630 [09:58<00:11,  1.09it/s]
 98%|█████████▊| 618/630 [09:59<00:10,  1.09it/s]
                                                 
{'loss': 0.5195, 'grad_norm': 1.8597618510886609, 'learning_rate': 4.25531914893617e-08, 'epoch': 2.94}

 98%|█████████▊| 618/630 [09:59<00:10,  1.09it/s]
 98%|█████████▊| 619/630 [10:00<00:09,  1.10it/s]
                                                 
{'loss': 0.476, 'grad_norm': 2.6139022845273905, 'learning_rate': 3.927986906710311e-08, 'epoch': 2.95}

 98%|█████████▊| 619/630 [10:00<00:09,  1.10it/s]
 98%|█████████▊| 620/630 [10:01<00:09,  1.10it/s]
                                                 
{'loss': 0.4621, 'grad_norm': 2.2921475398522, 'learning_rate': 3.6006546644844515e-08, 'epoch': 2.95}

 98%|█████████▊| 620/630 [10:01<00:09,  1.10it/s]
 99%|█████████▊| 621/630 [10:01<00:08,  1.10it/s]
                                                 
{'loss': 0.5365, 'grad_norm': 1.8132243626045033, 'learning_rate': 3.273322422258592e-08, 'epoch': 2.96}

 99%|█████████▊| 621/630 [10:01<00:08,  1.10it/s]
 99%|█████████▊| 622/630 [10:02<00:07,  1.11it/s]
                                                 
{'loss': 0.4268, 'grad_norm': 2.063810450457391, 'learning_rate': 2.945990180032733e-08, 'epoch': 2.96}

 99%|█████████▊| 622/630 [10:02<00:07,  1.11it/s]
 99%|█████████▉| 623/630 [10:03<00:06,  1.11it/s]
                                                 
{'loss': 0.5084, 'grad_norm': 2.0678829613578777, 'learning_rate': 2.618657937806874e-08, 'epoch': 2.97}

 99%|█████████▉| 623/630 [10:03<00:06,  1.11it/s]
 99%|█████████▉| 624/630 [10:04<00:05,  1.11it/s]
                                                 
{'loss': 0.4696, 'grad_norm': 2.1409778411445672, 'learning_rate': 2.2913256955810146e-08, 'epoch': 2.97}

 99%|█████████▉| 624/630 [10:04<00:05,  1.11it/s]
 99%|█████████▉| 625/630 [10:05<00:04,  1.12it/s]
                                                 
{'loss': 0.4605, 'grad_norm': 3.542908796366315, 'learning_rate': 1.9639934533551554e-08, 'epoch': 2.98}

 99%|█████████▉| 625/630 [10:05<00:04,  1.12it/s]
 99%|█████████▉| 626/630 [10:06<00:03,  1.11it/s]
                                                 
{'loss': 0.4176, 'grad_norm': 1.8709885011717253, 'learning_rate': 1.636661211129296e-08, 'epoch': 2.98}

 99%|█████████▉| 626/630 [10:06<00:03,  1.11it/s]
100%|█████████▉| 627/630 [10:07<00:02,  1.12it/s]
                                                 
{'loss': 0.6154, 'grad_norm': 2.3576733089050763, 'learning_rate': 1.309328968903437e-08, 'epoch': 2.99}

100%|█████████▉| 627/630 [10:07<00:02,  1.12it/s]
100%|█████████▉| 628/630 [10:08<00:01,  1.12it/s]
                                                 
{'loss': 0.4561, 'grad_norm': 1.812135203813665, 'learning_rate': 9.819967266775777e-09, 'epoch': 2.99}

100%|█████████▉| 628/630 [10:08<00:01,  1.12it/s]
100%|█████████▉| 629/630 [10:09<00:00,  1.12it/s]
                                                 
{'loss': 0.5139, 'grad_norm': 2.5532519990493046, 'learning_rate': 6.546644844517185e-09, 'epoch': 3.0}

100%|█████████▉| 629/630 [10:09<00:00,  1.12it/s]
100%|██████████| 630/630 [10:10<00:00,  1.12it/s]
                                                 
{'loss': 0.4375, 'grad_norm': 1.8563128650048482, 'learning_rate': 3.2733224222585923e-09, 'epoch': 3.0}

100%|██████████| 630/630 [10:10<00:00,  1.12it/s]
                                                 
{'train_runtime': 610.0152, 'train_samples_per_second': 82.252, 'train_steps_per_second': 1.033, 'train_loss': 0.5957004694238541, 'epoch': 3.0}

100%|██████████| 630/630 [10:10<00:00,  1.12it/s]
100%|██████████| 630/630 [10:10<00:00,  1.03it/s]
[2024-07-12 05:39:06,013] [INFO] [launch.py:351:main] Process 2177941 exits successfully.
[2024-07-12 05:39:06,013] [INFO] [launch.py:351:main] Process 2177938 exits successfully.
[2024-07-12 05:39:06,014] [INFO] [launch.py:351:main] Process 2177943 exits successfully.
[2024-07-12 05:39:07,014] [INFO] [launch.py:351:main] Process 2177939 exits successfully.
[2024-07-12 05:39:07,015] [INFO] [launch.py:351:main] Process 2177940 exits successfully.
[2024-07-12 05:39:07,015] [INFO] [launch.py:351:main] Process 2177942 exits successfully.
[2024-07-12 05:39:07,015] [INFO] [launch.py:351:main] Process 2177944 exits successfully.
[2024-07-12 05:39:15,016] [INFO] [launch.py:351:main] Process 2177937 exits successfully.
